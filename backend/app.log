2025-06-11 03:23:39,923 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:23:39,930 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:24:08,784 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-11 03:24:08,785 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-11 03:24:10,698 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:24:10,707 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:24:21,760 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-11 03:24:21,760 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-11 03:24:24,129 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:24:24,141 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:24:43,296 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-11 03:24:55,653 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.102:5000
2025-06-11 03:24:55,656 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-11 03:24:55,677 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:24:56,911 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:24:56,918 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:25:07,403 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:25:07] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 03:25:07,462 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:25:07] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 03:25:07,550 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:25:07] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 03:27:06,932 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\util.py', reloading
2025-06-11 03:27:06,945 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py', reloading
2025-06-11 03:27:07,090 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_response.py', reloading
2025-06-11 03:27:07,139 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\object_classes.py', reloading
2025-06-11 03:27:07,143 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\engine.py', reloading
2025-06-11 03:27:07,154 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\__init__.py', reloading
2025-06-11 03:27:07,170 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\listable_api_resource.py', reloading
2025-06-11 03:27:07,175 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\updateable_api_resource.py', reloading
2025-06-11 03:27:07,178 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\experimental\\completion_config.py', reloading
2025-06-11 03:27:07,186 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\createable_api_resource.py', reloading
2025-06-11 03:27:07,189 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\deletable_api_resource.py', reloading
2025-06-11 03:27:07,193 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\file.py', reloading
2025-06-11 03:27:07,204 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\fine_tune.py', reloading
2025-06-11 03:27:07,209 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\nested_resource_class_methods.py', reloading
2025-06-11 03:27:07,224 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\model.py', reloading
2025-06-11 03:27:07,226 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\deployment.py', reloading
2025-06-11 03:27:08,072 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:27:10,164 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:27:10,180 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:28:49,300 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-11 03:28:49,300 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\__init__.py', reloading
2025-06-11 03:28:49,310 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-11 03:28:49,310 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\scaffold.py', reloading
2025-06-11 03:28:49,500 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:28:51,817 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:28:51,869 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:29:33,541 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 03:29:33,884 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:33:21,486 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.102:5000
2025-06-11 03:33:21,488 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-11 03:33:21,514 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:33:22,906 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:33:22,914 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:33:27,534 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:33:27] "GET / HTTP/1.1" 200 -
2025-06-11 03:33:27,588 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:33:27] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 03:33:27,675 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:33:27] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 03:33:28,050 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:33:28] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 03:37:04,852 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:37:04] "GET / HTTP/1.1" 200 -
2025-06-11 03:37:04,909 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:37:04] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 03:37:04,924 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:37:04] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 03:37:05,205 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:37:05] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-06-11 03:37:05,405 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:37:05] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 03:39:09,176 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:09] "GET / HTTP/1.1" 200 -
2025-06-11 03:39:09,234 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:09] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 03:39:09,292 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:09] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 03:39:09,629 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:09] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 03:39:17,597 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_033917.wav, taille: 80339 bytes
2025-06-11 03:39:17,755 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\aifc.py', reloading
2025-06-11 03:39:17,785 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\chunk.py', reloading
2025-06-11 03:39:17,836 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\shaim\\\\AppData\\\\Local\\\\Temp\\\\tmpzllr0b9e.wav'"}
2025-06-11 03:39:17,844 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:39:18,397 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:39:19,986 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:39:19,991 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:39:22,904 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_033922.wav, taille: 80339 bytes
2025-06-11 03:39:23,019 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\shaim\\\\AppData\\\\Local\\\\Temp\\\\tmpe2ugycgj.wav'"}
2025-06-11 03:39:23,022 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:39:27,584 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_033927.wav, taille: 80339 bytes
2025-06-11 03:39:27,703 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\shaim\\\\AppData\\\\Local\\\\Temp\\\\tmpdtbvlhtu.wav'"}
2025-06-11 03:39:27,706 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:39:32,902 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_033932.wav, taille: 80339 bytes
2025-06-11 03:39:33,000 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\shaim\\\\AppData\\\\Local\\\\Temp\\\\tmpm1prico4.wav'"}
2025-06-11 03:39:33,009 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:39:33,014 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_033933.wav, taille: 1127 bytes
2025-06-11 03:39:33,100 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\shaim\\\\AppData\\\\Local\\\\Temp\\\\tmpge2g6d9r.wav'"}
2025-06-11 03:39:33,104 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:39:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:40:34,098 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-11 03:40:35,154 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:40:36,934 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:40:36,946 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:43:43,011 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.102:5000
2025-06-11 03:43:43,012 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-11 03:43:43,037 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:43:44,744 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:43:44,752 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:43:48,674 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:43:48] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 03:43:48,746 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:43:48] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 03:43:48,803 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:43:48] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 03:43:49,137 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:43:49] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 03:44:01,144 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034401.wav, taille: 963653 bytes
2025-06-11 03:44:02,874 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034401.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:06,444 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034406.wav, taille: 963653 bytes
2025-06-11 03:44:06,554 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034406.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:08,121 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:44:08,135 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0644\\u0627 \\u0628\\u0627\\u0633 \\u0643\\u064a\\u0641 \\u062f\\u0627\\u064a\\u0631 \\u0644\\u0627 \\u0628\\u0627\\u0633 \\u0639\\u0644\\u064a\\u0643 \\u0635\\"\\n            Fran\\u00e7ais: \\"salam lab\\u00e8s\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:44:08,145 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:44:08,164 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:44:09,664 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:44:09,674 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=568 request_id=req_ec4a160fe24d0ec2825516bc27d642e9 response_code=200
2025-06-11 03:44:09,852 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-11 03:44:10,047 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:10,185 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:44:12,438 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:44:12,488 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:44:12,655 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034412.wav, taille: 963653 bytes
2025-06-11 03:44:12,736 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034412.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:15,153 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:44:15,155 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:16,144 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034416.wav, taille: 961726 bytes
2025-06-11 03:44:16,244 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034416.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:18,543 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:44:18,545 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:21,452 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034421.wav, taille: 961726 bytes
2025-06-11 03:44:21,544 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034421.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:26,144 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034426.wav, taille: 961726 bytes
2025-06-11 03:44:26,241 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034426.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:26,360 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:44:26,360 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0641\\u064a \\u0638\\u0647\\u0631\\u064a \\u0641\\u064a \\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"mets la musique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:44:26,365 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:44:26,372 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:44:28,435 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:44:28,435 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=639 request_id=req_b7f732b0421fcce0e920b90158efc27d response_code=200
2025-06-11 03:44:28,574 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:29,376 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:44:29,377 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0627\\u0632\\u0627\\u0644 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0628\\u0632\\u0627\\u0641\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:44:29,379 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:44:29,382 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:44:30,584 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:44:30,584 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=552 request_id=req_437885a1d0f66c933688466bdc6c6ce0 response_code=200
2025-06-11 03:44:30,719 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:31,470 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034431.wav, taille: 963653 bytes
2025-06-11 03:44:31,569 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034431.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:34,066 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:44:34,070 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:36,135 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034436.wav, taille: 963653 bytes
2025-06-11 03:44:36,221 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034436.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:38,449 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:44:38,451 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:41,445 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034441.wav, taille: 963653 bytes
2025-06-11 03:44:41,524 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034441.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:46,149 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034446.wav, taille: 963653 bytes
2025-06-11 03:44:46,289 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034446.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:48,424 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:44:48,430 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062f\\u0631\\u0633 \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u062d\\u064a\\u062f \\u0627\\u0644\\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u0648\\u0644\\u0643\\u0646\\"\\n            Fran\\u00e7ais: \\"intersection\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:44:48,439 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:44:48,443 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:44:50,405 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:44:50,405 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062f\\u064a\\u0627\\u0644\\u064a \\u062e\\u0627\\u064a\\u0628\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:44:50,405 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:44:50,417 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:44:51,205 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:44:51,214 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1036 request_id=req_6d78eb83ec3599660eb9102d20c6058b response_code=200
2025-06-11 03:44:51,350 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:51,471 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034451.wav, taille: 959799 bytes
2025-06-11 03:44:51,552 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034451.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:51,699 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:44:51,701 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=354 request_id=req_42d4826bd732fc9b6e0d24b126bee3db response_code=200
2025-06-11 03:44:51,838 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:56,465 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034456.wav, taille: 963653 bytes
2025-06-11 03:44:56,559 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034456.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:44:56,865 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:44:56,865 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:44:59,282 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:44:59,285 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:44:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:45:01,448 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034501.wav, taille: 961726 bytes
2025-06-11 03:45:01,537 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034501.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:45:06,148 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034506.wav, taille: 963653 bytes
2025-06-11 03:45:06,228 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034506.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:45:09,335 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:45:09,344 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"alors arr\\u00eate\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:45:09,344 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:45:09,350 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:45:11,455 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034511.wav, taille: 963653 bytes
2025-06-11 03:45:11,545 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034511.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:45:11,689 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:45:11,690 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=464 request_id=req_7404493f9873072182097e7e4dd16881 response_code=200
2025-06-11 03:45:11,799 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'alors arrête', 'fused': 'Alors arrête.'}
2025-06-11 03:45:11,804 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:45:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:45:11,916 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:45:11,916 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0647\\u0630\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0631\\u0628\\u0639 \\u0627\\u064a\\u0627\\u0645 \\u062e\\u062f\\u064a\\u062a\\u0647\\u0627\\"\\n            Fran\\u00e7ais: \\"dessin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:45:11,916 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:45:11,924 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:45:15,754 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:45:15,754 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=637 request_id=req_5a3ca49be03cc4dc8d16c8a3a695eb45 response_code=200
2025-06-11 03:45:15,903 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:45:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:45:16,454 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034516.wav, taille: 965580 bytes
2025-06-11 03:45:16,578 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034516.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:45:18,884 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:45:18,884 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0628\\u0627\\u0642\\u064a \\u0639\\u0646\\u062f\\u064a \\u0635\\u062f\\u0627\\u0639\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:45:18,884 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:45:18,884 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:45:20,825 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:45:20,831 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=466 request_id=req_fa63ac8fd8b1d9950e8cb728e3b0758b response_code=200
2025-06-11 03:45:20,962 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:45:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:45:21,164 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:45:21,167 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:45:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:45:21,447 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034521.wav, taille: 961726 bytes
2025-06-11 03:45:21,529 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034521.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:45:26,454 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034526.wav, taille: 963653 bytes
2025-06-11 03:45:26,539 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034526.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:45:30,454 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:45:30,454 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:45:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:45:31,445 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034531.wav, taille: 963653 bytes
2025-06-11 03:45:31,543 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034531.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:45:31,709 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:45:31,715 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:45:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:45:32,627 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034532.wav, taille: 227539 bytes
2025-06-11 03:45:32,866 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034532.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:45:34,864 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:45:34,864 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:45:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:45:36,680 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:45:36,680 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:45:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:46:06,035 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_034606.wav, taille: 171656 bytes
2025-06-11 03:46:06,119 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_034606.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:46:07,045 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:46:07,047 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:46:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:53:29,475 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 03:53:29,497 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 03:53:29,904 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:53:31,315 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:53:31,367 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:53:32,995 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 03:53:32,996 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 03:53:33,964 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 03:53:35,611 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 03:53:35,618 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 03:53:57,390 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035357.wav, taille: 965580 bytes
2025-06-11 03:53:57,495 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035357.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:01,715 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:54:01,715 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0644\\u0627 \\u0628\\u0627\\u0633 \\u0643\\u064a\\u0641 \\u062f\\u0627\\u064a\\u0631\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:54:01,715 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:54:01,715 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:54:02,076 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035402.wav, taille: 963653 bytes
2025-06-11 03:54:02,154 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035402.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:02,595 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:54:02,595 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=428 request_id=req_eff422c3b562d6b901b583d659cc1733 response_code=200
2025-06-11 03:54:02,745 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:54:07,365 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035407.wav, taille: 963653 bytes
2025-06-11 03:54:07,457 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035407.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:09,390 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:54:09,391 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u064a\\u062b \\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0641\\u064a \\u0643\\u0628\\u0634\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:54:09,392 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:54:09,397 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:54:09,525 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:54:09,528 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:54:10,425 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:54:10,425 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=649 request_id=req_712b7f345e54d2819ac9fe0ae2c1f7a3 response_code=200
2025-06-11 03:54:10,569 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:54:12,376 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035412.wav, taille: 963653 bytes
2025-06-11 03:54:12,465 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035412.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:12,795 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035412.wav, taille: 142751 bytes
2025-06-11 03:54:12,886 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035412.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:15,524 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:54:15,526 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:54:15,541 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:54:15,545 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:54:35,720 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:35] "GET / HTTP/1.1" 200 -
2025-06-11 03:54:35,781 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:35] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 03:54:35,831 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:35] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 03:54:36,223 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:36] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 03:54:43,823 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035443.wav, taille: 965580 bytes
2025-06-11 03:54:43,918 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035443.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:49,133 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035449.wav, taille: 963653 bytes
2025-06-11 03:54:49,216 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035449.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:49,313 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:54:49,316 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0644\\u0627 \\u0628\\u0627\\u0633 \\u0639\\u0644\\u064a\\u0643\\"\\n            Fran\\u00e7ais: \\"salam aleykoum je veux une\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:54:49,326 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:54:49,331 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:54:53,673 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:54:53,673 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:54:54,133 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035454.wav, taille: 963653 bytes
2025-06-11 03:54:54,215 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035454.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:58,113 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:54:58,113 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=8046 request_id=req_a34249df19348c3d288a6231b8090e16 response_code=200
2025-06-11 03:54:58,239 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:54:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:54:59,137 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035459.wav, taille: 961726 bytes
2025-06-11 03:54:59,228 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035459.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:54:59,607 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:54:59,607 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"autobus canap\\u00e9 des m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:54:59,613 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:54:59,613 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:55:02,706 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:55:02,713 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=643 request_id=req_49abe51c564eccdd10ad724abf773aa9 response_code=200
2025-06-11 03:55:02,821 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'autobus canapé des médicaments', 'fused': "Dans l'autobus, il y avait un canapé plein de médicaments."}
2025-06-11 03:55:02,823 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:55:03,362 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:55:03,362 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0643\\u0627\\u0646\\u0628\\u0642\\u0649 \\u0641\\u064a\\u0627 \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642\\"\\n            Fran\\u00e7ais: \\"mets-moi alimentaire\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:55:03,362 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:55:03,362 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:55:04,112 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035504.wav, taille: 963653 bytes
2025-06-11 03:55:04,204 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035504.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:55:04,472 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:55:04,474 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=654 request_id=req_6508992c8f5afa87f3c55e2107d9362d response_code=200
2025-06-11 03:55:04,599 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:55:07,923 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:55:07,923 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0627 \\u0639\\u0631\\u0641\\u062a\\u0634 \\u0634\\u0646\\u0648 \\u0639\\u0646\\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"au Maroc\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:55:07,923 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:55:07,923 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:55:09,123 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035509.wav, taille: 961726 bytes
2025-06-11 03:55:09,197 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:55:09,206 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=485 request_id=req_c036ff4b77873045bce488a0df0a1cc6 response_code=200
2025-06-11 03:55:09,214 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035509.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:55:09,347 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:55:14,113 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035514.wav, taille: 965580 bytes
2025-06-11 03:55:14,198 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035514.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:55:15,789 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:55:15,793 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:55:18,233 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035518.wav, taille: 792150 bytes
2025-06-11 03:55:18,316 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035518.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:55:18,770 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:55:18,774 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:55:19,238 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:19] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 03:55:19,565 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:55:19,565 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Salam aleykoum, je veux une consultation, j\'esp\\u00e8re que vous allez bien.\\"\\nSegment 3: \\"Dans l\'autobus, il y avait un canap\\u00e9 plein de m\\u00e9dicaments.\\"\\nSegment 4: \\"Je ressens une br\\u00fblure, mais donne-moi quelque chose \\u00e0 manger.\\"\\nSegment 5: \\"Je ne sais pas ce que j\'ai au Maroc.\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements)\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. CORRIGE les erreurs grammaticales et syntaxiques\\n            6. MAINTIENS le style d\'une consultation m\\u00e9dicale professionnelle\\n            7. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:55:19,567 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:55:19,570 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:55:22,501 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:55:22,503 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:55:24,496 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:55:24,497 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4022 request_id=req_0b4534bbf4ebcd88daa93f48fe5bab46 response_code=200
2025-06-11 03:55:24,499 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:24] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 03:55:24,903 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:24] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 03:55:25,183 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:55:25,183 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Salam aleykoum, je veux une consultation, j\'esp\\u00e8re que vous allez bien.\\"\\nSegment 3: \\"Dans l\'autobus, il y avait un canap\\u00e9 plein de m\\u00e9dicaments.\\"\\nSegment 4: \\"Je ressens une br\\u00fblure, mais donne-moi quelque chose \\u00e0 manger.\\"\\nSegment 5: \\"Je ne sais pas ce que j\'ai au Maroc.\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements)\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. CORRIGE les erreurs grammaticales et syntaxiques\\n            6. MAINTIENS le style d\'une consultation m\\u00e9dicale professionnelle\\n            7. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:55:25,183 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:55:25,183 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:55:28,293 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:55:28,293 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2686 request_id=req_583d7df7d1709a58028fbc85541e3248 response_code=200
2025-06-11 03:55:28,298 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:28] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 03:55:53,342 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:53] "OPTIONS /api/transcription/save HTTP/1.1" 200 -
2025-06-11 03:55:53,653 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:55:53] "POST /api/transcription/save HTTP/1.1" 200 -
2025-06-11 03:56:33,653 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:56:33] "OPTIONS /api/report/generate HTTP/1.1" 200 -
2025-06-11 03:56:33,973 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:56:33,973 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un m\\u00e9decin expert en r\\u00e9daction de comptes rendus m\\u00e9dicaux.\\n            G\\u00e9n\\u00e8re un compte rendu m\\u00e9dical structur\\u00e9 et professionnel \\u00e0 partir de cette transcription d\'une consultation:\\n            \\n            Transcription: \\"bonjour je suis chaimma de 20ans et j\'ai des brulure d\'estomac je suis diabetique\\"\\n            \\n            Structure obligatoire:\\n            - MOTIF DE CONSULTATION\\n            - ANT\\u00c9C\\u00c9DENTS\\n            - EXAMEN CLINIQUE\\n            - DIAGNOSTIC\\n            - PLAN DE TRAITEMENT\\n            - RECOMMANDATIONS\\n            \\n            INSTRUCTIONS IMPORTANTES:\\n            1. MAINTIENS uniquement les informations pr\\u00e9sentes dans la transcription\\n            2. N\'INVENTE aucune information m\\u00e9dicale\\n            3. Si une section ne peut pas \\u00eatre remplie faute d\'informations, indique \\"Non pr\\u00e9cis\\u00e9 dans la consultation\\"\\n            4. UTILISE un fran\\u00e7ais m\\u00e9dical professionnel et adapt\\u00e9\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:56:33,973 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:56:33,973 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:56:39,343 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:56:39,343 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4791 request_id=req_e44247e0dddd97f42ae277a420e91454 response_code=200
2025-06-11 03:56:39,343 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:56:39] "POST /api/report/generate HTTP/1.1" 200 -
2025-06-11 03:57:01,631 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035701.wav, taille: 965580 bytes
2025-06-11 03:57:01,726 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035701.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:06,533 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:57:06,533 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Mohamed 3 jours\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:57:06,543 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:57:06,543 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:57:06,923 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035706.wav, taille: 961726 bytes
2025-06-11 03:57:07,018 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035706.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:07,817 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:57:07,817 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=831 request_id=req_6f6c8e28f6e650133ce007664117aaa3 response_code=200
2025-06-11 03:57:07,959 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:11,466 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:57:11,466 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0634\\u064a\\u0641 \\u0638\\u0647\\u0631\\u064a \\u0627\\u0646\\u0627 \\u062c\\u0648 \\u0633\\u0648\\u064a\\u062a\\u064a\\u0643\\"\\n            Fran\\u00e7ais: \\"Anna je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:57:11,466 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:57:11,473 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:57:11,943 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035711.wav, taille: 961726 bytes
2025-06-11 03:57:12,030 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035711.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:12,685 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:57:12,693 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=839 request_id=req_5bc6b368a0345e00f6fc781e917611ae response_code=200
2025-06-11 03:57:12,817 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:16,934 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035716.wav, taille: 963653 bytes
2025-06-11 03:57:17,033 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035716.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:19,849 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:57:19,850 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0646\\u0627\\u062e\\u0630 \\u0627\\u0644\\u062f\\u0648\\u0627\\u0621 \\u062f\\u064a\\u0627\\u0644 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u062f\\u064a\\u0627\\u0628\\u064a\\u062a\\u064a\\u0643\\"\\n            Fran\\u00e7ais: \\"ok Naruto Diallo diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:57:19,850 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:57:19,853 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:57:21,116 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:57:21,116 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=828 request_id=req_98af6687508ec135b4206cbfec34e337 response_code=200
2025-06-11 03:57:21,253 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:21,943 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035721.wav, taille: 963653 bytes
2025-06-11 03:57:22,048 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035721.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:22,557 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:57:22,557 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"po\\u00e8me\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:57:22,559 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:57:22,562 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:57:24,873 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:57:24,873 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=752 request_id=req_ee0f04dc33ed3e37c2cf8d503e1cede0 response_code=200
2025-06-11 03:57:24,983 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'poème', 'fused': 'Je ne peux pas fusionner les transcriptions car la transcription en Darija est vide.'}
2025-06-11 03:57:24,983 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:26,732 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:57:26,734 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0647\\u0630\\u0647 \\u062f\\u0631\\u062a \\u0627\\u0648\\u0628\\u064a\\u0631\\u0627\\u0633\\u064a\\"\\n            Fran\\u00e7ais: \\"op\\u00e9ration\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:57:26,734 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:57:26,738 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:57:26,930 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035726.wav, taille: 963653 bytes
2025-06-11 03:57:27,011 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035726.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:27,551 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:57:27,554 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=418 request_id=req_02a0f68c900497c7fcc0caa0a53ded8c response_code=200
2025-06-11 03:57:27,691 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:30,923 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:57:30,923 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"7\\"\\n            Fran\\u00e7ais: \\"Safari\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:57:30,923 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:57:30,923 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:57:31,753 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:57:31,753 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=464 request_id=req_1596a9ec9307bbdd4c047f4f725d0563 response_code=200
2025-06-11 03:57:31,865 - app - DEBUG - Résultat transcription: {'darija': '7', 'french': 'Safari', 'fused': 'Nous avons prévu un safari pour le 7.'}
2025-06-11 03:57:31,866 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:31,935 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035731.wav, taille: 963653 bytes
2025-06-11 03:57:32,021 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035731.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:34,293 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:57:34,296 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:36,947 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035736.wav, taille: 961726 bytes
2025-06-11 03:57:37,047 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035736.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:40,048 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:57:40,048 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:41,614 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035741.wav, taille: 963653 bytes
2025-06-11 03:57:41,708 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035741.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:45,697 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:57:45,697 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0639\\u064a\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:57:45,697 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:57:45,703 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:57:46,833 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:57:46,833 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=397 request_id=req_5dd31406a76f1b860729a4a24dd91d06 response_code=200
2025-06-11 03:57:46,933 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035746.wav, taille: 963653 bytes
2025-06-11 03:57:46,993 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:47,054 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035746.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:51,943 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035751.wav, taille: 963653 bytes
2025-06-11 03:57:52,028 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035751.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:52,996 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:57:52,996 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:54,288 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035754.wav, taille: 452998 bytes
2025-06-11 03:57:54,367 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035754.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:57:54,498 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:57:54,502 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:55,274 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:55] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 03:57:55,595 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:57:55,596 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum Mohamed, \\u00e7a fait 3 jours.\\"\\nSegment 2: \\"Anna, je suis diab\\u00e9tique et j\'ai mal au dos.\\"\\nSegment 3: \\"Je prends le m\\u00e9dicament pour mon diab\\u00e8te, ok Naruto Diallo diab\\u00e9tique.\\"\\nSegment 4: \\"Je ne peux pas fusionner les transcriptions car la transcription en Darija est vide.\\"\\nSegment 5: \\"J\'ai subi une op\\u00e9ration.\\"\\nSegment 6: \\"Nous avons pr\\u00e9vu un safari pour le 7.\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 9: \\"\\"\\u00c0 vos soins.\\"\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 11: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements)\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. CORRIGE les erreurs grammaticales et syntaxiques\\n            6. MAINTIENS le style d\'une consultation m\\u00e9dicale professionnelle\\n            7. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:57:55,600 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:57:55,605 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:57:55,695 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:57:55,696 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:57:58,883 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:57:58,883 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2890 request_id=req_5b9b28c0d6c3f6e5d4067dff7e685fab response_code=200
2025-06-11 03:57:58,892 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:57:58] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 03:58:32,544 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035832.wav, taille: 119627 bytes
2025-06-11 03:58:32,629 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035832.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:58:33,613 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:58:33,613 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:58:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:58:40,453 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035840.wav, taille: 967507 bytes
2025-06-11 03:58:40,542 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035840.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:58:45,753 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035845.wav, taille: 963653 bytes
2025-06-11 03:58:45,838 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035845.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:58:50,194 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:58:50,195 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:58:50,196 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:58:50,201 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:58:50,759 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035850.wav, taille: 963653 bytes
2025-06-11 03:58:50,837 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035850.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:58:52,812 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:58:52,812 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"o\\u00f9 aller je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:58:52,812 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:58:52,812 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:58:52,928 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:58:52,928 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=917 request_id=req_3ec2110b5151ffdd6a99ce5bab8abc65 response_code=200
2025-06-11 03:58:53,061 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:58:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:58:53,711 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:58:53,715 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=408 request_id=req_175c9dc0aee7b43ffc4f018de7b01945 response_code=200
2025-06-11 03:58:53,823 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'où aller je suis diabétique', 'fused': 'Où aller, je suis diabétique.'}
2025-06-11 03:58:53,827 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:58:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:58:55,753 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035855.wav, taille: 961726 bytes
2025-06-11 03:58:55,846 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035855.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:58:59,095 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:58:59,095 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"un compliment alimentaire\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:58:59,099 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:58:59,099 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:58:59,863 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:58:59,863 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=397 request_id=req_a0d677e8f50d76a41600de0cfdadb941 response_code=200
2025-06-11 03:58:59,978 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'un compliment alimentaire', 'fused': "Il s'agit d'un complément alimentaire."}
2025-06-11 03:58:59,978 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:58:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:59:00,760 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035900.wav, taille: 961726 bytes
2025-06-11 03:59:00,848 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035900.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:03,083 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:59:03,083 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u062d\\u064a\\u062a \\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a\\"\\n            Fran\\u00e7ais: \\"aucun texte \\u00e0 media\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:59:03,088 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:59:03,088 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:59:04,228 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:59:04,228 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=642 request_id=req_12acb5a07904aef8d740a3eaf0bc58ae response_code=200
2025-06-11 03:59:04,371 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:59:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:59:05,732 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035905.wav, taille: 963653 bytes
2025-06-11 03:59:05,833 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035905.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:06,613 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:59:06,613 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u064a\\u062f \\u0627\\u0644\\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u0628\\u0642\\u0627\\u0648\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:59:06,613 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:59:06,613 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:59:07,633 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:59:07,633 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=496 request_id=req_4ca50f08a1e174d0ea10db04b78d8e26 response_code=200
2025-06-11 03:59:07,756 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:59:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:59:10,763 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035910.wav, taille: 965580 bytes
2025-06-11 03:59:10,848 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035910.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:13,263 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:59:13,263 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:59:13,263 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:59:13,263 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:59:14,333 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:59:14,333 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=577 request_id=req_91966d21d62d4036f3add5faaca3ca8f response_code=200
2025-06-11 03:59:14,461 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:59:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:59:15,753 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035915.wav, taille: 963653 bytes
2025-06-11 03:59:15,833 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035915.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:17,636 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:59:17,636 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062c\\u0631\\u062d\\u0647 \\u062f\\u064a\\u0627\\u0644 \\u0627\\u0644\\u0639\\u0645\\u0644\\u064a\\u0647 \\u0628\\u0627\\u0644\\u062f\\u0645\\"\\n            Fran\\u00e7ais: \\"Adil Rami\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:59:17,636 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:59:17,636 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:59:19,909 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:59:19,909 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=796 request_id=req_e996bf7cc77b2b4ef745bfe8181c8d33 response_code=200
2025-06-11 03:59:20,054 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:59:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:59:20,353 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:59:20,353 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062c\\u0648\\u062c\\u0644\\"\\n            Fran\\u00e7ais: \\"nettoyage\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:59:20,353 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:59:20,363 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 03:59:20,742 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035920.wav, taille: 963653 bytes
2025-06-11 03:59:20,844 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035920.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:21,277 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 03:59:21,283 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=530 request_id=req_8ae8e770e9b18c305b664ca0e48fe1a2 response_code=200
2025-06-11 03:59:21,416 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:59:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:59:25,762 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035925.wav, taille: 961726 bytes
2025-06-11 03:59:25,933 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035925.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:27,694 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:59:27,694 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:59:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:59:30,733 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035930.wav, taille: 963653 bytes
2025-06-11 03:59:30,817 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035930.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:35,766 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035935.wav, taille: 963653 bytes
2025-06-11 03:59:35,857 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035935.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:40,753 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035940.wav, taille: 963653 bytes
2025-06-11 03:59:40,846 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035940.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:45,754 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035945.wav, taille: 963653 bytes
2025-06-11 03:59:45,755 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 03:59:45,757 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:59:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 03:59:45,857 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035945.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:48,763 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_035948.wav, taille: 578253 bytes
2025-06-11 03:59:48,844 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_035948.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 03:59:49,753 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 03:59:49] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 03:59:50,075 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 03:59:50,075 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans.\\"\\nSegment 2: \\"O\\u00f9 aller, je suis diab\\u00e9tique.\\"\\nSegment 3: \\"Il s\'agit d\'un compl\\u00e9ment alimentaire.\\"\\nSegment 4: \\"J\'ai subi une op\\u00e9ration car j\'avais une pierre dans le rein.\\"\\nSegment 5: \\"Les pierres dans les reins ont \\u00e9t\\u00e9 enlev\\u00e9es.\\"\\nSegment 6: \\"\\"Et ensuite, apr\\u00e8s une semaine.\\"\\"\\nSegment 7: \\"Adil Rami a une plaie de l\'op\\u00e9ration qui saigne.\\"\\nSegment 8: \\"Nous avons effectu\\u00e9 un nettoyage complet aujourd\'hui.\\"\\nSegment 9: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements)\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. CORRIGE les erreurs grammaticales et syntaxiques\\n            6. MAINTIENS le style d\'une consultation m\\u00e9dicale professionnelle\\n            7. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 03:59:50,075 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 03:59:50,075 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 04:00:04,738 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 04:00:04,743 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=12107 request_id=req_ee3347d5c68db2a9674bb63c1c737289 response_code=200
2025-06-11 04:00:04,751 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:00:04] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 04:00:09,655 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 04:00:09,658 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:00:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 04:00:12,258 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 04:00:12,260 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:00:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 04:00:13,924 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 04:00:13,927 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:00:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 04:00:21,138 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 04:00:21,141 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:00:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 04:00:30,788 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 04:00:30,790 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:00:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 04:07:23,563 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:07:23] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 04:07:23,662 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:07:23] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 04:07:23,688 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:07:23] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:07:24,189 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:07:24] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:07:32,253 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-11 04:07:32,270 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\os.py', reloading
2025-06-11 04:07:32,298 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\audio.py', reloading
2025-06-11 04:07:33,082 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\exceptions.py', reloading
2025-06-11 04:07:33,082 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\typing.py', reloading
2025-06-11 04:07:33,082 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\shutil.py', reloading
2025-06-11 04:07:33,082 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\wave.py', reloading
2025-06-11 04:07:33,276 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 04:07:35,406 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 04:07:35,417 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 04:07:37,316 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:07:37] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 04:07:37,364 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:07:37] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 04:07:37,369 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:07:37] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:07:37,756 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:07:37] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:09:04,084 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:09:04] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 04:09:04,144 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:09:04] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:09:04,166 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:09:04] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 04:09:04,515 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:09:04] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:09:22,521 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:09:22] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 04:09:22,572 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:09:22] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:09:22,599 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:09:22] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 04:09:22,623 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:09:22] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:10:09,225 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:10:09] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 04:10:09,293 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:10:09] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:10:09,310 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:10:09] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 04:10:09,665 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:10:09] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:11:15,875 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:11:15] "GET / HTTP/1.1" 200 -
2025-06-11 04:11:15,954 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:11:15] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 04:11:15,958 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:11:15] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:11:16,312 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:11:16] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:11:40,701 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:11:40] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 04:11:40,759 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:11:40] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 04:11:40,762 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:11:40] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:11:40,815 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:11:40] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:12:05,553 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:05] "GET / HTTP/1.1" 200 -
2025-06-11 04:12:05,617 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:05] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 04:12:05,618 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:05] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:12:05,969 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:05] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:12:18,458 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:18] "GET / HTTP/1.1" 200 -
2025-06-11 04:12:18,498 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:18] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 04:12:18,501 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:18] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:12:18,546 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:18] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:12:37,723 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:37] "GET / HTTP/1.1" 200 -
2025-06-11 04:12:37,779 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:37] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 04:12:37,794 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:37] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:12:38,156 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:12:38] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 04:13:20,813 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:13:20] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 04:13:20,880 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:13:20] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 04:13:20,908 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:13:20] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 04:13:20,936 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 04:13:20] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 13:05:12,336 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.102:5000
2025-06-11 13:05:12,337 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-11 13:05:12,369 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 13:05:13,852 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 13:05:13,862 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 13:05:54,795 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:05:54] "GET / HTTP/1.1" 200 -
2025-06-11 13:05:54,868 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:05:54] "GET /assets/style.css HTTP/1.1" 200 -
2025-06-11 13:05:54,928 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:05:54] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 13:05:55,195 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:05:55] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-06-11 13:05:55,346 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:05:55] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 13:06:35,276 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:06:35] "GET / HTTP/1.1" 200 -
2025-06-11 13:06:35,346 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:06:35] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 13:06:35,354 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:06:35] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-11 13:06:35,396 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:06:35] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 13:06:47,034 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130647.wav, taille: 975215 bytes
2025-06-11 13:06:47,737 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130647.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:06:51,714 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130651.wav, taille: 963653 bytes
2025-06-11 13:06:51,815 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130651.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:06:52,552 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:06:52,553 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0644\\u0645\\u0647\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u062c\\u064a\\u062a \\u062d\\u064a\\u062a \\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Mohamed\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:06:52,564 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:06:52,564 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:06:55,578 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:06:55,584 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1862 request_id=req_1a547e30a6fb464ac15a7eb0d996ea5c response_code=200
2025-06-11 13:06:55,704 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-11 13:06:55,744 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-11 13:06:55,745 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-11 13:06:55,747 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:06:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:06:55,748 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-11 13:06:55,751 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-11 13:06:55,760 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-11 13:06:56,008 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 13:06:57,517 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 13:06:57,530 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 13:06:57,648 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130657.wav, taille: 963653 bytes
2025-06-11 13:06:57,649 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130657.wav, taille: 963653 bytes
2025-06-11 13:06:57,768 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130657.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:06:57,773 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130657.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:02,025 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130701.wav, taille: 963653 bytes
2025-06-11 13:07:02,125 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130701.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:03,017 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:03,020 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:05,284 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:07:05,284 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0646\\u062f\\u064a \\u0635\\u062f\\u0627\\u0639 \\u0628\\u0632\\u0627\\u0641\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:07:05,295 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:07:05,299 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:07:05,674 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:05,674 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:06,459 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:07:06,460 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=460 request_id=req_337b84c7fd54c48626e367f88832d536 response_code=200
2025-06-11 13:07:06,602 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:07,034 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130707.wav, taille: 963653 bytes
2025-06-11 13:07:07,124 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130707.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:09,934 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:09,934 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:11,708 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130711.wav, taille: 963653 bytes
2025-06-11 13:07:11,808 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130711.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:14,016 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:14,018 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:17,034 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130717.wav, taille: 961726 bytes
2025-06-11 13:07:17,134 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130717.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:21,709 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130721.wav, taille: 963653 bytes
2025-06-11 13:07:21,796 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130721.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:21,830 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:21,836 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:24,908 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:24,908 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:27,014 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130726.wav, taille: 963653 bytes
2025-06-11 13:07:27,109 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130726.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:29,891 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:29,896 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:31,715 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130731.wav, taille: 963653 bytes
2025-06-11 13:07:31,809 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130731.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:34,704 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_130734.wav, taille: 514662 bytes
2025-06-11 13:07:34,789 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_130734.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:07:35,694 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:35] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:07:35,857 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:35,860 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:36,007 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:07:36,007 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum Mohamed, je suis venu parce que j\'avais une br\\u00fblure.\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"J\'ai tr\\u00e8s mal \\u00e0 la t\\u00eate.\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 9: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements)\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. MAINTIENS le style d\'une consultation m\\u00e9dicale professionnelle\\n            6. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:07:36,007 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:07:36,014 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:07:36,165 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:07:36,168 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:07:38,478 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:07:38,478 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1547 request_id=req_98050e854fe0145c2a8daad5bf351069 response_code=200
2025-06-11 13:07:38,478 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:07:38] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:09:04,080 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:09:04] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 13:09:04,144 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:09:04] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 13:09:04,209 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:09:04] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 13:09:04,603 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:09:04] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 13:10:26,259 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131026.wav, taille: 963653 bytes
2025-06-11 13:10:26,368 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131026.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:10:30,944 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131030.wav, taille: 963653 bytes
2025-06-11 13:10:31,032 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131030.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:10:32,000 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:10:32,000 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0644\\u0645\\u0647\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0634\\u0631\\u064a\\u062a \\u062d\\u064a\\u062a \\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Mohamed\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:10:32,004 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:10:32,004 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:10:33,584 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:10:33,594 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=810 request_id=req_1370212a20c39cb07e9f914057dcfb8e response_code=200
2025-06-11 13:10:33,721 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:10:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:10:35,604 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:10:35,604 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0641\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0641\\u064a \\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:10:35,604 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:10:35,614 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:10:36,254 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131036.wav, taille: 963653 bytes
2025-06-11 13:10:36,352 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131036.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:10:36,989 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:10:36,994 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=911 request_id=req_a8821f7d1098a01962018c298e38a57a response_code=200
2025-06-11 13:10:37,135 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:10:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:10:40,424 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:10:40,424 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u062d\\u064a\\u062a\\u0627\\u0634 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:10:40,424 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:10:40,432 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:10:41,244 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131041.wav, taille: 963653 bytes
2025-06-11 13:10:41,335 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131041.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:10:41,934 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:10:41,934 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1123 request_id=req_cb32815b87f828b3397b52d255dc6e3b response_code=200
2025-06-11 13:10:42,063 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:10:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:10:46,264 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131046.wav, taille: 961726 bytes
2025-06-11 13:10:46,359 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131046.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:10:46,471 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:10:46,472 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"mets je suis diab\\u00e9tique des gens ou\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:10:46,475 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:10:46,475 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:10:48,314 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:10:48,315 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1405 request_id=req_a560b31f6cc1046c3cc767611010be38 response_code=200
2025-06-11 13:10:48,424 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'mets je suis diabétique des gens ou', 'fused': 'Je suis diabétique, mets des gens ou.'}
2025-06-11 13:10:48,424 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:10:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:10:50,734 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:10:50,734 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0639\\u0645\\"\\n            Fran\\u00e7ais: \\"faible la slam\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:10:50,734 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:10:50,744 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:10:51,254 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131051.wav, taille: 961726 bytes
2025-06-11 13:10:51,356 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131051.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:10:52,099 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:10:52,099 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=940 request_id=req_b08c3a7ec02f9232e7725d508b762d56 response_code=200
2025-06-11 13:10:52,221 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:10:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:10:54,082 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:10:54,084 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:10:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:10:56,254 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131056.wav, taille: 963653 bytes
2025-06-11 13:10:56,349 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131056.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:10:59,720 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:10:59,723 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:10:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:01,761 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131101.wav, taille: 1115886 bytes
2025-06-11 13:11:01,953 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131101.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:07,053 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131107.wav, taille: 963653 bytes
2025-06-11 13:11:07,124 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131107.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:12,054 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131112.wav, taille: 963653 bytes
2025-06-11 13:11:12,137 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131112.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:13,822 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:11:13,825 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:17,054 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131117.wav, taille: 965580 bytes
2025-06-11 13:11:17,131 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131117.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:18,038 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:11:18,044 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:19,446 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:11:19,446 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:19,729 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:11:19,729 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:21,282 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131121.wav, taille: 807566 bytes
2025-06-11 13:11:21,453 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131121.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:24,854 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131124.wav, taille: 751683 bytes
2025-06-11 13:11:24,955 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131124.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:25,087 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:11:25,090 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:26,144 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:26] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:11:26,454 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:11:26,454 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements)\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. MAINTIENS le style d\'une consultation m\\u00e9dicale professionnelle\\n            6. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:11:26,454 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:11:26,454 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:11:32,828 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131132.wav, taille: 963653 bytes
2025-06-11 13:11:33,039 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131132.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:33,547 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:11:33,547 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3100 request_id=req_2eea94e2d215957d7fd1747b06fc0b15 response_code=200
2025-06-11 13:11:33,554 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:33] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:11:37,824 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131137.wav, taille: 963653 bytes
2025-06-11 13:11:37,906 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131137.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:41,142 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:11:41,147 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:41,474 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:11:41,474 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u062c\\u064a\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Fran\\u00e7ais: \\"salam aleykoum \\u00e0 la kendji semaine\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:11:41,474 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:11:41,479 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:11:42,824 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131142.wav, taille: 965580 bytes
2025-06-11 13:11:42,919 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131142.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:43,163 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:11:43,165 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=783 request_id=req_5ed0bca49ae085c32b24231cfa486e98 response_code=200
2025-06-11 13:11:43,300 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:44,254 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131144.wav, taille: 275714 bytes
2025-06-11 13:11:44,342 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131144.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:11:45,245 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:45] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:11:45,594 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:45] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:11:55,879 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:11:55,880 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u062f\\u0631\\u0633 \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0638\\u0647\\u0631\\u064a\\"\\n            Fran\\u00e7ais: \\"poudre Amalia Paris\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:11:55,884 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:11:55,887 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:11:57,009 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:11:57,014 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:11:57,244 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:11:57,244 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=681 request_id=req_e89799da850f32e1f7dedef6b4598aa2 response_code=200
2025-06-11 13:11:57,375 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:11:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:12:02,204 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:12:02,204 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"si maman\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:12:02,204 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:12:02,204 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:12:03,372 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:12:03,375 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=782 request_id=req_581b1352902cf5fbda7e9b89835a4a27 response_code=200
2025-06-11 13:12:03,518 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:12:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:13:33,179 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:13:33] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 13:13:33,243 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:13:33] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 13:13:33,303 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:13:33] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 13:13:33,708 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:13:33] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 13:13:40,056 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131340.wav, taille: 963653 bytes
2025-06-11 13:13:40,140 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131340.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:13:44,139 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:13:44,139 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0644\\u0627 \\u0628\\u0627\\u0633 \\u0627\\u0644\\u0645\\u0647\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\"\\n            Fran\\u00e7ais: \\"salam lab\\u00e8s\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:13:44,144 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:13:44,144 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:13:45,364 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131345.wav, taille: 963653 bytes
2025-06-11 13:13:45,447 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131345.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:13:45,493 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:13:45,495 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=929 request_id=req_0047389d664592a1ca67971b916fbe49 response_code=200
2025-06-11 13:13:45,622 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:13:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:13:50,364 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131350.wav, taille: 963653 bytes
2025-06-11 13:13:50,452 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131350.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:13:50,844 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:13:50,844 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u064a\\u062a \\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0641\\u064a \\u0638\\u0647\\u0631\\u064a \\u0641\\u064a \\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:13:50,844 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:13:50,844 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:13:52,907 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:13:52,914 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1212 request_id=req_5691a258be1bf2cabb51d2e4a62ad4a0 response_code=200
2025-06-11 13:13:53,044 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:13:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:13:55,364 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131355.wav, taille: 963653 bytes
2025-06-11 13:13:55,445 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131355.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:13:55,486 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:13:55,495 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062f\\u0631\\u0633 \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a\\"\\n            Fran\\u00e7ais: \\"aucune adresse\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:13:55,499 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:13:55,501 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:13:57,413 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:13:57,434 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1346 request_id=req_7b4ac468ab7a146901491f96010e0038 response_code=200
2025-06-11 13:13:57,571 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:13:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:13:58,170 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:13:58,176 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:13:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:14:00,357 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131400.wav, taille: 963653 bytes
2025-06-11 13:14:00,440 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131400.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:14:03,141 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:14:03,143 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:14:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:14:05,056 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131405.wav, taille: 959799 bytes
2025-06-11 13:14:05,148 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131405.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:14:06,924 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131406.wav, taille: 304619 bytes
2025-06-11 13:14:07,007 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131406.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:14:07,820 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:14:07,822 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:14:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:14:07,934 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:14:07] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:14:08,255 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:14:08,255 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam, \\u00e7a va? L\'important est que j\'\\u00e9tais l\\u00e0.\\"\\"\\nSegment 2: \\"Parce que j\'avais des br\\u00fblures dans le dos et dans l\'estomac.\\"\\nSegment 3: \\"Il a subi une op\\u00e9ration sur les reins et il n\'y a aucune adresse mentionn\\u00e9e.\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements)\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. MAINTIENS le style d\'une consultation m\\u00e9dicale professionnelle\\n            6. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:14:08,255 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:14:08,255 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:14:08,272 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:14:08,275 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:14:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:14:12,724 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:14:12,724 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4094 request_id=req_be5abdc7d094e2c0dd5b1cc83c48b203 response_code=200
2025-06-11 13:14:12,724 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:14:12] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:14:47,124 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 13:14:47,134 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 13:14:47,140 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 13:14:47,494 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 13:14:49,279 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 13:14:49,295 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 13:14:51,724 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 13:14:51,729 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 13:14:52,699 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 13:14:54,438 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 13:14:54,448 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 13:15:16,674 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 13:15:16,674 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-11 13:15:17,777 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 13:15:19,490 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 13:15:19,495 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 13:19:01,002 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131900.wav, taille: 738194 bytes
2025-06-11 13:19:01,116 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131900.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:19:04,909 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:19:04,910 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:19:04,912 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:19:04,915 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:19:05,802 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:19:05,806 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=493 request_id=req_83c1012ceb25fa04f4f1dbed20e86903 response_code=200
2025-06-11 13:19:06,133 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:19:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:19:47,027 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131947.wav, taille: 967507 bytes
2025-06-11 13:19:47,130 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131947.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:19:50,224 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_131950.wav, taille: 555129 bytes
2025-06-11 13:19:50,314 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_131950.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:19:52,434 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:19:52,435 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Anakin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:19:52,436 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:19:52,440 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:19:53,763 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:19:53,765 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=738 request_id=req_87951fe0e4884af7e750bbdc6a9526d7 response_code=200
2025-06-11 13:19:53,896 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:19:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:19:53,968 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:19:53,969 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:19:53,975 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:19:53,978 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:19:55,397 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:19:55,398 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=878 request_id=req_2dd5aec385f9e2e65fbffe7312225b82 response_code=200
2025-06-11 13:19:55,548 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:19:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:15,537 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132015.wav, taille: 967507 bytes
2025-06-11 13:20:15,636 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132015.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:20,196 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132020.wav, taille: 963653 bytes
2025-06-11 13:20:20,285 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132020.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:20,379 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:20:20,381 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Anas\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:20:20,384 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:20:20,394 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:20:22,702 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:20:22,706 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=730 request_id=req_74519cee10c183716c8ef4e5f5ca1f2c response_code=200
2025-06-11 13:20:22,835 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:25,082 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:20:25,083 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u062c\\u064a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a\\"\\n            Fran\\u00e7ais: \\"aucun GSM Manhattan\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:20:25,085 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:20:25,089 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:20:25,506 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132025.wav, taille: 961726 bytes
2025-06-11 13:20:25,606 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132025.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:27,902 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:20:27,906 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1937 request_id=req_e1bc0561665c507b768cd02aaa5d4b2e response_code=200
2025-06-11 13:20:28,048 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:30,521 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132030.wav, taille: 963653 bytes
2025-06-11 13:20:30,646 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132030.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:32,176 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:20:32,177 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0643\\u0627\\u0646 \\u062a\\u0632\\u0627\\u062f \\u0639\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:20:32,180 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:20:32,183 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:20:34,135 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:20:34,138 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1531 request_id=req_036f0cd19dfa8dc97d958cdbf6c11fab response_code=200
2025-06-11 13:20:34,282 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:35,497 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:20:35,498 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Auger 7\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:20:35,500 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:20:35,506 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:20:35,517 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132035.wav, taille: 965580 bytes
2025-06-11 13:20:35,645 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132035.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:36,391 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:20:36,398 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=458 request_id=req_f974f1b854f4f08ede1842ce77be8771 response_code=200
2025-06-11 13:20:36,510 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Auger 7', 'fused': 'Auger 7.'}
2025-06-11 13:20:36,514 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:39,757 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:20:39,758 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0646\\u062d\\u0633 \\u0628\\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0628\\u0632\\u0627\\u0641 \\u062e\\u062f\\u064a\\u062a 5\\"\\n            Fran\\u00e7ais: \\"Compl\\u00e9ment aliment\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:20:39,760 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:20:39,764 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:20:40,509 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132040.wav, taille: 963653 bytes
2025-06-11 13:20:40,621 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132040.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:42,048 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:20:42,050 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1558 request_id=req_231f922ed0bd8d23a6b8f96ec41d12b1 response_code=200
2025-06-11 13:20:42,180 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:44,960 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:20:44,961 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0627 \\u0648\\u0627\\u0644\\"\\n            Fran\\u00e7ais: \\"mais all\\u00f4\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:20:44,962 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:20:44,965 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:20:45,528 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132045.wav, taille: 963653 bytes
2025-06-11 13:20:45,638 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132045.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:46,059 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:20:46,068 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=689 request_id=req_574fa037980cc02d757ef9aefa8bfca1 response_code=200
2025-06-11 13:20:46,214 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:50,512 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132050.wav, taille: 963653 bytes
2025-06-11 13:20:50,604 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132050.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:51,013 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:20:51,016 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:53,472 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:20:53,475 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:54,883 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132054.wav, taille: 842252 bytes
2025-06-11 13:20:54,975 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132054.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:20:55,566 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:55] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:20:55,878 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:20:55,879 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans.\\"\\nSegment 2: \\"La semaine pass\\u00e9e, j\'ai subi une op\\u00e9ration sur les reins et je n\'ai aucun GSM Manhattan.\\"\\nSegment 3: \\"J\'ai des calculs r\\u00e9naux et apr\\u00e8s une semaine, la douleur a augment\\u00e9.\\"\\nSegment 4: \\"Auger 7.\\"\\nSegment 5: \\"Je ressens une forte sensation de br\\u00fblure, j\'ai pris 5 compl\\u00e9ments alimentaires.\\"\\nSegment 6: \\"Mais all\\u00f4.\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            6. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:20:55,881 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:20:55,883 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:20:57,922 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:20:57,925 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:20:59,405 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:20:59,420 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3090 request_id=req_a2c86aaf5f5ba02e3afe332f038bceec response_code=200
2025-06-11 13:20:59,424 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:20:59] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:22:50,188 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132250.wav, taille: 963653 bytes
2025-06-11 13:22:50,294 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132250.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:22:54,885 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132254.wav, taille: 963653 bytes
2025-06-11 13:22:54,984 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132254.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:22:55,327 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:22:55,328 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:22:55,335 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:22:55,340 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:22:58,727 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:22:58,730 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2156 request_id=req_eafa98ae4a0454b17c0f44b2471fd5bc response_code=200
2025-06-11 13:22:58,863 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:22:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:00,184 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132300.wav, taille: 961726 bytes
2025-06-11 13:23:00,290 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132300.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:00,881 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:23:00,882 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u062c\\u064a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u062d\\u064a\\u0627\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:23:00,884 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:23:00,886 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:23:04,247 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:23:04,249 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1860 request_id=req_e79879c8c3d33178c9db671f54fe4d6e response_code=200
2025-06-11 13:23:04,376 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:05,198 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132305.wav, taille: 965580 bytes
2025-06-11 13:23:05,304 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132305.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:09,710 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:23:09,711 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0646\\u0635\\u0628\\u062a \\u0639\\u0644\\u064a \\u0627\\u0644\\u062d\\u0627\\u0644\\"\\n            Fran\\u00e7ais: \\"omelette Siemens\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:23:09,717 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:23:09,723 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:23:10,182 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132310.wav, taille: 963653 bytes
2025-06-11 13:23:10,302 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132310.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:15,289 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132315.wav, taille: 961726 bytes
2025-06-11 13:23:15,366 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:23:15,371 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u064a\\u062f\\u064a\\u0643\\u0627\\u0645\\u0648\\u0646 \\u0628\\u0627\\u0634 \\u064a\\u0646\\u0642\\u0635\\u0648\\u0627 \\u0639\\u0644\\u064a\\u0647 \\u0645\\u0627 \\u0648\\u0627\\u0644\\u0648\\"\\n            Fran\\u00e7ais: \\"des m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:23:15,374 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:23:15,378 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:23:15,465 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:23:15,477 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=965 request_id=req_1f1e358818a83e6965dc08234a75e6eb response_code=200
2025-06-11 13:23:15,489 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:23:15,507 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u0633\\u0628 \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0627\\u0634\\u0648\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0644\\u064a\\u0644 \\u0648\\u0641\\u064a \\u0627\\u0644\\u0646\\u0647\\u0627\\u0631\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:23:15,520 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:23:15,526 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:23:15,570 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132315.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:15,725 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:17,633 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:23:17,635 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1643 request_id=req_ab5ad7ad65fdb71603682491affea161 response_code=200
2025-06-11 13:23:17,715 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:23:17,718 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=838 request_id=req_5529d2ec61c37266f4bdad99942c5771 response_code=200
2025-06-11 13:23:17,760 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:17,853 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:20,189 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132320.wav, taille: 963653 bytes
2025-06-11 13:23:20,296 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132320.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:21,693 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:23:21,697 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:24,540 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:23:24,542 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:25,189 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132325.wav, taille: 961726 bytes
2025-06-11 13:23:25,338 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132325.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:29,870 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132329.wav, taille: 961726 bytes
2025-06-11 13:23:29,971 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132329.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:33,172 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:23:33,175 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:35,183 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132335.wav, taille: 963653 bytes
2025-06-11 13:23:35,293 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132335.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:37,268 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132337.wav, taille: 400969 bytes
2025-06-11 13:23:37,358 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132337.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:23:38,713 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:23:38,718 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:44,436 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:23:44,438 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:46,860 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:23:46,864 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:23:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:23:58,538 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132358.wav, taille: 967507 bytes
2025-06-11 13:23:58,641 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132358.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:03,219 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132403.wav, taille: 963653 bytes
2025-06-11 13:24:03,302 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:24:03,303 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:24:03,307 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:24:03,313 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:24:03,339 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132403.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:05,905 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:24:05,907 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1526 request_id=req_b6e4f3ab30d4ff04f21c7f0a56bae6ab response_code=200
2025-06-11 13:24:06,041 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:07,175 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:24:07,175 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"aucune cette semaine\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:24:07,178 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:24:07,181 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:24:08,228 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:24:08,231 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=636 request_id=req_690e30a29b62911e47d8f8c4efcf6e76 response_code=200
2025-06-11 13:24:08,345 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'aucune cette semaine', 'fused': 'Aucune consultation médicale cette semaine.'}
2025-06-11 13:24:08,349 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:08,518 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132408.wav, taille: 963653 bytes
2025-06-11 13:24:08,618 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132408.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:13,247 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:24:13,247 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0628\\u0642\\u0649 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u062a\\u0632\\u0627\\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:24:13,249 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:24:13,251 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:24:13,528 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132413.wav, taille: 961726 bytes
2025-06-11 13:24:13,636 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132413.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:14,715 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:24:14,725 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1033 request_id=req_a8ce82a1a717e15a89622da40d03a25f response_code=200
2025-06-11 13:24:14,862 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:17,747 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:24:17,747 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0627\\u0644 \\u0628\\u0632\\u0627\\u0641 \\u0648\\u062e\\"\\n            Fran\\u00e7ais: \\"four\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:24:17,749 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:24:17,752 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:24:18,519 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132418.wav, taille: 963653 bytes
2025-06-11 13:24:18,624 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132418.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:18,978 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:24:18,981 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=820 request_id=req_90f22c2e48931021e817e0dfa146a6f2 response_code=200
2025-06-11 13:24:19,123 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:23,527 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132423.wav, taille: 963653 bytes
2025-06-11 13:24:23,632 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132423.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:25,763 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:24:25,764 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0648\\u0627\\u0644\\u0648\\"\\n            Fran\\u00e7ais: \\"comment tu t\'es compl\\u00e9ment alimentaire\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:24:25,765 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:24:25,767 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:24:28,520 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132428.wav, taille: 963653 bytes
2025-06-11 13:24:28,617 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132428.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:28,926 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:24:28,929 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1458 request_id=req_1f41e28017cb5c6cabb47d7d1f5ef768 response_code=200
2025-06-11 13:24:29,057 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:33,294 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:24:33,295 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:24:33,311 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:24:33,313 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:24:33,528 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132433.wav, taille: 965580 bytes
2025-06-11 13:24:33,633 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132433.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:34,497 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:24:34,500 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=776 request_id=req_29301568c071f02d704fb532788ce0ac response_code=200
2025-06-11 13:24:34,648 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:38,540 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132438.wav, taille: 961726 bytes
2025-06-11 13:24:38,659 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132438.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:40,789 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:24:40,793 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:41,822 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:24:41,831 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:43,529 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132443.wav, taille: 963653 bytes
2025-06-11 13:24:43,645 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132443.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:46,835 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:24:46,837 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:48,535 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132448.wav, taille: 961726 bytes
2025-06-11 13:24:48,652 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132448.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:51,800 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:24:51,804 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:53,539 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132453.wav, taille: 963653 bytes
2025-06-11 13:24:53,652 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132453.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:24:55,694 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:24:55,698 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:56,317 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:24:56,321 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:24:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:24:58,528 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132458.wav, taille: 963653 bytes
2025-06-11 13:24:58,633 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132458.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:25:02,478 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_132502.wav, taille: 821055 bytes
2025-06-11 13:25:02,605 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_132502.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:25:02,654 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:25:02,659 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:25:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:25:03,773 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:25:03] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:25:04,085 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:25:04,086 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans.\\"\\nSegment 2: \\"Aucune consultation m\\u00e9dicale cette semaine.\\"\\nSegment 3: \\"\\"J\'ai toujours des br\\u00fblures m\\u00eame apr\\u00e8s une semaine.\\"\\"\\nSegment 4: \\"La situation est tr\\u00e8s difficile.\\"\\nSegment 5: \\"Comment tu prends ton compl\\u00e9ment alimentaire, mais sans aucun effet?\\"\\nSegment 6: \\"Je ressens une sensation de br\\u00fblure.\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 9: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 11: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 12: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 13: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            6. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:25:04,090 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:25:04,094 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:25:07,134 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:25:07,137 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:25:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:25:15,776 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:25:15,778 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6394 request_id=req_9e55abd6ec1bb494d56847290d6f6381 response_code=200
2025-06-11 13:25:15,779 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:25:15] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:25:50,752 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:25:50] "OPTIONS /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:25:51,016 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:25:51,017 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un m\\u00e9decin expert en r\\u00e9daction de comptes rendus m\\u00e9dicaux.\\n            G\\u00e9n\\u00e8re un compte rendu m\\u00e9dical structur\\u00e9 et professionnel \\u00e0 partir de cette transcription d\'une consultation:\\n            \\n            Transcription: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans. Je ressens une sensation de br\\u00fblure persistante m\\u00eame apr\\u00e8s une semaine, ce qui rend la situation tr\\u00e8s difficile. J\'ai \\u00e9galement pris un compl\\u00e9ment alimentaire comme recommand\\u00e9, mais cela n\'a eu aucun effet sur mes sympt\\u00f4mes.\\"\\n            \\n            Structure obligatoire:\\n            - MOTIF DE CONSULTATION\\n            - ANT\\u00c9C\\u00c9DENTS\\n            - EXAMEN CLINIQUE\\n            - DIAGNOSTIC\\n            - PLAN DE TRAITEMENT\\n            - RECOMMANDATIONS\\n            \\n            INSTRUCTIONS IMPORTANTES:\\n            1. MAINTIENS uniquement les informations pr\\u00e9sentes dans la transcription\\n            2. N\'INVENTE aucune information m\\u00e9dicale\\n            3. Si une section ne peut pas \\u00eatre remplie faute d\'informations, indique \\"Non pr\\u00e9cis\\u00e9 dans la consultation\\"\\n            4. UTILISE un fran\\u00e7ais m\\u00e9dical professionnel et adapt\\u00e9\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:25:51,021 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:25:51,025 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:25:59,559 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:25:59,561 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=8120 request_id=req_413802e4a73d9b7b65716f8d0f2bda5f response_code=200
2025-06-11 13:25:59,563 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:25:59] "POST /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:30:08,851 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133008.wav, taille: 965580 bytes
2025-06-11 13:30:08,962 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133008.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:13,467 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:30:13,468 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam Ana Chaima indication\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:30:13,470 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:30:13,472 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:30:13,560 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133013.wav, taille: 965580 bytes
2025-06-11 13:30:13,671 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133013.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:15,722 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:30:15,724 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=685 request_id=req_1def4fd4d3dd827b1de8d37eda58036e response_code=200
2025-06-11 13:30:15,853 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:18,074 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:30:18,075 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Michael Jackson\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:30:18,081 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:30:18,085 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:30:18,858 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133018.wav, taille: 959799 bytes
2025-06-11 13:30:18,968 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133018.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:19,113 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:30:19,117 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=366 request_id=req_6a95e82a7ca4335882d9193f410e6d7d response_code=200
2025-06-11 13:30:19,221 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Michael Jackson', 'fused': 'Michael Jackson.'}
2025-06-11 13:30:19,223 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:23,831 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:30:23,831 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"je suis diab\\u00e9tique des gens ou scanner\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:30:23,834 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:30:23,839 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:30:23,874 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133023.wav, taille: 965580 bytes
2025-06-11 13:30:24,055 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133023.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:25,606 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:30:25,608 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=725 request_id=req_f3a5fe0ead43705ea3f8def3acb01eec response_code=200
2025-06-11 13:30:25,715 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'je suis diabétique des gens ou scanner', 'fused': 'Je suis diabétique, des gens ou scanner.'}
2025-06-11 13:30:25,717 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:28,864 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133028.wav, taille: 963653 bytes
2025-06-11 13:30:28,966 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133028.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:30,213 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:30:30,214 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0645\\u0646 \\u0628\\u0639\\u062f \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0639\\u0645\\u0644\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:30:30,216 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:30:30,218 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:30:32,096 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:30:32,098 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1179 request_id=req_3dcd2eb4b023b716168b2f882db68bf5 response_code=200
2025-06-11 13:30:32,232 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:32,596 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:30:32,599 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:33,856 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133033.wav, taille: 961726 bytes
2025-06-11 13:30:33,972 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133033.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:38,079 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:30:38,083 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:38,554 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133038.wav, taille: 963653 bytes
2025-06-11 13:30:38,656 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133038.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:41,331 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:30:41,334 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:43,870 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133043.wav, taille: 963653 bytes
2025-06-11 13:30:43,985 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133043.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:46,827 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:30:46,831 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:48,541 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133048.wav, taille: 961726 bytes
2025-06-11 13:30:48,649 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133048.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:51,182 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:30:51,184 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:30:53,563 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133053.wav, taille: 905843 bytes
2025-06-11 13:30:53,651 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133053.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:30:55,977 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:30:55,980 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:30:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:18,281 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133118.wav, taille: 967507 bytes
2025-06-11 13:31:18,388 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133118.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:31:23,668 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133123.wav, taille: 963653 bytes
2025-06-11 13:31:23,973 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133123.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:31:24,200 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:31:24,201 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:31:24,203 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:31:24,207 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:31:25,700 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:31:25,703 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=998 request_id=req_9259e217c9edbcd87a099a6ec50ec630 response_code=200
2025-06-11 13:31:25,833 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:31:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:28,587 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133128.wav, taille: 963653 bytes
2025-06-11 13:31:28,680 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133128.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:31:30,062 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:31:30,062 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0641\\u064a \\u062d\\u064a\\u062f\\u062a \\u0627\\u0644\\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\"\\n            Fran\\u00e7ais: \\"mets-moi du Slimane adresse\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:31:30,064 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:31:30,067 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:31:32,054 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:31:32,057 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1275 request_id=req_fd34cb40017674a8c88c5dae9ea6468f response_code=200
2025-06-11 13:31:32,191 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:31:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:33,042 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:31:33,043 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0627\\u0646\\u0627\\"\\n            Fran\\u00e7ais: \\"Anna je suis diab\\u00e9tique des gens\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:31:33,044 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:31:33,047 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:31:33,591 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133133.wav, taille: 963653 bytes
2025-06-11 13:31:33,694 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133133.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:31:34,933 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:31:34,995 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=680 request_id=req_7ca6fb1a28d65c4f96b6b35238ff60aa response_code=200
2025-06-11 13:31:35,124 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:31:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:38,593 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133138.wav, taille: 963653 bytes
2025-06-11 13:31:38,706 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133138.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:31:40,282 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:31:40,285 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:31:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:42,460 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:31:42,460 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0628\\u0632\\u0627\\u0641 \\u0628\\u0642\\u0649 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:31:42,466 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:31:42,469 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:31:43,593 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133143.wav, taille: 963653 bytes
2025-06-11 13:31:43,701 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133143.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:31:47,861 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:31:47,863 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1211 request_id=req_7a0da74bb1f33aa01155dfdd68c8cf51 response_code=200
2025-06-11 13:31:47,985 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:31:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:48,583 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133148.wav, taille: 961726 bytes
2025-06-11 13:31:48,729 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133148.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:31:49,490 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:31:49,491 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Costa\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:31:49,492 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:31:49,495 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:31:50,331 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:31:50,335 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=323 request_id=req_da39ddbb5c53e61c5301cd024a956381 response_code=200
2025-06-11 13:31:50,453 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Costa', 'fused': 'Costa.'}
2025-06-11 13:31:50,457 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:31:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:51,500 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:31:51,503 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:31:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:53,585 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133153.wav, taille: 961726 bytes
2025-06-11 13:31:53,692 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133153.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:31:56,535 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:31:56,540 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:31:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:31:58,282 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133158.wav, taille: 965580 bytes
2025-06-11 13:31:58,387 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133158.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:32:01,608 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:32:01,612 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:32:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:32:01,967 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133201.wav, taille: 651479 bytes
2025-06-11 13:32:02,053 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133201.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:32:02,640 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:32:02] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:32:02,962 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:32:02,962 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans.\\"\\nSegment 2: \\"\\"Cette semaine, j\'ai subi une op\\u00e9ration pour enlever une pierre dans la clavicule, adresse-moi du Slimane.\\"\\"\\nSegment 3: \\"Anna, je suis diab\\u00e9tique.\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Je ressens une forte br\\u00fblure.\\"\\nSegment 6: \\"Costa.\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 9: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            6. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:32:02,965 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:32:02,967 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:32:04,715 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:32:04,719 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:32:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:32:06,229 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:32:06,230 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2758 request_id=req_8610dd0dbf309907a150324643c23b35 response_code=200
2025-06-11 13:32:06,232 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:32:06] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:32:21,833 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:32:21] "OPTIONS /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:32:22,081 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:32:22,082 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un m\\u00e9decin expert en r\\u00e9daction de comptes rendus m\\u00e9dicaux.\\n            G\\u00e9n\\u00e8re un compte rendu m\\u00e9dical structur\\u00e9 et professionnel \\u00e0 partir de cette transcription d\'une consultation:\\n            \\n            Transcription: \\"Salam aleykoum, je suis Chaima, \\u00e2g\\u00e9e de 23 ans. R\\u00e9cemment, j\'ai subi une op\\u00e9ration pour enlever une pierre dans la clavicule. En plus de cela, je suis diab\\u00e9tique. Actuellement, je ressens une forte br\\u00fblure, ce qui n\\u00e9cessite une attention m\\u00e9dicale appropri\\u00e9e.\\"\\n            \\n            Structure obligatoire:\\n            - MOTIF DE CONSULTATION\\n            - ANT\\u00c9C\\u00c9DENTS\\n            - EXAMEN CLINIQUE\\n            - DIAGNOSTIC\\n            - PLAN DE TRAITEMENT\\n            - RECOMMANDATIONS\\n            \\n            INSTRUCTIONS IMPORTANTES:\\n            1. MAINTIENS uniquement les informations pr\\u00e9sentes dans la transcription\\n            2. N\'INVENTE aucune information m\\u00e9dicale\\n            3. Si une section ne peut pas \\u00eatre remplie faute d\'informations, indique \\"Non pr\\u00e9cis\\u00e9 dans la consultation\\"\\n            4. UTILISE un fran\\u00e7ais m\\u00e9dical professionnel et adapt\\u00e9\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:32:22,084 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:32:22,086 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:32:24,295 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:32:24,338 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un m\\u00e9decin expert en r\\u00e9daction de comptes rendus m\\u00e9dicaux.\\n            G\\u00e9n\\u00e8re un compte rendu m\\u00e9dical structur\\u00e9 et professionnel \\u00e0 partir de cette transcription d\'une consultation:\\n            \\n            Transcription: \\"Salam aleykoum, je suis Chaima, \\u00e2g\\u00e9e de 23 ans. R\\u00e9cemment, j\'ai subi une op\\u00e9ration pour enlever une pierre dans la clavicule. En plus de cela, je suis diab\\u00e9tique. Actuellement, je ressens une forte br\\u00fblure, ce qui n\\u00e9cessite une attention m\\u00e9dicale appropri\\u00e9e.\\"\\n            \\n            Structure obligatoire:\\n            - MOTIF DE CONSULTATION\\n            - ANT\\u00c9C\\u00c9DENTS\\n            - EXAMEN CLINIQUE\\n            - DIAGNOSTIC\\n            - PLAN DE TRAITEMENT\\n            - RECOMMANDATIONS\\n            \\n            INSTRUCTIONS IMPORTANTES:\\n            1. MAINTIENS uniquement les informations pr\\u00e9sentes dans la transcription\\n            2. N\'INVENTE aucune information m\\u00e9dicale\\n            3. Si une section ne peut pas \\u00eatre remplie faute d\'informations, indique \\"Non pr\\u00e9cis\\u00e9 dans la consultation\\"\\n            4. UTILISE un fran\\u00e7ais m\\u00e9dical professionnel et adapt\\u00e9\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:32:24,354 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:32:24,362 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:32:36,030 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:32:36,032 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=11229 request_id=req_3efd732937e2b5b4de6f93f09a2039c9 response_code=200
2025-06-11 13:32:36,033 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:32:36] "POST /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:32:43,293 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:32:43,295 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=20837 request_id=req_73b8d45352c53ee88edfec0fae27eb70 response_code=200
2025-06-11 13:32:43,296 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:32:43] "POST /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:33:57,957 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133357.wav, taille: 969434 bytes
2025-06-11 13:33:58,060 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133357.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:02,650 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133402.wav, taille: 963653 bytes
2025-06-11 13:34:02,755 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133402.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:03,210 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:34:03,210 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima lundi\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:34:03,212 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:34:03,215 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:34:07,584 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:34:07,586 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1153 request_id=req_d397ad5a9a0bbc3da5477b8fe01321c7 response_code=200
2025-06-11 13:34:07,696 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:34:07,711 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"l\\u00e0 je suis diab\\u00e9tique doit\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:34:07,713 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:07,715 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:34:07,751 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:34:07,956 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133407.wav, taille: 961726 bytes
2025-06-11 13:34:08,043 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133407.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:09,059 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:34:09,061 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=938 request_id=req_bb757b5dee44d8cff883a4797274e0b4 response_code=200
2025-06-11 13:34:09,172 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'là je suis diabétique doit', 'fused': 'Je suis diabétique.'}
2025-06-11 13:34:09,174 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:12,486 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:34:12,487 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u062d\\u064a\\u0627\\u0647 \\u0627\\u0644\\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:34:12,488 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:34:12,490 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:34:12,953 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133412.wav, taille: 963653 bytes
2025-06-11 13:34:13,056 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133412.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:14,048 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:34:14,051 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1178 request_id=req_fd8feca55b1865e0f35f80cfeaf5de4c response_code=200
2025-06-11 13:34:14,231 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:17,954 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133417.wav, taille: 963653 bytes
2025-06-11 13:34:18,044 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133417.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:18,591 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:34:18,591 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u062a\\u0633\\u062f \\u0639\\u0644\\u064a \\u0627\\u0644\\u0635\\u062f\\u0627\\u0639 \\u0628\\u0632\\u0627\\u0641\\"\\n            Fran\\u00e7ais: \\"snapchat\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:34:18,594 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:34:18,596 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:34:20,514 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:34:20,521 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1145 request_id=req_3b1dfc5d5514632cb3855662afe788ae response_code=200
2025-06-11 13:34:20,667 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:21,933 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:34:21,939 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:22,965 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133422.wav, taille: 961726 bytes
2025-06-11 13:34:23,081 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133422.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:26,714 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:34:26,717 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:27,650 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133427.wav, taille: 963653 bytes
2025-06-11 13:34:27,768 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133427.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:32,476 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:34:32,481 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:32,964 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133432.wav, taille: 963653 bytes
2025-06-11 13:34:33,086 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133432.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:36,563 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:34:36,567 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:37,641 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133437.wav, taille: 961726 bytes
2025-06-11 13:34:37,759 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133437.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:41,183 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:34:41,185 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133441.wav, taille: 620647 bytes
2025-06-11 13:34:41,188 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:34:41,302 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133441.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:34:42,159 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:42] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:34:42,471 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:42] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:34:43,478 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:34:43,482 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:34:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:12,881 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133512.wav, taille: 967507 bytes
2025-06-11 13:35:12,983 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133512.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:17,333 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:35:17,333 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:35:17,335 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:35:17,338 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:35:17,570 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133517.wav, taille: 963653 bytes
2025-06-11 13:35:17,670 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133517.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:19,068 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:35:19,070 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1088 request_id=req_aa14fb533ff6cd38a03066d2e7b7b91a response_code=200
2025-06-11 13:35:19,193 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:22,867 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133522.wav, taille: 963653 bytes
2025-06-11 13:35:22,969 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133522.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:23,008 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:35:23,008 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\"\\n            Fran\\u00e7ais: \\"musique maintenant\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:35:23,036 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:35:23,044 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:35:26,503 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:35:26,505 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1248 request_id=req_676be2d6a444fb357e9facf71cdc7d08 response_code=200
2025-06-11 13:35:26,642 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:27,375 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:35:27,375 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0633\\u0627\\u062f \\u0639\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"tu es tr\\u00e8s particulier\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:35:27,377 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:35:27,382 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:35:27,870 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133527.wav, taille: 963653 bytes
2025-06-11 13:35:27,981 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133527.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:28,318 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:35:28,326 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=520 request_id=req_54f0a7155b117a1c522a3265ed11158b response_code=200
2025-06-11 13:35:28,483 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:31,336 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:35:31,337 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0627\\u0644\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:35:31,339 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:35:31,341 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:35:32,452 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:35:32,454 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=717 request_id=req_ad0dcb3b6add9a1f2255860c69f26324 response_code=200
2025-06-11 13:35:32,590 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:32,876 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133532.wav, taille: 963653 bytes
2025-06-11 13:35:32,986 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133532.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:36,155 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:35:36,158 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:37,860 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133537.wav, taille: 963653 bytes
2025-06-11 13:35:37,981 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133537.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:40,927 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:35:40,933 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:42,566 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133542.wav, taille: 963653 bytes
2025-06-11 13:35:42,670 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133542.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:45,491 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:35:45,496 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:47,869 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133547.wav, taille: 963653 bytes
2025-06-11 13:35:47,988 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133547.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:50,867 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133550.wav, taille: 634136 bytes
2025-06-11 13:35:50,892 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:35:50,906 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:35:51,006 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133550.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:35:52,159 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:52] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:35:52,471 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:52] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:35:52,688 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:35:52,690 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:35:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:13,748 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133613.wav, taille: 967507 bytes
2025-06-11 13:36:13,854 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133613.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:18,439 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133618.wav, taille: 963653 bytes
2025-06-11 13:36:18,540 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133618.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:19,182 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:36:19,183 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:36:19,185 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:36:19,187 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:36:20,668 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:36:20,670 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=719 request_id=req_23e64342ffdca725f43b442284a59a96 response_code=200
2025-06-11 13:36:20,799 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:23,727 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133623.wav, taille: 961726 bytes
2025-06-11 13:36:23,821 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133623.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:24,899 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:36:24,900 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"je suis diab\\u00e9tique aura d\'ici maintenant\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:36:24,902 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:36:24,906 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:36:26,456 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:36:26,459 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=717 request_id=req_76d30f23c302835d66307467f5372315 response_code=200
2025-06-11 13:36:26,565 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "je suis diabétique aura d'ici maintenant", 'fused': 'Je suis diabétique depuis maintenant.'}
2025-06-11 13:36:26,569 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:28,724 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133628.wav, taille: 963653 bytes
2025-06-11 13:36:28,833 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133628.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:33,740 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133633.wav, taille: 963653 bytes
2025-06-11 13:36:33,851 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133633.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:34,462 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:36:34,463 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u064a\\u062f \\u0627\\u0644\\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u0648\\u0628\\u0642\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:36:34,464 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:36:34,467 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:36:37,630 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:36:37,630 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u062a\\u0635\\u0639\\u0628\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:36:37,632 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:36:37,636 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:36:38,571 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:36:38,573 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=508 request_id=req_c9e881752e2c27c7a5d15ea9768479d2 response_code=200
2025-06-11 13:36:38,717 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:38,786 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133638.wav, taille: 963653 bytes
2025-06-11 13:36:38,901 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133638.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:40,639 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:36:40,663 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4762 request_id=req_9b92ff440af2c9110c44350f000291fa response_code=200
2025-06-11 13:36:40,788 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:41,229 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:36:41,230 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0628\\u0632\\u0627\\u0641 \\u0645\\u0646 \\u0628\\u0639\\u062f \\u0630\\u064a\\u0643 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0628\\u0642\\u0649 \\u063a\\u0627\\u062f\\u064a\\u0647 \\u0627\\u0644\\u062d\\u0627\\u0644 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:36:41,233 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:36:41,237 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:36:41,790 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:36:41,794 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:43,411 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:36:43,419 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1172 request_id=req_1e3cd79697a7f9f0676b6cf79c95cc75 response_code=200
2025-06-11 13:36:43,572 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:43,754 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133643.wav, taille: 963653 bytes
2025-06-11 13:36:43,864 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133643.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:46,710 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:36:46,712 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:48,749 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133648.wav, taille: 963653 bytes
2025-06-11 13:36:48,860 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133648.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:51,682 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:36:51,685 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:53,435 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133653.wav, taille: 961726 bytes
2025-06-11 13:36:53,554 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133653.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:36:58,265 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:36:58,268 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:36:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:36:58,746 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133658.wav, taille: 963653 bytes
2025-06-11 13:36:58,850 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133658.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:03,440 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133703.wav, taille: 963653 bytes
2025-06-11 13:37:03,552 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133703.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:03,799 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:37:03,801 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:07,142 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:37:07,146 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:08,741 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133708.wav, taille: 963653 bytes
2025-06-11 13:37:08,847 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133708.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:11,500 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:37:11,504 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:13,449 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133713.wav, taille: 963653 bytes
2025-06-11 13:37:13,570 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133713.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:17,053 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:37:17,056 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:18,750 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133718.wav, taille: 963653 bytes
2025-06-11 13:37:18,867 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:21,386 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:37:21,391 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:23,431 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133723.wav, taille: 961726 bytes
2025-06-11 13:37:23,530 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133723.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:27,184 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:37:27,193 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:28,754 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133728.wav, taille: 963653 bytes
2025-06-11 13:37:28,849 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133728.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:31,910 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:37:31,912 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:33,446 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133733.wav, taille: 961726 bytes
2025-06-11 13:37:33,567 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133733.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:36,937 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:37:36,941 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:38,745 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133738.wav, taille: 963653 bytes
2025-06-11 13:37:38,849 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133738.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:43,436 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133743.wav, taille: 961726 bytes
2025-06-11 13:37:43,549 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133743.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:43,683 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:37:43,684 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:37:43,698 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:37:43,702 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:37:46,458 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:37:46,469 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1286 request_id=req_cf821fe922ee842b21a722687c575e3a response_code=200
2025-06-11 13:37:46,623 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:48,251 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:37:48,251 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:37:48,252 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:37:48,255 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:37:48,744 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133748.wav, taille: 961726 bytes
2025-06-11 13:37:48,841 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133748.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:49,905 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:37:49,914 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1242 request_id=req_9c0d58630c98f192cc581e60d2aa9f08 response_code=200
2025-06-11 13:37:50,098 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'je suis diabétique', 'fused': 'Je suis diabétique.'}
2025-06-11 13:37:50,115 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:53,526 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:37:53,527 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u062d\\u064a\\u062f \\u0627\\u0644\\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u0648\\u0628\\u0642\\u0649\\"\\n            Fran\\u00e7ais: \\"C\\u00e9cile maman\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:37:53,529 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:37:53,531 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:37:53,750 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133753.wav, taille: 963653 bytes
2025-06-11 13:37:53,852 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133753.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:55,409 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:37:55,411 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1514 request_id=req_986d806250b1660452b2d9c3b4a4a873 response_code=200
2025-06-11 13:37:55,536 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:37:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:37:58,733 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133758.wav, taille: 963653 bytes
2025-06-11 13:37:58,836 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133758.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:37:59,396 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:37:59,398 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0630\\u064a\\u0643 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0628\\u0642\\u0627\\u062a \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0648\\u0643\\u0627\\u062a\\u0632\\u0627\\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:37:59,404 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:37:59,417 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:38:00,752 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:38:00,756 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=758 request_id=req_de68cdf383388d0a3e4cdab28c225146 response_code=200
2025-06-11 13:38:00,897 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:38:01,498 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:38:01,502 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:38:03,764 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133803.wav, taille: 961726 bytes
2025-06-11 13:38:03,868 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133803.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:38:06,022 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:38:06,026 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:38:08,442 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133808.wav, taille: 963653 bytes
2025-06-11 13:38:08,562 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133808.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:38:11,687 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:38:11,694 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:38:13,748 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133813.wav, taille: 961726 bytes
2025-06-11 13:38:13,874 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133813.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:38:16,389 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:38:16,393 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:38:18,441 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133818.wav, taille: 963653 bytes
2025-06-11 13:38:18,565 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133818.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:38:18,801 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_133818.wav, taille: 11715 bytes
2025-06-11 13:38:18,891 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_133818.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:38:19,806 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:19] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:38:20,123 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:38:20,124 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans.\\"\\nSegment 7: \\"Je suis diab\\u00e9tique.\\"\\nSegment 8: \\"C\\u00e9cile, maman, a subi une intervention pour retirer une pierre au rein la semaine derni\\u00e8re et elle se porte bien d\\u00e9sormais.\\"\\nSegment 9: \\"Ma condition est rest\\u00e9e la m\\u00eame la semaine derni\\u00e8re et s\'est aggrav\\u00e9e.\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 11: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 12: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 13: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            6. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:38:20,127 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:38:20,132 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:38:20,930 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:38:20,933 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:38:21,412 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:38:21,413 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:38:24,709 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:38:24,711 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3158 request_id=req_09fb9ef4bbe8d74d7481032c5d7883e6 response_code=200
2025-06-11 13:38:24,713 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:38:24] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:39:07,498 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:39:07] "OPTIONS /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:39:07,763 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:39:07,764 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un m\\u00e9decin expert en r\\u00e9daction de comptes rendus m\\u00e9dicaux.\\n            G\\u00e9n\\u00e8re un compte rendu m\\u00e9dical structur\\u00e9 et professionnel \\u00e0 partir de cette transcription d\'une consultation:\\n            \\n            Transcription: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans. Je suis diab\\u00e9tique. Ma condition est rest\\u00e9e la m\\u00eame la semaine derni\\u00e8re et s\'est aggrav\\u00e9e. , j\'ai  subi une intervention chirurgicale pour retirer une pierre au rein la semaine derni\\u00e8re\\"\\n            \\n            Structure obligatoire:\\n            - MOTIF DE CONSULTATION\\n            - ANT\\u00c9C\\u00c9DENTS\\n            - EXAMEN CLINIQUE\\n            - DIAGNOSTIC\\n            - PLAN DE TRAITEMENT\\n            - RECOMMANDATIONS\\n            \\n            INSTRUCTIONS IMPORTANTES:\\n            1. MAINTIENS uniquement les informations pr\\u00e9sentes dans la transcription\\n            2. N\'INVENTE aucune information m\\u00e9dicale\\n            3. Si une section ne peut pas \\u00eatre remplie faute d\'informations, indique \\"Non pr\\u00e9cis\\u00e9 dans la consultation\\"\\n            4. UTILISE un fran\\u00e7ais m\\u00e9dical professionnel et adapt\\u00e9\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:39:07,766 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:39:07,768 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:39:24,301 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:39:24,648 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=16111 request_id=req_95b2bc20df4a944d99c517637867e727 response_code=200
2025-06-11 13:39:24,656 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:39:24] "POST /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:44:22,595 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_134422.wav, taille: 967507 bytes
2025-06-11 13:44:22,708 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_134422.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:44:27,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_134427.wav, taille: 963653 bytes
2025-06-11 13:44:27,397 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_134427.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:44:27,645 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:44:27,646 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:44:27,649 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:44:27,655 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:44:30,632 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:44:30,634 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=772 request_id=req_06c6e031b8dbe9fd3de20a241230c90a response_code=200
2025-06-11 13:44:30,760 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:44:32,294 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:44:32,295 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:44:32,296 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:44:32,298 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:44:32,594 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_134432.wav, taille: 961726 bytes
2025-06-11 13:44:32,692 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_134432.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:44:34,842 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:44:34,843 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1353 request_id=req_2b52d8cc3f1e79705f802f6e2a30bc58 response_code=200
2025-06-11 13:44:34,973 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:44:37,605 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_134437.wav, taille: 965580 bytes
2025-06-11 13:44:37,727 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_134437.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:44:38,359 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:44:38,360 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u064a\\u0627\\u0647 \\u0627\\u0644\\u062d\\u062c\\u0631 \\u0641\\u064a \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0643\\u0627\\u0646 \\u0632\\u0627\\u062f \\u0639\\u0644\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"rien t\\u00e9l\\u00e9charger\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:44:38,362 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:44:38,364 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:44:40,263 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:44:40,266 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:44:42,604 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_134442.wav, taille: 961726 bytes
2025-06-11 13:44:42,702 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_134442.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:44:42,898 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:44:42,905 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1576 request_id=req_052893c298a89e6ed99eb31c8a88b65f response_code=200
2025-06-11 13:44:43,034 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:44:45,742 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:44:45,744 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:44:47,592 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_134447.wav, taille: 965580 bytes
2025-06-11 13:44:47,698 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_134447.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:44:50,594 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:44:50,597 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:44:52,295 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_134452.wav, taille: 963653 bytes
2025-06-11 13:44:52,407 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_134452.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:44:55,576 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:44:55,579 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:44:56,118 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_134456.wav, taille: 676530 bytes
2025-06-11 13:44:56,233 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_134456.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 13:44:56,803 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:56] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:44:57,123 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:44:57,124 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans.\\"\\nSegment 2: \\"J\'avais subi une op\\u00e9ration sur.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Il a eu des calculs r\\u00e9naux et apr\\u00e8s une semaine, la situation s\'est aggrav\\u00e9e, rien n\'a \\u00e9t\\u00e9 t\\u00e9l\\u00e9charg\\u00e9.\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            6. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:44:57,126 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:44:57,130 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:44:58,118 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 13:44:58,121 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 13:44:59,533 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:44:59,535 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1863 request_id=req_04d62baea7107f56e08004dc25be8365 response_code=200
2025-06-11 13:44:59,539 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:44:59] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 13:45:07,514 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:45:07] "OPTIONS /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:45:07,761 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 13:45:07,762 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un m\\u00e9decin expert en r\\u00e9daction de comptes rendus m\\u00e9dicaux.\\n            G\\u00e9n\\u00e8re un compte rendu m\\u00e9dical structur\\u00e9 et professionnel \\u00e0 partir de cette transcription d\'une consultation:\\n            \\n            Transcription: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans. J\'avais subi une op\\u00e9ration en raison de calculs r\\u00e9naux. Une semaine apr\\u00e8s l\'op\\u00e9ration, la situation s\'est aggrav\\u00e9e.\\"\\n            \\n            Structure obligatoire:\\n            - MOTIF DE CONSULTATION\\n            - ANT\\u00c9C\\u00c9DENTS\\n            - EXAMEN CLINIQUE\\n            - DIAGNOSTIC\\n            - PLAN DE TRAITEMENT\\n            - RECOMMANDATIONS\\n            \\n            INSTRUCTIONS IMPORTANTES:\\n            1. MAINTIENS uniquement les informations pr\\u00e9sentes dans la transcription\\n            2. N\'INVENTE aucune information m\\u00e9dicale\\n            3. Si une section ne peut pas \\u00eatre remplie faute d\'informations, indique \\"Non pr\\u00e9cis\\u00e9 dans la consultation\\"\\n            4. UTILISE un fran\\u00e7ais m\\u00e9dical professionnel et adapt\\u00e9\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 13:45:07,764 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 13:45:07,767 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 13:45:15,970 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 13:45:16,758 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7360 request_id=req_66482d0feead071b13e0404d6f138245 response_code=200
2025-06-11 13:45:16,760 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 13:45:16] "POST /api/report/generate HTTP/1.1" 200 -
2025-06-11 13:54:48,320 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-11 13:54:48,328 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-11 13:54:48,335 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-11 13:54:48,337 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-11 13:54:48,366 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\__init__.py', reloading
2025-06-11 13:54:48,368 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\chat_completion.py', reloading
2025-06-11 13:54:48,375 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\deployment.py', reloading
2025-06-11 13:54:48,382 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\engine.py', reloading
2025-06-11 13:54:48,385 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\file.py', reloading
2025-06-11 13:54:48,387 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\fine_tune.py', reloading
2025-06-11 13:54:48,390 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\model.py', reloading
2025-06-11 13:54:48,394 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\util.py', reloading
2025-06-11 13:54:48,398 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py', reloading
2025-06-11 13:54:48,400 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py', reloading
2025-06-11 13:54:48,402 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\api_resource.py', reloading
2025-06-11 13:54:48,406 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_response.py', reloading
2025-06-11 13:54:48,408 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_object.py', reloading
2025-06-11 13:54:48,417 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-11 13:54:48,420 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\object_classes.py', reloading
2025-06-11 13:54:48,421 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\experimental\\completion_config.py', reloading
2025-06-11 13:54:48,423 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\__init__.py', reloading
2025-06-11 13:54:48,424 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\createable_api_resource.py', reloading
2025-06-11 13:54:48,430 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\deletable_api_resource.py', reloading
2025-06-11 13:54:48,431 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\listable_api_resource.py', reloading
2025-06-11 13:54:48,433 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\nested_resource_class_methods.py', reloading
2025-06-11 13:54:48,434 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\updateable_api_resource.py', reloading
2025-06-11 13:54:49,569 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 13:54:54,501 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 13:54:54,520 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 14:07:06,022 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140706.wav, taille: 965580 bytes
2025-06-11 14:07:07,652 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140706.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:10,699 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140710.wav, taille: 963653 bytes
2025-06-11 14:07:10,785 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140710.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:12,419 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 14:07:12,419 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 14:07:12,422 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 14:07:12,427 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 14:07:14,639 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 14:07:14,642 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1515 request_id=req_316937a463d46a22c78525b5da79fae8 response_code=200
2025-06-11 14:07:14,792 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-11 14:07:15,017 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-11 14:07:15,018 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-11 14:07:15,021 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-11 14:07:15,021 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:07:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:07:15,022 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-11 14:07:15,024 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-11 14:07:15,027 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-11 14:07:15,030 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-11 14:07:15,233 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 14:07:18,503 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 14:07:18,514 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 14:07:18,637 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140718.wav, taille: 963653 bytes
2025-06-11 14:07:18,641 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140718.wav, taille: 963653 bytes
2025-06-11 14:07:18,767 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:18,771 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:20,715 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140720.wav, taille: 963653 bytes
2025-06-11 14:07:20,820 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140720.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:26,023 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140726.wav, taille: 961726 bytes
2025-06-11 14:07:26,125 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140726.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:27,885 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:07:27,888 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:07:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:07:31,005 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140731.wav, taille: 963653 bytes
2025-06-11 14:07:31,083 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140731.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:36,014 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140735.wav, taille: 965580 bytes
2025-06-11 14:07:36,099 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140735.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:37,144 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:07:37,146 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:07:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:07:38,562 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:07:38,564 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:07:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:07:41,000 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140740.wav, taille: 963653 bytes
2025-06-11 14:07:41,083 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140740.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:46,036 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140746.wav, taille: 965580 bytes
2025-06-11 14:07:46,133 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140746.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:46,826 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:07:46,828 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:07:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:07:47,854 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:07:47,858 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:07:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:07:50,949 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_140750.wav, taille: 944383 bytes
2025-06-11 14:07:51,037 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_140750.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:07:51,927 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:07:51] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 14:07:52,262 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 14:07:52,263 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum, je suis Chaima et j\'ai 23 ans.\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 14:07:52,265 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 14:07:52,268 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 14:07:57,749 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 14:07:57,751 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=865 request_id=req_386658fb89518f5b54250a87d938b0af response_code=200
2025-06-11 14:07:57,757 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:07:57] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-11 14:08:03,968 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:08:03,971 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:08:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:08:10,975 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:08:10,978 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:08:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:08:30,387 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:08:30,389 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:08:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:08:44,930 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-11 14:08:44,932 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:08:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:10:07,908 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\inference\\ASR.py', reloading
2025-06-11 14:10:08,560 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 14:10:13,153 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 14:10:13,167 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 14:10:13,495 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_sentencepiece_objects.py', reloading
2025-06-11 14:10:13,521 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tokenizers_objects.py', reloading
2025-06-11 14:10:13,530 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_speech_objects.py', reloading
2025-06-11 14:10:13,555 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tensorflow_text_objects.py', reloading
2025-06-11 14:10:13,560 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_keras_nlp_objects.py', reloading
2025-06-11 14:10:13,587 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_vision_objects.py', reloading
2025-06-11 14:10:13,631 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_pt_objects.py', reloading
2025-06-11 14:10:13,823 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tf_objects.py', reloading
2025-06-11 14:10:13,897 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_flax_objects.py', reloading
2025-06-11 14:10:13,920 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\__init__.py', reloading
2025-06-11 14:10:13,925 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py', reloading
2025-06-11 14:10:14,005 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\queue.py', reloading
2025-06-11 14:10:14,037 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py', reloading
2025-06-11 14:10:14,135 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_utils.py', reloading
2025-06-11 14:10:14,252 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\__init__.py', reloading
2025-06-11 14:10:14,259 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\__init__.py', reloading
2025-06-11 14:10:14,267 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\packaging\\__init__.py', reloading
2025-06-11 14:10:14,295 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\packaging\\version.py', reloading
2025-06-11 14:10:14,334 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\import_utils.py', reloading
2025-06-11 14:10:14,567 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 14:10:17,508 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 14:10:17,520 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 14:10:17,605 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\_validators.py', reloading
2025-06-11 14:10:17,609 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\_typing.py', reloading
2025-06-11 14:10:17,645 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\constants.py', reloading
2025-06-11 14:10:17,708 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pytorch_utils.py', reloading
2025-06-11 14:10:17,737 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py', reloading
2025-06-11 14:10:18,318 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\utils\\dataclasses.py', reloading
2025-06-11 14:10:18,439 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_tf_pytorch_utils.py', reloading
2025-06-11 14:10:18,500 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_tf_utils.py', reloading
2025-06-11 14:10:19,590 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 14:10:22,323 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 14:10:22,330 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 14:10:22,671 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\marian\\__init__.py', reloading
2025-06-11 14:10:22,697 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\marian\\modeling_marian.py', reloading
2025-06-11 14:10:22,770 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\marian\\tokenization_marian.py', reloading
2025-06-11 14:10:22,811 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\__init__.py', reloading
2025-06-11 14:10:22,831 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\detector_factory.py', reloading
2025-06-11 14:10:22,884 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\detector.py', reloading
2025-06-11 14:10:22,924 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\utils\\ngram.py', reloading
2025-06-11 14:10:22,937 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\utils\\messages.py', reloading
2025-06-11 14:10:23,006 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\language.py', reloading
2025-06-11 14:10:23,053 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\logits_process.py', reloading
2025-06-11 14:10:23,088 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\stopping_criteria.py', reloading
2025-06-11 14:10:23,120 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\streamers.py', reloading
2025-06-11 14:10:23,190 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\inference\\interfaces.py', reloading
2025-06-11 14:10:23,227 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\logger.py', reloading
2025-06-11 14:10:23,263 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\fetching.py', reloading
2025-06-11 14:10:23,292 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\distributed.py', reloading
2025-06-11 14:10:23,386 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\hyperpyyaml\\__init__.py', reloading
2025-06-11 14:10:23,412 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\hyperpyyaml\\core.py', reloading
2025-06-11 14:10:23,452 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\__init__.py', reloading
2025-06-11 14:10:23,474 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\cyaml.py', reloading
2025-06-11 14:10:23,508 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\main.py', reloading
2025-06-11 14:10:23,558 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\tokens.py', reloading
2025-06-11 14:10:23,581 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\events.py', reloading
2025-06-11 14:10:23,759 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 14:10:25,793 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 14:10:25,800 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 14:15:23,948 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:15:23] "GET / HTTP/1.1" 200 -
2025-06-11 14:15:24,013 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:15:24] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 14:15:24,073 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:15:24] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 14:15:24,180 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:15:24] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 14:16:03,323 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:16:03] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-11 14:16:03,392 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:16:03] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-11 14:16:03,465 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:16:03] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-11 14:16:03,806 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:16:03] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-11 14:16:08,273 - app - INFO - Fichier sauvegardé: uploads\audio_20250611_141608.wav, taille: 451071 bytes
2025-06-11 14:16:08,391 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250611_141608.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-11 14:16:11,328 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-11 14:16:11,329 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            2. Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            3. N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            4. GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-11 14:16:11,331 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-11 14:16:11,333 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-11 14:16:12,328 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-11 14:16:12,330 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=423 request_id=req_4e14caf533ff85c0e03174d8f5b686d5 response_code=200
2025-06-11 14:16:12,458 - werkzeug - INFO - 127.0.0.1 - - [11/Jun/2025 14:16:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-11 14:49:21,613 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\__init__.py', reloading
2025-06-11 14:49:21,725 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\__init__.py', reloading
2025-06-11 14:49:21,801 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_waveforms.py', reloading
2025-06-11 14:49:21,864 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_bsplines.py', reloading
2025-06-11 14:49:21,930 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_filter_design.py', reloading
2025-06-11 14:49:22,993 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 14:49:28,194 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 14:49:28,204 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 14:55:19,937 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-11 14:55:19,948 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-11 14:55:19,959 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-11 14:55:19,962 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-11 14:55:19,984 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\__init__.py', reloading
2025-06-11 14:55:20,000 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\chat_completion.py', reloading
2025-06-11 14:55:20,003 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\deployment.py', reloading
2025-06-11 14:55:20,004 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\engine.py', reloading
2025-06-11 14:55:20,006 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\file.py', reloading
2025-06-11 14:55:20,010 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\fine_tune.py', reloading
2025-06-11 14:55:20,014 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\model.py', reloading
2025-06-11 14:55:20,016 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\util.py', reloading
2025-06-11 14:55:20,017 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py', reloading
2025-06-11 14:55:20,019 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py', reloading
2025-06-11 14:55:20,020 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\api_resource.py', reloading
2025-06-11 14:55:20,021 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_response.py', reloading
2025-06-11 14:55:20,023 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_object.py', reloading
2025-06-11 14:55:20,031 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\object_classes.py', reloading
2025-06-11 14:55:20,032 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\experimental\\completion_config.py', reloading
2025-06-11 14:55:20,034 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\__init__.py', reloading
2025-06-11 14:55:20,037 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\createable_api_resource.py', reloading
2025-06-11 14:55:20,038 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\deletable_api_resource.py', reloading
2025-06-11 14:55:20,039 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\listable_api_resource.py', reloading
2025-06-11 14:55:20,042 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\nested_resource_class_methods.py', reloading
2025-06-11 14:55:20,046 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\updateable_api_resource.py', reloading
2025-06-11 14:55:20,228 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 14:55:22,235 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 14:55:22,243 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 14:55:32,028 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\__init__.py', reloading
2025-06-11 14:55:32,060 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py', reloading
2025-06-11 14:55:32,062 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\audio.py', reloading
2025-06-11 14:55:32,089 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\audio.py', reloading
2025-06-11 14:55:32,093 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\exceptions.py', reloading
2025-06-11 14:55:32,116 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\tempfile.py', reloading
2025-06-11 14:55:32,153 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\typing.py', reloading
2025-06-11 14:55:32,189 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\subprocess.py', reloading
2025-06-11 14:55:32,213 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\traceback.py', reloading
2025-06-11 14:55:32,236 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\wave.py', reloading
2025-06-11 14:55:32,239 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\__init__.py', reloading
2025-06-11 14:55:32,242 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\blueprints.py', reloading
2025-06-11 14:55:32,268 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\scaffold.py', reloading
2025-06-11 14:55:32,953 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-11 14:55:35,131 - werkzeug - WARNING -  * Debugger is active!
2025-06-11 14:55:35,137 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-11 16:48:28,566 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-11 16:48:28,578 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-11 16:48:28,591 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-11 16:48:28,600 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-11 16:48:28,629 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\__init__.py', reloading
2025-06-11 16:48:28,635 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\chat_completion.py', reloading
2025-06-11 16:48:28,649 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\deployment.py', reloading
2025-06-11 16:48:28,666 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\engine.py', reloading
2025-06-11 16:48:28,682 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\file.py', reloading
2025-06-11 16:48:28,845 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\fine_tune.py', reloading
2025-06-11 16:48:28,932 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\model.py', reloading
2025-06-11 16:48:29,014 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\util.py', reloading
2025-06-11 16:48:29,101 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py', reloading
2025-06-11 16:48:29,786 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-18 22:52:46,320 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.62:5000
2025-06-18 22:52:46,322 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-18 22:52:46,369 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-18 22:52:48,205 - werkzeug - WARNING -  * Debugger is active!
2025-06-18 22:52:48,219 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-18 22:56:03,635 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:03] "GET / HTTP/1.1" 200 -
2025-06-18 22:56:03,763 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:03] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-18 22:56:03,874 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:03] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-18 22:56:04,195 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:04] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-06-18 22:56:04,291 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:04] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-18 22:56:21,910 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_225621.wav, taille: 980996 bytes
2025-06-18 22:56:23,880 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_225621.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 22:56:26,584 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_225626.wav, taille: 963653 bytes
2025-06-18 22:56:26,711 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_225626.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 22:56:27,449 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 22:56:27,453 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0644\\u0645\\u0647\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0639\\u0646\\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Mohamed kendji\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 22:56:27,459 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 22:56:27,463 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 22:56:29,267 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 22:56:29,271 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=698 request_id=req_34521f69c9c145902826b635c7f88ed3 response_code=200
2025-06-18 22:56:29,444 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-18 22:56:29,693 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 22:56:29,910 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-18 22:56:32,004 - werkzeug - WARNING -  * Debugger is active!
2025-06-18 22:56:32,017 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-18 22:56:32,175 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_225632.wav, taille: 963653 bytes
2025-06-18 22:56:32,175 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_225632.wav, taille: 963653 bytes
2025-06-18 22:56:32,340 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_225632.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 22:56:32,356 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_225632.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 22:56:35,220 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 22:56:35,221 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"des antibiotiques\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 22:56:35,225 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 22:56:35,227 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 22:56:35,235 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"des antibiotiques\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 22:56:35,238 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 22:56:35,240 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 22:56:35,245 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 22:56:36,341 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 22:56:36,341 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=845 request_id=req_7cf23dfb910bc3c9e9e96e9ef94d099b response_code=200
2025-06-18 22:56:36,456 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 22:56:36,460 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=909 request_id=req_09e94094e8907899075b20c43a6a68e0 response_code=200
2025-06-18 22:56:36,464 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'des antibiotiques', 'fused': 'Des antibiotiques.'}
2025-06-18 22:56:36,470 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 22:56:36,585 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'des antibiotiques', 'fused': 'Le médecin a prescrit des antibiotiques.'}
2025-06-18 22:56:36,585 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 22:56:36,871 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_225636.wav, taille: 963653 bytes
2025-06-18 22:56:36,991 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_225636.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 22:56:38,920 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 22:56:38,920 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0645\\u0627 \\u062f\\u0627\\u0631\\u0648\\u0627 \\u0644\\u064a \\u0648\\u0627\\u0644\\u0648\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 22:56:38,927 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 22:56:38,934 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 22:56:40,137 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 22:56:40,141 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=522 request_id=req_f99b42090df0c172d3f217e2b78a6689 response_code=200
2025-06-18 22:56:40,291 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 22:56:41,900 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_225641.wav, taille: 965580 bytes
2025-06-18 22:56:42,030 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_225641.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 22:56:43,402 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 22:56:43,402 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 22:56:46,584 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_225646.wav, taille: 961726 bytes
2025-06-18 22:56:46,723 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_225646.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 22:56:46,951 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_225646.wav, taille: 15569 bytes
2025-06-18 22:56:47,060 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_225646.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 22:56:47,801 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 22:56:47,801 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 22:56:47,823 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 22:56:47,826 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 22:56:47,961 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:47] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-18 22:56:48,283 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 22:56:48,283 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam aleykoum, je voulais vous dire que j\'avais\\"\\"\\nSegment 2: \\"Des antibiotiques.\\"\\nSegment 3: \\"Le m\\u00e9decin a prescrit des antibiotiques.\\"\\nSegment 4: \\"\\"Mais ils ne m\'ont rien fait.\\"\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 22:56:48,283 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 22:56:48,290 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 22:56:50,632 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 22:56:50,634 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1471 request_id=req_56f057f1cdfa85a9edd2490f170e8161 response_code=200
2025-06-18 22:56:50,636 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 22:56:50] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-18 22:57:38,836 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\queue.py', reloading
2025-06-18 22:57:40,009 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\__init__.py', reloading
2025-06-18 22:57:40,923 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-18 22:57:55,367 - werkzeug - WARNING -  * Debugger is active!
2025-06-18 22:57:55,427 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-18 22:57:56,411 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\webbrowser.py', reloading
2025-06-18 22:57:57,214 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py', reloading
2025-06-18 22:57:57,351 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\__init__.py', reloading
2025-06-18 22:57:57,409 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\big_modeling.py', reloading
2025-06-18 22:57:57,550 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py', reloading
2025-06-18 22:57:58,606 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-18 22:58:11,435 - werkzeug - WARNING -  * Debugger is active!
2025-06-18 22:58:11,481 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-18 22:58:11,823 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\typing\\__init__.py', reloading
2025-06-18 22:58:11,871 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_generic_alias.py', reloading
2025-06-18 22:58:11,951 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_array_like.py', reloading
2025-06-18 22:58:12,007 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_nested_sequence.py', reloading
2025-06-18 22:58:12,058 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_dtype_like.py', reloading
2025-06-18 22:58:12,170 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_shape.py', reloading
2025-06-18 22:58:12,232 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_scalars.py', reloading
2025-06-18 22:58:12,652 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py', reloading
2025-06-18 22:58:12,731 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\grad_mode.py', reloading
2025-06-18 22:58:12,796 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\_contextlib.py', reloading
2025-06-18 22:58:13,659 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-18 22:58:25,041 - werkzeug - WARNING -  * Debugger is active!
2025-06-18 22:58:25,075 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-18 23:08:44,134 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:08:44] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-18 23:08:44,239 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:08:44] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-18 23:08:44,331 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:08:44] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-18 23:08:44,677 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:08:44] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-18 23:23:41,582 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232341.wav, taille: 80339 bytes
2025-06-18 23:23:41,883 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232341.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:23:44,642 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:23:44,645 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646\\u062c\\u064a \\u0627\\u0644\\u064a\\u0648\\u0645 \\u062d\\u064a\\u062a \\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"salam aleykoum avec une vid\\u00e9o\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:23:44,648 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:23:44,652 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:23:46,273 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232346.wav, taille: 76475 bytes
2025-06-18 23:23:46,402 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232346.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:23:46,543 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:23:46,552 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1121 request_id=req_a28f6ee07fccb3e7e4cfce1951d26fa8 response_code=200
2025-06-18 23:23:46,734 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:23:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:23:49,142 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:23:49,153 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0637\\u0631\\u064a \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0648\\u0643\\u0627\\u0646\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:23:49,153 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:23:49,153 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:23:50,642 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:23:50,652 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=809 request_id=req_acf0039b0658e82544776e23173aefe0 response_code=200
2025-06-18 23:23:50,784 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:23:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:23:51,592 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232351.wav, taille: 77441 bytes
2025-06-18 23:23:51,808 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232351.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:23:54,428 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:23:54,432 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:23:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:23:56,278 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232356.wav, taille: 76475 bytes
2025-06-18 23:23:56,402 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232356.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:23:57,743 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:23:57,747 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:23:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:24:01,582 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232401.wav, taille: 76475 bytes
2025-06-18 23:24:01,710 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232401.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:24:03,412 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:24:03,412 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:24:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:24:06,272 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232406.wav, taille: 76475 bytes
2025-06-18 23:24:06,402 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232406.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:24:08,280 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:24:08,282 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:24:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:24:11,582 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232411.wav, taille: 76475 bytes
2025-06-18 23:24:11,702 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232411.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:24:13,513 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:24:13,513 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"25\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:24:13,523 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:24:13,527 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:24:14,601 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:24:14,603 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=836 request_id=req_f16489a0f6acb9e8ee6b44ac569d8fb8 response_code=200
2025-06-18 23:24:14,712 - app - DEBUG - Résultat transcription: {'darija': '25', 'french': '', 'fused': 'Le patient a 25 ans.'}
2025-06-18 23:24:14,715 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:24:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:24:16,272 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232416.wav, taille: 76475 bytes
2025-06-18 23:24:16,413 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232416.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:24:18,205 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:24:18,209 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"29 3\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:24:18,214 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:24:18,217 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:24:19,953 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:24:19,953 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=737 request_id=req_710da6f3981b7cbc9d285887a8119feb response_code=200
2025-06-18 23:24:20,061 - app - DEBUG - Résultat transcription: {'darija': '29 3', 'french': '', 'fused': 'Il n\'y a pas de transcription en français à fusionner avec celle en Darija "29 3".'}
2025-06-18 23:24:20,062 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:24:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:24:21,582 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232421.wav, taille: 77441 bytes
2025-06-18 23:24:21,730 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232421.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:24:23,493 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:24:23,495 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:24:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:24:26,262 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232426.wav, taille: 76475 bytes
2025-06-18 23:24:26,394 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232426.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:24:27,792 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:24:27,797 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:24:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:24:29,033 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:24:29] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-18 23:24:29,308 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:24:29,308 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam aleykoum, je suis venu aujourd\'hui car j\'avais.\\"\\"\\nSegment 2: \\"La semaine derni\\u00e8re, il \\u00e9tait.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Le patient a 25 ans.\\"\\nSegment 8: \\"Il n\'y a pas de transcription en fran\\u00e7ais \\u00e0 fusionner avec celle en Darija \\"29 3\\".\\"\\nSegment 9: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:24:29,312 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:24:29,312 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:24:30,717 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:24:30,719 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1182 request_id=req_c58bf6f53badefb708c94440b41a794d response_code=200
2025-06-18 23:24:30,722 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:24:30] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-18 23:28:02,003 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232802.wav, taille: 80339 bytes
2025-06-18 23:28:02,141 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232802.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:28:05,303 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:28:05,303 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062c\\u062f \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u062d\\u064a\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Anakin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:28:05,303 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:28:05,315 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:28:06,383 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:28:06,383 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=841 request_id=req_679072e6baefc716030be52dfd0ac4f6 response_code=200
2025-06-18 23:28:06,527 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:28:06,693 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232806.wav, taille: 76475 bytes
2025-06-18 23:28:06,815 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232806.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:28:08,623 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:28:08,623 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u062d\\u0631\\u064a\\u0642 \\u0627\\u0644\\u0643\\u0631\\u0634 \\u0641\\u064a \\u062f\\u0627\\u0631\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:28:08,623 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:28:08,633 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:28:10,048 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:28:10,052 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1079 request_id=req_b40f7082931534b3742ecf5624bf7065 response_code=200
2025-06-18 23:28:10,195 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:28:12,003 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232812.wav, taille: 77441 bytes
2025-06-18 23:28:12,143 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232812.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:28:15,433 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:28:15,433 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"passion avec clavier pour le canap\\u00e9 m\\u00e9dicament\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:28:15,433 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:28:15,439 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:28:16,233 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:28:16,233 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=486 request_id=req_cdb13e287d39c57f55a4a0a6eebd838e response_code=200
2025-06-18 23:28:16,347 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'passion avec clavier pour le canapé médicament', 'fused': '"Passion pour le médicament."'}
2025-06-18 23:28:16,347 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:28:16,693 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232816.wav, taille: 77441 bytes
2025-06-18 23:28:16,810 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232816.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:28:19,447 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:28:19,447 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0627\\u064a\\u0647 \\u0648\\u0644\\u0643\\u0646 \\u0646\\u0628\\u0642\\u0649 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642\\"\\n            Fran\\u00e7ais: \\"Audrey antibiotique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:28:19,453 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:28:19,460 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:28:20,714 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:28:20,714 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=956 request_id=req_460d9df75d49e86bef86f7493bb81717 response_code=200
2025-06-18 23:28:20,861 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:28:21,992 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232821.wav, taille: 77441 bytes
2025-06-18 23:28:22,151 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232821.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:28:23,850 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:28:23,853 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:28:26,683 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232826.wav, taille: 76475 bytes
2025-06-18 23:28:26,814 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232826.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:28:27,949 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:28:27,953 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:28:32,002 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232832.wav, taille: 76475 bytes
2025-06-18 23:28:32,123 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232832.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:28:33,518 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:28:33,568 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:28:36,693 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232836.wav, taille: 77441 bytes
2025-06-18 23:28:36,823 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232836.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:28:38,014 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:28:38,022 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:28:40,782 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:40] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-18 23:28:41,023 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:28:41,023 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam aleykoum, je me sens mal depuis une semaine.\\"\\"\\nSegment 2: \\"J\'avais des br\\u00fblures d\'estomac chez moi.\\"\\nSegment 3: \\"\\"Passion pour le m\\u00e9dicament.\\"\\"\\nSegment 4: \\"J\'ai toujours des br\\u00fblures, mais je prends un antibiotique.\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:28:41,023 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:28:41,033 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:28:43,163 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:28:43,163 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1478 request_id=req_9f8f5c14abd3b55f323026095aa38628 response_code=200
2025-06-18 23:28:43,163 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:28:43] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-18 23:29:56,653 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_232956.wav, taille: 80339 bytes
2025-06-18 23:29:56,774 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_232956.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:29:57,860 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:29:57,863 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:29:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:01,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233001.wav, taille: 76475 bytes
2025-06-18 23:30:01,448 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233001.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:02,513 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:02,516 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:06,645 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233006.wav, taille: 76475 bytes
2025-06-18 23:30:06,763 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233006.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:07,968 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:30:07,968 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645\\"\\n            Fran\\u00e7ais: \\"salam \\u00e0\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:30:07,988 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:30:07,996 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:30:08,778 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:30:08,783 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=473 request_id=req_0300e25514f8e7a76067df3b084f8224 response_code=200
2025-06-18 23:30:08,917 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:11,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233011.wav, taille: 77441 bytes
2025-06-18 23:30:11,460 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233011.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:14,161 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:30:14,163 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0646\\u0627 \\u0643\\u0627\\u064a\\u0646 \\u062c\\u064a\\u062a\\u064a \\u0645\\u0646\\u0641\\u0633\\u0647 \\u062f\\u0631\\u062a \\u0627\\u0648\\u0628\\u064a\\u0631\\u0627\\u0633\\u064a\\u0648\\u0646\\"\\n            Fran\\u00e7ais: \\"Anakin sans op\\u00e9ration\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:30:14,163 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:30:14,168 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:30:15,633 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:30:15,633 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=899 request_id=req_a9ab4bcff36e863a1db4bbdaa6e80ade response_code=200
2025-06-18 23:30:15,771 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:16,642 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233016.wav, taille: 76475 bytes
2025-06-18 23:30:16,764 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233016.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:18,195 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:18,195 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:21,338 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233021.wav, taille: 76475 bytes
2025-06-18 23:30:21,461 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233021.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:23,361 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:30:23,361 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0631\\u0648\\u0643\\u0647\\"\\n            Fran\\u00e7ais: \\"transforma marocain\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:30:23,363 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:30:23,370 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:30:24,613 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:30:24,613 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=603 request_id=req_27b4135599fe446660010a2e75728874 response_code=200
2025-06-18 23:30:24,755 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:26,653 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233026.wav, taille: 77441 bytes
2025-06-18 23:30:26,801 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233026.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:28,556 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:28,560 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:31,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233031.wav, taille: 76475 bytes
2025-06-18 23:30:31,453 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233031.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:33,213 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:33,213 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:36,642 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233036.wav, taille: 77441 bytes
2025-06-18 23:30:36,758 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233036.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:38,503 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:38,503 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:41,341 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233041.wav, taille: 77441 bytes
2025-06-18 23:30:41,444 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233041.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:43,210 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:43,213 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:46,643 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233046.wav, taille: 76475 bytes
2025-06-18 23:30:46,763 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233046.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:47,929 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:47,933 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:51,341 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233051.wav, taille: 76475 bytes
2025-06-18 23:30:51,496 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233051.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:52,578 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:52,582 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:30:57,523 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233057.wav, taille: 90965 bytes
2025-06-18 23:30:57,718 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233057.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:30:58,831 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:30:58,833 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:30:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:31:02,168 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233102.wav, taille: 63917 bytes
2025-06-18 23:31:02,311 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233102.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:31:03,353 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:31:03,357 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:31:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:31:07,493 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233107.wav, taille: 63917 bytes
2025-06-18 23:31:07,653 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233107.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:31:08,539 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:31:08,542 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:31:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:31:12,163 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233112.wav, taille: 63917 bytes
2025-06-18 23:31:12,263 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233112.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:31:13,188 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:31:13,204 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:31:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:31:17,647 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233117.wav, taille: 63917 bytes
2025-06-18 23:31:17,860 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233117.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:31:19,457 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:31:19,466 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:31:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:31:21,340 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233121.wav, taille: 50393 bytes
2025-06-18 23:31:21,474 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233121.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:31:22,724 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:31:22,724 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"ce matin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:31:22,724 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:31:22,733 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:31:23,743 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:31:23,743 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=471 request_id=req_90c5e13c00c0f760e4883603cc7b5943 response_code=200
2025-06-18 23:31:23,854 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'ce matin', 'fused': 'Ce matin.'}
2025-06-18 23:31:23,855 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:31:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:33:54,573 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233354.wav, taille: 80339 bytes
2025-06-18 23:33:54,701 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233354.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:33:57,583 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:33:57,583 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0627\\u0633\\u0645\\u064a\\u062a\\u064a \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Anass monsieur Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:33:57,593 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:33:57,593 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:33:59,273 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233359.wav, taille: 77441 bytes
2025-06-18 23:33:59,393 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233359.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:33:59,683 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:33:59,683 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1380 request_id=req_aa106af91c39e7185342b18d4619fcb5 response_code=200
2025-06-18 23:33:59,830 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:33:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:02,553 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:34:02,553 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"op\\u00e9ration\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:34:02,553 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:34:02,553 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:34:03,283 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:34:03,283 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=469 request_id=req_0858f13cffb2b8d7e651de5f242b94cf response_code=200
2025-06-18 23:34:03,399 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'opération', 'fused': "L'opération est prévue."}
2025-06-18 23:34:03,403 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:04,585 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233404.wav, taille: 77441 bytes
2025-06-18 23:34:04,716 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233404.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:07,293 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:34:07,293 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u062a \\u063a\\u0627\\u062f\\u064a \\u0643\\u0648\\u0645\\u0648\\u0646\\"\\n            Fran\\u00e7ais: \\"des antibiotiques des m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:34:07,299 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:34:07,305 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:34:08,049 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:34:08,049 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=440 request_id=req_9acb74a2bf7363ed45efd4cd58e2ce6c response_code=200
2025-06-18 23:34:08,192 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:09,273 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233409.wav, taille: 76475 bytes
2025-06-18 23:34:09,399 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233409.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:11,423 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:34:11,423 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0627\\u0644\\u062c\\u0631\\u0627\\u062d \\u062d\\u062a\\u0649 \\u0643\\u0627\\u064a\\u062f\\u0648\\u0632\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:34:11,423 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:34:11,423 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:34:12,702 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:34:12,704 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=949 request_id=req_e50f7c9a402418a4f060fedc2bdf8cbb response_code=200
2025-06-18 23:34:12,843 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:14,573 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233414.wav, taille: 76475 bytes
2025-06-18 23:34:14,705 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233414.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:15,584 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:34:15,587 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:19,278 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233419.wav, taille: 76475 bytes
2025-06-18 23:34:19,398 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233419.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:20,265 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:34:20,265 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:24,573 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233424.wav, taille: 76475 bytes
2025-06-18 23:34:24,703 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233424.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:26,086 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:34:26,099 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:40,553 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233440.wav, taille: 80339 bytes
2025-06-18 23:34:40,683 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233440.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:43,833 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:34:43,833 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0627\\u0633\\u0645\\u064a\\u062a\\u064a \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum NASA Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:34:43,833 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:34:43,833 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:34:44,783 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:34:44,783 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=708 request_id=req_72e4a18e8fb93013851f81d9a7d5e0f4 response_code=200
2025-06-18 23:34:44,924 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:45,873 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233445.wav, taille: 76475 bytes
2025-06-18 23:34:45,988 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233445.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:48,663 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:34:48,663 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u0633\\u0647 \\u0643\\u0627\\u0646 \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0628\\u0627\\u0628\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:34:48,663 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:34:48,677 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:34:49,953 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:34:49,968 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=974 request_id=req_29f7038aef0cc26df23433e144acde1e response_code=200
2025-06-18 23:34:50,107 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:50,553 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233450.wav, taille: 76475 bytes
2025-06-18 23:34:50,673 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233450.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:52,461 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:34:52,463 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:34:55,853 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233455.wav, taille: 77441 bytes
2025-06-18 23:34:55,983 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233455.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:34:58,333 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:34:58,333 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0643\\u0627\\u062a\\u0632\\u0627\\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:34:58,333 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:34:58,344 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:34:59,196 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:34:59,203 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=520 request_id=req_cd1ca0a479f7e1485741b165c5169660 response_code=200
2025-06-18 23:34:59,339 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:34:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:35:00,553 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233500.wav, taille: 77441 bytes
2025-06-18 23:35:00,683 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233500.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:35:03,243 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:35:03,253 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"antibiotique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:35:03,253 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:35:03,253 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:35:03,934 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:35:03,934 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=435 request_id=req_a13626050da843b992d8e66f8f4e8482 response_code=200
2025-06-18 23:35:04,044 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'antibiotique', 'fused': 'antibiotique'}
2025-06-18 23:35:04,047 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:35:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:35:05,873 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233505.wav, taille: 77441 bytes
2025-06-18 23:35:05,998 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233505.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:35:07,882 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:35:07,885 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:35:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:35:10,553 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233510.wav, taille: 76475 bytes
2025-06-18 23:35:10,684 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233510.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:35:11,614 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:35:11,614 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:35:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:35:16,490 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233516.wav, taille: 86135 bytes
2025-06-18 23:35:16,688 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233516.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:35:17,841 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:35:17,853 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:35:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:35:20,553 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_233520.wav, taille: 54257 bytes
2025-06-18 23:35:20,684 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_233520.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:35:21,746 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:35:21,746 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:35:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:53:32,632 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235332.wav, taille: 81305 bytes
2025-06-18 23:53:33,324 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235332.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:53:36,609 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:53:36,609 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0633\\u0645\\u064a\\u062a\\u064a \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Anass monsieur Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:53:36,615 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:53:36,622 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:53:37,319 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235337.wav, taille: 77441 bytes
2025-06-18 23:53:37,460 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235337.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:53:38,034 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:53:38,039 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=938 request_id=req_43785b59678e95f277990ada287b2b11 response_code=200
2025-06-18 23:53:38,185 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:53:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:53:39,670 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-18 23:53:39,670 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u062a \\u062d\\u064a\\u062a \\u062f\\u0631\\u062a \\u0627\\u0648\\u0628\\u064a\\u0631\\u0627\\u0633\\u064a\\u0648\\u0646 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u0644\\u0627\\u0648\\u064a\\"\\n            Fran\\u00e7ais: \\"op\\u00e9ration\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-18 23:53:39,675 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-18 23:53:39,680 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-18 23:53:41,296 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-18 23:53:41,298 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=810 request_id=req_28991833b89022bd9fcdab24513d7288 response_code=200
2025-06-18 23:53:41,443 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:53:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:53:42,623 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235342.wav, taille: 76475 bytes
2025-06-18 23:53:42,767 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235342.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:53:45,213 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:53:45,215 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:53:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:53:47,314 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235347.wav, taille: 76475 bytes
2025-06-18 23:53:47,437 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235347.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:53:49,005 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:53:49,008 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:53:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:53:52,615 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235352.wav, taille: 76475 bytes
2025-06-18 23:53:52,748 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235352.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:53:53,605 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:53:53,605 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:53:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:53:58,188 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235358.wav, taille: 77441 bytes
2025-06-18 23:53:58,420 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235358.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:00,656 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:01,026 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:02,818 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235402.wav, taille: 66815 bytes
2025-06-18 23:54:03,349 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-18 23:54:03,696 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235402.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:05,859 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-18 23:54:14,055 - werkzeug - WARNING -  * Debugger is active!
2025-06-18 23:54:14,072 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-18 23:54:14,249 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235414.wav, taille: 81920 bytes
2025-06-18 23:54:14,249 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235414.wav, taille: 89033 bytes
2025-06-18 23:54:14,534 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235414.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:14,597 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235414.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:16,216 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:16,229 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:16,548 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:16,565 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:18,511 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235418.wav, taille: 63917 bytes
2025-06-18 23:54:18,678 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235418.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:19,879 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:20,029 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:23,009 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-18 23:54:23,179 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235423.wav, taille: 63917 bytes
2025-06-18 23:54:24,128 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-18 23:54:26,994 - werkzeug - WARNING -  * Debugger is active!
2025-06-18 23:54:27,007 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-18 23:54:27,116 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235427.wav, taille: 63917 bytes
2025-06-18 23:54:27,264 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235427.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:28,172 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235428.wav, taille: 63916 bytes
2025-06-18 23:54:28,365 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:28,372 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:28,405 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235428.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:29,915 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:29,920 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:33,487 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235433.wav, taille: 63917 bytes
2025-06-18 23:54:33,708 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235433.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:35,049 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:35,064 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:38,161 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235438.wav, taille: 64883 bytes
2025-06-18 23:54:38,288 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235438.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:39,862 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:39,884 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:43,496 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235443.wav, taille: 63917 bytes
2025-06-18 23:54:43,674 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235443.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:44,669 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:44,672 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:48,173 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235448.wav, taille: 63917 bytes
2025-06-18 23:54:48,284 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235448.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:49,912 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:49,952 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:53,525 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235453.wav, taille: 63917 bytes
2025-06-18 23:54:53,656 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235453.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:54,818 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:54,845 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:54:58,166 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235458.wav, taille: 63917 bytes
2025-06-18 23:54:58,280 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235458.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:54:59,153 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:54:59,156 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:54:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:55:03,476 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235503.wav, taille: 63917 bytes
2025-06-18 23:55:03,588 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235503.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:55:04,642 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:55:04,645 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:55:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:55:08,209 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235508.wav, taille: 63917 bytes
2025-06-18 23:55:08,693 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235508.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:55:09,490 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:55:09,493 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:55:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:55:13,521 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235513.wav, taille: 62951 bytes
2025-06-18 23:55:13,744 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235513.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:55:15,084 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:55:15,172 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:55:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:55:18,191 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235518.wav, taille: 63917 bytes
2025-06-18 23:55:18,368 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235518.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:55:20,100 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:55:20,104 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:55:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:55:23,553 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235523.wav, taille: 63917 bytes
2025-06-18 23:55:23,788 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235523.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:55:26,530 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:55:26,630 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:55:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:55:28,191 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235528.wav, taille: 63917 bytes
2025-06-18 23:55:28,455 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235528.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:55:30,719 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:55:30,737 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:55:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-18 23:55:32,679 - app - INFO - Fichier sauvegardé: uploads\audio_20250618_235532.wav, taille: 50393 bytes
2025-06-18 23:55:33,217 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250618_235532.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-18 23:55:35,699 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-18 23:55:35,702 - werkzeug - INFO - 127.0.0.1 - - [18/Jun/2025 23:55:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:06:18,197 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_000618.wav, taille: 15455 bytes
2025-06-19 00:06:18,517 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_000618.wav', '-vn', '-f', 'wav', '-'])
2025-06-19 00:06:18,866 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 00:06:18,871 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\subprocess.py', reloading
2025-06-19 00:06:18,874 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py', reloading
2025-06-19 00:06:18,893 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: Impossible de convertir l'audio: Impossible de convertir le fichier audio: Conversion FFmpeg échouée"}
2025-06-19 00:06:18,899 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:06:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:06:19,816 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 00:06:22,220 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 00:06:22,237 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 00:06:23,205 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_000623.wav, taille: 77441 bytes
2025-06-19 00:06:23,330 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_000623.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:06:25,312 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:06:25,316 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:06:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:06:27,885 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_000627.wav, taille: 77441 bytes
2025-06-19 00:06:27,997 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_000627.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:06:29,747 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:06:29,747 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:06:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:06:33,205 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_000633.wav, taille: 76475 bytes
2025-06-19 00:06:33,320 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_000633.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:06:34,597 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:06:34,597 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:06:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:31:48,011 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:31:48] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 00:31:48,136 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:31:48] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 00:31:48,165 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:31:48] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 00:31:48,677 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:31:48] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 00:31:55,928 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_003155.wav, taille: 80339 bytes
2025-06-19 00:31:56,346 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_003155.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:32:01,429 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:32:01,430 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0627\\u0648\\u0628\\u0631\\u0627\\u0633\\u062a\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Anakin op\\u00e9ration \\u00e0\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:32:01,433 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:32:01,436 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:32:03,003 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:32:03,009 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=724 request_id=req_cd61580422987fceb69ca9c73f60e4c7 response_code=200
2025-06-19 00:32:03,150 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-19 00:32:03,193 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-19 00:32:03,199 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:32:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:32:03,200 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-19 00:32:03,202 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-19 00:32:03,210 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-19 00:32:03,217 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-19 00:32:03,219 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-19 00:32:03,220 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-19 00:32:03,748 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_003203.wav, taille: 72611 bytes
2025-06-19 00:32:03,913 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_003203.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:32:04,259 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 00:32:06,531 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 00:32:06,538 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 00:32:06,648 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_003206.wav, taille: 72611 bytes
2025-06-19 00:32:06,778 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_003206.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:32:11,829 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:32:11,830 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0648\\u0627\\u0644\\u0648\\"\\n            Fran\\u00e7ais: \\"antibiotique des traitements\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:32:11,836 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:32:11,841 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:32:13,748 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:32:13,748 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=858 request_id=req_e34484e3f958272567b41456dc8609ba response_code=200
2025-06-19 00:32:13,917 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:32:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:32:14,160 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_003214.wav, taille: 72611 bytes
2025-06-19 00:32:14,293 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_003214.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:33:01,478 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_003301.wav, taille: 19481 bytes
2025-06-19 00:33:01,590 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_003301.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:33:01,739 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 00:33:01,740 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 00:33:01,744 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:33:01,749 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:33:01,749 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:33:01,751 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002262BF1B8E0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 00:33:01,752 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 00:33:01,753 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:33:01,754 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002262BF1B7F0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 00:33:01,756 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 00:33:01,908 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 00:33:01,910 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 00:33:01,913 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-19 00:33:01,914 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:33:01,914 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002262BEC82B0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 00:33:01,914 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-19 00:33:01,917 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:33:01,917 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002262BEC8F40>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 00:33:01,920 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-19 00:33:02,142 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:33:02,148 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:33:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:33:37,992 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 00:33:37,998 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 00:33:37,998 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:33:37,998 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:33:38,006 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:33:38,009 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002262C028B80>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 00:33:38,010 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 00:33:38,011 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:33:38,012 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002262C028A90>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 00:33:38,014 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 00:33:38,237 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:33:38,239 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:33:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:39:29,013 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-19 00:39:29,018 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-19 00:39:29,028 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\__init__.py', reloading
2025-06-19 00:39:29,030 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-19 00:39:29,113 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\__init__.py', reloading
2025-06-19 00:39:29,133 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\audio.py', reloading
2025-06-19 00:39:29,133 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\exceptions.py', reloading
2025-06-19 00:39:29,143 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\audio.py', reloading
2025-06-19 00:39:29,148 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\chat_completion.py', reloading
2025-06-19 00:39:29,148 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\deployment.py', reloading
2025-06-19 00:39:29,148 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\engine.py', reloading
2025-06-19 00:39:29,156 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\file.py', reloading
2025-06-19 00:39:29,160 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\fine_tune.py', reloading
2025-06-19 00:39:29,163 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\model.py', reloading
2025-06-19 00:39:29,166 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py', reloading
2025-06-19 00:39:29,168 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\util.py', reloading
2025-06-19 00:39:29,178 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\__init__.py', reloading
2025-06-19 00:39:29,178 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\api_resource.py', reloading
2025-06-19 00:39:29,183 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\createable_api_resource.py', reloading
2025-06-19 00:39:29,183 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\deletable_api_resource.py', reloading
2025-06-19 00:39:29,193 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\listable_api_resource.py', reloading
2025-06-19 00:39:29,194 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\nested_resource_class_methods.py', reloading
2025-06-19 00:39:29,196 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\updateable_api_resource.py', reloading
2025-06-19 00:39:29,200 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_object.py', reloading
2025-06-19 00:39:29,207 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_response.py', reloading
2025-06-19 00:39:29,210 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\object_classes.py', reloading
2025-06-19 00:39:29,212 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\experimental\\completion_config.py', reloading
2025-06-19 00:39:29,212 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py', reloading
2025-06-19 00:39:29,214 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\tempfile.py', reloading
2025-06-19 00:39:29,216 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\typing.py', reloading
2025-06-19 00:39:29,218 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\traceback.py', reloading
2025-06-19 00:39:29,222 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\wave.py', reloading
2025-06-19 00:39:29,228 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\__init__.py', reloading
2025-06-19 00:39:29,228 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\json\\__init__.py', reloading
2025-06-19 00:39:29,233 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\blueprints.py', reloading
2025-06-19 00:39:29,233 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\config.py', reloading
2025-06-19 00:39:29,241 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\globals.py', reloading
2025-06-19 00:39:29,244 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\helpers.py', reloading
2025-06-19 00:39:29,245 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\typing.py', reloading
2025-06-19 00:39:29,248 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\scaffold.py', reloading
2025-06-19 00:39:29,258 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\utils.py', reloading
2025-06-19 00:39:29,263 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\wrappers.py', reloading
2025-06-19 00:39:29,290 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\__init__.py', reloading
2025-06-19 00:39:29,298 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sounddevice.py', reloading
2025-06-19 00:39:29,307 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\__init__.py', reloading
2025-06-19 00:39:29,314 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\arabic_reshaper\\__init__.py', reloading
2025-06-19 00:39:29,318 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\bidi\\algorithm.py', reloading
2025-06-19 00:39:29,333 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\__init__.py', reloading
2025-06-19 00:39:29,334 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\transforms\\__init__.py', reloading
2025-06-19 00:39:29,336 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\__init__.py', reloading
2025-06-19 00:39:29,340 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\inference\\ASR.py', reloading
2025-06-19 00:39:29,348 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\hyperpyyaml\\__init__.py', reloading
2025-06-19 00:39:29,350 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\logger.py', reloading
2025-06-19 00:39:29,351 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\__init__.py', reloading
2025-06-19 00:39:29,353 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\distributed.py', reloading
2025-06-19 00:39:29,358 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sentencepiece\\__init__.py', reloading
2025-06-19 00:39:29,358 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\data_utils.py', reloading
2025-06-19 00:39:29,373 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\__init__.py', reloading
2025-06-19 00:39:29,376 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\__init__.py', reloading
2025-06-19 00:39:29,378 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\fetching.py', reloading
2025-06-19 00:39:29,389 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\packaging\\__init__.py', reloading
2025-06-19 00:39:29,393 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\packaging\\version.py', reloading
2025-06-19 00:39:29,393 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\inference\\interfaces.py', reloading
2025-06-19 00:39:29,398 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\dataio\\preprocess.py', reloading
2025-06-19 00:39:29,398 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py', reloading
2025-06-19 00:39:29,398 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py', reloading
2025-06-19 00:39:29,408 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py', reloading
2025-06-19 00:39:29,411 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\queue.py', reloading
2025-06-19 00:39:29,411 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\__init__.py', reloading
2025-06-19 00:39:29,433 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py', reloading
2025-06-19 00:39:29,433 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\serialization.py', reloading
2025-06-19 00:39:29,441 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\functional.py', reloading
2025-06-19 00:39:29,444 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\__init__.py', reloading
2025-06-19 00:39:29,446 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\types.py', reloading
2025-06-19 00:39:29,448 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_jit_internal.py', reloading
2025-06-19 00:39:29,462 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\_sounddevice.py', reloading
2025-06-19 00:39:29,462 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\__init__.py', reloading
2025-06-19 00:39:29,468 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\logging.py', reloading
2025-06-19 00:39:29,468 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_sentencepiece_objects.py', reloading
2025-06-19 00:39:29,476 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tokenizers_objects.py', reloading
2025-06-19 00:39:29,478 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_speech_objects.py', reloading
2025-06-19 00:39:29,481 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tensorflow_text_objects.py', reloading
2025-06-19 00:39:29,482 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_keras_nlp_objects.py', reloading
2025-06-19 00:39:29,483 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_vision_objects.py', reloading
2025-06-19 00:39:29,492 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_pt_objects.py', reloading
2025-06-19 00:39:29,495 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tf_objects.py', reloading
2025-06-19 00:39:29,498 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_flax_objects.py', reloading
2025-06-19 00:39:29,498 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py', reloading
2025-06-19 00:39:29,509 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\feature_extraction_sequence_utils.py', reloading
2025-06-19 00:39:29,509 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\feature_extraction_utils.py', reloading
2025-06-19 00:39:29,513 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\__init__.py', reloading
2025-06-19 00:39:29,513 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_tf_pytorch_utils.py', reloading
2025-06-19 00:39:29,518 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\marian\\__init__.py', reloading
2025-06-19 00:39:29,521 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\__init__.py', reloading
2025-06-19 00:39:29,526 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\processing_utils.py', reloading
2025-06-19 00:39:29,529 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils.py', reloading
2025-06-19 00:39:29,533 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py', reloading
2025-06-19 00:39:29,538 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\quantization_config.py', reloading
2025-06-19 00:39:29,541 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pytorch_utils.py', reloading
2025-06-19 00:39:29,548 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_tf_utils.py', reloading
2025-06-19 00:39:29,548 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py', reloading
2025-06-19 00:39:29,553 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py', reloading
2025-06-19 00:39:29,559 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py', reloading
2025-06-19 00:39:29,561 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\deepspeed.py', reloading
2025-06-19 00:39:29,566 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\safetensors\\torch.py', reloading
2025-06-19 00:39:29,576 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\hub.py', reloading
2025-06-19 00:39:29,578 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\import_utils.py', reloading
2025-06-19 00:39:29,581 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\versions.py', reloading
2025-06-19 00:39:29,583 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\__init__.py', reloading
2025-06-19 00:39:29,585 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\utils\\__init__.py', reloading
2025-06-19 00:39:29,593 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\bitsandbytes.py', reloading
2025-06-19 00:39:29,598 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_flax_pytorch_utils.py', reloading
2025-06-19 00:39:29,598 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\__init__.py', reloading
2025-06-19 00:39:29,603 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py', reloading
2025-06-19 00:39:29,611 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py', reloading
2025-06-19 00:39:29,613 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\doc.py', reloading
2025-06-19 00:39:29,616 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\generic.py', reloading
2025-06-19 00:39:29,617 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\__init__.py', reloading
2025-06-19 00:39:29,631 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py', reloading
2025-06-19 00:39:29,633 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\streamers.py', reloading
2025-06-19 00:39:29,635 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\logits_process.py', reloading
2025-06-19 00:39:29,638 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\stopping_criteria.py', reloading
2025-06-19 00:39:29,645 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py', reloading
2025-06-19 00:39:29,663 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\re.py', reloading
2025-06-19 00:39:29,663 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\datetime.py', reloading
2025-06-19 00:39:29,668 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\webbrowser.py', reloading
2025-06-19 00:39:29,680 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\big_modeling.py', reloading
2025-06-19 00:39:29,998 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 00:39:39,908 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 00:39:39,935 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 00:46:04,728 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:04] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 00:46:04,821 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:04] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 00:46:04,891 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:04] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 00:46:05,322 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:05] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 00:46:13,475 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004613.wav, taille: 80339 bytes
2025-06-19 00:46:13,619 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004613.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:16,160 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:46:16,160 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23\\"\\n            Fran\\u00e7ais: \\"salam aleykoum hach\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:46:16,160 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:46:16,175 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:46:19,809 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:46:19,809 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=584 request_id=req_3f3fc47cfa2fff9af3caa28ee09606e7 response_code=200
2025-06-19 00:46:19,972 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:46:20,514 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004620.wav, taille: 71645 bytes
2025-06-19 00:46:20,674 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004620.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:23,389 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:46:23,389 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0643\\u0644\\u0627\\"\\n            Fran\\u00e7ais: \\"op\\u00e9ration avec cl\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:46:23,389 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:46:23,399 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:46:24,221 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:46:24,222 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=339 request_id=req_871cc9e8ecf6562253cb5c8744b052e8 response_code=200
2025-06-19 00:46:24,367 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:46:24,604 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004624.wav, taille: 71645 bytes
2025-06-19 00:46:24,711 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004624.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:26,403 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:46:26,405 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:46:26,409 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:46:26,412 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:46:27,972 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:46:27,972 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=377 request_id=req_260c6082539a8b718ab07ca17a8158aa response_code=200
2025-06-19 00:46:28,104 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:46:28,757 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004628.wav, taille: 72611 bytes
2025-06-19 00:46:28,915 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004628.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:31,039 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:46:31,039 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"titre de m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:46:31,049 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:46:31,054 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:46:32,179 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:46:32,189 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=802 request_id=req_889281eba6a46d11a6134787fec8228f response_code=200
2025-06-19 00:46:32,304 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'titre de médicaments', 'fused': 'Titre de médicaments.'}
2025-06-19 00:46:32,305 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:46:33,454 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004633.wav, taille: 71645 bytes
2025-06-19 00:46:33,590 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004633.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:35,879 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:46:35,879 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"des antibiotiques\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:46:35,886 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:46:35,889 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:46:37,009 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:46:37,009 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=813 request_id=req_acf820e75f72dc9816f260b897633fe2 response_code=200
2025-06-19 00:46:37,120 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'des antibiotiques', 'fused': 'Le patient a besoin de prendre des antibiotiques.'}
2025-06-19 00:46:37,120 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:46:38,761 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004638.wav, taille: 71645 bytes
2025-06-19 00:46:38,899 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004638.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:40,004 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:46:40,009 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:46:43,453 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004643.wav, taille: 71645 bytes
2025-06-19 00:46:43,579 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004643.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:45,289 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:46:45,289 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:46:48,570 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004648.wav, taille: 69713 bytes
2025-06-19 00:46:48,689 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004648.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:50,422 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:46:50,423 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:46:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:46:55,644 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004655.wav, taille: 80339 bytes
2025-06-19 00:46:55,789 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004655.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:46:59,289 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:46:59,289 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627\\"\\n            Fran\\u00e7ais: \\"salam aleykoum un homme\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:46:59,289 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:46:59,301 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:47:00,779 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:47:00,779 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1177 request_id=req_d8db3b09f428df051c056d19c9bb686d response_code=200
2025-06-19 00:47:00,933 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:47:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:47:04,920 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004704.wav, taille: 80339 bytes
2025-06-19 00:47:05,039 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004704.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:47:08,089 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:47:08,099 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0643\\u0646\\u062f\\u0631\\u062a \\u0627\\u0648\\u0628\\u064a\\u063a\\u0627\\u0633\\u064a\\u0648\\u0646 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"salam aleykoum op\\u00e9ration Simon\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:47:08,102 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:47:08,112 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:47:09,950 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:47:09,951 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1539 request_id=req_84ad78f02f4c78d2ba1506f645a54df3 response_code=200
2025-06-19 00:47:10,096 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:47:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:47:10,659 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004710.wav, taille: 71645 bytes
2025-06-19 00:47:10,824 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004710.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:47:13,119 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:47:13,129 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u062a\\u0632\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:47:13,129 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:47:13,138 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:47:14,973 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:47:14,979 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=803 request_id=req_12a5094fde387c53d2240b311ac23041 response_code=200
2025-06-19 00:47:15,110 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:47:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:47:15,351 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004715.wav, taille: 71645 bytes
2025-06-19 00:47:15,470 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004715.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:47:17,419 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:47:17,419 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:47:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:47:19,909 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004719.wav, taille: 72611 bytes
2025-06-19 00:47:20,044 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004719.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:47:21,509 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:47:21,509 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0631\\u064a\\u0642\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:47:21,509 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:47:21,525 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:47:22,679 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:47:22,685 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=584 request_id=req_710038d1bf27f228b9cfc0157c0a9907 response_code=200
2025-06-19 00:47:22,829 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:47:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:47:24,619 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004724.wav, taille: 72611 bytes
2025-06-19 00:47:24,749 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004724.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:47:36,098 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:47:36,105 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:47:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:47:36,659 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004736.wav, taille: 71645 bytes
2025-06-19 00:47:36,829 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004736.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:47:38,069 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:47:38,069 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:47:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:47:45,919 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004745.wav, taille: 80339 bytes
2025-06-19 00:47:46,050 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004745.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:47:54,510 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:47:54,510 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u064a\\u0641 \\u062f\\u0631\\u062a \\u0627\\u0648\\u0628\\u0631\\u0627\\u0633\\u064a\\u0648\\u0646 \\u0633\\u064a\\u0645\\u0627\\"\\n            Fran\\u00e7ais: \\"salam aleykoum op\\u00e9ration\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:47:54,516 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:47:54,524 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:47:56,233 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:47:56,233 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1463 request_id=req_4d29c36ab3c535c7d759dc9eebc9729f response_code=200
2025-06-19 00:47:56,378 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:47:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:47:56,616 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004756.wav, taille: 72611 bytes
2025-06-19 00:47:56,744 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004756.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:00,299 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:48:00,304 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0632\\u0627\\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:48:00,322 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:48:00,327 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:48:02,384 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:48:02,440 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=544 request_id=req_a9cb75a5625bf9ef953913a2b3a57165 response_code=200
2025-06-19 00:48:02,574 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:03,109 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004803.wav, taille: 71645 bytes
2025-06-19 00:48:03,246 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004803.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:05,989 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:48:05,989 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0628\\u0639\\u062f \\u0627\\u0644\\u0639\\u0645\\u0644\\u064a\\u0647 \\u0648\\u062e\\u062f\\u064a\\u062a 20\\"\\n            Fran\\u00e7ais: \\"m\\u00e9dicament\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:48:05,989 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:48:05,989 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:48:07,870 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:48:07,879 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1496 request_id=req_d985c0d67ce222df78ef39589e87ee47 response_code=200
2025-06-19 00:48:08,034 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:08,266 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004808.wav, taille: 71645 bytes
2025-06-19 00:48:08,374 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004808.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:10,359 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:48:10,359 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0642\\u0627\\u0639\\u062f\\u064a\\u0646 \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:48:10,359 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:48:10,373 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:48:12,149 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:48:12,149 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1131 request_id=req_00902ba4103ce628f0141e40fca2ef6b response_code=200
2025-06-19 00:48:12,295 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:12,839 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004812.wav, taille: 71645 bytes
2025-06-19 00:48:12,975 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004812.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:17,232 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:48:17,232 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:17,464 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004817.wav, taille: 71645 bytes
2025-06-19 00:48:17,589 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004817.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:18,365 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:48:18,369 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:18,900 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004818.wav, taille: 72611 bytes
2025-06-19 00:48:19,038 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004818.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:20,246 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:48:20,249 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:20,598 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004820.wav, taille: 72611 bytes
2025-06-19 00:48:20,700 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004820.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:21,889 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:48:21,889 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:25,900 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004825.wav, taille: 72611 bytes
2025-06-19 00:48:26,024 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004825.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:26,944 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:48:26,961 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:30,597 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004830.wav, taille: 71645 bytes
2025-06-19 00:48:30,724 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004830.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:32,084 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:48:32,087 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:35,919 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004835.wav, taille: 4829 bytes
2025-06-19 00:48:36,031 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004835.wav', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:36,305 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: Impossible de convertir l'audio: Impossible de convertir le fichier audio: Conversion FFmpeg échouée"}
2025-06-19 00:48:36,312 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:37,639 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004837.wav, taille: 24311 bytes
2025-06-19 00:48:37,752 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004837.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:38,630 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:48:38,632 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:45,569 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004845.wav, taille: 80339 bytes
2025-06-19 00:48:45,694 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004845.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:50,132 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:48:50,132 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u064a\\u0641 \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\"\\n            Fran\\u00e7ais: \\"salam Anakin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:48:50,142 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:48:50,148 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:48:51,647 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:48:51,649 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=844 request_id=req_51ae68c581aa8c095b495de85015b457 response_code=200
2025-06-19 00:48:51,789 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:52,031 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004852.wav, taille: 71645 bytes
2025-06-19 00:48:52,147 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004852.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:48:54,724 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:48:54,724 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"m\\u00e9dicament des\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:48:54,724 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:48:54,732 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:48:55,999 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:48:55,999 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=389 request_id=req_d87f9f00437e9d5883cc84a4cd1e8ba1 response_code=200
2025-06-19 00:48:56,111 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'médicament des', 'fused': 'médicament des'}
2025-06-19 00:48:56,113 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:48:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:48:56,649 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004856.wav, taille: 71645 bytes
2025-06-19 00:48:56,826 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004856.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:03,481 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:49:03,481 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:03,714 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004903.wav, taille: 72611 bytes
2025-06-19 00:49:03,819 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004903.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:05,344 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:49:05,347 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:05,869 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004905.wav, taille: 71645 bytes
2025-06-19 00:49:06,040 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004905.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:08,196 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:49:08,199 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:08,549 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004908.wav, taille: 44597 bytes
2025-06-19 00:49:08,679 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004908.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:13,379 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:49:13,381 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:19,169 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004919.wav, taille: 80339 bytes
2025-06-19 00:49:19,289 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004919.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:22,765 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:49:22,767 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646 \\u062f\\u0631\\u062a \\u0627\\u0648\\u0628\\u064a\\u063a\\u0627\\u0633\\u064a\\u0648\\u0646 \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\\u064a\\"\\n            Fran\\u00e7ais: \\"salam anaconda op\\u00e9ration 696\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:49:22,819 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:49:22,834 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:49:23,739 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:49:23,739 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=463 request_id=req_f12c74031dc682342df7fd9dbb1f3462 response_code=200
2025-06-19 00:49:23,874 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:24,120 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004924.wav, taille: 72611 bytes
2025-06-19 00:49:24,254 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004924.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:26,554 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:49:26,568 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u062a\\u0632\\u0627\\u062f \\u0639\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:49:26,576 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:49:26,630 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:49:27,599 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:49:27,609 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=667 request_id=req_17e7320ffd072df4f1af67f5178562d5 response_code=200
2025-06-19 00:49:27,742 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:29,169 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004929.wav, taille: 71645 bytes
2025-06-19 00:49:29,300 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004929.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:31,089 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:49:31,089 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062a\\u062f\\u0627\\u0631\\u064a \\u0627\\u0644\\u062d\\u062f \\u0628\\u0632\\u0627\\u0641\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:49:31,089 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:49:31,099 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:49:32,299 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:49:32,299 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=649 request_id=req_68498bbfc1233d12fcb7bbb567f005ce response_code=200
2025-06-19 00:49:32,437 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:33,766 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004933.wav, taille: 71645 bytes
2025-06-19 00:49:33,882 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004933.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:36,499 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:49:36,499 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Orte tes m\\u00e9dicaments des Antibi\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:49:36,499 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:49:36,499 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:49:37,511 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:49:37,519 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=506 request_id=req_00a184283c4230c5438a0d52d4b26efa response_code=200
2025-06-19 00:49:37,626 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Orte tes médicaments des Antibi', 'fused': 'Ordonne tes médicaments antibiotiques.'}
2025-06-19 00:49:37,629 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:39,169 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004939.wav, taille: 72611 bytes
2025-06-19 00:49:39,319 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004939.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:41,195 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:49:41,199 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:43,862 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004943.wav, taille: 72611 bytes
2025-06-19 00:49:43,999 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004943.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:45,112 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:49:45,112 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:47,170 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004947.wav, taille: 39767 bytes
2025-06-19 00:49:47,304 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004947.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:48,079 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:49:48,079 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:49:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:49:54,430 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_004954.wav, taille: 81305 bytes
2025-06-19 00:49:54,561 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_004954.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:49:58,109 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:49:58,109 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Fran\\u00e7ais: \\"salam Anakin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:49:58,109 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:49:58,120 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:49:59,860 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:49:59,860 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=961 request_id=req_bb4f26c7fcb1c5ecd5dc7b8a63ae04f6 response_code=200
2025-06-19 00:50:00,003 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:00,549 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005000.wav, taille: 72611 bytes
2025-06-19 00:50:00,707 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005000.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:02,949 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:50:02,949 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u062a\\u0632\\u0627\\u062f \\u0639\\u0644\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:50:02,954 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:50:02,954 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:50:04,010 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:50:04,020 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=816 request_id=req_e50bd6f7bfc05081017f69b8d4d750af response_code=200
2025-06-19 00:50:04,152 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:04,377 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005004.wav, taille: 72611 bytes
2025-06-19 00:50:04,484 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005004.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:06,750 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:50:06,750 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"pourtant m\\u00e9dicaments des anti-B\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:50:06,760 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:50:06,767 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:50:07,493 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:50:07,493 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=428 request_id=req_94fac5975d19339314f12e36fa3db7f9 response_code=200
2025-06-19 00:50:07,600 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'pourtant médicaments des anti-B', 'fused': 'Médicaments anti-B.'}
2025-06-19 00:50:07,600 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:09,730 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005009.wav, taille: 71645 bytes
2025-06-19 00:50:09,849 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005009.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:11,827 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:50:11,828 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"les stars\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:50:11,829 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:50:11,836 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:50:13,269 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:50:13,278 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=865 request_id=req_3791cc6f87aeca520471f0f29675cf30 response_code=200
2025-06-19 00:50:13,395 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'les stars', 'fused': 'Les stars.'}
2025-06-19 00:50:13,399 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:14,430 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005014.wav, taille: 71645 bytes
2025-06-19 00:50:14,569 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005014.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:15,979 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:50:15,979 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:19,728 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005019.wav, taille: 72611 bytes
2025-06-19 00:50:19,863 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005019.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:24,743 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:50:24,743 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:27,242 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005027.wav, taille: 80339 bytes
2025-06-19 00:50:27,376 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005027.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:31,609 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:50:31,609 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Fran\\u00e7ais: \\"salam Anakin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:50:31,609 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:50:31,620 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:50:33,329 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:50:33,329 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1399 request_id=req_09a717f8e1d79338bb4b4a8059ca8cde response_code=200
2025-06-19 00:50:33,475 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:34,019 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005034.wav, taille: 71645 bytes
2025-06-19 00:50:34,177 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005034.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:37,429 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:50:37,434 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u062a\\u0632\\u0627\\u062f \\u0639\\u0644\\u064a\\u0647 \\u0627\\u0644\\u062d\\u0627\\u0644 \\u0628\\u0632\\u0627\\u0641 \\u0645\\u0646 \\u0628\\u0639\\u062f \\u062e\\u062f\\u064a\\u062a \\u062f\\u0627\\u0645\\u064a\\u062f\\u064a\\u0643\\"\\n            Fran\\u00e7ais: \\"m\\u00e9dicament\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:50:37,434 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:50:37,444 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:50:38,742 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:50:38,742 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=861 request_id=req_fe2916f9427a540cc6b01d850ccd6dc1 response_code=200
2025-06-19 00:50:38,895 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:39,129 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005039.wav, taille: 72611 bytes
2025-06-19 00:50:39,275 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005039.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:41,629 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:50:41,629 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0628\\u0642\\u0649 \\u0639\\u0646\\u062f\\u064a \\u0635\\u062f\\u0627\\u0639 \\u0645\\u0639 \\u0627\\u0644\\u0639\\u0644\\u0645\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:50:41,634 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:50:41,638 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:50:42,811 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:50:42,811 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=794 request_id=req_17c8dec86012feef3e8f44a3d16870bc response_code=200
2025-06-19 00:50:42,952 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:43,499 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005043.wav, taille: 72611 bytes
2025-06-19 00:50:43,694 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005043.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:46,825 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:50:46,825 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"diab\\u00e9tiques ou qu\'est-ce que la Cholet\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:50:46,830 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:50:46,835 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:50:48,014 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:50:48,019 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=742 request_id=req_82e18ec3dafefed1c06dcc4a2d64965a response_code=200
2025-06-19 00:50:48,142 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "diabétiques ou qu'est-ce que la Cholet", 'fused': '"Diabétiques."'}
2025-06-19 00:50:48,142 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:48,679 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005048.wav, taille: 72611 bytes
2025-06-19 00:50:48,848 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005048.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:50,340 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:50:50,342 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:52,231 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005052.wav, taille: 71645 bytes
2025-06-19 00:50:52,381 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005052.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:53,593 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:50:53,593 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:50:57,560 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005057.wav, taille: 72611 bytes
2025-06-19 00:50:57,710 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005057.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:50:59,376 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:50:59,379 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:50:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:51:01,599 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005101.wav, taille: 61019 bytes
2025-06-19 00:51:01,706 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005101.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:51:02,475 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:51:02,475 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:51:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:51:05,465 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:51:05] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 00:51:05,725 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:51:05,771 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Bonjour, j\'ai subi une op\\u00e9ration la semaine derni\\u00e8re.\\"\\nSegment 2: \\"\\"Ma condition s\'est beaucoup aggrav\\u00e9e apr\\u00e8s avoir pris le m\\u00e9dicament.\\"\\"\\nSegment 3: \\"\\"J\'ai encore des maux de t\\u00eate.\\"\\"\\nSegment 4: \\"\\"Diab\\u00e9tiques.\\"\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:51:05,885 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:51:05,963 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:51:07,651 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:51:07,656 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1387 request_id=req_bffeaca419e0305f19ed2888262c434b response_code=200
2025-06-19 00:51:07,663 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:51:07] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 00:58:38,989 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 00:58:40,000 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 00:58:45,265 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 00:58:45,294 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 00:58:46,123 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_utils.py', reloading
2025-06-19 00:58:46,145 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_utils.py', reloading
2025-06-19 00:58:47,264 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 00:58:51,527 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 00:58:51,545 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 00:58:51,726 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005851.wav, taille: 80339 bytes
2025-06-19 00:58:52,854 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005851.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:58:58,790 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-19 00:58:59,048 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 00:59:01,476 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 00:59:01,491 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 00:59:01,614 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005901.wav, taille: 71645 bytes
2025-06-19 00:59:01,783 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005901.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:05,846 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:05,850 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:06,088 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005906.wav, taille: 71645 bytes
2025-06-19 00:59:06,262 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005906.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:10,178 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:59:10,179 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0645\\u0643\\u0646 \\u062f\\u0631\\u0633\\u064a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0642\\u0644\\u0628\\"\\n            Fran\\u00e7ais: \\"aucune personne\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:59:10,182 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:59:10,189 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:59:12,015 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:59:12,020 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=737 request_id=req_696b6bb3174a86635539ac0a82170db2 response_code=200
2025-06-19 00:59:12,205 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:12,757 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005912.wav, taille: 80339 bytes
2025-06-19 00:59:12,916 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005912.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:16,761 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:59:16,762 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Hanouna\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:59:16,765 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:59:16,772 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:59:18,055 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:59:18,063 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=699 request_id=req_f709ebd87181aec0a872b024a440f5ec response_code=200
2025-06-19 00:59:18,222 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:18,461 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005918.wav, taille: 72611 bytes
2025-06-19 00:59:18,746 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005918.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:24,290 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:24,294 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:24,831 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005924.wav, taille: 71645 bytes
2025-06-19 00:59:25,025 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005924.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:26,590 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:26,593 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:26,829 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005926.wav, taille: 71645 bytes
2025-06-19 00:59:27,024 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005926.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:29,139 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 00:59:29,140 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0632\\u0627\\u062f \\u0639\\u0644\\u064a \\u0627\\u0644\\u062d\\u0627\\u0644 \\u0645\\u0627 \\u0628\\u0642\\u064a\\u062a\\u0634 \\u0643\\u0627\\u0646\\u0642\\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 00:59:29,146 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 00:59:29,154 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 00:59:30,099 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 00:59:30,117 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=610 request_id=req_280a2556ac2094489a0c76914892927c response_code=200
2025-06-19 00:59:30,380 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:31,006 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005930.wav, taille: 71645 bytes
2025-06-19 00:59:31,246 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005930.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:32,264 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:32,274 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:32,555 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005932.wav, taille: 72611 bytes
2025-06-19 00:59:32,929 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005932.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:34,810 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:34,815 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:35,380 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005935.wav, taille: 71645 bytes
2025-06-19 00:59:35,569 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005935.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:37,120 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:37,123 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:37,351 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005937.wav, taille: 71645 bytes
2025-06-19 00:59:37,470 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005937.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:38,468 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:38,471 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:39,013 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005939.wav, taille: 72611 bytes
2025-06-19 00:59:39,156 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005939.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:40,568 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:40,570 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:42,002 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005941.wav, taille: 72611 bytes
2025-06-19 00:59:42,144 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005941.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:43,034 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:43,040 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:47,310 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005947.wav, taille: 72611 bytes
2025-06-19 00:59:47,440 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005947.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:48,885 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:48,885 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:52,036 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005952.wav, taille: 71645 bytes
2025-06-19 00:59:52,247 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005952.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:53,285 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:53,290 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 00:59:55,415 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_005955.wav, taille: 40733 bytes
2025-06-19 00:59:55,540 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_005955.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 00:59:56,367 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 00:59:56,369 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 00:59:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:17:19,401 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:17:19] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 01:17:19,503 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:17:19] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 01:17:19,573 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:17:19] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 01:17:20,021 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:17:20] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 01:24:34,139 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:24:34] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 01:24:34,248 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:24:34] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 01:24:34,318 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:24:34] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 01:24:34,688 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:24:34] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 01:27:31,638 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012731.wav, taille: 80339 bytes
2025-06-19 01:27:31,783 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012731.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:27:34,573 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 01:27:34,573 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u062c\\u0648\\u0633\\u0641\\u064a\\u062f\\u064a\\u0627 \\u0628\\u064a\\u062a\\u064a\\u0643\\"\\n            Fran\\u00e7ais: \\"salam Ana je suis diab\\u00e9tique ou\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 01:27:34,580 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 01:27:34,585 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 01:27:35,676 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 01:27:35,678 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=457 request_id=req_d61bc31bd00097eee692cd73822be185 response_code=200
2025-06-19 01:27:35,820 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:27:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:27:36,329 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012736.wav, taille: 71645 bytes
2025-06-19 01:27:36,457 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012736.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:27:38,968 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 01:27:38,968 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"Oman battle\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 01:27:38,968 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 01:27:38,968 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 01:27:42,818 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 01:27:42,818 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=695 request_id=req_e4843585745a2e36a6f7d30d1729f38d response_code=200
2025-06-19 01:27:42,968 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:27:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:27:43,498 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012743.wav, taille: 71645 bytes
2025-06-19 01:27:43,664 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012743.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:27:45,428 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 01:27:45,428 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0627\\u0644 \\u0645\\u0627 \\u0628\\u0642\\u064a\\u062a\\u0634 \\u0643\\u0627\\u0646\\u0642\\u062f\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 01:27:45,438 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 01:27:45,443 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 01:27:47,448 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 01:27:47,448 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1420 request_id=req_60f607f26b91a6c59f30e9fa90957426 response_code=200
2025-06-19 01:27:47,610 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:27:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:27:47,843 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012747.wav, taille: 71645 bytes
2025-06-19 01:27:47,968 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012747.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:27:50,349 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 01:27:50,349 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"chambre\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 01:27:50,349 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 01:27:50,358 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 01:27:52,218 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 01:27:52,225 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1311 request_id=req_489242ff6b4159d67a821c72a04d2520 response_code=200
2025-06-19 01:27:52,340 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'chambre', 'fused': 'La transcription en Darija est vide et celle en français mentionne uniquement le mot "chambre". Par conséquent, la fusion en une seule phrase en français serait simplement "chambre".'}
2025-06-19 01:27:52,341 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:27:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:27:52,878 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012752.wav, taille: 71645 bytes
2025-06-19 01:27:53,036 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012752.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:27:54,608 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 01:27:54,608 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:27:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:27:56,329 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012756.wav, taille: 72611 bytes
2025-06-19 01:27:56,453 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012756.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:27:57,928 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 01:27:57,928 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:27:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:01,628 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012801.wav, taille: 71645 bytes
2025-06-19 01:28:01,748 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012801.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:02,858 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 01:28:02,858 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:06,634 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012806.wav, taille: 71645 bytes
2025-06-19 01:28:06,768 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012806.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:17,283 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012817.wav, taille: 80339 bytes
2025-06-19 01:28:17,715 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012817.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:19,608 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 01:28:19,609 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:20,868 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 01:28:20,868 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u062c\\u0648\\u0633\\u0641\\u064a\\u0647 \\u062f\\u064a\\u0627\\u0628\\u064a\\u062a\\u064a\\u0643 \\u0648\\u0643\\u0646\\u062a \\u062f\\u0631\\u062a\\u0647\\u0627 \\u0645\\u0627\\u0644\\u064a\\u0647 \\u0639\\u0644\\u0649\\"\\n            Fran\\u00e7ais: \\"salam Ana je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 01:28:20,878 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 01:28:20,883 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 01:28:21,998 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 01:28:21,998 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=659 request_id=req_9bba05c0e5cf1a53b6f5648c0d2368d3 response_code=200
2025-06-19 01:28:22,190 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:22,568 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012822.wav, taille: 71645 bytes
2025-06-19 01:28:22,683 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012822.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:25,863 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 01:28:25,868 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0627\\u0644 \\u0628\\u0632\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 01:28:25,901 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 01:28:25,919 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 01:28:27,263 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012827.wav, taille: 72611 bytes
2025-06-19 01:28:27,408 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012827.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:27,894 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 01:28:27,897 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1142 request_id=req_c1c37632f2d675e301589d89b957ba4e response_code=200
2025-06-19 01:28:28,048 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:28,973 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 01:28:28,978 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:32,558 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012832.wav, taille: 71645 bytes
2025-06-19 01:28:32,683 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012832.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:34,434 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 01:28:34,434 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062a\\u0646\\u0641\\u0633\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 01:28:34,443 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 01:28:34,448 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 01:28:36,018 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 01:28:36,025 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1316 request_id=req_05b455893ae089df14ce5e05fd8e9726 response_code=200
2025-06-19 01:28:36,167 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:37,273 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012837.wav, taille: 71645 bytes
2025-06-19 01:28:37,410 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012837.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:38,291 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 01:28:38,292 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:42,579 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012842.wav, taille: 71645 bytes
2025-06-19 01:28:42,708 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012842.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:43,878 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 01:28:43,903 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:28:47,055 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_012847.wav, taille: 68747 bytes
2025-06-19 01:28:47,179 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_012847.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 01:28:48,291 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 01:28:48,295 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:28:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 01:41:15,614 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-19 01:41:15,619 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-19 01:41:15,623 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\__init__.py', reloading
2025-06-19 01:41:15,629 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-19 01:41:15,689 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py', reloading
2025-06-19 01:41:15,699 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\__init__.py', reloading
2025-06-19 01:41:15,719 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\audio.py', reloading
2025-06-19 01:41:15,723 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\exceptions.py', reloading
2025-06-19 01:41:15,728 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\audio.py', reloading
2025-06-19 01:41:15,731 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\chat_completion.py', reloading
2025-06-19 01:41:15,734 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\deployment.py', reloading
2025-06-19 01:41:15,736 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\engine.py', reloading
2025-06-19 01:41:15,742 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\file.py', reloading
2025-06-19 01:41:15,751 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\fine_tune.py', reloading
2025-06-19 01:41:15,752 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\model.py', reloading
2025-06-19 01:41:15,753 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py', reloading
2025-06-19 01:41:15,759 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\util.py', reloading
2025-06-19 01:41:15,761 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\__init__.py', reloading
2025-06-19 01:41:15,765 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\api_resource.py', reloading
2025-06-19 01:41:15,766 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\createable_api_resource.py', reloading
2025-06-19 01:41:15,767 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\deletable_api_resource.py', reloading
2025-06-19 01:41:15,769 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\listable_api_resource.py', reloading
2025-06-19 01:41:15,772 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\nested_resource_class_methods.py', reloading
2025-06-19 01:41:15,779 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\updateable_api_resource.py', reloading
2025-06-19 01:41:15,781 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_object.py', reloading
2025-06-19 01:41:15,782 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_response.py', reloading
2025-06-19 01:41:15,782 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\object_classes.py', reloading
2025-06-19 01:41:15,782 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\experimental\\completion_config.py', reloading
2025-06-19 01:41:15,789 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py', reloading
2025-06-19 01:41:15,795 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\tempfile.py', reloading
2025-06-19 01:41:15,801 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\typing.py', reloading
2025-06-19 01:41:15,805 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\subprocess.py', reloading
2025-06-19 01:41:15,809 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\traceback.py', reloading
2025-06-19 01:41:15,809 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\wave.py', reloading
2025-06-19 01:41:15,814 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\__init__.py', reloading
2025-06-19 01:41:15,814 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\json\\__init__.py', reloading
2025-06-19 01:41:15,840 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-19 01:41:15,849 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\blueprints.py', reloading
2025-06-19 01:41:15,849 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\config.py', reloading
2025-06-19 01:41:15,859 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\globals.py', reloading
2025-06-19 01:41:15,860 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\helpers.py', reloading
2025-06-19 01:41:15,863 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\typing.py', reloading
2025-06-19 01:41:15,863 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\scaffold.py', reloading
2025-06-19 01:41:15,874 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\utils.py', reloading
2025-06-19 01:41:15,879 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\wrappers.py', reloading
2025-06-19 01:41:15,904 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\__init__.py', reloading
2025-06-19 01:41:15,909 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sounddevice.py', reloading
2025-06-19 01:41:15,914 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\__init__.py', reloading
2025-06-19 01:41:15,924 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\arabic_reshaper\\__init__.py', reloading
2025-06-19 01:41:15,927 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\bidi\\algorithm.py', reloading
2025-06-19 01:41:15,939 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\__init__.py', reloading
2025-06-19 01:41:15,944 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\transforms\\__init__.py', reloading
2025-06-19 01:41:15,944 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\__init__.py', reloading
2025-06-19 01:41:15,944 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\inference\\ASR.py', reloading
2025-06-19 01:41:15,950 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\hyperpyyaml\\__init__.py', reloading
2025-06-19 01:41:15,952 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\logger.py', reloading
2025-06-19 01:41:15,954 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\__init__.py', reloading
2025-06-19 01:41:15,959 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\distributed.py', reloading
2025-06-19 01:41:15,959 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sentencepiece\\__init__.py', reloading
2025-06-19 01:41:15,965 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\data_utils.py', reloading
2025-06-19 01:41:15,974 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\__init__.py', reloading
2025-06-19 01:41:15,979 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\__init__.py', reloading
2025-06-19 01:41:15,979 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\fetching.py', reloading
2025-06-19 01:41:15,990 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\packaging\\__init__.py', reloading
2025-06-19 01:41:15,996 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\packaging\\version.py', reloading
2025-06-19 01:41:15,998 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\inference\\interfaces.py', reloading
2025-06-19 01:41:16,000 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\dataio\\preprocess.py', reloading
2025-06-19 01:41:16,001 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py', reloading
2025-06-19 01:41:16,002 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py', reloading
2025-06-19 01:41:16,009 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py', reloading
2025-06-19 01:41:16,014 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-19 01:41:16,014 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\queue.py', reloading
2025-06-19 01:41:16,019 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\__init__.py', reloading
2025-06-19 01:41:16,040 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py', reloading
2025-06-19 01:41:16,040 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\serialization.py', reloading
2025-06-19 01:41:16,040 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\functional.py', reloading
2025-06-19 01:41:16,052 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\__init__.py', reloading
2025-06-19 01:41:16,053 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\types.py', reloading
2025-06-19 01:41:16,059 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_jit_internal.py', reloading
2025-06-19 01:41:16,064 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\_sounddevice.py', reloading
2025-06-19 01:41:16,066 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\__init__.py', reloading
2025-06-19 01:41:16,070 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\logging.py', reloading
2025-06-19 01:41:16,072 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_sentencepiece_objects.py', reloading
2025-06-19 01:41:16,072 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tokenizers_objects.py', reloading
2025-06-19 01:41:16,079 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_speech_objects.py', reloading
2025-06-19 01:41:16,084 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tensorflow_text_objects.py', reloading
2025-06-19 01:41:16,084 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_keras_nlp_objects.py', reloading
2025-06-19 01:41:16,091 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_vision_objects.py', reloading
2025-06-19 01:41:16,095 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_pt_objects.py', reloading
2025-06-19 01:41:16,101 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tf_objects.py', reloading
2025-06-19 01:41:16,102 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_flax_objects.py', reloading
2025-06-19 01:41:16,109 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py', reloading
2025-06-19 01:41:16,519 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 01:41:20,790 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 01:41:20,819 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 01:42:46,600 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:42:46] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 01:42:46,686 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:42:46] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 01:42:46,767 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:42:46] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 01:42:47,204 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 01:42:47] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:02:56,059 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020256.wav, taille: 80339 bytes
2025-06-19 02:02:56,306 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020256.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:02:59,369 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:02:59,369 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627\\"\\n            Fran\\u00e7ais: \\"salam Alain je suis diab\\u00e9tique ou op\\u00e9ration\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:02:59,369 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:02:59,369 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:03:00,799 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:03:00,809 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=736 request_id=req_5a35e68a15fe4ad53ca613d17990781c response_code=200
2025-06-19 02:03:00,939 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-19 02:03:00,980 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-19 02:03:00,982 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:03:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:03:00,988 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 02:03:00,990 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-19 02:03:01,003 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-19 02:03:01,004 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-19 02:03:01,005 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-19 02:03:01,087 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020301.wav, taille: 78407 bytes
2025-06-19 02:03:01,219 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020301.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:03:02,114 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 02:03:04,348 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 02:03:04,350 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 02:03:04,474 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020304.wav, taille: 78407 bytes
2025-06-19 02:03:04,609 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020304.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:03:07,317 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:03:07,319 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u062a\\u0632\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:03:07,322 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:03:07,325 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:03:10,219 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:03:10,219 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1097 request_id=req_657a90cb4744b98b643d932e208257fc response_code=200
2025-06-19 02:03:10,387 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:03:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:03:10,509 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020310.wav, taille: 78407 bytes
2025-06-19 02:03:10,639 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020310.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:03:12,999 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:03:13,009 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0627 \\u0628\\u0642\\u064a\\u062a\\u0634 \\u0645\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0645\\u0634\\u0643\\u0644\\"\\n            Fran\\u00e7ais: \\"membre du lundi\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:03:13,030 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:03:13,039 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:03:14,109 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:03:14,113 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=761 request_id=req_9d4b9a94a9a0c91a386e84bf6dfad310 response_code=200
2025-06-19 02:03:14,277 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:03:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:03:14,739 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020314.wav, taille: 78407 bytes
2025-06-19 02:03:14,873 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020314.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:03:23,209 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:03:23,209 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"PS4\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:03:23,209 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:03:23,209 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:03:26,319 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:03:26,319 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2515 request_id=req_25602a0448d50972b2e0703d477a1325 response_code=200
2025-06-19 02:03:26,430 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'PS4', 'fused': 'La transcription en Darija est vide et ne contient aucune information médicale, tandis que la transcription en français mentionne "PS4" qui n\'est pas pertinent au contexte médical. Par conséquent, il n\'y a pas de contenu médical à fusionner ou à transcrire.'}
2025-06-19 02:03:26,433 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:03:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:03:26,879 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020326.wav, taille: 88067 bytes
2025-06-19 02:03:27,009 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020326.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:03:28,871 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:03:28,874 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:03:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:03:28,982 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020328.wav, taille: 63917 bytes
2025-06-19 02:03:29,104 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020328.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:03:30,561 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:03:30,563 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:03:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:03:30,989 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020330.wav, taille: 62951 bytes
2025-06-19 02:03:31,102 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020330.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:03:32,762 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:03:32,765 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:03:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:03:53,277 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020353.wav, taille: 80339 bytes
2025-06-19 02:03:53,694 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020353.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:03:55,696 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:03:55,696 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627\\"\\n            Fran\\u00e7ais: \\"salam ah non je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:03:55,699 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:03:55,699 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:03:56,970 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:03:56,970 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=659 request_id=req_8004e819bd10d1c88d7a594d89731581 response_code=200
2025-06-19 02:03:57,123 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:03:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:03:58,589 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020358.wav, taille: 78407 bytes
2025-06-19 02:03:58,731 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020358.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:01,463 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:04:01,463 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0645\\u0644\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:04:01,463 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:04:01,469 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:04:03,199 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:04:03,199 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1445 request_id=req_d2fb407405bc44229b38ed6dced4f7c6 response_code=200
2025-06-19 02:04:03,359 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:03,423 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020403.wav, taille: 78407 bytes
2025-06-19 02:04:03,546 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020403.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:06,129 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:04:06,129 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0627\\u0644 \\u0645\\u0627 \\u0628\\u0642\\u064a\\u062a\\u0634 \\u0643\\u0627\\u062a\\u0642\\u062f\\u0645 \\u0644\\u0647\\u0627 \\u062d\\u062a\\u0649 \\u0627\\u064a\\u0641\\u0648\\u0646 \\u0645\\u0627\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:04:06,139 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:04:06,139 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:04:07,055 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:04:07,079 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=620 request_id=req_873ba05d152736946dd61e43d4543425 response_code=200
2025-06-19 02:04:07,500 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:09,168 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020409.wav, taille: 79373 bytes
2025-06-19 02:04:09,851 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020409.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:11,463 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:11,466 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:13,284 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020413.wav, taille: 69713 bytes
2025-06-19 02:04:13,411 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020413.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:14,487 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:14,497 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:18,593 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020418.wav, taille: 78407 bytes
2025-06-19 02:04:18,710 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020418.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:19,944 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:19,949 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:25,159 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020425.wav, taille: 49265 bytes
2025-06-19 02:04:25,331 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020425.wav', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:25,549 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 02:04:25,585 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: Impossible de convertir l'audio: Impossible de convertir le fichier audio: Conversion FFmpeg échouée"}
2025-06-19 02:04:25,597 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:26,560 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 02:04:28,784 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 02:04:28,793 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 02:04:29,479 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020429.wav, taille: 63917 bytes
2025-06-19 02:04:29,593 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020429.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:30,626 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:30,629 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:34,169 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020434.wav, taille: 63917 bytes
2025-06-19 02:04:34,285 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020434.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:35,229 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:35,229 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:40,479 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020440.wav, taille: 63917 bytes
2025-06-19 02:04:40,589 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020440.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:41,574 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:41,574 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:44,169 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020444.wav, taille: 63917 bytes
2025-06-19 02:04:44,279 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020444.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:45,370 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:45,374 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:49,469 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020449.wav, taille: 63917 bytes
2025-06-19 02:04:49,590 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020449.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:50,601 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:50,604 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:53,304 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020453.wav, taille: 62951 bytes
2025-06-19 02:04:54,738 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020453.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:04:56,749 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:04:56,754 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:04:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:04:58,332 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_020458.wav, taille: 73577 bytes
2025-06-19 02:04:58,553 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_020458.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:05:00,019 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:05:00,072 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:05:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:05:04,342 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\utils.py', reloading
2025-06-19 02:05:05,900 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 02:05:10,884 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 02:05:10,900 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 02:05:16,679 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-19 02:05:17,076 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 02:05:19,821 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 02:05:19,844 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 02:10:32,418 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:10:32] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 02:10:32,514 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:10:32] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 02:10:32,587 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:10:32] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 02:10:33,027 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:10:33] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:10:41,512 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021041.wav, taille: 80339 bytes
2025-06-19 02:10:41,658 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021041.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:10:44,243 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:10:44,245 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627\\"\\n            Fran\\u00e7ais: \\"salam aleykoum alors je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:10:44,245 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:10:44,255 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:10:45,863 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:10:45,863 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=742 request_id=req_aaef2c3038ee3be8b7171fef2923a58f response_code=200
2025-06-19 02:10:46,029 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:10:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:10:46,828 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021046.wav, taille: 78407 bytes
2025-06-19 02:10:46,948 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021046.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:10:48,777 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:10:48,777 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u200fopen \\u062a\\u0631\\u0633\\u0627 \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"open de samedi\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:10:48,783 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:10:48,783 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:10:50,553 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:10:50,553 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=915 request_id=req_4dfc91ce630342ae6e6af6bc71dc0681 response_code=200
2025-06-19 02:10:50,703 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:10:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:10:51,503 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021051.wav, taille: 78407 bytes
2025-06-19 02:10:51,625 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021051.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:10:53,826 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:10:53,826 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"adresse\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:10:53,833 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:10:53,833 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:10:54,783 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:10:54,783 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=376 request_id=req_3aa52d728678fe1d70aaf93313fd208c response_code=200
2025-06-19 02:10:54,891 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'adresse', 'fused': 'Adresse.'}
2025-06-19 02:10:54,894 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:10:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:10:56,815 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021056.wav, taille: 78407 bytes
2025-06-19 02:10:56,953 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021056.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:10:59,325 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:10:59,325 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0631\\u0648\\u0628\\u0647 \\u0628\\u0627\\u0634 \\u0646\\u062f\\u064a\\u0631 \\u0627\\u0641\\u0648\\u0631\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:10:59,333 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:10:59,333 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:11:00,253 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:11:00,253 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=656 request_id=req_04e601db0476c448006f7a25aee2f8ce response_code=200
2025-06-19 02:11:00,385 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:01,514 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021101.wav, taille: 78407 bytes
2025-06-19 02:11:01,673 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021101.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:03,533 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:11:03,534 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0627\\u0634 \\u0646\\u062f\\u064a\\u0631\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:11:03,537 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:11:03,544 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:11:04,183 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:11:04,191 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=364 request_id=req_4c646f9605f43400e29d9257c2ea9d69 response_code=200
2025-06-19 02:11:04,335 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:06,814 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021106.wav, taille: 78407 bytes
2025-06-19 02:11:06,938 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021106.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:07,964 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:11:07,967 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:09,127 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021109.wav, taille: 39767 bytes
2025-06-19 02:11:09,268 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021109.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:10,139 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:11:10,144 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:16,993 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021116.wav, taille: 80339 bytes
2025-06-19 02:11:17,133 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021116.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:20,424 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:11:20,424 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0645\\u0633\\u0645\\u064a\\u0647 \\u062f\\u064a\\u0627\\u0628\\u064a\\"\\n            Fran\\u00e7ais: \\"salam aleykoum \\u00e0 la Chaima je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:11:20,424 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:11:20,424 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:11:21,758 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:11:21,758 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1068 request_id=req_59145de5d0c54a865bb35e57f99b2416 response_code=200
2025-06-19 02:11:21,903 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:22,024 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021122.wav, taille: 78407 bytes
2025-06-19 02:11:22,148 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021122.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:24,474 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:11:24,474 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:11:24,480 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:11:24,484 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:11:25,493 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:11:25,493 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=470 request_id=req_252bcc212ad9ce708d4b4c3796ccf188 response_code=200
2025-06-19 02:11:25,632 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:26,993 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021126.wav, taille: 78407 bytes
2025-06-19 02:11:27,143 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021126.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:28,918 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:11:28,918 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0642\\u0644\\u0628 \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u062a\\u0633\\u062f \\u0639\\u0644\\u064a \\u0627\\u0644\\u062d\\u0627\\u0644\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:11:28,933 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:11:28,935 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:11:29,998 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:11:30,033 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=833 request_id=req_c1ffb04f8e5b86207777b0e2a7d2460d response_code=200
2025-06-19 02:11:30,384 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:31,683 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021131.wav, taille: 78407 bytes
2025-06-19 02:11:31,818 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021131.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:33,941 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:11:33,943 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:36,983 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021136.wav, taille: 78407 bytes
2025-06-19 02:11:37,113 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021136.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:40,090 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:11:40,093 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0635\\u0639\\u0648\\u0628\\u0647 \\u0641\\u064a \\u0627\\u0644\\u062a\\u0646\\u0641\\u0633\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:11:40,093 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:11:40,100 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:11:44,683 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:11:44,683 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1288 request_id=req_30eff69fcd3457e4271efb103c30a285 response_code=200
2025-06-19 02:11:44,864 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:45,033 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021145.wav, taille: 78407 bytes
2025-06-19 02:11:45,248 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021145.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:47,190 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:11:47,194 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:47,547 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021147.wav, taille: 78407 bytes
2025-06-19 02:11:47,683 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021147.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:49,307 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:11:49,307 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:11:51,698 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021151.wav, taille: 78407 bytes
2025-06-19 02:11:51,886 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021151.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:11:59,326 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:11:59,329 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:11:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:03,693 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021203.wav, taille: 80339 bytes
2025-06-19 02:12:03,823 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021203.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:06,963 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:12:06,963 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam and Chaima Andy Playstation\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:12:06,963 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:12:06,977 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:12:08,033 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:12:08,033 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=611 request_id=req_0f12a38a12b51d3daa0e78e5df06f112 response_code=200
2025-06-19 02:12:08,166 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:08,397 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021208.wav, taille: 78407 bytes
2025-06-19 02:12:08,526 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021208.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:10,618 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:12:10,623 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"je suis diab\\u00e9tique des gens ou qu\'une personne\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:12:10,627 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:12:10,630 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:12:11,573 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:12:11,583 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=698 request_id=req_fa56011051410e5624e16a8d665bd4c0 response_code=200
2025-06-19 02:12:11,714 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:13,763 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021213.wav, taille: 78407 bytes
2025-06-19 02:12:14,052 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021213.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:16,763 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:12:16,763 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Google\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:12:16,763 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:12:16,772 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:12:20,343 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:12:20,343 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3007 request_id=req_5078f095960b6b33024470c43e645973 response_code=200
2025-06-19 02:12:20,454 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Google', 'fused': 'La transcription en Darija est vide et le mot "Google" en français n\'est pas pertinent au contexte médical. Par conséquent, il n\'y a pas de contenu à fusionner ou à transcrire.'}
2025-06-19 02:12:20,455 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:20,593 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021220.wav, taille: 78407 bytes
2025-06-19 02:12:20,733 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021220.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:23,723 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:12:23,723 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062a\\u0646\\u0641\\u0633 \\u0645\\u0632\\u064a\\u0627\\u0646 \\u0627\\u0644\\u0627 \\u062f\\u0631\\u062a \\u0627\\u064a \\u0627\\u0646\\u0641\\u0648\\u0631 \\u0643\\u0646\\u062a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:12:23,723 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:12:23,734 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:12:24,783 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:12:24,788 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=775 request_id=req_7554eae1238517a3b3f08d81054441d1 response_code=200
2025-06-19 02:12:24,952 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:25,394 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021225.wav, taille: 78407 bytes
2025-06-19 02:12:25,521 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021225.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:27,521 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:12:27,523 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:28,383 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021228.wav, taille: 78407 bytes
2025-06-19 02:12:28,513 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021228.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:29,755 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:12:29,763 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:33,693 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021233.wav, taille: 78407 bytes
2025-06-19 02:12:33,828 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021233.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:35,373 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:12:35,373 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:38,383 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021238.wav, taille: 78407 bytes
2025-06-19 02:12:38,778 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021238.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:39,823 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:12:39,826 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:43,693 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021243.wav, taille: 78407 bytes
2025-06-19 02:12:43,823 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021243.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:44,856 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:12:44,860 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:48,387 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021248.wav, taille: 78407 bytes
2025-06-19 02:12:48,513 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021248.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:49,905 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:12:49,905 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:12:53,693 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021253.wav, taille: 78407 bytes
2025-06-19 02:12:53,813 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021253.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:12:54,751 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:12:54,755 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:12:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:02,120 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021302.wav, taille: 80339 bytes
2025-06-19 02:13:02,239 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021302.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:04,770 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:13:04,771 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:13:04,773 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:13:04,779 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:13:05,893 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:13:05,902 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=836 request_id=req_f01b9c1883cdf4dac52c12dbb60aa43e response_code=200
2025-06-19 02:13:06,046 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:07,425 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021307.wav, taille: 78407 bytes
2025-06-19 02:13:07,563 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021307.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:10,458 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:13:10,460 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:12,113 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021312.wav, taille: 78407 bytes
2025-06-19 02:13:12,228 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021312.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:14,104 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:13:14,104 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0634\\u0647\\u0631\\u064a\\u0646 \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0643\\u0627\\u0646 \\u062a\\u0632\\u0627\\u062f \\u0639\\u0644\\u064a\\u0647 \\u0627\\u0644\\u062d\\u0627\\u0644\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:13:14,104 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:13:14,113 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:13:15,443 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:13:15,443 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1054 request_id=req_daf14118b7ded3fefaccd3766fca222a response_code=200
2025-06-19 02:13:15,580 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:17,428 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021317.wav, taille: 78407 bytes
2025-06-19 02:13:17,554 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021317.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:20,204 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:13:20,204 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0630\\u0627 \\u062a\\u062d\\u0631\\u0643\\u062a \\u0627\\u0644\\u0627 \\u0637\\u0644\\u0639\\u062a \\u0641\\u064a \\u0627\\u0644\\u062f\\u0631\\u0648\\u062c \\u0627\\u0644\\u0649\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:13:20,204 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:13:20,216 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:13:21,320 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:13:21,322 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=838 request_id=req_f878b1371909d99cfff2681a37170973 response_code=200
2025-06-19 02:13:21,466 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:22,123 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021322.wav, taille: 78407 bytes
2025-06-19 02:13:22,702 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021322.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:25,641 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:13:25,643 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u0627\\u0648\\u0644\\u062a \\u0646\\u062f\\u064a\\u0631 \\u0633\\u0628\\u0648\\u0631\\"\\n            Fran\\u00e7ais: \\"Intersport\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:13:25,653 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:13:25,657 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:13:26,793 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:13:26,803 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=673 request_id=req_9398e40e68536150c58944cb06c0b19a response_code=200
2025-06-19 02:13:26,950 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:27,425 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021327.wav, taille: 78407 bytes
2025-06-19 02:13:27,551 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021327.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:29,572 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:13:29,574 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:32,118 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021332.wav, taille: 78407 bytes
2025-06-19 02:13:32,243 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021332.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:33,736 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:13:33,739 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:36,701 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021336.wav, taille: 66815 bytes
2025-06-19 02:13:36,809 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021336.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:37,938 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:13:37,941 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:47,873 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021347.wav, taille: 80339 bytes
2025-06-19 02:13:48,003 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021347.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:50,652 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:13:50,653 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0627\\u0646\\u0627 \\u062c\\u0648\\u0633\\u0648\\u064a\\u062f\\u064a\\u0627 \\u0628\\u064a\\u062a\\u064a\\u0643\\"\\n            Fran\\u00e7ais: \\"salam Ana Chaima je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:13:50,653 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:13:50,660 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:13:51,623 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:13:51,623 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=699 request_id=req_1b7cc8db9cfaa7d6911ea4817e0d5ee9 response_code=200
2025-06-19 02:13:51,778 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:53,193 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021353.wav, taille: 78407 bytes
2025-06-19 02:13:53,336 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021353.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:13:55,936 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:13:55,936 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0645\\u0643\\u0646 \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0647\\u0630\\u0647 \\u0634\\u0647\\u0631\\u0627\\u064a\\u0646 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0642\\u0644\\u0628\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:13:55,936 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:13:55,936 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:13:57,003 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:13:57,003 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=570 request_id=req_367a7ef534299076a3cdbacee26f6859 response_code=200
2025-06-19 02:13:57,146 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:13:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:13:57,893 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021357.wav, taille: 78407 bytes
2025-06-19 02:13:58,034 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021357.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:14:00,150 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:14:00,153 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:14:03,193 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021403.wav, taille: 78407 bytes
2025-06-19 02:14:03,317 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021403.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:14:05,743 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:14:05,743 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:14:07,883 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021407.wav, taille: 78407 bytes
2025-06-19 02:14:08,013 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021407.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:14:09,103 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:14:09,108 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:14:13,173 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021413.wav, taille: 78407 bytes
2025-06-19 02:14:13,311 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021413.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:14:14,868 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:14:14,873 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:14:16,722 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021416.wav, taille: 14489 bytes
2025-06-19 02:14:16,835 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021416.wav', '-vn', '-f', 'wav', '-'])
2025-06-19 02:14:17,061 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription: Impossible de convertir l'audio: Impossible de convertir le fichier audio: Conversion FFmpeg échouée"}
2025-06-19 02:14:17,064 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:14:54,212 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:54] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 02:14:54,304 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:54] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 02:14:54,388 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:54] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 02:14:54,816 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:14:54] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:15:05,336 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021505.wav, taille: 963653 bytes
2025-06-19 02:15:05,476 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021505.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:08,435 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:15:08,435 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621\\"\\n            Fran\\u00e7ais: \\"salam Ana Rachida je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:15:08,435 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:15:08,448 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:15:10,230 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:15:10,230 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1509 request_id=req_2605fa90b2e52fe643e476a80de87e7f response_code=200
2025-06-19 02:15:10,374 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:10,664 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021510.wav, taille: 963653 bytes
2025-06-19 02:15:10,780 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021510.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:13,055 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:15:13,063 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0645\\u0634\\u0643\\u0644 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0644\\u0628 \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:15:13,069 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:15:13,074 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:15:13,997 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:15:13,997 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=657 request_id=req_9fc916a23a4ed0630ab28c7873da1ab3 response_code=200
2025-06-19 02:15:14,140 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:15,667 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021515.wav, taille: 963653 bytes
2025-06-19 02:15:15,786 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021515.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:17,814 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:15:17,816 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0634\\u0647\\u0631\\u064a\\u0646 \\u0632\\u0627\\u062f \\u0639\\u0644\\u064a \\u0627\\u0644\\u062d\\u0627\\u0644\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:15:17,821 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:15:17,826 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:15:18,886 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:15:18,886 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=587 request_id=req_727dbbffb949028876aff0ad0ec45657 response_code=200
2025-06-19 02:15:19,025 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:20,350 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021520.wav, taille: 963653 bytes
2025-06-19 02:15:20,466 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021520.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:23,565 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:15:23,566 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"\\u00e9l\\u00e9phant couleur\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:15:23,568 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:15:23,570 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:15:24,956 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:15:24,965 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1163 request_id=req_7247a799246681c3c3a037a5326d8a99 response_code=200
2025-06-19 02:15:25,092 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'éléphant couleur', 'fused': 'La transcription en Darija étant vide et le terme "éléphant couleur" en français étant non pertinent au contexte médical, il n\'y a pas de contenu médical à fusionner ou à transcrire.'}
2025-06-19 02:15:25,110 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:25,665 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021525.wav, taille: 963653 bytes
2025-06-19 02:15:25,801 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021525.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:27,365 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:15:27,369 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:30,356 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021530.wav, taille: 961726 bytes
2025-06-19 02:15:30,486 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021530.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:31,447 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:15:31,450 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:35,669 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021535.wav, taille: 963653 bytes
2025-06-19 02:15:35,797 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021535.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:36,630 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:15:36,636 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:40,366 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021540.wav, taille: 963653 bytes
2025-06-19 02:15:40,470 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021540.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:41,729 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:15:41,734 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:45,655 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021545.wav, taille: 963653 bytes
2025-06-19 02:15:45,765 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021545.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:45,822 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021545.wav, taille: 32912 bytes
2025-06-19 02:15:45,977 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021545.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:46,930 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:15:46,936 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:46,955 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:15:46,959 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:47,336 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021547.wav, taille: 208269 bytes
2025-06-19 02:15:47,463 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021547.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:15:48,676 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:15:48,677 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:15:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:15:58,748 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021558.wav, taille: 969434 bytes
2025-06-19 02:15:58,864 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021558.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:01,116 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:16:01,116 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621\\"\\n            Fran\\u00e7ais: \\"salam Ana Chaima je suis diab\\u00e9tique des gens ou\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:16:01,116 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:16:01,130 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:16:02,516 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:16:02,516 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=759 request_id=req_d8f21dd74ef4472ea4f16c42fa684977 response_code=200
2025-06-19 02:16:02,655 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:03,441 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021603.wav, taille: 963653 bytes
2025-06-19 02:16:03,571 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021603.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:05,536 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:16:05,544 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0644\\u0649 \\u0627\\u0644\\u0642\\u0644\\u0628 \\u0647\\u0630\\u0647 \\u0634\\u0647\\u0631\\u064a\\u0646 \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:16:05,550 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:16:05,554 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:16:06,706 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:16:06,714 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=875 request_id=req_33b908b16db8e337209967afa0182b83 response_code=200
2025-06-19 02:16:06,855 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:08,731 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021608.wav, taille: 963653 bytes
2025-06-19 02:16:08,853 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021608.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:13,441 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021613.wav, taille: 963653 bytes
2025-06-19 02:16:13,863 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021613.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:13,940 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:16:13,942 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0627 \\u0628\\u0642\\u064a\\u062a\\u0634 \\u0643\\u0627\\u0646\\u062f\\u064a\\u0631 \\u0645\\u0627 \\u0628\\u0642\\u064a\\u062a\\u0634 \\u0643\\u0627\\u0646\\u0642\\u0627\\u062f \\u0646\\u062f\\u064a\\u0631 \\u0627\\u0641\\u0648\\u0631\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:16:13,955 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:16:14,002 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:16:16,179 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:16:16,180 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:16,262 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:16:16,266 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=628 request_id=req_dc03ea96428127770ba2df3c0bcca6b4 response_code=200
2025-06-19 02:16:16,406 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:18,763 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021618.wav, taille: 965580 bytes
2025-06-19 02:16:18,886 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021618.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:23,461 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021623.wav, taille: 961726 bytes
2025-06-19 02:16:23,656 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021623.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:28,756 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021628.wav, taille: 963653 bytes
2025-06-19 02:16:28,880 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021628.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:29,728 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:16:29,730 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:30,086 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:16:30,091 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:31,006 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:16:31,011 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:33,761 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021633.wav, taille: 963653 bytes
2025-06-19 02:16:33,870 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021633.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:38,446 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021638.wav, taille: 963653 bytes
2025-06-19 02:16:38,566 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:16:38,566 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"poudre kanatani des antibiotiques\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:16:38,572 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:16:38,581 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:16:38,617 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021638.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:41,933 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:16:41,936 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1611 request_id=req_d2dbf08b638cbae837adb9fee5789654 response_code=200
2025-06-19 02:16:42,041 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'poudre kanatani des antibiotiques', 'fused': "La poudre mentionnée est un type d'antibiotiques."}
2025-06-19 02:16:42,045 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:43,756 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021643.wav, taille: 963653 bytes
2025-06-19 02:16:43,886 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021643.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:47,465 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021647.wav, taille: 711216 bytes
2025-06-19 02:16:47,566 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021647.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:48,428 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:48] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:16:48,746 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:16:48,746 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam, je suis Chaima et je suis diab\\u00e9tique.\\"\\nSegment 2: \\"\\"Le patient ressent cette douleur au c\\u0153ur depuis deux mois et elle s\'est intensifi\\u00e9e la semaine derni\\u00e8re.\\"\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Je ne peux plus faire ce que je faisais avant, je n\'arrive plus \\u00e0 g\\u00e9rer.\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"La poudre mentionn\\u00e9e est un type d\'antibiotiques.\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:16:48,751 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:16:48,757 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:16:48,896 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:16:48,898 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:50,544 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:16:50,546 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:55,111 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:16:55,115 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2761 request_id=req_17a0bb0be007c71265f4803191be41dc response_code=200
2025-06-19 02:16:55,117 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:55] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:16:55,194 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:16:55,198 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:16:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:16:56,016 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021655.wav, taille: 967507 bytes
2025-06-19 02:16:56,147 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021655.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:16:59,577 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:16:59,577 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23\\"\\n            Fran\\u00e7ais: \\"salam Alg\\u00e9rie\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:16:59,577 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:16:59,586 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:17:00,712 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021700.wav, taille: 963653 bytes
2025-06-19 02:17:00,821 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021700.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:17:01,394 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:17:01,399 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1343 request_id=req_2be70f60020e326f1b48cbdb55a29fa6 response_code=200
2025-06-19 02:17:01,535 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:03,295 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:17:03,296 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0645\\u0627 \\u0628\\u0642\\u064a\\u062a\\u0634\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:17:03,296 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:17:03,303 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:17:04,227 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:17:04,227 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=655 request_id=req_5405fc41dc366d11f81b35a2bed4f173 response_code=200
2025-06-19 02:17:04,370 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:06,016 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021706.wav, taille: 961726 bytes
2025-06-19 02:17:06,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021706.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:17:09,316 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:17:09,316 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"effort pour presque dire sport\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:17:09,316 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:17:09,316 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:17:10,715 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021710.wav, taille: 963653 bytes
2025-06-19 02:17:10,786 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:17:10,789 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=928 request_id=req_92b258b3d7a2a5a3d6fb228488ef675a response_code=200
2025-06-19 02:17:10,836 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021710.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:17:10,900 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'effort pour presque dire sport', 'fused': 'effort pour presque dire sport'}
2025-06-19 02:17:10,923 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:12,336 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:17:12,336 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u0631\\u0643\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:17:12,336 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:17:12,347 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:17:16,026 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021716.wav, taille: 963653 bytes
2025-06-19 02:17:16,127 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021716.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:17:17,616 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:17:17,624 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4942 request_id=req_c3c18b3dc705e5cb1e52cd670878e0ee response_code=200
2025-06-19 02:17:17,727 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:17:17,729 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:17,780 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:21,026 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021720.wav, taille: 963653 bytes
2025-06-19 02:17:21,128 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021720.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:17:25,710 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021725.wav, taille: 963653 bytes
2025-06-19 02:17:25,831 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021725.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:17:26,559 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:17:26,563 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:27,456 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:17:27,461 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:31,007 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021730.wav, taille: 961726 bytes
2025-06-19 02:17:31,269 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021730.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:17:31,586 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_021731.wav, taille: 171656 bytes
2025-06-19 02:17:31,800 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_021731.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:17:32,896 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:32] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:17:33,027 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:17:33,027 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:33,209 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:17:33,209 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Bonjour, je suis Chaimaa et j\'ai 23 ans.\\"\\nSegment 3: \\"Cette semaine, je ne me suis plus senti bien apr\\u00e8s.\\"\\nSegment 4: \\"effort pour presque dire sport\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Il n\'y a pas de transcription en fran\\u00e7ais fournie pour fusionner avec la transcription en darija \\"\\u062d\\u0631\\u0643\\u0647\\". Veuillez fournir le texte en fran\\u00e7ais pour que je puisse effectuer la fusion selon vos instructions.\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:17:33,212 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:17:33,217 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:17:33,407 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:17:33,410 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:17:35,666 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:17:35,687 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2088 request_id=req_3afacd7874e2f63d34ba1b2ab47e631f response_code=200
2025-06-19 02:17:35,701 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:17:35] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:32:16,303 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:32:16] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 02:32:16,381 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:32:16] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 02:32:16,467 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:32:16] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 02:32:16,886 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:32:16] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:32:54,238 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023254.wav, taille: 48461 bytes
2025-06-19 02:32:54,507 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023254.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:32:56,971 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:32:56,971 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621\\"\\n            Fran\\u00e7ais: \\"salam Ana Rachid\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:32:56,976 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:32:56,985 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:32:58,649 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:32:58,655 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=974 request_id=req_29b8b69f956a4e27d96454582d1a222a response_code=200
2025-06-19 02:32:58,799 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:32:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:32:59,243 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023259.wav, taille: 44597 bytes
2025-06-19 02:32:59,396 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023259.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:01,564 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:33:01,569 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:01,704 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023301.wav, taille: 44597 bytes
2025-06-19 02:33:01,841 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023301.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:05,384 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:33:05,458 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0634\\u0647\\u0631\\u064a\\u0646\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:33:05,507 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:33:05,549 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:33:06,752 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:33:06,755 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=637 request_id=req_5efb344c33764560cf383e2b68a18c03 response_code=200
2025-06-19 02:33:06,891 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:07,352 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023307.wav, taille: 44597 bytes
2025-06-19 02:33:07,493 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023307.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:09,469 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:33:09,473 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:09,569 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023309.wav, taille: 44597 bytes
2025-06-19 02:33:09,704 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023309.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:12,918 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:33:12,922 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:13,371 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023313.wav, taille: 44597 bytes
2025-06-19 02:33:13,509 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023313.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:15,152 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:33:15,154 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:15,287 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023315.wav, taille: 44597 bytes
2025-06-19 02:33:15,438 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023315.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:17,109 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:33:17,119 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:17,568 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023317.wav, taille: 44597 bytes
2025-06-19 02:33:17,695 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023317.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:18,922 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:33:19,021 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:19,270 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023319.wav, taille: 44597 bytes
2025-06-19 02:33:19,592 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023319.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:20,700 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:33:20,706 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:30,120 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023330.wav, taille: 48461 bytes
2025-06-19 02:33:30,432 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023330.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:37,168 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:33:37,168 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam je suis\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:33:37,171 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:33:37,175 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:33:38,918 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:33:38,920 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=428 request_id=req_7ffc67b5e41f08c005ad2c7302445f37 response_code=200
2025-06-19 02:33:39,061 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:39,201 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023339.wav, taille: 44597 bytes
2025-06-19 02:33:39,338 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023339.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:48,434 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:33:48,435 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0646\\u062a \\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:33:48,437 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:33:48,441 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:33:50,910 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:33:50,915 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1569 request_id=req_0e780ec21eff3c58d72a143194c5f803 response_code=200
2025-06-19 02:33:51,070 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:33:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:33:51,507 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023351.wav, taille: 44597 bytes
2025-06-19 02:33:51,641 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023351.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:33:58,505 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:33:58,526 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:33:58,547 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:33:58,557 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:34:01,693 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:34:01,701 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1867 request_id=req_ef70fc0973be9c505ae28c184029681b response_code=200
2025-06-19 02:34:01,842 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:34:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:34:01,987 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023401.wav, taille: 44597 bytes
2025-06-19 02:34:02,140 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023401.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:34:05,442 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:34:05,443 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"hier\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:34:05,447 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:34:05,452 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:34:06,394 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:34:06,409 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=630 request_id=req_92ff7df14267fefe2498b43c1bde7bbd response_code=200
2025-06-19 02:34:06,615 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'hier', 'fused': 'Hier.'}
2025-06-19 02:34:06,656 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:34:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:34:07,174 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023407.wav, taille: 44597 bytes
2025-06-19 02:34:07,323 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023407.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:34:10,810 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:34:10,821 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:34:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:34:11,002 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023410.wav, taille: 44597 bytes
2025-06-19 02:34:11,191 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023410.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:34:12,856 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:34:12,859 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:34:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:34:13,348 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023413.wav, taille: 44597 bytes
2025-06-19 02:34:13,494 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023413.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:34:15,513 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:34:15,520 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:34:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:34:26,101 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023426.wav, taille: 48461 bytes
2025-06-19 02:34:26,236 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023426.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:34:30,882 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:34:30,891 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u062c\\u0648 \\u0633\\u0648\\u064a\\"\\n            Fran\\u00e7ais: \\"salam alors je suis\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:34:30,899 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:34:30,902 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:34:32,496 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:34:32,504 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=396 request_id=req_28ae7c22b8e0d407a78ff68434645348 response_code=200
2025-06-19 02:34:32,766 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:34:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:34:33,236 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023433.wav, taille: 44597 bytes
2025-06-19 02:34:33,416 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023433.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:34:39,100 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:34:39,101 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062f\\u0631\\u0633\\u0647 \\u0645\\u0627\\u062f\\u064a\\u0647 \\u0647\\u0630\\u0647 \\u0634\\u0647\\u0631\\u064a\\u0646\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:34:39,108 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:34:39,115 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:34:55,529 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:34:55,531 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=707 request_id=req_ff77e90280302c2d510817065510b51c response_code=200
2025-06-19 02:34:55,672 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:34:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:34:56,231 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023456.wav, taille: 44597 bytes
2025-06-19 02:34:56,384 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023456.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:34:59,006 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:34:59,011 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u062a\\u062f\\u0631\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:34:59,018 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:34:59,023 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:35:00,221 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:35:00,241 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=880 request_id=req_80cbe6abfd09834bfa493643e85d4309 response_code=200
2025-06-19 02:35:00,387 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:00,444 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023500.wav, taille: 44597 bytes
2025-06-19 02:35:00,567 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023500.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:02,879 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:35:02,879 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"effort\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:35:02,881 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:35:02,881 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:35:07,121 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:35:07,121 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=630 request_id=req_183f6b3969e427376e6ced8f3d532985 response_code=200
2025-06-19 02:35:07,242 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'effort', 'fused': "L'effort."}
2025-06-19 02:35:07,243 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:07,671 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023507.wav, taille: 44597 bytes
2025-06-19 02:35:07,773 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023507.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:09,331 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:35:09,341 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"TF1 sur\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:35:09,341 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:35:09,341 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:35:13,042 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:35:13,051 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2059 request_id=req_26a33e0e90320e7119f0f89380f7f709 response_code=200
2025-06-19 02:35:13,161 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'TF1 sur', 'fused': 'La transcription en Darija est vide et le texte en français "TF1 sur" ne contient aucune information médicale pertinente. Par conséquent, il n\'y a pas de contenu à fusionner ou à transcrire en une phrase médicale cohérente.'}
2025-06-19 02:35:13,161 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:13,600 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023513.wav, taille: 44597 bytes
2025-06-19 02:35:13,711 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023513.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:14,526 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:35:14,526 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:14,651 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023514.wav, taille: 44597 bytes
2025-06-19 02:35:14,783 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023514.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:16,409 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:35:16,411 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:16,842 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023516.wav, taille: 44597 bytes
2025-06-19 02:35:16,945 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023516.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:18,242 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:35:18,245 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:18,371 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023518.wav, taille: 44597 bytes
2025-06-19 02:35:18,473 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023518.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:19,291 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:35:19,291 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:19,726 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023519.wav, taille: 44597 bytes
2025-06-19 02:35:19,831 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023519.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:21,007 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:35:21,009 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:21,136 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023521.wav, taille: 44597 bytes
2025-06-19 02:35:21,235 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023521.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:22,575 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:35:22,576 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:35:23,011 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023523.wav, taille: 44597 bytes
2025-06-19 02:35:23,116 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023523.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:35:25,026 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:35:25,029 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:35:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:36:50,347 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:36:50] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 02:36:50,441 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:36:50] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 02:36:50,513 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:36:50] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 02:36:50,956 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:36:50] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:37:04,308 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023704.wav, taille: 48461 bytes
2025-06-19 02:37:04,431 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023704.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:08,906 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:37:08,906 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u062f\\u064a\\u0631 \\u062a\\u0627\\u0639 \\u0645\\u0627\\"\\n            Fran\\u00e7ais: \\"alarme alarme\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:37:08,906 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:37:08,916 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:37:10,475 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:37:10,475 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=749 request_id=req_e88826b186dd4f97f3a71c87feae761b response_code=200
2025-06-19 02:37:10,615 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:11,056 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023711.wav, taille: 44597 bytes
2025-06-19 02:37:11,175 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023711.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:13,539 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:37:13,546 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:37:13,546 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:37:13,546 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:37:14,761 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:37:14,766 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=603 request_id=req_568564c759a81447d6f7e49377f6c513 response_code=200
2025-06-19 02:37:14,905 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:15,037 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023715.wav, taille: 44597 bytes
2025-06-19 02:37:15,161 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023715.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:17,126 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:37:17,136 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"mosqu\\u00e9e\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:37:17,139 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:37:17,144 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:37:18,346 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:37:18,346 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=640 request_id=req_740c9b56c8bc4e49808be0ab6ac32d6f response_code=200
2025-06-19 02:37:18,466 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'mosquée', 'fused': "Il n'y a pas de contenu médical pertinent à fusionner dans les transcriptions fournies."}
2025-06-19 02:37:18,466 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:18,915 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023718.wav, taille: 44597 bytes
2025-06-19 02:37:19,040 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:21,742 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:21,745 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:21,871 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023721.wav, taille: 44597 bytes
2025-06-19 02:37:22,001 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023721.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:24,206 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:37:24,206 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0627 \\u0628\\u0642\\u064a\\u062a\\u0634 \\u0643\\u0627\\u0646\\u0642\\u062f \\u0646\\u062a\\u0645\\u0634\\u0649\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:37:24,206 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:37:24,216 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:37:25,604 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:37:25,606 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1039 request_id=req_95b09921f8dd524c2705ea3d91460d10 response_code=200
2025-06-19 02:37:25,743 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:26,176 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023726.wav, taille: 44597 bytes
2025-06-19 02:37:26,301 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023726.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:27,718 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:27,721 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:27,852 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023727.wav, taille: 44597 bytes
2025-06-19 02:37:27,960 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023727.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:28,900 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:28,907 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:29,345 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023729.wav, taille: 44597 bytes
2025-06-19 02:37:29,456 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023729.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:30,270 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:30,270 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:30,396 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023730.wav, taille: 44597 bytes
2025-06-19 02:37:30,510 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023730.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:31,489 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:31,489 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:31,946 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023731.wav, taille: 44597 bytes
2025-06-19 02:37:32,072 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023731.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:33,296 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:33,296 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:36,276 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023736.wav, taille: 48461 bytes
2025-06-19 02:37:36,411 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023736.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:37,396 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:37:37,396 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"salam\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:37:37,396 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:37:37,406 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:37:38,006 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:37:38,006 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=374 request_id=req_3120e9e8a8b2abc85678a90d7442ad5c response_code=200
2025-06-19 02:37:38,122 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'salam', 'fused': 'Salam.'}
2025-06-19 02:37:38,126 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:39,611 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023739.wav, taille: 44597 bytes
2025-06-19 02:37:39,746 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023739.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:41,389 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:37:41,390 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0647\\u0630\\u0647 \\u0634\\u0647\\u0631\\u064a\\u0646\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:37:41,390 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:37:41,396 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:37:42,756 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:37:42,756 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=892 request_id=req_a4d56a016a3867d94743fb1a994b21dc response_code=200
2025-06-19 02:37:42,891 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:43,019 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023743.wav, taille: 44597 bytes
2025-06-19 02:37:43,139 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023743.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:44,427 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:44,459 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:45,586 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023745.wav, taille: 44597 bytes
2025-06-19 02:37:45,716 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023745.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:47,270 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:47,270 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:48,303 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023748.wav, taille: 44597 bytes
2025-06-19 02:37:48,411 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023748.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:49,468 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:49,476 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:51,611 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023751.wav, taille: 44597 bytes
2025-06-19 02:37:51,736 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023751.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:53,056 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:53,056 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:54,286 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023754.wav, taille: 44597 bytes
2025-06-19 02:37:54,421 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023754.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:55,470 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:55,474 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:37:57,586 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023757.wav, taille: 44597 bytes
2025-06-19 02:37:57,711 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023757.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:37:58,670 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:37:58,670 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:37:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:00,303 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023800.wav, taille: 44597 bytes
2025-06-19 02:38:00,452 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023800.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:01,286 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:01,288 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:03,596 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023803.wav, taille: 44597 bytes
2025-06-19 02:38:03,741 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023803.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:04,669 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:04,669 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:06,216 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:06] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:38:06,569 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:38:06,604 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam.\\"\\nSegment 2: \\"J\'ai subi une op\\u00e9ration il y a deux mois.\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:38:06,709 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:38:06,730 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023806.wav, taille: 44597 bytes
2025-06-19 02:38:06,788 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:38:07,174 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023806.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:07,618 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:38:07,621 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=529 request_id=req_2b7d1fed78e7f024669257bc2703e835 response_code=200
2025-06-19 02:38:07,622 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:07] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:38:08,349 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:08,386 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:19,544 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:19] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 02:38:19,631 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:19] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 02:38:19,722 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:19] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 02:38:19,836 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:19] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:38:27,211 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023827.wav, taille: 963653 bytes
2025-06-19 02:38:27,405 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023827.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:29,570 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:38:29,570 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0639\\u0645\\u0644\\u064a\\u0647 \\u0647\\u0630\\u0647 \\u0634\\u0647\\u0631\\u064a\\u0646\\"\\n            Fran\\u00e7ais: \\"salam Anatole\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:38:29,581 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:38:29,586 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:38:31,340 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:38:31,340 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1378 request_id=req_a10838e3dfe8ea8aa6e06d4dd7899449 response_code=200
2025-06-19 02:38:31,486 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:31,884 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023831.wav, taille: 961726 bytes
2025-06-19 02:38:32,001 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023831.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:33,901 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:33,901 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:37,200 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023837.wav, taille: 965580 bytes
2025-06-19 02:38:37,340 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023837.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:39,102 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:39,102 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:41,884 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023841.wav, taille: 963653 bytes
2025-06-19 02:38:42,001 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023841.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:43,000 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:43,000 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:47,183 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023847.wav, taille: 963653 bytes
2025-06-19 02:38:47,290 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023847.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:48,167 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:48,170 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:51,890 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023851.wav, taille: 961726 bytes
2025-06-19 02:38:52,025 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023851.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:53,169 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:53,172 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:38:57,201 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023857.wav, taille: 965580 bytes
2025-06-19 02:38:57,302 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023857.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:38:58,251 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:38:58,251 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:38:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:39:01,890 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023901.wav, taille: 963653 bytes
2025-06-19 02:39:02,005 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023901.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:39:02,800 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:39:02,805 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:39:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:39:04,128 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023904.wav, taille: 373991 bytes
2025-06-19 02:39:04,250 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023904.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:39:04,821 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:39:04] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:39:05,001 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:39:05,005 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:39:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:39:05,130 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:39:05,132 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Bonjour, je voulais vous dire que j\'ai subi une op\\u00e9ration il y a deux mois.\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:39:05,142 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:39:05,149 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:39:06,424 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:39:06,427 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=996 request_id=req_2f7686b6532fd35179109563c8743cd4 response_code=200
2025-06-19 02:39:06,429 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:39:06] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:39:58,707 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_023958.wav, taille: 969434 bytes
2025-06-19 02:39:58,846 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_023958.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:40:02,417 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:40:02,419 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062c\\u064a \\u0644\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u064a\\u062a\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam Anakin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:40:02,424 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:40:02,427 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:40:03,387 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024003.wav, taille: 963653 bytes
2025-06-19 02:40:03,544 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024003.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:40:05,497 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:40:05,501 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=627 request_id=req_7aacb51e8106122e729a44c56d68ec87 response_code=200
2025-06-19 02:40:05,649 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:40:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:40:07,722 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:40:07,724 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0645\\u0634\\u0643\\u0644 \\u0641\\u064a \\u0627\\u0644\\u062d\\u0644\\u0627\\u0642\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:40:07,736 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:40:07,741 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:40:08,691 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024008.wav, taille: 963653 bytes
2025-06-19 02:40:08,892 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024008.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:40:10,210 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:40:10,219 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=924 request_id=req_d0731780088d9192571b4a251f37a4ad response_code=200
2025-06-19 02:40:10,353 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:40:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:40:11,000 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:40:11,001 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u062d\\u064a\\u0637\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:40:11,004 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:40:11,008 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:40:12,442 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:40:12,447 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1135 request_id=req_67703864d014da9392a9a0dfeea0dacb response_code=200
2025-06-19 02:40:12,591 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:40:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:40:13,696 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024013.wav, taille: 963653 bytes
2025-06-19 02:40:13,840 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024013.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:40:17,648 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:40:17,653 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:40:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:40:18,386 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024018.wav, taille: 965580 bytes
2025-06-19 02:40:18,537 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024018.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:40:20,524 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024020.wav, taille: 352794 bytes
2025-06-19 02:40:20,623 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:40:20,629 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:40:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:40:20,679 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024020.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:40:21,514 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:40:21] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:40:21,662 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:40:21,666 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:40:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:40:21,829 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:40:21,830 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salut, je viens pour le ciment chaque semaine.\\"\\nSegment 2: \\"J\'avais un probl\\u00e8me chez le coiffeur.\\"\\nSegment 3: \\"La transcription en Darija \\"\\u0627\\u062d\\u064a\\u0637\\" ne fournit aucun contenu en fran\\u00e7ais \\u00e0 fusionner.\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:40:21,837 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:40:21,843 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:40:24,120 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:40:24,127 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=896 request_id=req_9f6c82bbcebb8d763bd377e09ec8da72 response_code=200
2025-06-19 02:40:24,131 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:40:24] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:42:05,746 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-19 02:42:05,747 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-19 02:42:05,753 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\__init__.py', reloading
2025-06-19 02:42:05,755 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-19 02:42:05,828 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py', reloading
2025-06-19 02:42:05,847 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\__init__.py', reloading
2025-06-19 02:42:05,870 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\audio.py', reloading
2025-06-19 02:42:05,871 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\exceptions.py', reloading
2025-06-19 02:42:05,877 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\audio.py', reloading
2025-06-19 02:42:05,886 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\chat_completion.py', reloading
2025-06-19 02:42:05,886 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\deployment.py', reloading
2025-06-19 02:42:05,899 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\engine.py', reloading
2025-06-19 02:42:05,900 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\file.py', reloading
2025-06-19 02:42:05,902 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\fine_tune.py', reloading
2025-06-19 02:42:05,904 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\model.py', reloading
2025-06-19 02:42:05,913 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_requestor.py', reloading
2025-06-19 02:42:05,920 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\util.py', reloading
2025-06-19 02:42:05,932 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\__init__.py', reloading
2025-06-19 02:42:05,935 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\api_resource.py', reloading
2025-06-19 02:42:05,945 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\createable_api_resource.py', reloading
2025-06-19 02:42:05,950 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\deletable_api_resource.py', reloading
2025-06-19 02:42:05,950 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\listable_api_resource.py', reloading
2025-06-19 02:42:05,964 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\nested_resource_class_methods.py', reloading
2025-06-19 02:42:05,966 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\updateable_api_resource.py', reloading
2025-06-19 02:42:05,968 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_object.py', reloading
2025-06-19 02:42:05,971 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_response.py', reloading
2025-06-19 02:42:05,972 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\object_classes.py', reloading
2025-06-19 02:42:05,975 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\experimental\\completion_config.py', reloading
2025-06-19 02:42:05,977 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py', reloading
2025-06-19 02:42:05,981 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\tempfile.py', reloading
2025-06-19 02:42:05,982 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\typing.py', reloading
2025-06-19 02:42:05,982 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\subprocess.py', reloading
2025-06-19 02:42:05,982 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\traceback.py', reloading
2025-06-19 02:42:05,995 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\wave.py', reloading
2025-06-19 02:42:05,997 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\__init__.py', reloading
2025-06-19 02:42:06,000 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\json\\__init__.py', reloading
2025-06-19 02:42:06,002 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-19 02:42:06,004 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\blueprints.py', reloading
2025-06-19 02:42:06,011 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\config.py', reloading
2025-06-19 02:42:06,014 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\globals.py', reloading
2025-06-19 02:42:06,015 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\helpers.py', reloading
2025-06-19 02:42:06,016 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\typing.py', reloading
2025-06-19 02:42:06,018 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\scaffold.py', reloading
2025-06-19 02:42:06,031 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\utils.py', reloading
2025-06-19 02:42:06,035 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\wrappers.py', reloading
2025-06-19 02:42:06,065 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\__init__.py', reloading
2025-06-19 02:42:06,070 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sounddevice.py', reloading
2025-06-19 02:42:06,080 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\__init__.py', reloading
2025-06-19 02:42:06,085 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\arabic_reshaper\\__init__.py', reloading
2025-06-19 02:42:06,093 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\bidi\\algorithm.py', reloading
2025-06-19 02:42:06,103 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\__init__.py', reloading
2025-06-19 02:42:06,111 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\transforms\\__init__.py', reloading
2025-06-19 02:42:06,111 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\__init__.py', reloading
2025-06-19 02:42:06,115 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\inference\\ASR.py', reloading
2025-06-19 02:42:06,115 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\hyperpyyaml\\__init__.py', reloading
2025-06-19 02:42:06,124 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\logger.py', reloading
2025-06-19 02:42:06,127 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\__init__.py', reloading
2025-06-19 02:42:06,132 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\distributed.py', reloading
2025-06-19 02:42:06,134 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sentencepiece\\__init__.py', reloading
2025-06-19 02:42:06,147 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\data_utils.py', reloading
2025-06-19 02:42:06,149 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\__init__.py', reloading
2025-06-19 02:42:06,150 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\__init__.py', reloading
2025-06-19 02:42:06,151 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\utils\\fetching.py', reloading
2025-06-19 02:42:06,161 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\packaging\\__init__.py', reloading
2025-06-19 02:42:06,161 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\packaging\\version.py', reloading
2025-06-19 02:42:06,166 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\inference\\interfaces.py', reloading
2025-06-19 02:42:06,166 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speechbrain\\dataio\\preprocess.py', reloading
2025-06-19 02:42:06,171 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\__init__.py', reloading
2025-06-19 02:42:06,171 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py', reloading
2025-06-19 02:42:06,178 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py', reloading
2025-06-19 02:42:06,188 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-19 02:42:06,195 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\queue.py', reloading
2025-06-19 02:42:06,195 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\__init__.py', reloading
2025-06-19 02:42:06,215 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py', reloading
2025-06-19 02:42:06,221 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\serialization.py', reloading
2025-06-19 02:42:06,228 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\functional.py', reloading
2025-06-19 02:42:06,233 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\__init__.py', reloading
2025-06-19 02:42:06,234 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\types.py', reloading
2025-06-19 02:42:06,236 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_jit_internal.py', reloading
2025-06-19 02:42:06,239 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\_sounddevice.py', reloading
2025-06-19 02:42:06,245 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\__init__.py', reloading
2025-06-19 02:42:06,245 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\logging.py', reloading
2025-06-19 02:42:06,250 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_sentencepiece_objects.py', reloading
2025-06-19 02:42:06,252 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tokenizers_objects.py', reloading
2025-06-19 02:42:06,254 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_speech_objects.py', reloading
2025-06-19 02:42:06,256 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tensorflow_text_objects.py', reloading
2025-06-19 02:42:06,261 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_keras_nlp_objects.py', reloading
2025-06-19 02:42:06,261 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_vision_objects.py', reloading
2025-06-19 02:42:06,266 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_pt_objects.py', reloading
2025-06-19 02:42:06,266 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_tf_objects.py', reloading
2025-06-19 02:42:06,271 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\dummy_flax_objects.py', reloading
2025-06-19 02:42:06,276 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\configuration_utils.py', reloading
2025-06-19 02:42:06,280 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\feature_extraction_sequence_utils.py', reloading
2025-06-19 02:42:06,284 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\feature_extraction_utils.py', reloading
2025-06-19 02:42:06,286 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\__init__.py', reloading
2025-06-19 02:42:06,288 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_tf_pytorch_utils.py', reloading
2025-06-19 02:42:06,291 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\marian\\__init__.py', reloading
2025-06-19 02:42:06,296 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\__init__.py', reloading
2025-06-19 02:42:06,297 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\processing_utils.py', reloading
2025-06-19 02:42:06,300 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils.py', reloading
2025-06-19 02:42:06,302 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py', reloading
2025-06-19 02:42:06,305 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\quantization_config.py', reloading
2025-06-19 02:42:06,310 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_utils.py', reloading
2025-06-19 02:42:06,319 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pytorch_utils.py', reloading
2025-06-19 02:42:06,321 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_tf_utils.py', reloading
2025-06-19 02:42:06,326 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\feature_extraction_wav2vec2.py', reloading
2025-06-19 02:42:06,330 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py', reloading
2025-06-19 02:42:06,335 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py', reloading
2025-06-19 02:42:06,338 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\deepspeed.py', reloading
2025-06-19 02:42:06,340 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\safetensors\\torch.py', reloading
2025-06-19 02:42:06,345 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\hub.py', reloading
2025-06-19 02:42:06,351 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\import_utils.py', reloading
2025-06-19 02:42:06,351 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\versions.py', reloading
2025-06-19 02:42:06,356 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\__init__.py', reloading
2025-06-19 02:42:06,361 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\utils\\__init__.py', reloading
2025-06-19 02:42:06,366 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\bitsandbytes.py', reloading
2025-06-19 02:42:06,371 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_flax_pytorch_utils.py', reloading
2025-06-19 02:42:06,372 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\__init__.py', reloading
2025-06-19 02:42:06,375 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py', reloading
2025-06-19 02:42:06,385 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py', reloading
2025-06-19 02:42:06,388 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\doc.py', reloading
2025-06-19 02:42:06,395 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\generic.py', reloading
2025-06-19 02:42:06,398 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\__init__.py', reloading
2025-06-19 02:42:06,402 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py', reloading
2025-06-19 02:42:06,403 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\streamers.py', reloading
2025-06-19 02:42:06,404 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\logits_process.py', reloading
2025-06-19 02:42:06,404 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\stopping_criteria.py', reloading
2025-06-19 02:42:06,416 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py', reloading
2025-06-19 02:42:06,438 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\re.py', reloading
2025-06-19 02:42:06,446 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\datetime.py', reloading
2025-06-19 02:42:06,446 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\webbrowser.py', reloading
2025-06-19 02:42:06,452 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\big_modeling.py', reloading
2025-06-19 02:42:06,455 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\utils\\dataclasses.py', reloading
2025-06-19 02:42:06,461 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\utils\\environment.py', reloading
2025-06-19 02:42:06,465 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\utils\\imports.py', reloading
2025-06-19 02:42:06,467 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\accelerate\\utils\\modeling.py', reloading
2025-06-19 02:42:06,471 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\memory.py', reloading
2025-06-19 02:42:06,476 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\random.py', reloading
2025-06-19 02:42:06,487 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\constants.py', reloading
2025-06-19 02:42:06,490 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\logging.py', reloading
2025-06-19 02:42:06,495 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\tqdm.py', reloading
2025-06-19 02:42:06,500 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\_typing.py', reloading
2025-06-19 02:42:06,500 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\utils\\_validators.py', reloading
2025-06-19 02:42:06,506 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py', reloading
2025-06-19 02:42:06,511 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_nested_sequence.py', reloading
2025-06-19 02:42:06,513 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_scalars.py', reloading
2025-06-19 02:42:06,514 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_shape.py', reloading
2025-06-19 02:42:06,517 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_dtype_like.py', reloading
2025-06-19 02:42:06,531 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_array_like.py', reloading
2025-06-19 02:42:06,531 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_generic_alias.py', reloading
2025-06-19 02:42:06,535 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\typing\\__init__.py', reloading
2025-06-19 02:42:06,535 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\autograd\\grad_mode.py', reloading
2025-06-19 02:42:06,540 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\_contextlib.py', reloading
2025-06-19 02:42:06,545 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\_backend\\__init__.py', reloading
2025-06-19 02:42:06,545 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\arabic_reshaper\\arabic_reshaper.py', reloading
2025-06-19 02:42:06,550 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\_backend\\utils.py', reloading
2025-06-19 02:42:06,553 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\_backend\\backend.py', reloading
2025-06-19 02:42:06,555 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\transforms\\_transforms.py', reloading
2025-06-19 02:42:06,556 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\marian\\tokenization_marian.py', reloading
2025-06-19 02:42:06,561 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\marian\\modeling_marian.py', reloading
2025-06-19 02:42:06,566 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\detector_factory.py', reloading
2025-06-19 02:42:06,566 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\detector.py', reloading
2025-06-19 02:42:06,571 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\language.py', reloading
2025-06-19 02:42:06,577 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\utils\\ngram.py', reloading
2025-06-19 02:42:06,582 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\langdetect\\utils\\messages.py', reloading
2025-06-19 02:42:06,590 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\hyperpyyaml\\core.py', reloading
2025-06-19 02:42:06,596 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\__init__.py', reloading
2025-06-19 02:42:06,601 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\cyaml.py', reloading
2025-06-19 02:42:06,603 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\main.py', reloading
2025-06-19 02:42:06,604 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\constructor.py', reloading
2025-06-19 02:42:06,610 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\resolver.py', reloading
2025-06-19 02:42:06,610 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\error.py', reloading
2025-06-19 02:42:06,610 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\tokens.py', reloading
2025-06-19 02:42:06,621 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\events.py', reloading
2025-06-19 02:42:06,621 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\nodes.py', reloading
2025-06-19 02:42:06,629 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\loader.py', reloading
2025-06-19 02:42:06,633 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\comments.py', reloading
2025-06-19 02:42:06,633 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\tag.py', reloading
2025-06-19 02:42:06,638 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\reader.py', reloading
2025-06-19 02:42:06,639 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\scanner.py', reloading
2025-06-19 02:42:06,645 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\parser.py', reloading
2025-06-19 02:42:06,645 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\composer.py', reloading
2025-06-19 02:42:06,645 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\ruamel\\yaml\\util.py', reloading
2025-06-19 02:42:06,671 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\datastructures\\__init__.py', reloading
2025-06-19 02:42:07,017 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 02:42:12,001 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 02:42:12,016 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 02:42:13,236 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:42:13] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 02:42:13,310 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:42:13] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 02:42:13,381 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:42:13] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 02:42:13,861 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:42:13] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:44:15,178 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024415.wav, taille: 80339 bytes
2025-06-19 02:44:15,314 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024415.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:44:16,640 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:44:16,656 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:44:19,885 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024419.wav, taille: 76475 bytes
2025-06-19 02:44:20,008 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024419.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:44:21,403 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:44:21,409 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:44:25,178 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024425.wav, taille: 77441 bytes
2025-06-19 02:44:25,293 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024425.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:44:26,802 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:44:26,802 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:44:29,869 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024429.wav, taille: 77441 bytes
2025-06-19 02:44:29,985 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024429.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:44:31,519 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:44:31,519 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:44:35,178 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024435.wav, taille: 76475 bytes
2025-06-19 02:44:35,293 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024435.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:44:36,785 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:44:36,788 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:44:39,871 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024439.wav, taille: 76475 bytes
2025-06-19 02:44:39,988 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024439.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:44:41,469 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:44:41,469 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:44:42,618 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:42] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:44:42,888 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:44:42,888 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:44:42,888 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:44:42,888 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:44:44,152 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:44:44,160 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1040 request_id=req_507f71e593b302a58acc69030c6d00d5 response_code=200
2025-06-19 02:44:44,171 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:44] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:44:58,064 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:58] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 02:44:58,164 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:58] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 02:44:58,240 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:58] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 02:44:58,284 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:44:58] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:45:07,980 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024507.wav, taille: 965580 bytes
2025-06-19 02:45:08,117 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024507.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:09,101 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:09,105 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:12,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024512.wav, taille: 963653 bytes
2025-06-19 02:45:12,770 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024512.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:14,151 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:14,151 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:17,982 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024517.wav, taille: 963653 bytes
2025-06-19 02:45:18,100 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024517.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:19,203 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:19,203 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:22,670 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024522.wav, taille: 963653 bytes
2025-06-19 02:45:22,775 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024522.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:24,283 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:24,287 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:27,982 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024527.wav, taille: 963653 bytes
2025-06-19 02:45:28,100 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024527.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:29,583 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:29,590 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:32,670 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024532.wav, taille: 961726 bytes
2025-06-19 02:45:32,790 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024532.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:34,266 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:34,270 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:37,951 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024537.wav, taille: 963653 bytes
2025-06-19 02:45:38,070 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024537.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:39,610 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:39,615 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:42,688 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024542.wav, taille: 963653 bytes
2025-06-19 02:45:43,053 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024542.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:44,437 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:44] "OPTIONS /api/transcription/save HTTP/1.1" 200 -
2025-06-19 02:45:44,500 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:44,500 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:44,751 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:44] "POST /api/transcription/save HTTP/1.1" 200 -
2025-06-19 02:45:47,970 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024547.wav, taille: 959799 bytes
2025-06-19 02:45:48,100 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024547.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:49,550 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:49,550 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:45:50,951 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024550.wav, taille: 632209 bytes
2025-06-19 02:45:51,083 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024550.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:45:51,996 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:45:51,997 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:45:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:46:14,694 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:46:14] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 02:46:14,778 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:46:14] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 02:46:14,778 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:46:14] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 02:46:15,264 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:46:15] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 02:46:46,828 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024646.wav, taille: 965580 bytes
2025-06-19 02:46:46,940 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024646.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:46:48,346 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:46:48,346 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:46:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:46:52,128 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024652.wav, taille: 963653 bytes
2025-06-19 02:46:52,234 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024652.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:46:53,579 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:46:53,584 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:46:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:46:56,828 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024656.wav, taille: 963653 bytes
2025-06-19 02:46:56,954 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024656.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:46:58,414 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:46:58,414 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:46:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:47:02,162 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024702.wav, taille: 965580 bytes
2025-06-19 02:47:02,274 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024702.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:47:03,862 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:47:03,864 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:47:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:47:06,844 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024706.wav, taille: 963653 bytes
2025-06-19 02:47:06,949 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024706.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:47:08,514 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:47:08,514 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:47:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:47:12,164 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024712.wav, taille: 961726 bytes
2025-06-19 02:47:12,275 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024712.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:47:13,930 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:47:13,930 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:47:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:47:16,845 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024716.wav, taille: 963653 bytes
2025-06-19 02:47:16,962 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024716.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:47:18,554 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:47:18,554 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:47:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:47:22,144 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024722.wav, taille: 963653 bytes
2025-06-19 02:47:22,264 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024722.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:47:22,696 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_024722.wav, taille: 165875 bytes
2025-06-19 02:47:22,841 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_024722.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 02:47:23,561 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:47:23,564 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:47:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:47:24,041 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 02:47:24,048 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:47:24] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 02:47:24,056 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:47:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 02:47:24,523 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 02:47:24,524 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 02:47:24,537 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 02:47:24,545 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 02:47:27,817 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 02:47:27,819 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2898 request_id=req_06fe454c88b28e5dfa282fe366f3af98 response_code=200
2025-06-19 02:47:27,821 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 02:47:27] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 04:10:51,250 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.62:5000
2025-06-19 04:10:51,321 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-19 04:10:51,555 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:10:54,930 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:10:54,963 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:11:17,134 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\__init__.py', reloading
2025-06-19 04:11:17,169 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\blueprints.py', reloading
2025-06-19 04:11:17,228 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\scaffold.py', reloading
2025-06-19 04:11:18,387 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:11:23,245 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:11:23,261 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:11:37,703 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\__init__.py', reloading
2025-06-19 04:11:37,774 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\terminal\\embed.py', reloading
2025-06-19 04:11:38,207 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:11:41,881 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:11:41,898 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:11:42,062 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_stats_py.py', reloading
2025-06-19 04:11:42,261 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\distributions.py', reloading
2025-06-19 04:11:42,394 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_continuous_distns.py', reloading
2025-06-19 04:11:42,643 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_discrete_distns.py', reloading
2025-06-19 04:11:42,727 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_morestats.py', reloading
2025-06-19 04:11:42,834 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_multicomp.py', reloading
2025-06-19 04:11:42,902 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_binned_statistic.py', reloading
2025-06-19 04:11:42,924 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:11:42] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 04:11:42,990 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_multivariate.py', reloading
2025-06-19 04:11:43,014 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:11:43] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 04:11:43,049 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:11:43] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 04:11:43,145 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_entropy.py', reloading
2025-06-19 04:11:43,565 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:11:46,575 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:11:46,588 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:11:46,720 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:11:46] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-06-19 04:11:46,720 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:11:46] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 04:11:47,650 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sympy\\core\\intfunc.py', reloading
2025-06-19 04:11:48,168 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:11:52,095 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:11:52,120 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:11:52,303 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\vegalite\\v5\\schema\\core.py', reloading
2025-06-19 04:11:52,598 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\vegalite\\v5\\display.py', reloading
2025-06-19 04:11:52,669 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\utils\\data.py', reloading
2025-06-19 04:11:52,752 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\vegalite\\v5\\data.py', reloading
2025-06-19 04:11:52,878 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\vegalite\\data.py', reloading
2025-06-19 04:11:52,942 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\utils\\schemapi.py', reloading
2025-06-19 04:11:53,031 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\expr\\core.py', reloading
2025-06-19 04:11:53,079 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\vegalite\\v5\\compiler.py', reloading
2025-06-19 04:11:53,120 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\jupyter\\__init__.py', reloading
2025-06-19 04:11:53,176 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\jupyter\\jupyter_chart.py', reloading
2025-06-19 04:11:53,260 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\expr\\__init__.py', reloading
2025-06-19 04:11:53,308 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\utils\\__init__.py', reloading
2025-06-19 04:11:53,350 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\altair\\utils\\deprecation.py', reloading
2025-06-19 04:11:53,618 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:11:57,076 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:11:57,089 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:11:57,382 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\filelock\\_soft.py', reloading
2025-06-19 04:11:57,458 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041157.wav, taille: 994485 bytes
2025-06-19 04:11:57,471 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\filelock\\_unix.py', reloading
2025-06-19 04:11:57,537 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\filelock\\_windows.py', reloading
2025-06-19 04:11:57,572 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\fitz\\__init__.py', reloading
2025-06-19 04:11:57,623 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\app.py', reloading
2025-06-19 04:11:57,718 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\__init__.py', reloading
2025-06-19 04:11:57,833 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\blueprints.py', reloading
2025-06-19 04:11:57,887 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\sansio\\blueprints.py', reloading
2025-06-19 04:11:57,927 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041157.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:11:57,947 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\cli.py', reloading
2025-06-19 04:11:58,033 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\config.py', reloading
2025-06-19 04:11:58,087 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\ctx.py', reloading
2025-06-19 04:11:58,150 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\debughelpers.py', reloading
2025-06-19 04:11:58,234 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\globals.py', reloading
2025-06-19 04:11:58,308 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\helpers.py', reloading
2025-06-19 04:11:58,369 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\json\\__init__.py', reloading
2025-06-19 04:11:58,410 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\logging.py', reloading
2025-06-19 04:11:58,497 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\flask\\sessions.py', reloading
2025-06-19 04:11:58,788 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:12:01,937 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:12:01,947 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:12:02,097 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\hstspreload\\__init__.py', reloading
2025-06-19 04:12:02,133 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041202.wav, taille: 961726 bytes
2025-06-19 04:12:02,230 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\httpcore\\__init__.py', reloading
2025-06-19 04:12:02,281 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\httpcore\\_async\\base.py', reloading
2025-06-19 04:12:02,403 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\httpcore\\_async\\connection_pool.py', reloading
2025-06-19 04:12:02,468 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\httpcore\\_async\\http_proxy.py', reloading
2025-06-19 04:12:02,496 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041202.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:12:02,505 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\httpcore\\_exceptions.py', reloading
2025-06-19 04:12:02,649 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\httpcore\\_sync\\base.py', reloading
2025-06-19 04:12:02,825 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\httpcore\\_sync\\connection_pool.py', reloading
2025-06-19 04:12:03,184 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\httpcore\\_sync\\http_proxy.py', reloading
2025-06-19 04:12:04,168 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:12:12,772 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:12:12,787 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:12:12,963 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\isoduration\\formatter\\exceptions.py', reloading
2025-06-19 04:12:12,989 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\isoduration\\parser\\__init__.py', reloading
2025-06-19 04:12:13,022 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041212.wav, taille: 963653 bytes
2025-06-19 04:12:13,022 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041212.wav, taille: 963653 bytes
2025-06-19 04:12:13,073 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\isoduration\\parser\\exceptions.py', reloading
2025-06-19 04:12:13,132 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\isort\\__init__.py', reloading
2025-06-19 04:12:13,170 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\isort\\_version.py', reloading
2025-06-19 04:12:13,218 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\isort\\api.py', reloading
2025-06-19 04:12:13,268 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041212.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:12:13,268 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\isort\\place.py', reloading
2025-06-19 04:12:13,330 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\isort\\settings.py', reloading
2025-06-19 04:12:13,355 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041212.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:12:13,435 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\jedi\\__init__.py', reloading
2025-06-19 04:12:13,482 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\jinja2\\__init__.py', reloading
2025-06-19 04:12:13,582 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\jinja2\\bccache.py', reloading
2025-06-19 04:12:13,683 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\jinja2\\environment.py', reloading
2025-06-19 04:12:13,897 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\jinja2\\exceptions.py', reloading
2025-06-19 04:12:14,012 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\jinja2\\loaders.py', reloading
2025-06-19 04:12:14,094 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\jinja2\\runtime.py', reloading
2025-06-19 04:12:14,369 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:12:20,202 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:12:20,219 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:12:20,513 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\narwhals\\dataframe.py', reloading
2025-06-19 04:12:20,519 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041220.wav, taille: 973288 bytes
2025-06-19 04:12:20,520 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041220.wav, taille: 973288 bytes
2025-06-19 04:12:20,708 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\narwhals\\dtypes.py', reloading
2025-06-19 04:12:20,787 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\narwhals\\expr.py', reloading
2025-06-19 04:12:20,850 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041220.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:12:20,890 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041220.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:12:20,898 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\narwhals\\functions.py', reloading
2025-06-19 04:12:21,084 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\narwhals\\schema.py', reloading
2025-06-19 04:12:21,164 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\narwhals\\series.py', reloading
2025-06-19 04:12:21,239 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\narwhals\\translate.py', reloading
2025-06-19 04:12:21,388 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\narwhals\\utils.py', reloading
2025-06-19 04:12:21,469 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\nbclient\\__init__.py', reloading
2025-06-19 04:12:21,559 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\nbclient\\_version.py', reloading
2025-06-19 04:12:21,806 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:12:29,779 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.62:5000
2025-06-19 04:12:29,779 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-19 04:12:29,820 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:12:32,891 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:12:32,908 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:12:33,089 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\odr\\_models.py', reloading
2025-06-19 04:12:33,146 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\__init__.py', reloading
2025-06-19 04:12:33,206 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_waveforms.py', reloading
2025-06-19 04:12:33,261 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_bsplines.py', reloading
2025-06-19 04:12:33,311 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_filter_design.py', reloading
2025-06-19 04:12:33,431 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_fir_filter_design.py', reloading
2025-06-19 04:12:33,503 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_ltisys.py', reloading
2025-06-19 04:12:33,567 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_lti_conversion.py', reloading
2025-06-19 04:12:33,644 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_signaltools.py', reloading
2025-06-19 04:12:33,738 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_spectral_py.py', reloading
2025-06-19 04:12:33,827 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_short_time_fft.py', reloading
2025-06-19 04:12:33,882 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_wavelets.py', reloading
2025-06-19 04:12:33,922 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_peak_finding.py', reloading
2025-06-19 04:12:33,995 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_czt.py', reloading
2025-06-19 04:12:34,038 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\spatial\\__init__.py', reloading
2025-06-19 04:12:34,081 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\spatial\\_kdtree.py', reloading
2025-06-19 04:12:34,368 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:12:57,692 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.62:5000
2025-06-19 04:12:57,693 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-19 04:12:57,727 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:12:59,327 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:12:59,343 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:13:18,182 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:18] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 04:13:18,264 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:18] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 04:13:18,289 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:18] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 04:13:18,664 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:18] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 04:13:27,342 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041327.wav, taille: 965580 bytes
2025-06-19 04:13:27,506 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041327.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:13:29,952 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:13:29,953 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0627\\u0646\\u062a \\u062a\\u0633\\u0648\\u0649 20 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam al Hashima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:13:29,958 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:13:29,964 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:13:31,746 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:13:31,756 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=942 request_id=req_4e6b614db2af4f5cde3d0aebee507adb response_code=200
2025-06-19 04:13:31,896 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-19 04:13:31,952 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-19 04:13:31,959 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-19 04:13:31,956 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:13:31,961 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-19 04:13:31,976 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-19 04:13:31,978 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-19 04:13:31,980 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-19 04:13:32,629 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 04:13:34,926 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 04:13:34,934 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 04:13:35,081 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041335.wav, taille: 963653 bytes
2025-06-19 04:13:35,222 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041335.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:13:37,325 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041337.wav, taille: 963653 bytes
2025-06-19 04:13:37,446 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041337.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:13:38,595 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:13:38,595 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"\\u00e9couter Slimane \\u00e0 kendji\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:13:38,612 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:13:38,615 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:13:39,822 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:13:39,826 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u0644\\u0642\\u0647 \\u0645\\u0646\\u0641\\u0648\\u062e\\u064a\\u0646 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0644\\u064a \\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"la famille Google\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:13:39,832 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:13:39,839 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:13:40,389 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:13:40,396 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=875 request_id=req_8e04b669b5f17a9e8cff4af81d04a8e0 response_code=200
2025-06-19 04:13:40,526 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'écouter Slimane à kendji', 'fused': "La transcription fusionnée est vide car il n'y a pas de contenu médical pertinent à fusionner."}
2025-06-19 04:13:40,531 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:13:41,757 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:13:41,760 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=693 request_id=req_238c16c0355171184a003b6a669d4de7 response_code=200
2025-06-19 04:13:41,934 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:13:42,962 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041342.wav, taille: 963653 bytes
2025-06-19 04:13:43,194 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041342.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:13:44,917 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:13:44,927 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:13:47,336 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041347.wav, taille: 963653 bytes
2025-06-19 04:13:47,486 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041347.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:13:48,471 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:13:48,476 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:13:52,628 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041352.wav, taille: 961726 bytes
2025-06-19 04:13:52,757 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041352.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:13:53,538 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:13:53,538 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:13:56,161 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041356.wav, taille: 738194 bytes
2025-06-19 04:13:56,272 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041356.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:13:57,038 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:13:57,043 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:13:57,440 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:13:57] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 04:13:57,704 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:13:57,708 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam, je suis Chaima et j\'ai 20 ans.\\"\\"\\nSegment 2: \\"La transcription fusionn\\u00e9e est vide car il n\'y a pas de contenu m\\u00e9dical pertinent \\u00e0 fusionner.\\"\\nSegment 3: \\"\\"Il a les ganglions enfl\\u00e9s et m\'a dit de revenir la semaine prochaine.\\"\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:13:57,748 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:13:57,756 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:14:00,441 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:14:00,441 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1705 request_id=req_658423d0754dfb98a06b869c462916e1 response_code=200
2025-06-19 04:14:00,446 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:14:00] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 04:16:44,312 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:16:44] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 04:16:44,414 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:16:44] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 04:16:44,544 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:16:44] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 04:16:44,898 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:16:44] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 04:16:53,675 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041653.wav, taille: 80339 bytes
2025-06-19 04:16:53,804 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041653.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:16:56,465 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:16:56,465 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0643\\u0646\\u062a \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0634\\u0641\\u062a \\u0627\\u0644\\u0637\\"\\n            Fran\\u00e7ais: \\"salam je suis malade\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:16:56,465 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:16:56,465 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:16:57,335 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:16:57,335 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=624 request_id=req_bf385543c19d96b67327579e422eb770 response_code=200
2025-06-19 04:16:57,474 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:16:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:16:58,984 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041658.wav, taille: 80339 bytes
2025-06-19 04:16:59,110 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041658.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:01,315 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:17:01,315 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0644\\u0642 \\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:17:01,324 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:17:01,324 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:17:02,505 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:17:02,505 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=552 request_id=req_a773a8ee071941903f63c24379f545ed response_code=200
2025-06-19 04:17:02,653 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:03,674 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041703.wav, taille: 80339 bytes
2025-06-19 04:17:03,784 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041703.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:06,105 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:17:06,105 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:17:06,105 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:17:06,117 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:17:07,255 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:17:07,255 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=609 request_id=req_c4ba4b903de4707617b3eeea1ea2ecb0 response_code=200
2025-06-19 04:17:07,407 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:08,985 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041708.wav, taille: 80339 bytes
2025-06-19 04:17:09,097 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041708.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:10,915 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:17:10,915 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u064a\\u0641 \\u0648\\u0635\\u0644\\u062a \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0627\\u0644\\u0627 \\u0643\\u0627\\u0646\\u062a \\u062e\\u0627\\u064a\\u0628\\u0647 \\u063a\\u0627\\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"il a 15\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:17:10,915 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:17:10,922 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:17:12,165 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:17:12,171 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1045 request_id=req_12f3cda5c9d34f40add7956c310e07d2 response_code=200
2025-06-19 04:17:12,309 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:13,678 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041713.wav, taille: 80339 bytes
2025-06-19 04:17:13,790 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041713.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:16,129 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:17:16,134 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:18,984 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041718.wav, taille: 80339 bytes
2025-06-19 04:17:19,099 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:20,095 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:17:20,098 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:23,683 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041723.wav, taille: 80339 bytes
2025-06-19 04:17:23,794 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041723.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:24,647 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:17:24,647 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:28,984 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041728.wav, taille: 80339 bytes
2025-06-19 04:17:29,090 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041728.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:29,933 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:17:29,937 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:33,675 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041733.wav, taille: 80339 bytes
2025-06-19 04:17:33,780 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041733.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:34,854 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:17:34,854 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Radi\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:17:34,854 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:17:34,863 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:17:35,814 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:17:35,814 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=646 request_id=req_3033f5de00f1b2c23bcb37281083e676 response_code=200
2025-06-19 04:17:35,929 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Radi', 'fused': 'Radi'}
2025-06-19 04:17:35,929 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:38,985 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041738.wav, taille: 80339 bytes
2025-06-19 04:17:39,096 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041738.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:40,981 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 04:17:40,982 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0641\\u062a\\u062d\\u064a\\u0647 \\u062a\\u0648\\u0645\\u064a\\u062f\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 04:17:40,985 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 04:17:40,988 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 04:17:42,215 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 04:17:42,215 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=913 request_id=req_c626de69c6610ab0abc8048df7023e87 response_code=200
2025-06-19 04:17:42,350 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:43,677 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041743.wav, taille: 80339 bytes
2025-06-19 04:17:43,790 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041743.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:45,214 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:17:45,214 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:48,996 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041748.wav, taille: 80339 bytes
2025-06-19 04:17:49,110 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041748.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:50,060 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:17:50,064 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:53,685 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041753.wav, taille: 80339 bytes
2025-06-19 04:17:53,804 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041753.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:54,779 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:17:54,782 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 04:17:58,534 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_041758.wav, taille: 72611 bytes
2025-06-19 04:17:58,639 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_041758.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 04:17:59,619 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 04:17:59,622 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 04:17:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:40:17,332 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.122:5000
2025-06-19 09:40:17,332 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-19 09:40:17,382 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 09:40:19,249 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 09:40:19,260 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 09:40:40,729 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:40:40] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 09:40:40,808 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:40:40] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 09:40:40,817 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:40:40] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 09:40:41,186 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:40:41] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-06-19 09:40:41,339 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:40:41] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 09:42:02,127 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094202.wav, taille: 81305 bytes
2025-06-19 09:42:02,507 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094202.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:05,977 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:42:05,977 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u062c\\u0648\\u0632 \\u0641\\u064a \\u062f\\u064a\\u0627\\u0628\\u062a\\u064a\\u0643\\"\\n            Fran\\u00e7ais: \\"salam Ana Chaima je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:42:05,977 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:42:05,991 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:42:06,819 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094206.wav, taille: 80339 bytes
2025-06-19 09:42:06,948 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094206.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:07,420 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:42:07,426 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=616 request_id=req_331ec2317b072673c2246e19bdf2312f response_code=200
2025-06-19 09:42:07,573 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-19 09:42:07,627 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-19 09:42:07,632 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:07,641 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-19 09:42:07,668 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-19 09:42:07,676 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-19 09:42:07,896 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 09:42:10,062 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 09:42:10,078 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 09:42:10,192 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094210.wav, taille: 80339 bytes
2025-06-19 09:42:10,332 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094210.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:11,807 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094211.wav, taille: 80339 bytes
2025-06-19 09:42:11,947 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094211.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:13,979 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:42:13,979 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Anthony des m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:42:13,991 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:42:13,997 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:42:14,386 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:42:14,386 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0644\\u0642\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:42:14,396 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:42:14,396 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:42:15,402 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:42:15,402 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=501 request_id=req_415277f0dfb8995644ebc58011820f92 response_code=200
2025-06-19 09:42:15,519 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Anthony des médicaments', 'fused': 'Anthony prend des médicaments.'}
2025-06-19 09:42:15,523 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:15,837 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:42:15,837 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=865 request_id=req_db121fc774920eb0568812927d5fdaa8 response_code=200
2025-06-19 09:42:15,994 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:17,126 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094217.wav, taille: 80339 bytes
2025-06-19 09:42:17,262 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094217.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:19,886 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:42:19,888 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:21,818 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094221.wav, taille: 80339 bytes
2025-06-19 09:42:21,961 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094221.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:23,086 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:42:23,086 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:27,127 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094227.wav, taille: 80339 bytes
2025-06-19 09:42:27,247 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094227.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:28,151 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:42:28,156 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:31,827 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094231.wav, taille: 80339 bytes
2025-06-19 09:42:31,957 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094231.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:32,900 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:42:32,900 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:35,137 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094235.wav, taille: 47495 bytes
2025-06-19 09:42:35,247 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094235.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:35,836 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:35] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 09:42:35,950 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:42:35,955 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:36,157 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:42:36,157 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Bonjour, je suis Chaima et je suis diab\\u00e9tique.\\"\\nSegment 2: \\"Anthony prend des m\\u00e9dicaments.\\"\\nSegment 3: \\"Le patient se plaint de douleurs \\u00e0 la gorge.\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:42:36,191 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:42:36,207 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:42:38,386 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:42:38,386 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1891 request_id=req_d04e9b6d9779c8de3c35bdcde4a0fa80 response_code=200
2025-06-19 09:42:38,391 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:38] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 09:42:51,156 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094251.wav, taille: 80339 bytes
2025-06-19 09:42:51,286 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094251.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:53,961 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:42:53,967 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621\\"\\n            Fran\\u00e7ais: \\"je suis diab\\u00e9tique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:42:53,970 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:42:53,975 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:42:55,849 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094255.wav, taille: 80339 bytes
2025-06-19 09:42:56,026 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094255.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:42:56,391 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:42:56,399 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1577 request_id=req_871962c05d1b863569b0c5d1da0b4bca response_code=200
2025-06-19 09:42:56,553 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:42:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:42:58,907 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:42:58,907 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0641\\u064a\\u0632\\u0627 \\u0639\\u0646 \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0648\\u0643\\u0627\\u0646\\u0639\\u0637\\u0627\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"des m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:42:58,907 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:42:58,917 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:43:00,632 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:43:00,637 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=754 request_id=req_92e2e1e42a4521cc38eceb29b9a4ce1b response_code=200
2025-06-19 09:43:00,773 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:01,137 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094301.wav, taille: 80339 bytes
2025-06-19 09:43:01,248 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094301.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:03,308 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:03,310 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:05,846 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094305.wav, taille: 80339 bytes
2025-06-19 09:43:05,967 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094305.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:09,250 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:09,250 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:11,137 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094311.wav, taille: 80339 bytes
2025-06-19 09:43:11,271 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094311.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:12,334 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:12,337 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:15,837 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094315.wav, taille: 80339 bytes
2025-06-19 09:43:15,967 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094315.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:16,882 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:16,883 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:21,157 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094321.wav, taille: 80339 bytes
2025-06-19 09:43:21,306 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094321.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:22,451 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:22,451 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:25,836 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094325.wav, taille: 80339 bytes
2025-06-19 09:43:25,986 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094325.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:29,133 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:29,136 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:31,156 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094331.wav, taille: 80339 bytes
2025-06-19 09:43:31,287 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094331.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:32,382 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:32,386 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:35,830 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094335.wav, taille: 80339 bytes
2025-06-19 09:43:35,947 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094335.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:36,911 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:36,913 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:41,157 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094341.wav, taille: 80339 bytes
2025-06-19 09:43:41,297 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094341.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:43,658 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:43:43,659 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0648\\u0643\\u0631\\u0627\\u0646\\u064a\\u0627 \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0644\\u064a \\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"au Cannet de cin\\u00e9ma\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:43:43,662 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:43:43,669 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:43:45,086 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:43:45,086 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=768 request_id=req_ff92c2a7e120882194bb96fa45a8f173 response_code=200
2025-06-19 09:43:45,227 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:45,849 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094345.wav, taille: 80339 bytes
2025-06-19 09:43:45,998 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094345.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:48,597 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:43:48,597 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0634\\u0648\\u0641 \\u0648\\u0627\\u0634 \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u062a\\u062d\\u0633\\u0646\\u062a \\u0648\\u0644\\u0627 \\u0644\\u0627\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:43:48,597 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:43:48,597 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:43:49,798 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:43:49,798 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=883 request_id=req_13b20eda8db3b1a743df77a4884ba93b response_code=200
2025-06-19 09:43:49,939 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:51,151 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094351.wav, taille: 80339 bytes
2025-06-19 09:43:51,268 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094351.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:52,433 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:52,437 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:43:55,837 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094355.wav, taille: 80339 bytes
2025-06-19 09:43:55,948 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094355.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:43:58,463 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:43:58,467 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:43:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:44:01,167 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094401.wav, taille: 80339 bytes
2025-06-19 09:44:01,262 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094401.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:44:01,298 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_094401.wav, taille: 2093 bytes
2025-06-19 09:44:01,440 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_094401.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 09:44:01,984 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:44:01] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 09:44:02,196 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:44:02,200 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:44:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:44:02,215 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 09:44:02,218 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:44:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 09:44:02,304 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 09:44:02,305 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Bonjour, je m\'appelle Chaima et je suis diab\\u00e9tique.\\"\\"\\nSegment 2: \\"Le m\\u00e9decin m\'a donn\\u00e9 une ordonnance pour des m\\u00e9dicaments.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 9: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 11: \\"\\"En Ukraine, il a retrouv\\u00e9 la semaine suivante.\\"\\"\\nSegment 12: \\"Regarde si ma condition s\'est am\\u00e9lior\\u00e9e ou non.\\"\\nSegment 13: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 14: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 09:44:02,308 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 09:44:02,312 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 09:44:05,807 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 09:44:05,817 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2866 request_id=req_4ad542821b782fa85a94ba37dcbacc24 response_code=200
2025-06-19 09:44:05,827 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 09:44:05] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 10:06:59,487 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-19 10:06:59,866 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-19 10:07:00,456 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:07:06,269 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:07:06,306 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:07:16,241 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 10:07:17,201 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:07:19,739 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:07:19,756 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:07:20,226 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 10:07:20,226 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 10:07:21,048 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:07:22,941 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:07:22,950 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:08:26,966 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\globals.py', reloading
2025-06-19 10:08:27,039 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\wrappers.py', reloading
2025-06-19 10:08:27,059 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\wrappers\\__init__.py', reloading
2025-06-19 10:08:27,069 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\wrappers\\request.py', reloading
2025-06-19 10:08:27,090 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\sansio\\request.py', reloading
2025-06-19 10:08:27,093 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\json\\__init__.py', reloading
2025-06-19 10:08:27,103 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\wrappers\\response.py', reloading
2025-06-19 10:08:27,141 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\sansio\\response.py', reloading
2025-06-19 10:08:27,171 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\helpers.py', reloading
2025-06-19 10:08:27,281 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\config.py', reloading
2025-06-19 10:08:27,317 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\typing.py', reloading
2025-06-19 10:08:27,336 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\datastructures\\__init__.py', reloading
2025-06-19 10:08:27,381 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sounddevice.py', reloading
2025-06-19 10:08:27,529 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\_sounddevice.py', reloading
2025-06-19 10:08:27,781 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\utils.py', reloading
2025-06-19 10:08:27,873 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\_internal.py', reloading
2025-06-19 10:08:27,951 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\sessions.py', reloading
2025-06-19 10:08:27,969 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\json\\tag.py', reloading
2025-06-19 10:08:28,636 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:08:31,215 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:08:31,232 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:08:38,701 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:08:39,851 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:08:42,246 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:08:42,246 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:09:09,341 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:09:09,346 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:09:09,736 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:09:12,293 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:09:12,298 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:09:52,646 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:09:52] "GET / HTTP/1.1" 200 -
2025-06-19 10:09:52,729 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:09:52] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 10:09:52,806 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:09:52] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 10:09:53,242 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:09:53] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 10:10:05,699 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101005_699.wav, taille: 80339 bytes
2025-06-19 10:10:05,844 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101005_699.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:10:19,835 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101005_699.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:10:33,723 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101005_699.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:10:36,530 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101036_521.wav, taille: 80339 bytes
2025-06-19 10:10:36,645 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101036_521.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:10:36,816 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:10:36,816 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:10:36,827 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:10:36,833 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:10:38,240 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:10:38,240 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=669 request_id=req_03358e3ea78895847833455273f6001c response_code=200
2025-06-19 10:10:39,322 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101005_699.wav
2025-06-19 10:10:39,323 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:10:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:10:43,030 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:10:43,030 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:10:43,030 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:10:43,030 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:10:44,661 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:10:44,677 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=917 request_id=req_1511a4dba3446deb3794c317d876c91d response_code=200
2025-06-19 10:10:45,771 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101036_521.wav
2025-06-19 10:10:45,771 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:10:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:10:46,299 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101046_290.wav, taille: 80339 bytes
2025-06-19 10:10:46,509 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101046_290.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:10:52,579 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101046_290.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:10:58,864 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101046_290.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:03,311 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\recognizers\\google.py', reloading
2025-06-19 10:11:03,840 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:11:04,353 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101046_290.wav
2025-06-19 10:11:04,353 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:11:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:11:04,511 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:11:06,560 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:11:06,561 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:11:06,659 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101106_653.wav, taille: 80339 bytes
2025-06-19 10:11:06,789 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101106_653.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:12,503 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101106_653.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:17,832 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101106_653.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:22,253 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:11:22,764 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101106_653.wav
2025-06-19 10:11:22,766 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:11:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:11:23,304 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101123_300.wav, taille: 80339 bytes
2025-06-19 10:11:23,426 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101123_300.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:28,460 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101123_300.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:33,350 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101123_300.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:36,889 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:11:37,404 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101123_300.wav
2025-06-19 10:11:37,409 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:11:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:11:39,019 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101139_15.wav, taille: 80339 bytes
2025-06-19 10:11:39,242 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101139_15.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:44,484 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101139_15.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:49,191 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101139_15.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:11:52,719 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:11:53,230 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101139_15.wav
2025-06-19 10:11:53,230 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:11:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:11:54,679 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101154_670.wav, taille: 80339 bytes
2025-06-19 10:11:54,814 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101154_670.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:00,120 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101154_670.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:05,030 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101154_670.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:09,174 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:12:09,684 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101154_670.wav
2025-06-19 10:12:09,686 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:12:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:12:10,975 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101210_975.wav, taille: 80339 bytes
2025-06-19 10:12:11,139 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101210_975.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:18,766 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101210_975.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:26,368 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101210_975.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:33,533 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:12:34,050 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101210_975.wav
2025-06-19 10:12:34,050 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:12:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:12:34,680 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101234_676.wav, taille: 80339 bytes
2025-06-19 10:12:34,810 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101234_676.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:40,290 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101234_676.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:45,472 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101234_676.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:49,660 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:12:50,171 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101234_676.wav
2025-06-19 10:12:50,173 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:12:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:12:51,987 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101251_983.wav, taille: 80339 bytes
2025-06-19 10:12:52,110 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101251_983.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:12:56,755 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101251_983.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:01,490 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101251_983.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:06,054 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:13:06,602 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101251_983.wav
2025-06-19 10:13:06,604 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:13:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:13:07,666 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101307_661.wav, taille: 80339 bytes
2025-06-19 10:13:07,809 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101307_661.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:13,905 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101307_661.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:20,167 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101307_661.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:25,225 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:13:25,732 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101307_661.wav
2025-06-19 10:13:25,735 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:13:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:13:27,044 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101327_40.wav, taille: 80339 bytes
2025-06-19 10:13:27,254 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101327_40.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:33,575 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101327_40.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:39,439 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101327_40.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:43,268 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:13:43,781 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101327_40.wav
2025-06-19 10:13:43,782 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:13:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:13:44,714 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101344_710.wav, taille: 80339 bytes
2025-06-19 10:13:45,131 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101344_710.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:50,959 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101344_710.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:13:56,300 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101344_710.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:14:02,570 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:14:03,081 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101344_710.wav
2025-06-19 10:14:03,081 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:14:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:14:03,984 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101403_980.wav, taille: 80339 bytes
2025-06-19 10:14:04,135 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101403_980.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:14:09,918 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101403_980.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:14:15,804 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101403_980.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:14:21,124 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur de transcription après 3 tentatives: 'TranscriptionService' object has no attribute '_transcribe_with_whisper'"}
2025-06-19 10:14:21,649 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101403_980.wav
2025-06-19 10:14:21,649 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:14:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:14:22,203 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_101422_194.wav, taille: 3059 bytes
2025-06-19 10:14:22,483 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_101422_194.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:14:25,129 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Silence ou bruit de fond détecté', 'fused': 'Silence ou bruit de fond détecté'}
2025-06-19 10:14:25,708 - app - INFO - Fichier temporaire supprimé: uploads\audio_20250619_101422_194.wav
2025-06-19 10:14:25,775 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:14:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:14:28,195 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:14:28] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 10:14:28,616 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:14:28,618 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Bonjour, je m\'appelle Chaima et j\'ai 23 ans.\\"\\nSegment 2: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 3: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 4: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 5: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 6: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 7: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 8: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 9: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 10: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 11: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 12: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 13: \\"Erreur de transcription apr\\u00e8s 3 tentatives: \'TranscriptionService\' object has no attribute \'_transcribe_with_whisper\'\\"\\nSegment 14: \\"Silence ou bruit de fond d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:14:28,667 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:14:28,675 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:14:30,849 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:14:30,849 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1060 request_id=req_ad9722774f0d9bbfe2d8ccfda5661c76 response_code=200
2025-06-19 10:14:30,862 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:14:30] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 10:14:49,311 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 10:14:50,544 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:14:54,498 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:14:54,516 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:15:07,280 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:15:07,302 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:15:08,244 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:15:10,262 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:15:10,278 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:15:10,669 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:15:10,675 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:15:11,584 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:15:13,679 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:15:13,684 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:19:14,732 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:19:14] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 10:19:14,812 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:19:14] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 10:19:14,881 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:19:14] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 10:19:15,320 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:19:15] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 10:35:33,954 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:35:34,035 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-19 10:35:34,683 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:35:36,559 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:35:36,572 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:41:31,500 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-19 10:41:32,469 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:41:36,857 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:41:36,871 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:41:53,326 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104153_184.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:41:55,354 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:41:55,354 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne rapidement:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621\\"\\n            Fran\\u00e7ais: \\"salam \\u00e0 Nassima\\"\\n            \\n            Instructions: Produis une phrase fluide en fran\\u00e7ais. Garde uniquement les informations pertinentes.\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-19 10:41:55,354 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:41:55,361 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:41:56,017 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104155_871.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:41:56,652 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:41:56,652 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=492 request_id=req_eb4249bbf89f387513876ed97d272e9c response_code=200
2025-06-19 10:41:57,196 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:41:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:41:59,321 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104159_193.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:00,771 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:02,326 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104202_191.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:03,152 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:05,296 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104205_182.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:05,336 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:08,331 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104208_191.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:08,653 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:11,301 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104211_183.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:11,900 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:14,321 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104214_191.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:14,667 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:17,306 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104217_183.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:17,856 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:20,303 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104220_183.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:21,067 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:23,306 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104223_183.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:24,005 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:25,159 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104224_824.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:27,383 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:27,801 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:41,761 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104241_635.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:44,034 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:42:44,034 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne rapidement:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062c\\u064a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628\\"\\n            Fran\\u00e7ais: \\"salam\\"\\n            \\n            Instructions: Produis une phrase fluide en fran\\u00e7ais. Garde uniquement les informations pertinentes.\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-19 10:42:44,041 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:42:44,041 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:42:44,441 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104244_318.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:44,947 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:42:44,951 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=249 request_id=req_97adabd1e6524e9c7872957905bd073f response_code=200
2025-06-19 10:42:45,473 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:47,751 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104247_634.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:49,101 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:50,783 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104250_633.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:52,386 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:53,741 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104253_621.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:54,134 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:56,741 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104256_631.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:42:57,469 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:42:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:42:59,771 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104259_631.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:01,016 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:02,782 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104302_621.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:04,084 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:05,131 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104305_15.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:06,481 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:08,100 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:27,143 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104327_15.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:29,382 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:43:29,382 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne rapidement:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\"\\n            Fran\\u00e7ais: \\"salam\\"\\n            \\n            Instructions: Produis une phrase fluide en fran\\u00e7ais. Garde uniquement les informations pertinentes.\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-19 10:43:29,382 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:43:29,382 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:43:30,113 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104330_3.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:30,301 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:43:30,304 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=228 request_id=req_ef5e1f56484016a6840b2258587337b8 response_code=200
2025-06-19 10:43:30,821 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:32,731 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:43:32,731 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne rapidement:\\n            Darija: \\"\\u0648\\u0643\\u0646\\u0639\\u0637\\u064a\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"aucune id\\u00e9e m\\u00e9dicament\\"\\n            \\n            Instructions: Produis une phrase fluide en fran\\u00e7ais. Garde uniquement les informations pertinentes.\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-19 10:43:32,731 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:43:32,731 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:43:33,151 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104333_13.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:33,931 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:43:33,941 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=242 request_id=req_33894d5bf1c6021a1b19935e3aa75430 response_code=200
2025-06-19 10:43:34,451 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:36,141 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104336_1.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:37,466 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:39,121 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104339_1.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:40,151 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:42,152 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104342_17.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:43,082 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:45,106 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:45,182 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104345_21.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:47,831 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:48,126 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104348_1.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:51,039 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:51,152 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104351_16.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:53,971 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:43:55,153 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104354_976.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:57,813 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104357_667.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:43:59,368 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:43:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:01,091 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104400_971.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:01,501 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:04,121 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104403_980.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:04,168 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:07,091 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104406_967.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:07,251 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:10,085 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104409_971.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:10,186 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:12,145 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104412_11.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:13,416 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:13,732 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104413_618.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:15,201 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:16,332 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:41,936 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 10:44:41,951 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 10:44:42,577 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 10:44:44,640 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 10:44:44,649 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 10:44:49,399 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104449_281.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:52,066 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104451_962.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:52,465 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:44:52,465 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0643\\u0646\\u062a\\"\\n            Fran\\u00e7ais: \\"salam Ana Chaima\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:44:52,469 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:44:52,472 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:44:53,751 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:44:53,784 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=874 request_id=req_15a058046bf7f9a35664cdc44c351142 response_code=200
2025-06-19 10:44:53,904 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:54,293 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:44:54,293 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0634\\u0627\\u0641 \\u0645\\u0639\\u064a \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u062d\\u0644\\u0642\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:44:54,293 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:44:54,304 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:44:55,401 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104455_281.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:55,651 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:44:55,661 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=750 request_id=req_aaf892ccaa7d387ac973da4472e2dae6 response_code=200
2025-06-19 10:44:55,781 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:44:57,261 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:44:57,261 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646\\u0639\\u0637\\u064a\\u0646\\u064a \\u062f\\u064a \\u0645\\u064a\\u062f\\u064a\\u0643\\u0627\\u0645\\u0648\\u0646\\"\\n            Fran\\u00e7ais: \\"des m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:44:57,271 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:44:57,276 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:44:58,376 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104458_261.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:44:59,012 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:44:59,012 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=910 request_id=req_a163627df64feeaff908b4044386a989 response_code=200
2025-06-19 10:44:59,131 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:44:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:45:01,101 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:45:01,101 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"antibiotique ou galerie\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:45:01,101 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:45:01,114 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:45:01,401 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104501_281.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:45:02,794 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:45:02,813 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=888 request_id=req_da2e3fc267cf0da355112b42399761c8 response_code=200
2025-06-19 10:45:02,931 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:45:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:45:04,371 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104504_262.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:45:04,458 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:45:04,467 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0646\\u0634\\u0648\\u0641 \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:45:04,484 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:45:04,488 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:45:06,012 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:45:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:45:06,093 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:45:06,101 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=822 request_id=req_037778c405402c2d273865a855421574 response_code=200
2025-06-19 10:45:06,212 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:45:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:45:07,406 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104507_261.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:45:08,435 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:45:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:45:10,101 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104509_961.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:45:11,451 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:45:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:45:12,821 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_104512_711.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 10:45:13,402 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:45:13] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 10:45:13,732 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 10:45:13,732 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Bonjour, je suis Chaima.\\"\\nSegment 2: \\"Le m\\u00e9decin a examin\\u00e9 ma gorge.\\"\\nSegment 3: \\"Il me donne des m\\u00e9dicaments.\\"\\nSegment 4: \\"\\"antibiotique\\"\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Je viens pour v\\u00e9rifier ma situation m\\u00e9dicale.\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 10:45:13,732 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 10:45:13,741 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 10:45:13,966 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:45:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 10:45:15,575 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 10:45:15,581 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1410 request_id=req_932ce7da0c5fb39bf676d947e1c50056 response_code=200
2025-06-19 10:45:15,581 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 10:45:15] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:10:18,671 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:10:18] "OPTIONS /api/report/generate HTTP/1.1" 200 -
2025-06-19 11:10:18,920 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:10:18,920 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un m\\u00e9decin expert en r\\u00e9daction de comptes rendus m\\u00e9dicaux.\\n            G\\u00e9n\\u00e8re un compte rendu m\\u00e9dical structur\\u00e9 et professionnel \\u00e0 partir de cette transcription d\'une consultation:\\n            \\n            Transcription: \\"Bonjour, je suis Chaima. Je viens pour v\\u00e9rifier ma situation m\\u00e9dicale. Le m\\u00e9decin a examin\\u00e9 ma gorge et m\'a prescrit des m\\u00e9dicaments, notamment un antibiotique, pour traiter mon\\"\\n            \\n            Structure obligatoire:\\n            - MOTIF DE CONSULTATION\\n            - ANT\\u00c9C\\u00c9DENTS\\n            - EXAMEN CLINIQUE\\n            - DIAGNOSTIC\\n            - PLAN DE TRAITEMENT\\n            - RECOMMANDATIONS\\n            \\n            INSTRUCTIONS IMPORTANTES:\\n            1. MAINTIENS uniquement les informations pr\\u00e9sentes dans la transcription\\n            2. N\'INVENTE aucune information m\\u00e9dicale\\n            3. Si une section ne peut pas \\u00eatre remplie faute d\'informations, indique \\"Non pr\\u00e9cis\\u00e9 dans la consultation\\"\\n            4. UTILISE un fran\\u00e7ais m\\u00e9dical professionnel et adapt\\u00e9\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:10:18,920 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:10:18,920 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:10:26,160 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:10:26,180 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5910 request_id=req_1a3ee4ec3f19f0953bb03fe672bb9d56 response_code=200
2025-06-19 11:10:26,189 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:10:26] "POST /api/report/generate HTTP/1.1" 200 -
2025-06-19 11:22:04,660 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:04] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:22:04,736 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:04] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:22:04,741 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:04] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:22:05,240 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:05] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:22:13,735 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112213_594.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:17,005 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112216_894.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:20,009 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112219_895.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:23,014 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112222_905.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:25,895 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:22:25,895 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0647\\u0644\\u0627 \\u0643\\u064a\\u0641 \\u062f\\u0627\\u064a\\u0631 \\u0628\\u062e\\u064a\\u0631 \\u0644\\u0627 \\u0628\\u0627\\u0633 \\u0639\\u0644\\u064a\\u0643\\"\\n            Fran\\u00e7ais: \\"aflam Kidal\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:22:25,910 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:22:25,926 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:22:26,054 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112225_888.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:26,251 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:26,894 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:26,911 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:27,558 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:22:27,561 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1190 request_id=req_bd97f1f88fbd1ad638066d913bb74db6 response_code=200
2025-06-19 11:22:27,680 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:27,905 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:29,025 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112228_895.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:31,709 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112231_595.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:35,010 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112234_893.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:36,075 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:36,474 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:37,105 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:38,057 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112237_907.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:40,556 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112240_437.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:22:41,754 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:41] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:22:42,071 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:22:42,071 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Bonjour, comment allez-vous, tout va bien, j\'esp\\u00e8re que vous n\'avez pas de soucis.\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:22:42,075 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:22:42,075 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:22:47,706 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:22:49,321 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:22:49,325 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1111 request_id=req_666524edc04f8615bb6d929f9814809a response_code=200
2025-06-19 11:22:49,336 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:49] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:22:50,435 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:22:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:11,528 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:11] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:23:11,596 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:11] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:23:11,686 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:11] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 11:23:12,003 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:12] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:23:20,515 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112320_394.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:23:25,818 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112325_704.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:23:30,824 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112330_705.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:23:35,818 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112335_704.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:23:39,826 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:23:39,826 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0641 \\u062f\\u0627\\u064a\\u0631 \\u0627\\u0644\\u0628\\u0627\\u0631\\u062d \\u0643\\u0646\\u062a \\u0647\\u0627\\u0628\\u0637 \\u0645\\u0646 \\u0627\\u0644\\u062f\\u0631\\u0648\\u062c\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:23:39,835 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:23:39,843 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:23:40,212 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:23:40,212 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0644\\u0649 \\u0631\\u0627\\u0633\\u064a \\u0645\\u0627 \\u0639\\u0631\\u0641\\u062a\\u0634 \\u0641\\u064a\\u0646 \\u063a\\u0627\\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"P\\u00f4le emploi\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:23:40,228 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:23:40,269 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:23:40,424 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:40,547 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:41,009 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:23:41,016 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=416 request_id=req_aca26633fd31fe0fd1acbd406937c5e6 response_code=200
2025-06-19 11:23:41,153 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:41,292 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112340_978.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:23:41,487 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:23:41,514 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=759 request_id=req_84bcd6f57a09ac8d59de4cfbc86f3bda response_code=200
2025-06-19 11:23:41,672 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:43,855 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:45,849 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112345_704.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:23:49,084 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:50,557 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112350_401.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:23:51,970 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112351_854.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:23:52,889 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:52] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:23:53,230 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:23:53,230 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Segment en cours de traitement...\\"\\nSegment 4: \\"Segment en cours de traitement...\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:23:53,241 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:23:53,250 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:23:53,568 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:54,178 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:23:55,435 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:23:55,439 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1132 request_id=req_721f31c8142dde9e35875f3a8f01cb32 response_code=200
2025-06-19 11:23:55,444 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:23:55] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:24:12,515 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-19 11:24:12,575 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\__init__.py', reloading
2025-06-19 11:24:12,609 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\chat_completion.py', reloading
2025-06-19 11:24:12,629 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py', reloading
2025-06-19 11:24:12,669 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\api_resources\\abstract\\api_resource.py', reloading
2025-06-19 11:24:12,694 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\openai_object.py', reloading
2025-06-19 11:24:13,050 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 11:24:16,189 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 11:24:16,203 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 11:24:16,784 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-19 11:24:17,040 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\typing.py', reloading
2025-06-19 11:24:17,049 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\wrappers\\__init__.py', reloading
2025-06-19 11:24:17,055 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\wrappers\\response.py', reloading
2025-06-19 11:24:17,105 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\sansio\\response.py', reloading
2025-06-19 11:24:17,152 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\datastructures\\__init__.py', reloading
2025-06-19 11:24:17,201 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\json\\__init__.py', reloading
2025-06-19 11:24:17,209 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\wrappers.py', reloading
2025-06-19 11:24:17,899 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 11:24:20,044 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 11:24:20,061 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 11:24:21,789 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\__init__.py', reloading
2025-06-19 11:24:21,894 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\typing\\__init__.py', reloading
2025-06-19 11:24:21,904 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_generic_alias.py', reloading
2025-06-19 11:24:21,944 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_array_like.py', reloading
2025-06-19 11:24:21,963 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_nested_sequence.py', reloading
2025-06-19 11:24:21,974 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_dtype_like.py', reloading
2025-06-19 11:24:22,000 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_shape.py', reloading
2025-06-19 11:24:22,053 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_scalars.py', reloading
2025-06-19 11:24:22,199 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py', reloading
2025-06-19 11:24:22,749 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 11:24:25,325 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 11:24:25,347 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 11:24:33,936 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:24:33] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:24:34,066 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:24:34] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:24:34,071 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:24:34] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:24:34,433 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:24:34] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:24:45,025 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112445.wav, taille: 80339 bytes
2025-06-19 11:24:45,396 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112445.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:24:47,673 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:24:47,675 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0644\\u0628\\u0627\\u0631\\u062d \\u0643\\u0646\\u062a \\u063a\\u0627\\u062f\\u064a \\u0643\\u0627\\u0646\\u062a\\u0645\\u0634\\u0649\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:24:47,675 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:24:47,683 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:24:48,415 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:24:48,415 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=355 request_id=req_14b50ee54502e94727c98fe91283e13a response_code=200
2025-06-19 11:24:48,535 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-19 11:24:48,579 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-19 11:24:48,585 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-19 11:24:48,585 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:24:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:24:48,590 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-19 11:24:48,599 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-19 11:24:48,610 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-19 11:24:49,075 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 11:24:51,106 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 11:24:51,120 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 11:24:51,227 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112451.wav, taille: 80339 bytes
2025-06-19 11:24:51,360 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112451.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:24:53,548 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:24:53,548 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:24:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:24:54,707 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112454.wav, taille: 80339 bytes
2025-06-19 11:24:54,835 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112454.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:24:57,345 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:24:57,347 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:24:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:00,025 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112500.wav, taille: 80339 bytes
2025-06-19 11:25:00,148 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112500.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:01,900 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:25:01,900 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:04,705 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112504.wav, taille: 80339 bytes
2025-06-19 11:25:04,832 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112504.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:07,000 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:25:07,002 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Ratatat\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:25:07,004 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:25:07,007 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:25:08,789 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112508.wav, taille: 60053 bytes
2025-06-19 11:25:08,892 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112508.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:09,294 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:25:09,297 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1990 request_id=req_d28629db0b0a91352a0e4ffed98da637 response_code=200
2025-06-19 11:25:09,413 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Ratatat', 'fused': 'La transcription en Darija est vide et celle en français contient uniquement le mot "Ratatat" qui ne semble pas pertinent au contexte médical. Par conséquent, il n\'y a pas de contenu médical à fusionner ou à transcrire.'}
2025-06-19 11:25:09,417 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:09,783 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:09] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:25:10,101 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:25:10,102 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Hier, je marchais.\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"La transcription en Darija est vide et celle en fran\\u00e7ais contient uniquement le mot \\"Ratatat\\" qui ne semble pas pertinent au contexte m\\u00e9dical. Par cons\\u00e9quent, il n\'y a pas de contenu m\\u00e9dical \\u00e0 fusionner ou \\u00e0 transcrire.\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:25:10,114 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:25:10,121 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:25:10,562 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:25:10,566 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:10,925 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:25:10,930 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=321 request_id=req_29f101cfc928b7559f067465cac8fc53 response_code=200
2025-06-19 11:25:10,931 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:10] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:25:24,635 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112524.wav, taille: 80339 bytes
2025-06-19 11:25:24,775 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112524.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:27,265 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:25:27,265 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0644\\u0628\\u0627\\u0631\\u062d \\u0643\\u0646\\u062a\\u0645\\u0634\\u0649\\"\\n            Fran\\u00e7ais: \\"salam\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:25:27,265 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:25:27,265 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:25:28,035 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:25:28,046 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=421 request_id=req_67de77f7fddd22b7cb8d472a9c48e738 response_code=200
2025-06-19 11:25:28,204 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:29,329 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112529.wav, taille: 80339 bytes
2025-06-19 11:25:29,466 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112529.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:31,712 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:25:31,713 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0643\\u062a\\u0641 \\u0648\\u0627\\u0642\\u064a\\u0644\\u0627 \\u0627\\u0644\\u0643\\u062a\\u0641\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:25:31,718 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:25:31,723 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:25:32,879 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:25:32,885 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=769 request_id=req_bae4f5cd36b817fe9a08b26d13d209f5 response_code=200
2025-06-19 11:25:33,024 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:34,635 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112534.wav, taille: 80339 bytes
2025-06-19 11:25:34,765 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112534.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:36,415 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:25:36,415 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:39,325 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112539.wav, taille: 80339 bytes
2025-06-19 11:25:39,448 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112539.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:41,431 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:25:41,434 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:44,635 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112544.wav, taille: 80339 bytes
2025-06-19 11:25:44,755 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112544.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:46,863 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:25:46,865 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:25:48,682 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112548.wav, taille: 69713 bytes
2025-06-19 11:25:48,798 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112548.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:25:49,985 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:49] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:25:50,295 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:25:50,295 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam, hier je marchais.\\"\\"\\nSegment 2: \\"Il semble que le probl\\u00e8me soit au niveau de l\'\\u00e9paule.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:25:50,295 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:25:50,295 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:25:51,550 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:25:51,550 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=961 request_id=req_8ca934e27acf2ac5132badb0e599fbeb response_code=200
2025-06-19 11:25:51,555 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:25:51] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:26:02,605 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112602.wav, taille: 80339 bytes
2025-06-19 11:26:02,715 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112602.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:06,305 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:26:06,308 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0644\\u0628\\u0627\\u0631\\u062d \\u0643\\u0646\\u062a \\u063a\\u0627\\u062f\\u064a \\u0643\\u0627\\u0646\\u062a\\u0645\\u0634\\u0649 \\u0648\\u0627\\u0646\\u0627 \\u0646\\u0632\\u0644\\u0627\\u0642\\"\\n            Fran\\u00e7ais: \\"salam Albert traducteur\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:26:06,320 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:26:06,322 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:26:06,412 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:06,415 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:07,595 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112607.wav, taille: 80339 bytes
2025-06-19 11:26:07,656 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:26:07,672 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=598 request_id=req_d44d4ba8a1e2669516a613d94e40756b response_code=200
2025-06-19 11:26:07,740 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112607.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:07,850 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:10,596 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:10,597 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:12,596 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112612.wav, taille: 80339 bytes
2025-06-19 11:26:12,727 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112612.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:15,195 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:26:15,195 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0627 \\u064a\\u0628\\u063a\\u0627\\u0634 \\u064a\\u0636\\u0631\\u0646\\u064a \\u0648\\u0627\\u0634 \\u062e\\u0627\\u0635\\u0646\\u064a \\u0648\\u0644\\u0627 \\u0634\\u0646\\u0648\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:26:15,195 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:26:15,205 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:26:17,155 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:26:17,161 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1145 request_id=req_fb3cc78275445584197f4b7f695740c9 response_code=200
2025-06-19 11:26:17,294 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112617.wav, taille: 80339 bytes
2025-06-19 11:26:17,320 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:17,461 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112617.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:21,360 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:21,360 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:22,605 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112622.wav, taille: 80339 bytes
2025-06-19 11:26:22,717 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112622.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:24,246 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:24,246 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:27,285 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112627.wav, taille: 80339 bytes
2025-06-19 11:26:27,405 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112627.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:29,235 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:29,235 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:32,595 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112632.wav, taille: 80339 bytes
2025-06-19 11:26:32,743 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112632.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:34,855 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:34,855 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:37,293 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112637.wav, taille: 80339 bytes
2025-06-19 11:26:37,422 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112637.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:38,978 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:38,978 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:43,025 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112643.wav, taille: 86135 bytes
2025-06-19 11:26:43,570 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112643.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:45,727 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:45,730 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:47,675 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112647.wav, taille: 80339 bytes
2025-06-19 11:26:47,838 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112647.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:49,028 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:49,028 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:52,976 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112652.wav, taille: 80339 bytes
2025-06-19 11:26:53,085 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112652.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:54,259 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:54,259 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:26:57,285 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112657.wav, taille: 74543 bytes
2025-06-19 11:26:57,420 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112657.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:26:58,795 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:26:58,795 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:26:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:27:00,226 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112700.wav, taille: 41699 bytes
2025-06-19 11:27:00,343 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112700.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:27:00,943 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:27:00] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:27:01,229 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:27:01,235 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:27:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:27:01,274 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:27:01,279 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Hier, alors que je marchais, j\'ai gliss\\u00e9.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Il ne veut pas me faire mal, est-ce que j\'ai besoin de quelque chose ou quoi?\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 9: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 11: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 12: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 13: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:27:01,315 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:27:01,327 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:27:03,447 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:27:03,454 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1607 request_id=req_77b13bb209bec8a36452708795431f62 response_code=200
2025-06-19 11:27:03,471 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:27:03] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:29:03,489 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:03] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:29:03,557 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:03] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:29:03,632 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:03] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 11:29:04,071 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:04] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:29:36,314 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112936.wav, taille: 80339 bytes
2025-06-19 11:29:36,439 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112936.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:29:38,889 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:29:38,889 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0628\\u0648\\u0646\\u062c\\u0648\\u0631 \\u0627\\u0644\\u062d\\u0633\\u064a\\u0646\\"\\n            Fran\\u00e7ais: \\"bonjour je m\'appelle\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:29:38,889 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:29:38,897 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:29:39,739 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:29:39,739 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=495 request_id=req_d762adfe11c1b5ddf78d1a0f3c80a953 response_code=200
2025-06-19 11:29:39,879 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:29:41,619 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112941.wav, taille: 80339 bytes
2025-06-19 11:29:41,752 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112941.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:29:43,869 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:29:43,869 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0628\\u0627\\u0631\\u062d \\u0643\\u0646\\u062a\\u0645\\u0634\\u0649 \\u0648\\u0647\\u064a \\u062a\\u062e\\u0628\\u0637\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:29:43,869 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:29:43,869 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:29:45,601 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:29:45,609 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1430 request_id=req_fbf9f517a542a41327db720413e1f9f7 response_code=200
2025-06-19 11:29:45,743 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:29:46,309 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112946.wav, taille: 80339 bytes
2025-06-19 11:29:46,461 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112946.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:29:48,259 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:29:48,259 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0636\\u0631\\u0628\\u062a\\u0646\\u064a \\u0627\\u0644\\u0643\\u062a\\u0641\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:29:48,279 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:29:48,287 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:29:49,451 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:29:49,459 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=883 request_id=req_89dcdebfdbcc24f1f76aa5f7276b119e response_code=200
2025-06-19 11:29:49,589 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:29:51,619 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112951.wav, taille: 80339 bytes
2025-06-19 11:29:51,744 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112951.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:29:53,004 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:29:53,004 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:29:56,309 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_112956.wav, taille: 80339 bytes
2025-06-19 11:29:56,439 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_112956.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:29:57,720 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:29:57,720 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:29:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:01,624 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113001.wav, taille: 80339 bytes
2025-06-19 11:30:01,739 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113001.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:03,650 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:30:03,653 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:03,767 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113003.wav, taille: 38801 bytes
2025-06-19 11:30:03,885 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113003.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:05,066 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:05] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:30:05,189 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:30:05,189 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:05,385 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:30:05,385 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Bonjour, je m\'appelle Hussein.\\"\\nSegment 2: \\"Hier, je marchais et soudainement, j\'ai \\u00e9t\\u00e9 heurt\\u00e9.\\"\\nSegment 3: \\"\\"J\'ai mal \\u00e0 l\'\\u00e9paule.\\"\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:30:05,389 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:30:05,389 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:30:07,459 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:30:07,468 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1697 request_id=req_7d464959d333661e4f860a3d0957ffdb response_code=200
2025-06-19 11:30:07,469 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:07] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:30:12,514 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113012.wav, taille: 80339 bytes
2025-06-19 11:30:12,704 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113012.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:14,451 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:30:14,451 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:17,200 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113017.wav, taille: 80339 bytes
2025-06-19 11:30:17,316 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113017.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:19,139 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113019.wav, taille: 26243 bytes
2025-06-19 11:30:19,274 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113019.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:19,306 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:30:19,311 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"arr\\u00eater arr\\u00eater\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:30:19,341 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:30:19,351 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:30:20,123 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:20] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:30:20,154 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:30:20,157 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=437 request_id=req_f9828e078b44125766c011db126c136e response_code=200
2025-06-19 11:30:20,218 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:30:20,219 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:20,266 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'arrêter arrêter', 'fused': 'Arrêter.'}
2025-06-19 11:30:20,270 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:20,433 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:20] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:30:35,559 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113035.wav, taille: 80339 bytes
2025-06-19 11:30:35,669 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113035.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:37,479 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:30:37,483 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0644\\u0628\\u0627\\u0631\\u062d \\u0643\\u0646\\u062a\\"\\n            Fran\\u00e7ais: \\"salam\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:30:37,489 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:30:37,492 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:30:39,039 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:30:39,051 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=906 request_id=req_0b402d8a8c6c9e1962fcdfedd1bf48c4 response_code=200
2025-06-19 11:30:39,181 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:40,239 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113040.wav, taille: 80339 bytes
2025-06-19 11:30:40,359 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113040.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:43,319 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:30:43,319 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0642\\u062f\\u0627\\u0645 \\u0627\\u0644\\u062f\\u0627\\u0631 \\u0648\\u0647\\u064a \\u0636\\u0631\\u0628\\u062a\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:30:43,329 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:30:43,337 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:30:44,749 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:30:44,759 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=825 request_id=req_b5c0c07c95230f77eadd6a9445041e2f response_code=200
2025-06-19 11:30:45,155 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:45,559 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113045.wav, taille: 80339 bytes
2025-06-19 11:30:45,682 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113045.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:47,299 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:30:47,300 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:50,559 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113050.wav, taille: 80339 bytes
2025-06-19 11:30:50,733 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113050.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:52,529 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:30:52,533 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:55,247 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113055.wav, taille: 80339 bytes
2025-06-19 11:30:55,381 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113055.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:57,649 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:30:57,649 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:30:58,284 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113058.wav, taille: 43631 bytes
2025-06-19 11:30:58,416 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113058.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:30:58,959 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:58] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:30:59,283 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:30:59,283 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam, hier j\'\\u00e9tais l\\u00e0.\\"\\nSegment 2: \\"Devant la maison, elle m\'a frapp\\u00e9.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:30:59,289 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:30:59,302 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:30:59,915 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:30:59,915 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:30:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:31:00,649 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:31:00,659 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1047 request_id=req_30fff02e56f9d61f18d0d18abde2697b response_code=200
2025-06-19 11:31:00,662 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:31:00] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:33:12,699 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113312.wav, taille: 80339 bytes
2025-06-19 11:33:12,829 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113312.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:33:14,760 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:33:14,760 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0644\\u0628\\u0627\\u0631\\u062d \\u0643\\u0646\\u062a \\u063a\\u0627\\u062f\\u064a \\u0643\\u0627\\u0646\\u062a\\u0645\\u0634\\u0649\\"\\n            Fran\\u00e7ais: \\"salam Albert\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:33:14,760 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:33:14,769 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:33:15,975 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:33:15,977 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=855 request_id=req_e6b06df980a1fbe9456131feddd074a8 response_code=200
2025-06-19 11:33:16,119 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:33:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:33:17,393 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113317.wav, taille: 80339 bytes
2025-06-19 11:33:17,511 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113317.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:33:19,199 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:33:19,199 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0637\\u0648\\u0645\\u0648\\u0628\\u064a\\u0644 \\u0627\\u0644\\u0628\\u064a\\u062a\\u0641\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:33:19,209 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:33:19,215 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:33:20,663 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:33:20,663 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1185 request_id=req_f3d45b4dd4067f1fe1ac976e2ea72475 response_code=200
2025-06-19 11:33:20,805 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:33:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:33:22,699 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113322.wav, taille: 80339 bytes
2025-06-19 11:33:22,831 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113322.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:33:24,609 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:33:24,609 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:33:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:33:27,404 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113327.wav, taille: 80339 bytes
2025-06-19 11:33:27,534 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113327.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:33:29,043 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:33:29,043 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"vite fait\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:33:29,043 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:33:29,052 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:33:30,579 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:33:30,579 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1199 request_id=req_d98fa5d69f293260bd9a9b3f3cb9b0f1 response_code=200
2025-06-19 11:33:30,691 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'vite fait', 'fused': 'La transcription en Darija étant vide et celle en Français contenant uniquement les mots "vite fait", il n\'y a pas de contenu médical spécifique à fusionner ou à corriger.'}
2025-06-19 11:33:30,691 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:33:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:33:31,719 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113331.wav, taille: 63917 bytes
2025-06-19 11:33:31,834 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113331.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:33:32,399 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:33:32] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:33:32,709 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:33:32,709 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Bonjour, hier j\'\\u00e9tais en train de marcher.\\"\\nSegment 2: \\"La transcription en fran\\u00e7ais est vide, donc il n\'y a rien \\u00e0 fusionner avec la transcription en darija \\"\\u0637\\u0648\\u0645\\u0648\\u0628\\u064a\\u0644 \\u0627\\u0644\\u0628\\u064a\\u062a\\u0641\\u064a\\".\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"La transcription en Darija \\u00e9tant vide et celle en Fran\\u00e7ais contenant uniquement les mots \\"vite fait\\", il n\'y a pas de contenu m\\u00e9dical sp\\u00e9cifique \\u00e0 fusionner ou \\u00e0 corriger.\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:33:32,709 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:33:32,714 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:33:33,224 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:33:33,224 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:33:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:33:37,059 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:33:37,059 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4032 request_id=req_4f14f4657830e202bbbc5f2d3f569c85 response_code=200
2025-06-19 11:33:37,059 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:33:37] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:35:47,349 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:35:47] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:35:47,468 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:35:47] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:35:47,548 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:35:47] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 11:35:48,020 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:35:48] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:36:06,216 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113606.wav, taille: 80339 bytes
2025-06-19 11:36:06,343 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113606.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:08,784 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:36:08,784 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u062c\\u0648 \\u0645\\u0627\\u0628\\u064a\\u0644 \\u0627\\u0648\\u0642\\u064a\\u0647 \\u0627\\u0644\\u062d\\u0633\\u064a\\u0646\\"\\n            Fran\\u00e7ais: \\"salam je m\'appelle Hocine hier\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:36:08,784 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:36:08,794 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:36:09,854 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:36:09,854 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=769 request_id=req_6839b3850e3b7529aebf9370ebe15971 response_code=200
2025-06-19 11:36:09,993 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:11,524 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113611.wav, taille: 80339 bytes
2025-06-19 11:36:11,644 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113611.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:14,544 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:36:14,544 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"au march\\u00e9 et je t\'ai bless\\u00e9 dans mon c\\u0153ur\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:36:14,544 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:36:14,550 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:36:16,213 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113616.wav, taille: 80339 bytes
2025-06-19 11:36:16,224 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:36:16,227 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1352 request_id=req_5512a990fd97dcf6344d1844360c4237 response_code=200
2025-06-19 11:36:16,341 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113616.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:16,353 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "au marché et je t'ai blessé dans mon cur", 'fused': "Je t'ai blessé dans mon cur."}
2025-06-19 11:36:16,358 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:19,034 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:36:19,034 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:21,529 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113621.wav, taille: 80339 bytes
2025-06-19 11:36:21,649 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113621.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:23,599 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:36:23,603 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:26,215 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113626.wav, taille: 80339 bytes
2025-06-19 11:36:26,338 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113626.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:27,043 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113627.wav, taille: 7889 bytes
2025-06-19 11:36:27,149 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113627.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:28,035 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:28] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:36:28,043 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:36:28,046 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:28,243 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:36:28,243 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:28,354 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:36:28,355 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam, je m\'appelle Hocine.\\"\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:36:28,360 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:36:28,367 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:36:29,345 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:36:29,351 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=754 request_id=req_c6cab9ea004c4a8e8998cda48aefc81a response_code=200
2025-06-19 11:36:29,354 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:29] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:36:38,904 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113638.wav, taille: 80339 bytes
2025-06-19 11:36:39,017 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113638.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:41,083 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:36:41,083 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u064a\\u0648\\u0645 \\u062c\\u0627\\u0621 \\u0627\\u0644\\u0628\\u0637\\u0644\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:36:41,093 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:36:41,093 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:36:42,504 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:36:42,515 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=764 request_id=req_a50338e46f36fbd6fa0e02c50abc47df response_code=200
2025-06-19 11:36:42,659 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:43,583 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113643.wav, taille: 80339 bytes
2025-06-19 11:36:43,709 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113643.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:45,899 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:36:45,904 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:48,884 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113648.wav, taille: 80339 bytes
2025-06-19 11:36:49,000 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113648.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:50,782 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113650.wav, taille: 34937 bytes
2025-06-19 11:36:50,904 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113650.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:36:51,085 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:36:51,085 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062c\\u0627\\u0621 \\u0627\\u0644\\u0628\\u0637\\u0644\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:36:51,093 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:36:51,099 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:36:52,024 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:36:52,024 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=331 request_id=req_68f3d1864a38b9e2be177a53b9a88ce4 response_code=200
2025-06-19 11:36:52,094 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:52] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:36:52,113 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:52] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:36:52,198 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:52] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:36:52,213 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:52] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:36:52,293 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:36:52,496 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:52] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:36:52,975 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:36:52,977 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:36:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:03,968 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113703.wav, taille: 80339 bytes
2025-06-19 11:37:04,089 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113703.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:07,074 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:37:07,074 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0644\\u0628\\u0627\\u0631\\u062d\\u0647 \\u0627\\u0644\\u0648\\u0627\\u0644\\u062f\\u0647\\"\\n            Fran\\u00e7ais: \\"Walid\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:37:07,074 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:37:07,083 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:37:08,064 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:37:08,074 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=584 request_id=req_43561320040c815e5611281eade1d504 response_code=200
2025-06-19 11:37:08,205 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:08,659 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113708.wav, taille: 80339 bytes
2025-06-19 11:37:08,769 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113708.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:11,832 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:37:11,832 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0645\\u0627 \\u0646\\u0642\\u062f\\u0631\\u0634 \\u0646\\u0647\\u0632 \\u0641\\u0647\\u0645\\u062a\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:37:11,834 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:37:11,841 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:37:12,965 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:37:12,983 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=771 request_id=req_c1ce6ed042a104ed19f0730b190b2c09 response_code=200
2025-06-19 11:37:13,126 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:13,967 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113713.wav, taille: 80339 bytes
2025-06-19 11:37:14,099 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113713.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:15,982 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:37:15,987 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:18,654 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113718.wav, taille: 80339 bytes
2025-06-19 11:37:18,774 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:20,399 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:37:20,399 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:23,963 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113723.wav, taille: 80339 bytes
2025-06-19 11:37:24,089 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113723.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:26,097 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113726.wav, taille: 38801 bytes
2025-06-19 11:37:26,224 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113726.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:26,488 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:37:26,491 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:27,398 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:27] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:37:27,714 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:37:27,714 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salut, hier ma m\\u00e8re Walid.\\"\\"\\nSegment 2: \\"Je ne peux pas lever mon bras.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:37:27,714 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:37:27,714 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:37:27,910 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:37:27,913 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:30,330 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:37:30,332 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=946 request_id=req_32e16c19196d7bced6c9953975af0541 response_code=200
2025-06-19 11:37:30,334 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:30] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:37:47,114 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113747.wav, taille: 80339 bytes
2025-06-19 11:37:47,239 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113747.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:49,404 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:37:49,404 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0644\\u0628\\u0627\\u0631\\u062d \\u0643\\u0646\\u062a\\u0645\\u0634\\u0649\\"\\n            Fran\\u00e7ais: \\"salam Albert 94\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:37:49,404 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:37:49,418 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:37:50,245 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:37:50,245 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=473 request_id=req_722e1fbde1bf000dc0573bc451c5930b response_code=200
2025-06-19 11:37:50,377 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:51,814 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113751.wav, taille: 80339 bytes
2025-06-19 11:37:51,946 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113751.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:53,978 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:37:53,978 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:37:57,119 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113757.wav, taille: 80339 bytes
2025-06-19 11:37:57,234 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113757.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:37:59,962 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:37:59,964 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:37:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:38:01,650 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113801.wav, taille: 77441 bytes
2025-06-19 11:38:01,778 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113801.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:38:02,945 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:38:02] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:38:03,264 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:38:03,264 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam, hier je me promenais.\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:38:03,268 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:38:03,268 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:38:04,284 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:38:04,284 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=613 request_id=req_7c34799518769112d862b441d01f9227 response_code=200
2025-06-19 11:38:04,284 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:38:04] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:38:12,096 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113812.wav, taille: 80339 bytes
2025-06-19 11:38:12,218 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113812.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:38:17,104 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113817.wav, taille: 80339 bytes
2025-06-19 11:38:17,214 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113817.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:38:22,103 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113822.wav, taille: 80339 bytes
2025-06-19 11:38:22,213 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113822.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:38:27,094 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113827.wav, taille: 80339 bytes
2025-06-19 11:38:27,219 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113827.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:38:32,149 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113832.wav, taille: 80339 bytes
2025-06-19 11:38:32,354 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113832.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:38:33,482 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:38:33,483 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:38:33,483 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:38:33,488 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:38:38,446 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:38:38,448 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:38:38,449 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:38:38,456 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:38:42,494 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:38:42,494 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 11:38:42,494 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:38:42,506 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:38:43,459 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:38:43,459 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:38:43,459 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:38:43,472 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:38:48,494 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:38:48,504 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:38:48,509 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:38:48,525 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:38:53,627 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:38:53,635 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:38:53,636 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:38:53,643 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:39:04,754 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:04,754 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13C23A0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:39:04,754 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:39:04,764 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:04,773 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13C29A0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:39:04,780 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:39:13,574 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-19 11:39:13,576 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=901 request_id=req_828874c56fccbfc69ab0f2dbe0369341 response_code=200
2025-06-19 11:39:15,564 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:15,564 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001CFA1386FD0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-19 11:39:15,575 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:39:16,233 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-19 11:39:16,241 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2255 request_id=req_ee857086a030bcc18671b65271270540 response_code=200
2025-06-19 11:39:17,434 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:39:17,434 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"iPhone 7\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:39:19,273 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:39:19,278 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1377 request_id=req_4e4fd7a3fec0687ef671dae078c0e0b6 response_code=200
2025-06-19 11:39:19,448 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:19,764 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113919.wav, taille: 80339 bytes
2025-06-19 11:39:19,884 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113919.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:39:21,157 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 34
2025-06-19 11:39:21,160 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1688 request_id=req_9bc39ce1f03543ca8ea7995b896e26c6 response_code=200
2025-06-19 11:39:21,273 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:39:21,273 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Avec plaisir et pardon.\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:39:21,275 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:39:21,287 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:21,609 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113921.wav, taille: 65849 bytes
2025-06-19 11:39:21,753 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113921.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:39:22,474 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:39:22,477 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:23,295 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:39:23,304 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=441 request_id=req_92c43a48d0fdeeb7985754e8c0cedd06 response_code=200
2025-06-19 11:39:23,430 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Avec plaisir et pardon.', 'fused': 'Avec plaisir.'}
2025-06-19 11:39:23,432 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:24,683 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:39:24,683 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0642\\u0644\\u064a\\u0644 \\u064a\\u0631\\u062c\\u0639 \\u0646\\u062a\\u0648\\u0633\\u064a \\u0645\\u0646\\u0627 \\u064a\\u0646\\u0628\\u062a \\u0628\\u0627\\u062a\\u0634\\u0627 \\u0628\\u0627\\u062a\\u0634\\u0627\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:39:25,124 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:39:25,127 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:25,313 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-19 11:39:25,313 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=9146 request_id=req_39a85659c5750fbebda91858a2b98b31 response_code=200
2025-06-19 11:39:25,992 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:39:25,993 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1109 request_id=req_c81e5f477f251177e295ff83ac1ba7c5 response_code=200
2025-06-19 11:39:26,154 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:27,665 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:39:27,700 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0627\\u0644\\u0642\\u0627\\u0628\\u0644 \\u0627\\u0644\\u0644\\u064a \\u0631\\u0627\\u062d \\u0646\\u0634\\u0648\\u0641\\u0647 \\u0648\\u0643\\u0646\\u0627 \\u062a\\u0627\\u0646\\u064a \\u062f\\u064a \\u0645\\u064a\\u062f\\u064a \\u0643\\u0627\\u0645\\u0644\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:39:27,814 - urllib3.connectionpool - DEBUG - Resetting dropped connection: api.openai.com
2025-06-19 11:39:27,854 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/chat/completions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:27,868 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13A26A0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/chat/completions
2025-06-19 11:39:27,951 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:39:28,017 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/chat/completions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:28,045 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13A25E0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/chat/completions
2025-06-19 11:39:28,131 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:39:28,132 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:39:28,137 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 11:39:28,180 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:39:28,298 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:28,411 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13C20D0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:39:28,516 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-19 11:39:28,549 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:28,654 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13C2490>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:39:28,698 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-19 11:39:28,932 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:28,982 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:39:28,986 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:45,599 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113945.wav, taille: 80339 bytes
2025-06-19 11:39:45,740 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113945.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:39:50,289 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113950.wav, taille: 80339 bytes
2025-06-19 11:39:50,424 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113950.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:39:53,325 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:39:53,325 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646\\u0634\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u064a\\u0632\\u0627 \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0648\\u0643\\u0627\\u0646 \\u0634\\u0627\\u0641\\"\\n            Fran\\u00e7ais: \\"salam Anakin\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:39:53,331 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:53,336 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:39:54,393 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:39:54,393 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0627\\u0646 \\u0639\\u0637\\u0627\\u0646\\u064a \\u0627\\u0644\\u062f\\u0648\\u0627\\u0621 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:39:54,393 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:39:54,393 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:39:54,773 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:39:54,783 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=784 request_id=req_05e899fc6ef41439b0bed2bde2694e3b response_code=200
2025-06-19 11:39:54,941 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:55,613 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_113955.wav, taille: 80339 bytes
2025-06-19 11:39:55,816 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_113955.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:39:56,183 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:39:56,206 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1202 request_id=req_d77a075cf3f65564f6fb8d1348cb8c68 response_code=200
2025-06-19 11:39:56,402 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:39:57,674 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:39:57,679 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:39:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:40:00,599 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114000.wav, taille: 80339 bytes
2025-06-19 11:40:00,757 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114000.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:40:02,640 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114002.wav, taille: 37835 bytes
2025-06-19 11:40:02,830 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114002.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:40:03,032 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:40:03,034 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:40:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:40:03,936 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:40:03] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:40:04,008 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:40:04,012 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:40:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:40:04,263 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:40:04] "[35m[1mPOST /api/transcription/consolidate HTTP/1.1[0m" 500 -
2025-06-19 11:40:09,759 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:40:09] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:40:09,862 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:40:09] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:40:09,862 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:40:09] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:40:10,392 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:40:10] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:40:20,089 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114020.wav, taille: 80339 bytes
2025-06-19 11:40:20,242 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114020.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:40:25,396 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114025.wav, taille: 80339 bytes
2025-06-19 11:40:25,526 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114025.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:40:30,411 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114030.wav, taille: 80339 bytes
2025-06-19 11:40:30,576 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114030.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:40:32,581 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:40:32,582 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:40:32,582 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:40:32,589 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:40:35,411 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114035.wav, taille: 80339 bytes
2025-06-19 11:40:35,551 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114035.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:40:40,416 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114040.wav, taille: 80339 bytes
2025-06-19 11:40:40,591 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114040.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:40:44,031 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114044.wav, taille: 58121 bytes
2025-06-19 11:40:44,151 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114044.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:40:44,614 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:40:44,615 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:40:44,616 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:40:44,632 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:40:56,643 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:40:56,643 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:40:56,647 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:40:56,659 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:41:08,666 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:08,666 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA1386550>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:08,666 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:41:16,751 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:16,751 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:16,751 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:16,761 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13A2B20>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:16,801 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13AC9D0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:16,814 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13A2FA0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:16,862 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:41:16,889 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:41:16,889 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:41:16,928 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:41:16,975 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:41:16,975 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:41:16,984 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,007 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:41:17,050 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:41:17,088 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,112 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:41:17,128 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13AC340>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:17,149 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,212 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,245 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13AC2E0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:17,264 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,321 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:41:17,329 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:41:17,340 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:41:17,344 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:41:17,366 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:41:17,456 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,524 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,555 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,619 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA0261310>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:17,653 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:41:17,681 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13C2DF0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:17,709 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA02398B0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:17,730 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:41:17,744 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 11:41:17,763 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:41:17,793 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:41:17,816 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,822 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:41:17,832 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-19 11:41:17,861 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,911 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,936 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:41:17,942 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA1344C70>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:17,961 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 11:41:17,972 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:17,974 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13447F0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:17,997 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA1344CD0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:18,004 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 11:41:18,011 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:41:18,030 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13D63A0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:18,034 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-19 11:41:18,041 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:41:18,066 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 11:41:18,075 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-19 11:41:18,115 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-19 11:41:18,141 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:18,191 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:18,226 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:18,228 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13D6CA0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:18,241 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13D6FD0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:18,258 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13863A0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:18,320 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-19 11:41:18,382 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-19 11:41:18,408 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-19 11:41:18,446 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:18,472 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:18,524 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13DF430>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:18,639 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001CFA13DF4F0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 11:41:18,756 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-19 11:41:18,799 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-19 11:41:19,042 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:41:19,044 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 11:41:19,053 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-19 11:41:19,160 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:19,207 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:20,231 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114120.wav, taille: 80339 bytes
2025-06-19 11:41:20,328 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:20,391 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:20,541 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:20,631 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:20,892 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114120.wav, taille: 80339 bytes
2025-06-19 11:41:20,908 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-19 11:41:20,909 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114120.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:20,924 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=732 request_id=req_760d1c30adf023887eeba8c30076c60f response_code=200
2025-06-19 11:41:21,071 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114121.wav, taille: 80339 bytes
2025-06-19 11:41:21,131 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:41:21,156 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Merci d\'avoir regard\\u00e9 cette vid\\u00e9o !\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:41:21,385 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114120.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:21,497 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114121.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:21,702 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-19 11:41:21,725 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-19 11:41:21,728 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1184 request_id=req_71183657f63903a77d1f6a98beb9907f response_code=200
2025-06-19 11:41:21,782 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1024 request_id=req_3ea6ea07d36fb6ac0507ad1de93c85cd response_code=200
2025-06-19 11:41:22,021 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:41:22,172 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"C\'est ce qu\'il m\'a dit, il m\'a donn\\u00e9 de l\'eau et il m\'a dit qu\'il allait me donner de l\'eau.\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:41:22,286 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:41:22,365 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:22,530 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=688 request_id=req_da012bb3dd3b1756fc1ba46fc92f4c14 response_code=200
2025-06-19 11:41:22,554 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:22,795 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "Merci d'avoir regardé cette vidéo !", 'fused': "Merci d'avoir regardé cette vidéo !"}
2025-06-19 11:41:22,831 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:22,996 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114122.wav, taille: 80339 bytes
2025-06-19 11:41:23,228 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114123.wav, taille: 80339 bytes
2025-06-19 11:41:23,333 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114122.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:24,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114123.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:24,193 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:24,216 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:26,192 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:41:26,192 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u062c\\u0627\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:41:26,201 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:26,242 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:41:26,248 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:41:26,261 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u062c\\u0627\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:41:26,276 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:26,281 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:41:26,456 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:41:26,468 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1190 request_id=req_39f6c0b44a6b9672b8dd2b11267b2a3e response_code=200
2025-06-19 11:41:26,621 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "C'est ce qu'il m'a dit, il m'a donné de l'eau et il m'a dit qu'il allait me donner de l'eau.", 'fused': "Il m'a dit qu'il allait me donner de l'eau."}
2025-06-19 11:41:26,625 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:27,326 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:27,331 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:27,336 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:27,343 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114127.wav, taille: 69713 bytes
2025-06-19 11:41:27,361 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:27,723 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114127.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:27,727 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:41:27,729 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=730 request_id=req_5a332dacf84d605b9656993bfdf0b528 response_code=200
2025-06-19 11:41:27,814 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:41:27,859 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1059 request_id=req_6c4c5d7e9094f092db2c3acb4c136150 response_code=200
2025-06-19 11:41:29,045 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:29,477 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:30,071 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114130.wav, taille: 43631 bytes
2025-06-19 11:41:30,221 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114130.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:31,046 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:31] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:41:31,413 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:31] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:41:31,773 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-19 11:41:31,792 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-19 11:41:32,674 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 11:41:37,326 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 11:41:37,345 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 11:41:37,629 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114137.wav, taille: 69713 bytes
2025-06-19 11:41:37,631 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114137.wav, taille: 69713 bytes
2025-06-19 11:41:37,978 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114137.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:37,988 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114137.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:39,793 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:39] "GET / HTTP/1.1" 200 -
2025-06-19 11:41:39,984 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:39] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:41:40,358 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:40] "GET / HTTP/1.1" 200 -
2025-06-19 11:41:40,498 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:40] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:41:40,528 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:40] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:41:41,188 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:41] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:41:41,556 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:41] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:41:41,648 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:41,696 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:41] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:41:41,709 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:41,826 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:41] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:41:41,941 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:41] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:41:42,012 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:41:42,015 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:43,244 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:43] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:41:43,325 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:43] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:41:43,342 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:43] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:41:43,835 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:43] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:41:53,136 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114153.wav, taille: 80339 bytes
2025-06-19 11:41:53,734 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114153.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:41:56,393 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:41:56,394 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0639\\u0646\\u062f \\u0641\\u0627\\u064a\\u0632\\u0647 \\u0643\\u0627\\u0646\\"\\n            Fran\\u00e7ais: \\"salami\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:41:56,397 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:41:56,408 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:41:57,567 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:41:57,567 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=800 request_id=req_4ca2bcfa1114e8764dec4468d0463e79 response_code=200
2025-06-19 11:41:57,709 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:41:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:41:58,434 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114158.wav, taille: 80339 bytes
2025-06-19 11:41:58,563 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114158.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:42:01,786 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:42:01,786 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0639\\u0637\\u0627\\u0646\\u064a \\u0627\\u0644\\u062f\\u0648\\u0627\\u0621 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"aller au Canada\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:42:01,786 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:42:01,786 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:42:03,127 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114203.wav, taille: 80339 bytes
2025-06-19 11:42:03,236 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:42:03,239 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1142 request_id=req_553452ef3f4088b4a5560ac4a578d17e response_code=200
2025-06-19 11:42:03,257 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114203.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:42:03,397 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:42:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:42:04,998 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:42:05,000 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:42:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:42:08,416 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114208.wav, taille: 79373 bytes
2025-06-19 11:42:08,533 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114208.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:42:09,092 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:42:09] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:42:09,401 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:42:09,402 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Je suis all\\u00e9 chez Faiza.\\"\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:42:09,405 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:42:09,411 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:42:10,083 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:42:10,087 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:42:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:42:10,553 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:42:10,634 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=515 request_id=req_a49fd9d35056c9b164f9483b2e31fe10 response_code=200
2025-06-19 11:42:10,792 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:42:10] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:46:11,839 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:11] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:46:11,925 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:11] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:46:11,996 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:11] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 11:46:12,354 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:12] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:46:31,123 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114631.wav, taille: 80339 bytes
2025-06-19 11:46:31,254 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114631.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:46:34,413 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:46:34,421 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u064a\\u0646 \\u0642\\u0628\\u064a\\"\\n            Fran\\u00e7ais: \\"salam Hussein\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:46:34,426 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:46:34,431 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:46:35,333 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:46:35,342 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=511 request_id=req_fa5b9cdffabba4f83dafbb8c8b143b89 response_code=200
2025-06-19 11:46:35,480 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:46:35,813 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114635.wav, taille: 80339 bytes
2025-06-19 11:46:35,928 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114635.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:46:38,393 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:46:38,393 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0648\\u0627\\u0644\\u062f\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0627\\u0644\\u0643\\u062a\\u0641\\u064a\\"\\n            Fran\\u00e7ais: \\"appeler lwalida Diali\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:46:38,408 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:46:38,412 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:46:39,554 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:46:39,563 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=869 request_id=req_c8b559a810433cfdd13cec9224969389 response_code=200
2025-06-19 11:46:39,737 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:46:41,124 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114641.wav, taille: 80339 bytes
2025-06-19 11:46:41,243 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114641.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:46:44,420 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:46:44,423 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:46:45,819 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114645.wav, taille: 80339 bytes
2025-06-19 11:46:45,933 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114645.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:46:48,745 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:46:48,745 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"qui a mal\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:46:48,745 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:46:48,758 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:46:49,670 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:46:49,672 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=520 request_id=req_b646228bed6fcadbf7061492541fbd52 response_code=200
2025-06-19 11:46:49,787 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'qui a mal', 'fused': '"qui a mal"'}
2025-06-19 11:46:49,787 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:46:51,193 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114651.wav, taille: 80339 bytes
2025-06-19 11:46:51,323 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114651.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:46:54,004 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:46:54,008 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:46:56,123 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114656.wav, taille: 80339 bytes
2025-06-19 11:46:56,228 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114656.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:46:57,788 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:46:57,788 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:46:58,654 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114658.wav, taille: 45563 bytes
2025-06-19 11:46:58,773 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114658.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:46:59,973 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:46:59] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:47:00,287 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:47:00,287 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam Hussein.\\"\\"\\nSegment 2: \\"Appeler lwalida diali qui a mal \\u00e0 l\'\\u00e9paule.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"\\"qui a mal\\"\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:47:00,287 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:47:00,293 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:47:00,323 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:47:00,323 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0643\\u062b\\u0631 \\u0641\\u064a\\u062f\\u064a\\u0648\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:47:00,323 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:47:00,323 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:47:01,633 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:47:01,633 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=975 request_id=req_08b070eb6351ffc56b350c5e19e2bab6 response_code=200
2025-06-19 11:47:01,643 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:01] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:47:02,553 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:47:02,563 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1779 request_id=req_956769ec5907017323095bdcc33e1320 response_code=200
2025-06-19 11:47:02,694 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:47:09,090 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:09] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:47:09,173 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:09] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:47:09,183 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:09] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:47:09,636 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:09] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:47:18,572 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114718.wav, taille: 80339 bytes
2025-06-19 11:47:18,692 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:47:22,992 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:47:22,992 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0641\\u064a\\u0646 \\u0627\\u0644\\u0639\\u0627\\u064a\\u0644 \\u0643\\u064a\\u0641 \\u062f\\u0627\\u064a\\u0631 \\u0628\\u062e\\u064a\\u0631 \\u0634\\u064a 500\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:47:22,992 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:47:22,992 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:47:23,262 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114723.wav, taille: 80339 bytes
2025-06-19 11:47:23,385 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114723.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:47:25,386 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:47:25,386 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:47:25,592 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:47:25,602 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1461 request_id=req_6f3b4868e6297b8a22be0ae661c3cbd1 response_code=200
2025-06-19 11:47:25,744 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:47:28,597 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114728.wav, taille: 80339 bytes
2025-06-19 11:47:28,742 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114728.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:47:30,947 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:47:30,960 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:47:33,182 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114733.wav, taille: 73577 bytes
2025-06-19 11:47:33,286 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114733.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:47:33,872 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:33] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:47:34,192 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:47:34,192 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Comment va la famille, tout va bien ?\\"\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:47:34,192 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:47:34,202 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:47:35,218 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:47:35,219 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:47:42,072 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:47:42,082 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=500 request_id=req_6344d3a2e95f63009c3f69b76ecf4c5a response_code=200
2025-06-19 11:47:42,087 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:47:42] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:47:44,322 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114744.wav, taille: 80339 bytes
2025-06-19 11:47:44,436 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114744.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:47:49,017 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114749.wav, taille: 80339 bytes
2025-06-19 11:47:49,122 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114749.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:47:54,322 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114754.wav, taille: 80339 bytes
2025-06-19 11:47:54,445 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114754.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:47:59,322 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114759.wav, taille: 80339 bytes
2025-06-19 11:47:59,452 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114759.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:48:00,422 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:48:00,422 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0628\\u0627\\u0634 \\u064a\\u0634\\u0648\\u0641 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:48:00,422 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:48:00,422 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:48:02,312 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:48:02,317 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=628 request_id=req_75f0d6cebcac3a11f7c35fd162b39743 response_code=200
2025-06-19 11:48:02,458 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:04,322 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114804.wav, taille: 80339 bytes
2025-06-19 11:48:04,462 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114804.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:48:05,711 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:48:05,712 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:48:05,712 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:48:05,725 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:48:06,004 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:06] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:48:06,097 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:06] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:48:06,110 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:06] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:48:06,601 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:06] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:48:10,069 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:48:10,069 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:10,367 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:48:10,370 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:48:10,373 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:48:10,377 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:48:12,757 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-19 11:48:12,757 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=621 request_id=req_1d06f251b70908727dbf7db05a75ecaf response_code=200
2025-06-19 11:48:13,964 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114813.wav, taille: 80339 bytes
2025-06-19 11:48:14,086 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114813.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:48:15,955 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:48:15,955 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0646\\u0627 \\u062a\\u0627\\u0646\\u064a \\u0634\\u062f\\u0648\\u0649 \\u0648\\u0643\\u0627\\u0644\\u064a \\u0633\\u064a\\u0645\\u0627\\u0646\\"\\n            Fran\\u00e7ais: \\"OK\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:48:17,188 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:48:17,199 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=894 request_id=req_ccd5b50ed7df457e006242804d25adb3 response_code=200
2025-06-19 11:48:17,285 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:48:17,289 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:17,347 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:18,979 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:48:19,021 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0644\\u0649\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:48:19,078 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:48:19,171 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:48:19,453 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114819.wav, taille: 80339 bytes
2025-06-19 11:48:19,907 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114819.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:48:21,227 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:48:21,227 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1414 request_id=req_d489eec9c6739a588b50023511d75683 response_code=200
2025-06-19 11:48:21,374 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:21,573 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:48:21,573 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"salam \\u00e0 la caisse maladie\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:48:21,578 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 11:48:22,867 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:48:22,877 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=875 request_id=req_0e148a6286ff5803717da7086232c188 response_code=200
2025-06-19 11:48:22,983 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'salam à la caisse maladie', 'fused': 'Bonjour, je suis à la caisse maladie.'}
2025-06-19 11:48:22,987 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:23,341 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:48:23,341 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:24,287 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114824.wav, taille: 80339 bytes
2025-06-19 11:48:24,407 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114824.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:48:26,551 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:48:26,554 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:28,957 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114828.wav, taille: 80339 bytes
2025-06-19 11:48:29,068 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114828.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:48:30,334 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:48:30,337 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:34,257 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114834.wav, taille: 80339 bytes
2025-06-19 11:48:34,372 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114834.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:48:36,399 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:48:36,407 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:36,883 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_114836.wav, taille: 46529 bytes
2025-06-19 11:48:37,003 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_114836.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:48:38,290 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:38] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:48:38,687 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:48:38,722 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:48:38,778 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:48:38,811 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:48:38,876 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:48:38,904 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:48:43,167 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:48:43,223 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3712 request_id=req_97f479d211afdd27818b969af2647d89 response_code=200
2025-06-19 11:48:43,229 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:48:43] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:50:10,505 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:10] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:50:10,593 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:10] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:50:10,678 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:10] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 11:50:11,013 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:11] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:50:23,243 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115023.wav, taille: 80339 bytes
2025-06-19 11:50:23,367 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115023.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:50:26,197 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:50:26,197 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u064a\\u0635\\u0644 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"salam \\u00e0 la cuisine\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:50:26,197 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:50:26,207 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:50:27,667 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:50:27,677 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=992 request_id=req_da244c615682732fef987f9d11a7d2c9 response_code=200
2025-06-19 11:50:27,819 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:50:28,551 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115028.wav, taille: 80339 bytes
2025-06-19 11:50:28,704 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115028.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:50:32,817 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:50:32,825 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0639\\u0637\\u0627\\u0646\\u064a \\u0637\\u0628\\u064a\\u0628 \\u0634\\u062f\\u0648\\u0627 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:50:32,832 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:50:32,836 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:50:33,237 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115033.wav, taille: 80339 bytes
2025-06-19 11:50:33,360 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115033.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:50:34,110 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:50:34,137 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=942 request_id=req_40ff22cad4ec0f19d25c735719122a28 response_code=200
2025-06-19 11:50:34,305 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:50:36,160 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:50:36,160 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:50:38,547 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115038.wav, taille: 80339 bytes
2025-06-19 11:50:38,668 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115038.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:50:40,546 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:50:40,549 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:50:42,327 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115042.wav, taille: 64883 bytes
2025-06-19 11:50:42,452 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115042.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:50:43,628 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:43] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:50:43,943 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:50:43,943 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam, cette semaine je me suis focalis\\u00e9 sur mon probl\\u00e8me de gorge.\\"\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:50:43,947 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:50:43,947 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:50:44,409 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:50:44,409 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:50:45,127 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:50:45,127 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=633 request_id=req_7aeb97baccdad44b0a414ac7b25bcf0d response_code=200
2025-06-19 11:50:45,137 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:50:45] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:52:19,631 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:19] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:52:19,716 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:19] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:52:19,805 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:19] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 11:52:20,139 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:20] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:52:26,719 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115226.wav, taille: 80339 bytes
2025-06-19 11:52:26,840 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115226.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:52:30,149 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:52:30,153 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0627\\u0644\\u062d\\u0631\\u0642 \\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"salam Anakin cette semaine\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:52:30,159 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:52:30,164 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:52:31,904 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:52:31,909 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=852 request_id=req_3dffb9648005b2c6e1bb49c70c0fc0c8 response_code=200
2025-06-19 11:52:32,029 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115232.wav, taille: 80339 bytes
2025-06-19 11:52:32,085 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:52:32,194 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115232.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:52:36,699 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:52:36,699 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"canap\\u00e9 chez toi\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:52:36,712 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:52:36,716 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:52:37,029 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115237.wav, taille: 80339 bytes
2025-06-19 11:52:37,139 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115237.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:52:38,929 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:52:38,944 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1748 request_id=req_b19b82d0937ba9fee2a75da0d03d0b28 response_code=200
2025-06-19 11:52:39,129 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:52:42,009 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115242.wav, taille: 80339 bytes
2025-06-19 11:52:42,129 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115242.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:52:43,604 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:52:43,609 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:52:47,029 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115247.wav, taille: 80339 bytes
2025-06-19 11:52:47,139 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115247.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:52:47,144 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:52:47,144 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:52:47,972 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115247.wav, taille: 14651 bytes
2025-06-19 11:52:48,090 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115247.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:52:48,591 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:48] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:52:48,674 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:48] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:52:48,680 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:48] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:52:49,055 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:49] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:52:50,923 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:52:50,926 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:52:50,959 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:52:50,962 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:52:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:52:55,652 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115255.wav, taille: 80339 bytes
2025-06-19 11:52:55,770 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115255.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:52:59,404 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:52:59,404 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0627\\u0644\\u062d\\u0627\\u0642\\u0647\\"\\n            Fran\\u00e7ais: \\"salam feuilleton\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:52:59,404 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:52:59,409 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:53:00,779 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:53:00,789 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=743 request_id=req_4f59635fd01f48b2ff0ff082b6ac3bf3 response_code=200
2025-06-19 11:53:00,929 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:53:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:53:00,967 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115300.wav, taille: 80339 bytes
2025-06-19 11:53:01,091 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115300.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:53:05,959 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115305.wav, taille: 80339 bytes
2025-06-19 11:53:06,071 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115305.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:53:07,606 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:53:07,608 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:53:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:53:07,705 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:53:07,706 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:53:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:53:10,342 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115310.wav, taille: 69713 bytes
2025-06-19 11:53:10,443 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115310.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:53:11,030 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:53:11] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:53:11,411 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:53:11,428 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:53:11,442 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:53:11,460 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:53:13,027 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:53:13,030 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:53:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:53:13,787 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:53:13,798 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1183 request_id=req_488891fde233650832b87fadd727fa5b response_code=200
2025-06-19 11:53:13,800 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:53:13] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:54:56,025 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:54:56] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:54:56,097 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:54:56] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:54:56,185 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:54:56] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 11:54:56,736 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:54:56] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:55:03,060 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115503.wav, taille: 80339 bytes
2025-06-19 11:55:03,185 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115503.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:06,215 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:55:06,215 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0627\\u0644\\u062d\\u0644\\u0642 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"salam Anakin cette semaine\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:55:06,215 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:55:06,215 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:55:07,635 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:55:07,635 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=844 request_id=req_83c5d1fec5d9aa39b077d8444f9c7107 response_code=200
2025-06-19 11:55:07,774 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:08,365 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115508.wav, taille: 80339 bytes
2025-06-19 11:55:08,625 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115508.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:11,498 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:55:11,499 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:13,060 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115513.wav, taille: 80339 bytes
2025-06-19 11:55:13,182 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115513.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:14,582 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:55:14,585 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:18,371 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115518.wav, taille: 80339 bytes
2025-06-19 11:55:18,498 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115518.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:20,231 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:55:20,235 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:21,635 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115521.wav, taille: 52325 bytes
2025-06-19 11:55:21,759 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115521.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:22,319 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:22] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:55:22,635 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:55:22,635 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salut, je suis venu \\u00e0 cause de ma gorge cette semaine.\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:55:22,635 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:55:22,649 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:55:22,797 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:55:22,800 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:23,935 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:55:23,935 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=945 request_id=req_f3cfeb546bd3e1b50afddd04cc5841de response_code=200
2025-06-19 11:55:23,945 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:23] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:55:27,456 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:27] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:55:27,538 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:27] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:55:27,546 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:27] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:55:27,930 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:27] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:55:37,311 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115537.wav, taille: 80339 bytes
2025-06-19 11:55:37,424 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115537.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:41,012 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:55:41,012 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646\\u062c\\u064a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0644\\u0641\\u0627\\u064a\\u0633\\u0647 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"salam avec M6 semaine\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:55:41,019 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:55:41,019 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:55:42,469 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:55:42,480 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1022 request_id=req_2e251174ab7b73c17ccf46e6b6f92ce9 response_code=200
2025-06-19 11:55:42,618 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:42,639 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115542.wav, taille: 80339 bytes
2025-06-19 11:55:42,769 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115542.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:45,819 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:55:45,819 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:47,619 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115547.wav, taille: 80339 bytes
2025-06-19 11:55:47,774 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115547.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:48,069 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115548.wav, taille: 11753 bytes
2025-06-19 11:55:48,197 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115548.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:55:48,945 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:55:48,950 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:49,381 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:49] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:55:49,767 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:55:49,819 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:55:49,879 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:55:49,907 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:55:50,454 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:55:50,460 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:55:52,239 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:55:52,266 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1837 request_id=req_f8481a4281baf15e40a722384e898eb2 response_code=200
2025-06-19 11:55:52,306 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:55:52] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:57:11,397 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:57:11] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:57:11,481 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:57:11] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:57:11,574 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:57:11] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 11:57:11,924 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:57:11] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:57:18,851 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115718.wav, taille: 80339 bytes
2025-06-19 11:57:18,961 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:57:23,540 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115723.wav, taille: 80339 bytes
2025-06-19 11:57:23,661 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115723.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:57:28,851 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115728.wav, taille: 80339 bytes
2025-06-19 11:57:28,980 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115728.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:57:31,248 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:57:31,251 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:57:31,251 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:57:31,262 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:57:33,831 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115733.wav, taille: 80339 bytes
2025-06-19 11:57:33,951 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115733.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:57:38,358 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115738.wav, taille: 71645 bytes
2025-06-19 11:57:38,480 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115738.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:57:43,271 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:57:43,276 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:57:43,278 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:57:43,281 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:57:55,322 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:57:55,325 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 11:57:55,329 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:57:55,336 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:58:05,141 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-19 11:58:05,141 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=946 request_id=req_d7857a0041f48a9aca6cff316c0453e4 response_code=200
2025-06-19 11:58:06,101 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:58:06,101 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:58:06,501 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-19 11:58:06,501 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=745 request_id=req_6c4722d1f2b30f9d81b39e907be49bdb response_code=200
2025-06-19 11:58:07,531 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:58:07,531 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1207 request_id=req_ebcd013b39e2c7f91adf9a545f1c39e4 response_code=200
2025-06-19 11:58:07,656 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:08,517 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-19 11:58:08,525 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2389 request_id=req_6af681090b82e6ffbc0cf2985d2eac7f response_code=200
2025-06-19 11:58:08,674 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:58:08,674 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u064a\\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0629 \\u0645\\u0646 \\u0628\\u064a\\u062a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:58:11,349 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:58:11,351 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1068 request_id=req_efdff136698cf681de5f4f14267cded8 response_code=200
2025-06-19 11:58:11,491 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:17,826 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 11:58:17,826 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 11:58:17,828 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:58:17,830 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:58:18,249 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:18] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 11:58:18,333 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:18] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 11:58:18,341 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:18] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 11:58:18,723 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:18] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 11:58:19,602 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 24
2025-06-19 11:58:19,606 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=851 request_id=req_3c0bea1940085d970e5ff6de5bd0fbb3 response_code=200
2025-06-19 11:58:19,722 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:58:19,722 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"Ah c\'est bien\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:58:20,764 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:58:20,764 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=814 request_id=req_503ad2959e9b141ee9c2643fc2409a0d response_code=200
2025-06-19 11:58:20,888 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "Ah c'est bien", 'fused': "Ah c'est bien."}
2025-06-19 11:58:20,889 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:26,181 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115826.wav, taille: 80339 bytes
2025-06-19 11:58:26,304 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115826.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:58:27,922 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:58:27,922 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645. \\u0623\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0627\\u0633\\u0645\\u064a \\u0645\\u0646\\u0627\\u0641\\u0642\\u0629 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0628 \\u062d\\u0644\\u0642\\u0629 \\u064a\\u0627\\u0644\\u064a.\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:58:29,092 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:58:29,092 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=930 request_id=req_de21c8fb6663681c98df95fbd69987bf response_code=200
2025-06-19 11:58:29,231 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:29,854 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:58:29,859 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a\\"\\n            Fran\\u00e7ais: \\"salam Anakin c\'est magnifique\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:58:29,865 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:58:29,870 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:58:30,761 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:58:30,761 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=502 request_id=req_bcc3f3262626048f05808f5aad47756f response_code=200
2025-06-19 11:58:30,910 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:31,491 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115831.wav, taille: 80339 bytes
2025-06-19 11:58:31,646 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115831.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:58:31,727 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:58:31,731 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:34,931 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:58:34,931 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0637\\u0628\\u064a\\u0628 \\u0627\\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"au contraire de tennis su\\u00e9dois ou quelque chose\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:58:34,931 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:58:34,941 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:58:36,181 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115836.wav, taille: 80339 bytes
2025-06-19 11:58:36,321 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115836.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:58:36,531 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:58:36,531 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1136 request_id=req_03dad76f65a3fe75ccb0aa4e149ac4b3 response_code=200
2025-06-19 11:58:36,675 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:37,585 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:58:37,588 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:41,491 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115841.wav, taille: 80339 bytes
2025-06-19 11:58:41,620 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115841.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:58:43,188 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:58:43,191 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:46,186 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115846.wav, taille: 80339 bytes
2025-06-19 11:58:46,304 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115846.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:58:47,446 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_115847.wav, taille: 14651 bytes
2025-06-19 11:58:47,561 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_115847.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 11:58:48,254 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:58:48,254 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:48,443 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:48] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:58:48,754 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 11:58:48,754 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam, je suis Anakin.\\"\\"\\nSegment 2: \\"Le m\\u00e9decin m\'a donn\\u00e9 un m\\u00e9dicament et m\'a dit de revenir le voir la semaine suivante.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 11:58:48,754 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 11:58:48,761 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 11:58:48,871 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 11:58:48,871 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 11:58:50,839 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 11:58:50,848 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1467 request_id=req_4ed7cbf0ede61696398d63ff308a20d3 response_code=200
2025-06-19 11:58:50,850 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 11:58:50] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 11:59:28,921 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\__init__.py', reloading
2025-06-19 11:59:28,921 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\__init__.py', reloading
2025-06-19 11:59:29,251 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py', reloading
2025-06-19 11:59:29,391 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\rnn.py', reloading
2025-06-19 11:59:29,461 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\functional.py', reloading
2025-06-19 11:59:29,656 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 11:59:31,770 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 11:59:31,780 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 11:59:33,032 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_prims\\__init__.py', reloading
2025-06-19 11:59:33,341 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_meta_registrations.py', reloading
2025-06-19 11:59:33,731 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\__init__.py', reloading
2025-06-19 11:59:33,760 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\_extension\\__init__.py', reloading
2025-06-19 11:59:33,797 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchaudio\\_extension\\utils.py', reloading
2025-06-19 11:59:33,866 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_ops.py', reloading
2025-06-19 11:59:33,941 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\ctypes\\__init__.py', reloading
2025-06-19 11:59:34,184 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 11:59:36,011 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 11:59:36,021 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:00:18,221 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\pip\\_vendor\\pyparsing\\core.py', reloading
2025-06-19 12:00:18,414 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\site-packages\\pip\\_vendor\\packaging\\markers.py', reloading
2025-06-19 12:00:18,719 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:00:21,106 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:00:21,111 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:00:32,726 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:00:32] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:00:32,815 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:00:32] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:00:32,827 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:00:32] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:00:33,227 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:00:33] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:00:50,716 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_120050.wav, taille: 80339 bytes
2025-06-19 12:00:50,856 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_120050.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:00:55,522 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:00:55,522 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0636\\u0631\\u0646\\u064a \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"salam un Android\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:00:55,524 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:00:55,526 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:00:56,026 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_120056.wav, taille: 80339 bytes
2025-06-19 12:00:56,152 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_120056.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:00:57,236 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:00:57,249 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=492 request_id=req_f6dad5913cddc27943bf1a2ef39d4ca3 response_code=200
2025-06-19 12:00:57,416 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:00:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:01:00,197 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:01:00,201 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"basket\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:01:00,205 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:01:00,208 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:01:01,041 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_120101.wav, taille: 80339 bytes
2025-06-19 12:01:01,217 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_120101.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:01:02,188 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:01:02,192 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1557 request_id=req_83c89576d6cb47af94a0027d8d82601b response_code=200
2025-06-19 12:01:02,301 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'basket', 'fused': 'La transcription en Darija est vide et le mot "basket" en français n\'est pas pertinent dans un contexte médical, donc il n\'y a pas de contenu à fusionner pour former une phrase médicale cohérente.'}
2025-06-19 12:01:02,306 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:01:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:01:04,801 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:01:04,804 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:01:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:01:06,026 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_120106.wav, taille: 80339 bytes
2025-06-19 12:01:06,171 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_120106.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:01:08,406 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:01:08,411 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:01:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:01:10,719 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_120110.wav, taille: 80339 bytes
2025-06-19 12:01:10,900 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_120110.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:01:12,636 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_120112.wav, taille: 25277 bytes
2025-06-19 12:01:12,746 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_120112.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:01:13,549 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:01:13,549 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:01:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:01:13,630 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:01:13] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 12:01:13,930 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:01:13,930 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:01:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:01:13,951 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:01:13,952 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam, j\'ai mal \\u00e0 mon dos.\\"\\"\\nSegment 2: \\"La transcription en Darija est vide et le mot \\"basket\\" en fran\\u00e7ais n\'est pas pertinent dans un contexte m\\u00e9dical, donc il n\'y a pas de contenu \\u00e0 fusionner pour former une phrase m\\u00e9dicale coh\\u00e9rente.\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:01:13,956 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:01:13,961 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:01:15,098 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:01:15,106 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=589 request_id=req_93e9882918fc136c2ff69be63371c810 response_code=200
2025-06-19 12:01:15,111 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:01:15] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 12:01:36,886 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\__init__.py', reloading
2025-06-19 12:01:36,886 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\compile\\__init__.py', reloading
2025-06-19 12:01:36,886 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\batch_tensor.py', reloading
2025-06-19 12:01:36,886 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\delayed_mul_tensor.py', reloading
2025-06-19 12:01:36,895 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\dim.py', reloading
2025-06-19 12:01:36,896 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\magic_trace.py', reloading
2025-06-19 12:01:36,897 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\op_properties.py', reloading
2025-06-19 12:01:36,898 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\reference.py', reloading
2025-06-19 12:01:36,900 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\tree_map.py', reloading
2025-06-19 12:01:36,902 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\wrap_type.py', reloading
2025-06-19 12:01:36,903 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\dim\\__init__.py', reloading
2025-06-19 12:01:36,907 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\experimental\\control_flow.py', reloading
2025-06-19 12:01:36,908 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\experimental\\ops.py', reloading
2025-06-19 12:01:36,909 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\experimental\\_cond.py', reloading
2025-06-19 12:01:36,910 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\experimental\\_map.py', reloading
2025-06-19 12:01:36,911 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\experimental\\__init__.py', reloading
2025-06-19 12:01:36,916 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\_src\\__init__.py', reloading
2025-06-19 12:01:36,918 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\_src\\aot_autograd\\__init__.py', reloading
2025-06-19 12:01:36,921 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\_src\\eager_transforms\\__init__.py', reloading
2025-06-19 12:01:36,923 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\_src\\make_functional\\__init__.py', reloading
2025-06-19 12:01:36,929 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\functorch\\_src\\vmap\\__init__.py', reloading
2025-06-19 12:01:36,942 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\functional.py', reloading
2025-06-19 12:01:36,944 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\hub.py', reloading
2025-06-19 12:01:36,946 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\library.py', reloading
2025-06-19 12:01:36,948 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\overrides.py', reloading
2025-06-19 12:01:36,950 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\quasirandom.py', reloading
2025-06-19 12:01:36,952 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\random.py', reloading
2025-06-19 12:01:36,954 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\return_types.py', reloading
2025-06-19 12:01:36,955 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\serialization.py', reloading
2025-06-19 12:01:36,957 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\storage.py', reloading
2025-06-19 12:01:36,958 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\torch_version.py', reloading
2025-06-19 12:01:36,960 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\types.py', reloading
2025-06-19 12:01:36,971 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\version.py', reloading
2025-06-19 12:01:36,974 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_appdirs.py', reloading
2025-06-19 12:01:36,976 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_classes.py', reloading
2025-06-19 12:01:36,978 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_deploy.py', reloading
2025-06-19 12:01:36,979 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_guards.py', reloading
2025-06-19 12:01:36,979 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_jit_internal.py', reloading
2025-06-19 12:01:36,984 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_linalg_utils.py', reloading
2025-06-19 12:01:36,985 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_lobpcg.py', reloading
2025-06-19 12:01:36,986 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_lowrank.py', reloading
2025-06-19 12:01:36,987 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_meta_registrations.py', reloading
2025-06-19 12:01:36,987 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_namedtensor_internals.py', reloading
2025-06-19 12:01:36,987 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_ops.py', reloading
2025-06-19 12:01:36,987 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_python_dispatcher.py', reloading
2025-06-19 12:01:36,987 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_sources.py', reloading
2025-06-19 12:01:36,987 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_storage_docs.py', reloading
2025-06-19 12:01:36,997 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_tensor.py', reloading
2025-06-19 12:01:36,998 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_tensor_docs.py', reloading
2025-06-19 12:01:36,999 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_tensor_str.py', reloading
2025-06-19 12:01:37,002 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_torch_docs.py', reloading
2025-06-19 12:01:37,003 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_utils.py', reloading
2025-06-19 12:01:37,006 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_utils_internal.py', reloading
2025-06-19 12:01:37,007 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_VF.py', reloading
2025-06-19 12:01:37,008 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_vmap_internals.py', reloading
2025-06-19 12:01:37,010 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\_weights_only_unpickler.py', reloading
2025-06-19 12:01:37,012 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\__config__.py', reloading
2025-06-19 12:01:37,014 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\__future__.py', reloading
2025-06-19 12:01:37,015 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\__init__.py', reloading
2025-06-19 12:01:37,017 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\amp\\autocast_mode.py', reloading
2025-06-19 12:01:37,019 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\amp\\__init__.py', reloading
2025-06-19 12:01:37,020 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\__init__.py', reloading
2025-06-19 12:01:37,023 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\__init__.py', reloading
2025-06-19 12:01:37,025 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\__init__.py', reloading
2025-06-19 12:01:37,026 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\modules\\fused.py', reloading
2025-06-19 12:01:37,027 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\modules\\__init__.py', reloading
2025-06-19 12:01:37,030 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\__init__.py', reloading
2025-06-19 12:01:37,032 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\modules\\conv_fused.py', reloading
2025-06-19 12:01:37,034 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\modules\\linear_fused.py', reloading
2025-06-19 12:01:37,035 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\modules\\linear_relu.py', reloading
2025-06-19 12:01:37,037 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\modules\\__init__.py', reloading
2025-06-19 12:01:37,040 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\__init__.py', reloading
2025-06-19 12:01:37,042 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:01:37,043 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\dynamic\\modules\\linear_relu.py', reloading
2025-06-19 12:01:37,045 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:01:37,048 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\bn_relu.py', reloading
2025-06-19 12:01:37,051 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\conv_add.py', reloading
2025-06-19 12:01:37,053 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\conv_relu.py', reloading
2025-06-19 12:01:37,056 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\linear_relu.py', reloading
2025-06-19 12:01:37,058 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:01:37,060 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\__init__.py', reloading
2025-06-19 12:01:37,063 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\dynamic\\__init__.py', reloading
2025-06-19 12:01:37,065 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\dynamic\\modules\\linear.py', reloading
2025-06-19 12:01:37,066 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:01:37,069 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\modules\\conv.py', reloading
2025-06-19 12:01:37,071 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\modules\\embedding_ops.py', reloading
2025-06-19 12:01:37,072 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\modules\\linear.py', reloading
2025-06-19 12:01:37,074 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\modules\\__init__.py', reloading
2025-06-19 12:01:37,077 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantizable\\__init__.py', reloading
2025-06-19 12:01:37,079 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantizable\\modules\\activation.py', reloading
2025-06-19 12:01:37,082 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantizable\\modules\\rnn.py', reloading
2025-06-19 12:01:37,083 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantizable\\modules\\__init__.py', reloading
2025-06-19 12:01:37,086 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\functional.py', reloading
2025-06-19 12:01:37,087 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\__init__.py', reloading
2025-06-19 12:01:37,089 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:01:37,091 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\modules\\conv.py', reloading
2025-06-19 12:01:37,092 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\modules\\linear.py', reloading
2025-06-19 12:01:37,094 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\modules\\rnn.py', reloading
2025-06-19 12:01:37,096 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:01:37,099 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\activation.py', reloading
2025-06-19 12:01:37,101 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\batchnorm.py', reloading
2025-06-19 12:01:37,103 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\conv.py', reloading
2025-06-19 12:01:37,104 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\dropout.py', reloading
2025-06-19 12:01:37,106 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\embedding_ops.py', reloading
2025-06-19 12:01:37,108 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\functional_modules.py', reloading
2025-06-19 12:01:37,109 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\linear.py', reloading
2025-06-19 12:01:37,111 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\normalization.py', reloading
2025-06-19 12:01:37,114 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\rnn.py', reloading
2025-06-19 12:01:37,115 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\utils.py', reloading
2025-06-19 12:01:37,117 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:01:37,122 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\__init__.py', reloading
2025-06-19 12:01:37,125 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\conv.py', reloading
2025-06-19 12:01:37,127 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\linear.py', reloading
2025-06-19 12:01:37,130 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\rnn.py', reloading
2025-06-19 12:01:37,133 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\sparse.py', reloading
2025-06-19 12:01:37,134 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\utils.py', reloading
2025-06-19 12:01:37,138 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\__init__.py', reloading
2025-06-19 12:01:37,143 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\__init__.py', reloading
2025-06-19 12:01:37,145 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\linear.py', reloading
2025-06-19 12:01:37,150 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\utils.py', reloading
2025-06-19 12:01:37,154 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\__init__.py', reloading
2025-06-19 12:01:37,157 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\dynamic\\linear.py', reloading
2025-06-19 12:01:37,228 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:01:37,290 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\_numeric_suite.py', reloading
2025-06-19 12:01:37,335 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\_numeric_suite_fx.py', reloading
2025-06-19 12:01:37,370 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\__init__.py', reloading
2025-06-19 12:01:37,387 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\graph_matcher.py', reloading
2025-06-19 12:01:37,446 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\graph_passes.py', reloading
2025-06-19 12:01:37,464 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\mappings.py', reloading
2025-06-19 12:01:37,496 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\ns_types.py', reloading
2025-06-19 12:01:37,529 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\n_shadows_utils.py', reloading
2025-06-19 12:01:37,547 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\pattern_utils.py', reloading
2025-06-19 12:01:39,186 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:01:45,666 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:01:45,703 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:02:07,435 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\__init__.py', reloading
2025-06-19 12:02:07,436 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\__init__.py', reloading
2025-06-19 12:02:07,486 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\__init__.py', reloading
2025-06-19 12:02:07,498 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_async.py', reloading
2025-06-19 12:02:07,500 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_async.py', reloading
2025-06-19 12:02:07,509 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_await.py', reloading
2025-06-19 12:02:07,516 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_await.py', reloading
2025-06-19 12:02:07,519 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_builtins.py', reloading
2025-06-19 12:02:07,524 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_builtins.py', reloading
2025-06-19 12:02:07,527 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_check.py', reloading
2025-06-19 12:02:07,536 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_check.py', reloading
2025-06-19 12:02:07,539 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_dataclass_impls.py', reloading
2025-06-19 12:02:07,542 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_dataclass_impls.py', reloading
2025-06-19 12:02:07,545 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_decomposition_utils.py', reloading
2025-06-19 12:02:07,549 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_decomposition_utils.py', reloading
2025-06-19 12:02:07,550 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_decompositions.py', reloading
2025-06-19 12:02:07,552 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_decompositions.py', reloading
2025-06-19 12:02:07,553 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_freeze.py', reloading
2025-06-19 12:02:07,554 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_freeze.py', reloading
2025-06-19 12:02:07,556 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_fuser.py', reloading
2025-06-19 12:02:07,559 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_fuser.py', reloading
2025-06-19 12:02:07,562 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_ir_utils.py', reloading
2025-06-19 12:02:07,566 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_ir_utils.py', reloading
2025-06-19 12:02:07,577 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_logging.py', reloading
2025-06-19 12:02:07,587 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_logging.py', reloading
2025-06-19 12:02:07,596 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_monkeytype_config.py', reloading
2025-06-19 12:02:07,601 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_monkeytype_config.py', reloading
2025-06-19 12:02:07,603 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_pickle.py', reloading
2025-06-19 12:02:07,742 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_pickle.py', reloading
2025-06-19 12:02:07,827 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_recursive.py', reloading
2025-06-19 12:02:07,875 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_recursive.py', reloading
2025-06-19 12:02:07,897 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_script.py', reloading
2025-06-19 12:02:07,904 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_script.py', reloading
2025-06-19 12:02:07,907 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_serialization.py', reloading
2025-06-19 12:02:07,912 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_serialization.py', reloading
2025-06-19 12:02:07,914 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_shape_functions.py', reloading
2025-06-19 12:02:07,916 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_shape_functions.py', reloading
2025-06-19 12:02:07,916 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_state.py', reloading
2025-06-19 12:02:07,922 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_state.py', reloading
2025-06-19 12:02:07,924 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_trace.py', reloading
2025-06-19 12:02:07,963 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\_trace.py', reloading
2025-06-19 12:02:07,972 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\annotations.py', reloading
2025-06-19 12:02:07,974 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\annotations.py', reloading
2025-06-19 12:02:07,979 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\jit\\frontend.py', reloading
2025-06-19 12:02:08,127 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:02:10,655 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:02:10,666 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:02:21,976 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\linalg\\__init__.py', reloading
2025-06-19 12:02:21,978 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\linalg\\__init__.py', reloading
2025-06-19 12:02:21,978 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\__init__.py', reloading
2025-06-19 12:02:21,985 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\__init__.py', reloading
2025-06-19 12:02:21,989 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\__init__.py', reloading
2025-06-19 12:02:21,990 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\_docs.py', reloading
2025-06-19 12:02:21,992 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\_docs.py', reloading
2025-06-19 12:02:21,995 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\_ops.py', reloading
2025-06-19 12:02:21,998 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\_ops.py', reloading
2025-06-19 12:02:22,004 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\__init__.py', reloading
2025-06-19 12:02:22,005 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\__init__.py', reloading
2025-06-19 12:02:22,006 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\_ops_refs.py', reloading
2025-06-19 12:02:22,008 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\_ops_refs.py', reloading
2025-06-19 12:02:22,012 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\binary.py', reloading
2025-06-19 12:02:22,014 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\binary.py', reloading
2025-06-19 12:02:22,020 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\core.py', reloading
2025-06-19 12:02:22,023 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\core.py', reloading
2025-06-19 12:02:22,028 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\creation.py', reloading
2025-06-19 12:02:22,029 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\creation.py', reloading
2025-06-19 12:02:22,030 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\passthrough.py', reloading
2025-06-19 12:02:22,031 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\passthrough.py', reloading
2025-06-19 12:02:22,035 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\reductions.py', reloading
2025-06-19 12:02:22,039 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\reductions.py', reloading
2025-06-19 12:02:22,043 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\unary.py', reloading
2025-06-19 12:02:22,047 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\masked\\maskedtensor\\unary.py', reloading
2025-06-19 12:02:22,048 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\monitor\\__init__.py', reloading
2025-06-19 12:02:22,049 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\monitor\\__init__.py', reloading
2025-06-19 12:02:22,053 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\monitor\\__init__.py', reloading
2025-06-19 12:02:22,056 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mps\\__init__.py', reloading
2025-06-19 12:02:22,062 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mps\\__init__.py', reloading
2025-06-19 12:02:22,064 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mps\\event.py', reloading
2025-06-19 12:02:22,065 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mps\\event.py', reloading
2025-06-19 12:02:22,066 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mps\\profiler.py', reloading
2025-06-19 12:02:22,068 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mps\\profiler.py', reloading
2025-06-19 12:02:22,069 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mtia\\__init__.py', reloading
2025-06-19 12:02:22,071 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mtia\\__init__.py', reloading
2025-06-19 12:02:22,073 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mtia\\__init__.py', reloading
2025-06-19 12:02:22,077 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mtia\\_utils.py', reloading
2025-06-19 12:02:22,081 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mtia\\_utils.py', reloading
2025-06-19 12:02:22,083 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mtia\\memory.py', reloading
2025-06-19 12:02:22,086 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\mtia\\memory.py', reloading
2025-06-19 12:02:22,087 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\__init__.py', reloading
2025-06-19 12:02:22,088 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\__init__.py', reloading
2025-06-19 12:02:22,090 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\__init__.py', reloading
2025-06-19 12:02:22,094 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\_atfork.py', reloading
2025-06-19 12:02:22,095 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\_atfork.py', reloading
2025-06-19 12:02:22,099 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\pool.py', reloading
2025-06-19 12:02:22,101 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\pool.py', reloading
2025-06-19 12:02:22,103 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\queue.py', reloading
2025-06-19 12:02:22,107 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\queue.py', reloading
2025-06-19 12:02:22,110 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\reductions.py', reloading
2025-06-19 12:02:22,110 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\reductions.py', reloading
2025-06-19 12:02:22,111 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\spawn.py', reloading
2025-06-19 12:02:22,112 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\multiprocessing\\spawn.py', reloading
2025-06-19 12:02:22,113 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\__init__.py', reloading
2025-06-19 12:02:22,114 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\__init__.py', reloading
2025-06-19 12:02:22,115 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\__init__.py', reloading
2025-06-19 12:02:22,117 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\__init__.py', reloading
2025-06-19 12:02:22,121 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\__init__.py', reloading
2025-06-19 12:02:22,125 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\nested_int.py', reloading
2025-06-19 12:02:22,133 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\nested_int.py', reloading
2025-06-19 12:02:22,133 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\nested_tensor.py', reloading
2025-06-19 12:02:22,135 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\nested_tensor.py', reloading
2025-06-19 12:02:22,137 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\ops.py', reloading
2025-06-19 12:02:22,140 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\ops.py', reloading
2025-06-19 12:02:22,143 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\sdpa.py', reloading
2025-06-19 12:02:22,145 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nested\\_internal\\sdpa.py', reloading
2025-06-19 12:02:22,150 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\__init__.py', reloading
2025-06-19 12:02:22,152 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\__init__.py', reloading
2025-06-19 12:02:22,153 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\_reduction.py', reloading
2025-06-19 12:02:22,154 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\_reduction.py', reloading
2025-06-19 12:02:22,155 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\common_types.py', reloading
2025-06-19 12:02:22,158 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\common_types.py', reloading
2025-06-19 12:02:22,165 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\cpp.py', reloading
2025-06-19 12:02:22,167 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\cpp.py', reloading
2025-06-19 12:02:22,172 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py', reloading
2025-06-19 12:02:22,173 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\functional.py', reloading
2025-06-19 12:02:22,175 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\grad.py', reloading
2025-06-19 12:02:22,177 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\grad.py', reloading
2025-06-19 12:02:22,181 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\init.py', reloading
2025-06-19 12:02:22,183 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\init.py', reloading
2025-06-19 12:02:22,188 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\parameter.py', reloading
2025-06-19 12:02:22,191 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\parameter.py', reloading
2025-06-19 12:02:22,193 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\__init__.py', reloading
2025-06-19 12:02:22,194 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\__init__.py', reloading
2025-06-19 12:02:22,197 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\__init__.py', reloading
2025-06-19 12:02:22,201 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\_utils.py', reloading
2025-06-19 12:02:22,204 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\_utils.py', reloading
2025-06-19 12:02:22,213 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\bias.py', reloading
2025-06-19 12:02:22,216 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\bias.py', reloading
2025-06-19 12:02:22,219 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\flex_attention.py', reloading
2025-06-19 12:02:22,222 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\flex_attention.py', reloading
2025-06-19 12:02:22,224 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\experimental\\__init__.py', reloading
2025-06-19 12:02:22,227 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\experimental\\__init__.py', reloading
2025-06-19 12:02:22,230 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\experimental\\__init__.py', reloading
2025-06-19 12:02:22,235 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\experimental\\_paged_attention.py', reloading
2025-06-19 12:02:22,238 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\attention\\experimental\\_paged_attention.py', reloading
2025-06-19 12:02:22,241 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\backends\\__init__.py', reloading
2025-06-19 12:02:22,248 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\backends\\thnn.py', reloading
2025-06-19 12:02:22,249 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\backends\\thnn.py', reloading
2025-06-19 12:02:22,250 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\__init__.py', reloading
2025-06-19 12:02:22,250 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\__init__.py', reloading
2025-06-19 12:02:22,252 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\__init__.py', reloading
2025-06-19 12:02:22,254 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\modules\\__init__.py', reloading
2025-06-19 12:02:22,257 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\modules\\__init__.py', reloading
2025-06-19 12:02:22,264 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\modules\\fused.py', reloading
2025-06-19 12:02:22,272 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\modules\\fused.py', reloading
2025-06-19 12:02:22,277 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\__init__.py', reloading
2025-06-19 12:02:22,278 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\__init__.py', reloading
2025-06-19 12:02:22,279 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\__init__.py', reloading
2025-06-19 12:02:22,283 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\__init__.py', reloading
2025-06-19 12:02:22,288 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\__init__.py', reloading
2025-06-19 12:02:22,290 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\__init__.py', reloading
2025-06-19 12:02:22,294 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\conv_fused.py', reloading
2025-06-19 12:02:22,295 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\conv_fused.py', reloading
2025-06-19 12:02:22,296 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\linear_fused.py', reloading
2025-06-19 12:02:22,298 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\linear_fused.py', reloading
2025-06-19 12:02:22,301 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\linear_relu.py', reloading
2025-06-19 12:02:22,306 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\qat\\modules\\linear_relu.py', reloading
2025-06-19 12:02:22,314 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\__init__.py', reloading
2025-06-19 12:02:22,319 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\__init__.py', reloading
2025-06-19 12:02:22,322 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\__init__.py', reloading
2025-06-19 12:02:22,323 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:02:22,324 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:02:22,325 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:02:22,326 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:02:22,327 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:02:22,327 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:02:22,329 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\dynamic\\modules\\linear_relu.py', reloading
2025-06-19 12:02:22,331 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\dynamic\\modules\\linear_relu.py', reloading
2025-06-19 12:02:22,332 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:02:22,333 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:02:22,334 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:02:22,337 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\bn_relu.py', reloading
2025-06-19 12:02:22,338 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\bn_relu.py', reloading
2025-06-19 12:02:22,340 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\conv_relu.py', reloading
2025-06-19 12:02:22,342 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\conv_relu.py', reloading
2025-06-19 12:02:22,344 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\linear_relu.py', reloading
2025-06-19 12:02:22,345 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\intrinsic\\quantized\\modules\\linear_relu.py', reloading
2025-06-19 12:02:22,348 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\__init__.py', reloading
2025-06-19 12:02:22,354 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\__init__.py', reloading
2025-06-19 12:02:22,357 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\__init__.py', reloading
2025-06-19 12:02:22,364 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\_functions.py', reloading
2025-06-19 12:02:22,365 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\_functions.py', reloading
2025-06-19 12:02:22,367 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\activation.py', reloading
2025-06-19 12:02:22,368 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\activation.py', reloading
2025-06-19 12:02:22,370 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\adaptive.py', reloading
2025-06-19 12:02:22,372 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\adaptive.py', reloading
2025-06-19 12:02:22,375 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\batchnorm.py', reloading
2025-06-19 12:02:22,381 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\batchnorm.py', reloading
2025-06-19 12:02:22,385 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\channelshuffle.py', reloading
2025-06-19 12:02:22,386 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\channelshuffle.py', reloading
2025-06-19 12:02:22,388 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py', reloading
2025-06-19 12:02:22,393 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\container.py', reloading
2025-06-19 12:02:22,399 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py', reloading
2025-06-19 12:02:22,402 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\conv.py', reloading
2025-06-19 12:02:22,403 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\distance.py', reloading
2025-06-19 12:02:22,404 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\distance.py', reloading
2025-06-19 12:02:22,405 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\dropout.py', reloading
2025-06-19 12:02:22,408 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\dropout.py', reloading
2025-06-19 12:02:22,413 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\flatten.py', reloading
2025-06-19 12:02:22,419 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\flatten.py', reloading
2025-06-19 12:02:22,421 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\fold.py', reloading
2025-06-19 12:02:22,423 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\fold.py', reloading
2025-06-19 12:02:22,424 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\instancenorm.py', reloading
2025-06-19 12:02:22,425 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\instancenorm.py', reloading
2025-06-19 12:02:22,427 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\lazy.py', reloading
2025-06-19 12:02:22,430 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\lazy.py', reloading
2025-06-19 12:02:22,433 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py', reloading
2025-06-19 12:02:22,435 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py', reloading
2025-06-19 12:02:22,438 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\loss.py', reloading
2025-06-19 12:02:22,441 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\loss.py', reloading
2025-06-19 12:02:22,443 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py', reloading
2025-06-19 12:02:22,449 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py', reloading
2025-06-19 12:02:22,621 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:02:25,500 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:02:25,511 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:03:40,416 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\compile\\__init__.py', reloading
2025-06-19 12:03:40,424 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\batch_tensor.py', reloading
2025-06-19 12:03:40,427 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\delayed_mul_tensor.py', reloading
2025-06-19 12:03:40,430 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\dim.py', reloading
2025-06-19 12:03:40,433 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\magic_trace.py', reloading
2025-06-19 12:03:40,436 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\op_properties.py', reloading
2025-06-19 12:03:40,439 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\reference.py', reloading
2025-06-19 12:03:40,446 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\tree_map.py', reloading
2025-06-19 12:03:40,449 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\wrap_type.py', reloading
2025-06-19 12:03:40,453 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\dim\\__init__.py', reloading
2025-06-19 12:03:40,458 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\experimental\\control_flow.py', reloading
2025-06-19 12:03:40,462 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\experimental\\ops.py', reloading
2025-06-19 12:03:40,465 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\experimental\\_cond.py', reloading
2025-06-19 12:03:40,466 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\experimental\\_map.py', reloading
2025-06-19 12:03:40,469 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\experimental\\__init__.py', reloading
2025-06-19 12:03:40,472 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\_src\\aot_autograd\\__init__.py', reloading
2025-06-19 12:03:40,477 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\_src\\eager_transforms\\__init__.py', reloading
2025-06-19 12:03:40,479 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\_src\\make_functional\\__init__.py', reloading
2025-06-19 12:03:40,480 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\_src\\vmap\\__init__.py', reloading
2025-06-19 12:03:40,484 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\_src\\__init__.py', reloading
2025-06-19 12:03:40,486 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~unctorch\\__init__.py', reloading
2025-06-19 12:03:40,491 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\amp\\autocast_mode.py', reloading
2025-06-19 12:03:40,493 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\amp\\__init__.py', reloading
2025-06-19 12:03:40,495 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\modules\\fused.py', reloading
2025-06-19 12:03:40,497 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\modules\\__init__.py', reloading
2025-06-19 12:03:40,499 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\modules\\conv_fused.py', reloading
2025-06-19 12:03:40,501 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\modules\\linear_fused.py', reloading
2025-06-19 12:03:40,502 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\modules\\linear_relu.py', reloading
2025-06-19 12:03:40,504 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\modules\\__init__.py', reloading
2025-06-19 12:03:40,508 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\qat\\__init__.py', reloading
2025-06-19 12:03:40,511 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\dynamic\\modules\\linear_relu.py', reloading
2025-06-19 12:03:40,513 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:03:40,515 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:03:40,519 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\bn_relu.py', reloading
2025-06-19 12:03:40,520 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\conv_add.py', reloading
2025-06-19 12:03:40,523 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\conv_relu.py', reloading
2025-06-19 12:03:40,525 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\linear_relu.py', reloading
2025-06-19 12:03:40,527 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:03:40,529 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\quantized\\__init__.py', reloading
2025-06-19 12:03:40,537 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\intrinsic\\__init__.py', reloading
2025-06-19 12:03:40,543 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\dynamic\\modules\\linear.py', reloading
2025-06-19 12:03:40,543 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:03:40,549 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\dynamic\\__init__.py', reloading
2025-06-19 12:03:40,553 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\modules\\conv.py', reloading
2025-06-19 12:03:40,554 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\modules\\embedding_ops.py', reloading
2025-06-19 12:03:40,557 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\modules\\linear.py', reloading
2025-06-19 12:03:40,558 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\modules\\__init__.py', reloading
2025-06-19 12:03:40,565 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\qat\\__init__.py', reloading
2025-06-19 12:03:40,569 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantizable\\modules\\activation.py', reloading
2025-06-19 12:03:40,570 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantizable\\modules\\rnn.py', reloading
2025-06-19 12:03:40,572 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantizable\\modules\\__init__.py', reloading
2025-06-19 12:03:40,576 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantizable\\__init__.py', reloading
2025-06-19 12:03:40,582 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\modules\\conv.py', reloading
2025-06-19 12:03:40,583 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\modules\\linear.py', reloading
2025-06-19 12:03:40,586 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\modules\\rnn.py', reloading
2025-06-19 12:03:40,588 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:03:40,592 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:03:40,598 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\functional.py', reloading
2025-06-19 12:03:40,599 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\activation.py', reloading
2025-06-19 12:03:40,600 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\batchnorm.py', reloading
2025-06-19 12:03:40,602 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\conv.py', reloading
2025-06-19 12:03:40,603 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\dropout.py', reloading
2025-06-19 12:03:40,605 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\embedding_ops.py', reloading
2025-06-19 12:03:40,607 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\functional_modules.py', reloading
2025-06-19 12:03:40,610 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\linear.py', reloading
2025-06-19 12:03:40,611 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\normalization.py', reloading
2025-06-19 12:03:40,613 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\rnn.py', reloading
2025-06-19 12:03:40,614 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\utils.py', reloading
2025-06-19 12:03:40,616 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:03:40,629 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\conv.py', reloading
2025-06-19 12:03:40,630 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\linear.py', reloading
2025-06-19 12:03:40,632 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\rnn.py', reloading
2025-06-19 12:03:40,635 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\sparse.py', reloading
2025-06-19 12:03:40,637 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\utils.py', reloading
2025-06-19 12:03:40,638 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\modules\\__init__.py', reloading
2025-06-19 12:03:40,648 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\reference\\__init__.py', reloading
2025-06-19 12:03:40,650 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\quantized\\__init__.py', reloading
2025-06-19 12:03:40,650 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\dynamic\\linear.py', reloading
2025-06-19 12:03:40,657 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:03:40,663 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\linear.py', reloading
2025-06-19 12:03:40,679 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\utils.py', reloading
2025-06-19 12:03:40,686 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\quantized\\__init__.py', reloading
2025-06-19 12:03:40,695 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\sparse\\__init__.py', reloading
2025-06-19 12:03:40,697 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\nn\\__init__.py', reloading
2025-06-19 12:03:40,701 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\graph_matcher.py', reloading
2025-06-19 12:03:40,703 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\graph_passes.py', reloading
2025-06-19 12:03:40,705 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\mappings.py', reloading
2025-06-19 12:03:40,712 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\ns_types.py', reloading
2025-06-19 12:03:40,713 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\n_shadows_utils.py', reloading
2025-06-19 12:03:40,715 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\pattern_utils.py', reloading
2025-06-19 12:03:40,717 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\qconfig_multi_mapping.py', reloading
2025-06-19 12:03:40,719 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\utils.py', reloading
2025-06-19 12:03:40,720 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\weight_utils.py', reloading
2025-06-19 12:03:40,722 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\fx\\__init__.py', reloading
2025-06-19 12:03:40,729 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\_numeric_suite.py', reloading
2025-06-19 12:03:40,731 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\_numeric_suite_fx.py', reloading
2025-06-19 12:03:40,733 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\ns\\__init__.py', reloading
2025-06-19 12:03:40,736 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\scheduler\\base_scheduler.py', reloading
2025-06-19 12:03:40,740 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\scheduler\\cubic_scheduler.py', reloading
2025-06-19 12:03:40,743 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\scheduler\\lambda_scheduler.py', reloading
2025-06-19 12:03:40,744 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\scheduler\\__init__.py', reloading
2025-06-19 12:03:40,748 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\sparsifier\\base_sparsifier.py', reloading
2025-06-19 12:03:40,753 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\sparsifier\\nearly_diagonal_sparsifier.py', reloading
2025-06-19 12:03:40,754 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\sparsifier\\utils.py', reloading
2025-06-19 12:03:40,757 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\sparsifier\\weight_norm_sparsifier.py', reloading
2025-06-19 12:03:40,760 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\sparsifier\\__init__.py', reloading
2025-06-19 12:03:40,763 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\_experimental\\activation_sparsifier\\activation_sparsifier.py', reloading
2025-06-19 12:03:40,763 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\_experimental\\activation_sparsifier\\__init__.py', reloading
2025-06-19 12:03:40,767 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\_experimental\\data_scheduler\\base_data_scheduler.py', reloading
2025-06-19 12:03:40,769 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\_experimental\\data_scheduler\\__init__.py', reloading
2025-06-19 12:03:40,773 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\_experimental\\data_sparsifier\\base_data_sparsifier.py', reloading
2025-06-19 12:03:40,776 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\ao\\pruning\\_experimental\\data_sparsifier\\data_norm_sparsifier.py', reloading
2025-06-19 12:03:41,001 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:03:44,611 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:03:44,628 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:03:47,469 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\annotations.py', reloading
2025-06-19 12:03:47,472 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\frontend.py', reloading
2025-06-19 12:03:47,477 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\generate_bytecode.py', reloading
2025-06-19 12:03:47,483 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\mobile\\__init__.py', reloading
2025-06-19 12:03:47,486 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\quantized.py', reloading
2025-06-19 12:03:47,490 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\supported_ops.py', reloading
2025-06-19 12:03:47,493 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\unsupported_tensor_ops.py', reloading
2025-06-19 12:03:47,499 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_async.py', reloading
2025-06-19 12:03:47,501 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_await.py', reloading
2025-06-19 12:03:47,508 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_builtins.py', reloading
2025-06-19 12:03:47,511 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_check.py', reloading
2025-06-19 12:03:47,516 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_dataclass_impls.py', reloading
2025-06-19 12:03:47,519 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_decompositions.py', reloading
2025-06-19 12:03:47,524 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_decomposition_utils.py', reloading
2025-06-19 12:03:47,528 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_freeze.py', reloading
2025-06-19 12:03:47,531 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_fuser.py', reloading
2025-06-19 12:03:47,534 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_ir_utils.py', reloading
2025-06-19 12:03:47,538 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_logging.py', reloading
2025-06-19 12:03:47,542 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_monkeytype_config.py', reloading
2025-06-19 12:03:47,547 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_passes\\_property_propagation.py', reloading
2025-06-19 12:03:47,551 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_passes\\__init__.py', reloading
2025-06-19 12:03:47,560 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_pickle.py', reloading
2025-06-19 12:03:47,565 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_recursive.py', reloading
2025-06-19 12:03:47,568 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_script.py', reloading
2025-06-19 12:03:47,574 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_serialization.py', reloading
2025-06-19 12:03:47,577 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_shape_functions.py', reloading
2025-06-19 12:03:47,585 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_state.py', reloading
2025-06-19 12:03:47,588 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\_trace.py', reloading
2025-06-19 12:03:47,592 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\jit\\__init__.py', reloading
2025-06-19 12:03:47,608 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\library.py', reloading
2025-06-19 12:03:47,611 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\linalg\\__init__.py', reloading
2025-06-19 12:03:47,616 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\maskedtensor\\binary.py', reloading
2025-06-19 12:03:47,620 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\maskedtensor\\core.py', reloading
2025-06-19 12:03:47,625 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\maskedtensor\\creation.py', reloading
2025-06-19 12:03:47,629 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\maskedtensor\\passthrough.py', reloading
2025-06-19 12:03:47,633 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\maskedtensor\\reductions.py', reloading
2025-06-19 12:03:47,636 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\maskedtensor\\unary.py', reloading
2025-06-19 12:03:47,640 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\maskedtensor\\_ops_refs.py', reloading
2025-06-19 12:03:47,643 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\maskedtensor\\__init__.py', reloading
2025-06-19 12:03:47,651 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\_docs.py', reloading
2025-06-19 12:03:47,658 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\_ops.py', reloading
2025-06-19 12:03:47,666 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\masked\\__init__.py', reloading
2025-06-19 12:03:47,673 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\monitor\\__init__.py', reloading
2025-06-19 12:03:47,675 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\mps\\__init__.py', reloading
2025-06-19 12:03:47,680 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\multiprocessing\\pool.py', reloading
2025-06-19 12:03:47,685 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\multiprocessing\\queue.py', reloading
2025-06-19 12:03:47,689 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\multiprocessing\\reductions.py', reloading
2025-06-19 12:03:47,691 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\multiprocessing\\spawn.py', reloading
2025-06-19 12:03:47,694 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\multiprocessing\\_atfork.py', reloading
2025-06-19 12:03:47,697 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\multiprocessing\\__init__.py', reloading
2025-06-19 12:03:47,702 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nested\\__init__.py', reloading
2025-06-19 12:03:47,709 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\backends\\thnn.py', reloading
2025-06-19 12:03:47,714 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\backends\\__init__.py', reloading
2025-06-19 12:03:47,718 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\common_types.py', reloading
2025-06-19 12:03:47,724 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\cpp.py', reloading
2025-06-19 12:03:47,730 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\functional.py', reloading
2025-06-19 12:03:47,733 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\grad.py', reloading
2025-06-19 12:03:47,739 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\init.py', reloading
2025-06-19 12:03:47,742 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\modules\\fused.py', reloading
2025-06-19 12:03:47,746 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\modules\\__init__.py', reloading
2025-06-19 12:03:47,750 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\qat\\modules\\conv_fused.py', reloading
2025-06-19 12:03:47,754 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\qat\\modules\\linear_fused.py', reloading
2025-06-19 12:03:47,758 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\qat\\modules\\linear_relu.py', reloading
2025-06-19 12:03:47,762 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\qat\\modules\\__init__.py', reloading
2025-06-19 12:03:47,770 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\qat\\__init__.py', reloading
2025-06-19 12:03:47,779 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\quantized\\dynamic\\modules\\linear_relu.py', reloading
2025-06-19 12:03:47,787 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:03:47,795 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:03:47,801 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\quantized\\modules\\bn_relu.py', reloading
2025-06-19 12:03:47,803 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\quantized\\modules\\conv_relu.py', reloading
2025-06-19 12:03:47,810 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\quantized\\modules\\linear_relu.py', reloading
2025-06-19 12:03:47,818 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:03:47,826 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\quantized\\__init__.py', reloading
2025-06-19 12:03:47,831 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\intrinsic\\__init__.py', reloading
2025-06-19 12:03:47,834 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\activation.py', reloading
2025-06-19 12:03:47,837 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\adaptive.py', reloading
2025-06-19 12:03:47,840 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\batchnorm.py', reloading
2025-06-19 12:03:47,842 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\channelshuffle.py', reloading
2025-06-19 12:03:47,848 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\container.py', reloading
2025-06-19 12:03:47,851 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\conv.py', reloading
2025-06-19 12:03:47,854 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\distance.py', reloading
2025-06-19 12:03:47,862 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\dropout.py', reloading
2025-06-19 12:03:47,866 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\flatten.py', reloading
2025-06-19 12:03:47,871 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\fold.py', reloading
2025-06-19 12:03:47,874 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\instancenorm.py', reloading
2025-06-19 12:03:47,877 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\lazy.py', reloading
2025-06-19 12:03:47,881 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\linear.py', reloading
2025-06-19 12:03:47,884 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\loss.py', reloading
2025-06-19 12:03:47,886 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\module.py', reloading
2025-06-19 12:03:47,893 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\normalization.py', reloading
2025-06-19 12:03:47,897 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\padding.py', reloading
2025-06-19 12:03:47,902 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\pixelshuffle.py', reloading
2025-06-19 12:03:47,904 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\pooling.py', reloading
2025-06-19 12:03:47,909 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\rnn.py', reloading
2025-06-19 12:03:47,913 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\sparse.py', reloading
2025-06-19 12:03:47,919 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\transformer.py', reloading
2025-06-19 12:03:47,921 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\upsampling.py', reloading
2025-06-19 12:03:47,936 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\utils.py', reloading
2025-06-19 12:03:47,941 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\_functions.py', reloading
2025-06-19 12:03:47,943 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\modules\\__init__.py', reloading
2025-06-19 12:03:47,951 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\comm.py', reloading
2025-06-19 12:03:47,957 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\data_parallel.py', reloading
2025-06-19 12:03:47,964 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\distributed.py', reloading
2025-06-19 12:03:47,972 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\parallel_apply.py', reloading
2025-06-19 12:03:47,978 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\replicate.py', reloading
2025-06-19 12:03:47,982 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\scatter_gather.py', reloading
2025-06-19 12:03:47,984 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\_functions.py', reloading
2025-06-19 12:03:47,989 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\_replicated_tensor_ddp_interop.py', reloading
2025-06-19 12:03:47,990 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\_replicated_tensor_ddp_utils.py', reloading
2025-06-19 12:03:47,997 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parallel\\__init__.py', reloading
2025-06-19 12:03:48,003 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\parameter.py', reloading
2025-06-19 12:03:48,008 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\qat\\dynamic\\modules\\linear.py', reloading
2025-06-19 12:03:48,014 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\qat\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:03:48,018 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\qat\\dynamic\\__init__.py', reloading
2025-06-19 12:03:48,024 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\qat\\modules\\conv.py', reloading
2025-06-19 12:03:48,027 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\qat\\modules\\embedding_ops.py', reloading
2025-06-19 12:03:48,030 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\qat\\modules\\linear.py', reloading
2025-06-19 12:03:48,034 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\qat\\modules\\__init__.py', reloading
2025-06-19 12:03:48,037 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\qat\\__init__.py', reloading
2025-06-19 12:03:48,048 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantizable\\modules\\activation.py', reloading
2025-06-19 12:03:48,059 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantizable\\modules\\rnn.py', reloading
2025-06-19 12:03:48,062 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantizable\\modules\\__init__.py', reloading
2025-06-19 12:03:48,066 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantizable\\__init__.py', reloading
2025-06-19 12:03:48,075 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\dynamic\\modules\\conv.py', reloading
2025-06-19 12:03:48,081 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\dynamic\\modules\\linear.py', reloading
2025-06-19 12:03:48,084 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\dynamic\\modules\\rnn.py', reloading
2025-06-19 12:03:48,088 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\dynamic\\modules\\__init__.py', reloading
2025-06-19 12:03:48,091 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\dynamic\\__init__.py', reloading
2025-06-19 12:03:48,098 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\functional.py', reloading
2025-06-19 12:03:48,103 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\activation.py', reloading
2025-06-19 12:03:48,104 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\batchnorm.py', reloading
2025-06-19 12:03:48,107 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\conv.py', reloading
2025-06-19 12:03:48,114 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\dropout.py', reloading
2025-06-19 12:03:48,122 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\embedding_ops.py', reloading
2025-06-19 12:03:48,125 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\functional_modules.py', reloading
2025-06-19 12:03:48,131 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\linear.py', reloading
2025-06-19 12:03:48,140 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\normalization.py', reloading
2025-06-19 12:03:48,144 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\rnn.py', reloading
2025-06-19 12:03:48,149 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\utils.py', reloading
2025-06-19 12:03:48,155 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\modules\\__init__.py', reloading
2025-06-19 12:03:48,173 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\_reference\\modules\\conv.py', reloading
2025-06-19 12:03:48,177 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\_reference\\modules\\linear.py', reloading
2025-06-19 12:03:48,183 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\_reference\\modules\\rnn.py', reloading
2025-06-19 12:03:48,187 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\~orch\\nn\\quantized\\_reference\\modules\\sparse.py', reloading
2025-06-19 12:03:48,401 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:03:55,042 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:03:55,076 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:04:41,766 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\functools.py', reloading
2025-06-19 12:04:42,041 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:04:45,431 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:04:45,443 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:04:54,207 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py', reloading
2025-06-19 12:04:54,558 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:04:58,050 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:04:58,119 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:13:40,161 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.122:5000
2025-06-19 12:13:40,164 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-19 12:13:40,199 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:13:41,855 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:13:41,864 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:14:08,703 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:14:08] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:14:08,977 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:14:08] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:14:08,980 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:14:08] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:14:09,517 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:14:09] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:18:18,272 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121818.wav, taille: 80339 bytes
2025-06-19 12:18:18,927 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121818.wav, taille: 14651 bytes
2025-06-19 12:18:19,577 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121818.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:18:19,592 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121818.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:18:21,218 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:18:21,222 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:18:21,278 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:18:21,284 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:18:22,124 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:22] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:18:22,212 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:22] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:18:22,232 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:22] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:18:22,621 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:22] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:18:34,464 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121834.wav, taille: 80339 bytes
2025-06-19 12:18:34,608 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121834.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:18:36,884 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:18:36,884 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:18:39,774 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121839.wav, taille: 80339 bytes
2025-06-19 12:18:39,924 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121839.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:18:43,471 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:18:43,479 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062c\\u0647\\u0627\\u0632 \\u0627\\u0644\\u0647\\u0636\\u0645\\u064a \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:18:43,487 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:18:43,491 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:18:44,464 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121844.wav, taille: 80339 bytes
2025-06-19 12:18:44,612 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121844.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:18:47,116 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:18:47,119 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:18:47,414 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:18:47,419 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=430 request_id=req_7552a3b5f386bfb5cd2384602863f117 response_code=200
2025-06-19 12:18:47,571 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:18:49,774 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121849.wav, taille: 80339 bytes
2025-06-19 12:18:49,943 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121849.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:18:51,533 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:51] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:18:51,596 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:51] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:18:51,612 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:51] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:18:51,702 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:51] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:18:51,755 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:18:51,759 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:18:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:03,338 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121903.wav, taille: 80339 bytes
2025-06-19 12:19:03,473 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121903.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:08,028 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121908.wav, taille: 80339 bytes
2025-06-19 12:19:08,153 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121908.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:10,056 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121910.wav, taille: 27209 bytes
2025-06-19 12:19:10,164 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121910.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:11,599 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:19:11,602 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:15,040 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:15] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:19:15,110 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:15] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:19:15,118 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:15] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:19:15,498 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:15] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:19:19,382 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:19:19,385 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:24,098 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121924.wav, taille: 80339 bytes
2025-06-19 12:19:24,226 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121924.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:27,446 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:19:27,446 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"bonjour comment tu es l\\u00e0\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:19:27,452 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:19:27,459 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:19:28,552 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:19:28,552 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=509 request_id=req_a6dc3b9c308c9e638a589a7e315cd7fe response_code=200
2025-06-19 12:19:28,664 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'bonjour comment tu es là', 'fused': 'Bonjour, comment tu es là?'}
2025-06-19 12:19:28,664 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:29,417 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121929.wav, taille: 80339 bytes
2025-06-19 12:19:29,552 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121929.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:29,792 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:19:29,792 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"salade\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:19:29,792 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:19:29,801 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:19:31,282 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:19:31,292 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1007 request_id=req_676577f388dfe625da16579cf04b1c95 response_code=200
2025-06-19 12:19:31,397 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:19:31,401 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:31,415 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'salade', 'fused': 'Salade.'}
2025-06-19 12:19:31,421 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:34,402 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121934.wav, taille: 80339 bytes
2025-06-19 12:19:34,540 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121934.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:36,401 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:19:36,626 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:39,094 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121939.wav, taille: 80339 bytes
2025-06-19 12:19:39,237 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121939.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:41,869 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:19:41,875 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:44,576 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121944.wav, taille: 80339 bytes
2025-06-19 12:19:45,312 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121944.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:46,002 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_121945.wav, taille: 30107 bytes
2025-06-19 12:19:46,189 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:46] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:19:46,352 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:46] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:19:46,389 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_121945.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:19:46,422 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:46] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:19:46,869 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:46] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:19:47,316 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:19:47,321 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:19:48,232 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:19:48,234 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:19:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:04,412 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122004.wav, taille: 80339 bytes
2025-06-19 12:20:04,584 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122004.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:07,164 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:20:07,166 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:09,111 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122009.wav, taille: 80339 bytes
2025-06-19 12:20:09,237 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122009.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:11,637 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:20:11,637 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:14,417 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122014.wav, taille: 80339 bytes
2025-06-19 12:20:14,555 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122014.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:14,805 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:14] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:20:14,870 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:14] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:20:14,879 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:14] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:20:14,944 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:14] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:20:16,228 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:20:16,230 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:22,767 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122022.wav, taille: 80339 bytes
2025-06-19 12:20:22,900 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122022.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:27,197 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:20:27,197 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646\\u062c\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"salam cette semaine\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:20:27,206 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:20:27,213 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:20:27,456 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122027.wav, taille: 80339 bytes
2025-06-19 12:20:27,560 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122027.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:30,197 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:20:30,216 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1846 request_id=req_e845e9e03ec6b7f45ca171a52268593b response_code=200
2025-06-19 12:20:30,370 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:32,279 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:20:32,279 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:32,776 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122032.wav, taille: 80339 bytes
2025-06-19 12:20:32,900 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122032.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:36,428 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:20:36,431 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:37,457 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122037.wav, taille: 80339 bytes
2025-06-19 12:20:37,587 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122037.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:39,260 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:20:39,260 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:42,766 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122042.wav, taille: 80339 bytes
2025-06-19 12:20:42,887 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122042.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:45,711 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:20:45,711 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:47,456 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122047.wav, taille: 80339 bytes
2025-06-19 12:20:47,595 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122047.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:20:48,780 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:20:48,781 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:20:51,509 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:51] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:20:51,586 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:51] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:20:51,603 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:51] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:20:51,993 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:20:51] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:20:58,455 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122058.wav, taille: 80339 bytes
2025-06-19 12:20:58,596 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122058.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:02,335 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:21:02,335 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u062a\\u0628\\u062a\\"\\n            Fran\\u00e7ais: \\"salam Facebook\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:21:02,335 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:21:02,344 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:21:03,445 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:21:03,445 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=756 request_id=req_f2f9b37d43310a8e2c398db9d30508df response_code=200
2025-06-19 12:21:03,589 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:03,767 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122103.wav, taille: 80339 bytes
2025-06-19 12:21:03,885 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122103.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:06,145 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:21:06,145 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"o\\u00f9 \\u00e9tait\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:21:06,155 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:21:06,160 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:21:07,076 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:21:07,076 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=559 request_id=req_491f59c4708c7b46c319a71eb0794dd2 response_code=200
2025-06-19 12:21:07,194 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'où était', 'fused': 'où était'}
2025-06-19 12:21:07,196 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:08,765 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122108.wav, taille: 80339 bytes
2025-06-19 12:21:08,877 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122108.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:11,842 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:21:11,843 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"ann\\u00e9e de m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:21:11,845 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:21:11,851 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:21:13,176 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:21:13,176 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1083 request_id=req_a8366b832cac750c4978451cd13408f3 response_code=200
2025-06-19 12:21:13,285 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'année de médicaments', 'fused': 'année de médicaments'}
2025-06-19 12:21:13,285 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:13,450 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122113.wav, taille: 80339 bytes
2025-06-19 12:21:13,565 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122113.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:15,326 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:21:15,326 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:15,765 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:15] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:21:15,820 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:15] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:21:15,829 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:15] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:21:16,211 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:16] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:21:20,027 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:20] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:21:20,081 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:20] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:21:20,087 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:20] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:21:20,132 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:20] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:21:28,880 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122128.wav, taille: 80339 bytes
2025-06-19 12:21:29,009 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122128.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:30,459 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:21:30,460 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:33,570 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122133.wav, taille: 80339 bytes
2025-06-19 12:21:33,690 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122133.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:35,623 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:21:35,627 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:38,880 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122138.wav, taille: 80339 bytes
2025-06-19 12:21:39,000 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122138.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:40,730 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:21:40,730 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:43,570 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122143.wav, taille: 80339 bytes
2025-06-19 12:21:43,691 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122143.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:46,190 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:21:46,190 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:48,881 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122148.wav, taille: 80339 bytes
2025-06-19 12:21:48,995 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122148.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:51,404 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:21:51,407 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:53,571 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122153.wav, taille: 80339 bytes
2025-06-19 12:21:53,691 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122153.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:21:55,591 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:21:55,595 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:21:57,181 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:57] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:21:57,273 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:57] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:21:57,283 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:57] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:21:57,808 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:21:57] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:22:16,257 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122216.wav, taille: 80339 bytes
2025-06-19 12:22:16,378 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122216.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:20,949 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122220.wav, taille: 80339 bytes
2025-06-19 12:22:21,057 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122220.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:25,158 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:22:25,158 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0627\\u0643\\u062a\\u0628\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:22:25,158 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:22:25,158 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:22:26,257 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122226.wav, taille: 80339 bytes
2025-06-19 12:22:26,309 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:22:26,318 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0648\\u0643\\u0627\\u0646 \\u0643\\u064a\\u0636\\u0631\\"\\n            Fran\\u00e7ais: \\"salam Ana Rachid\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:22:26,332 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:22:26,340 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:22:26,427 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122226.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:27,407 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:22:27,407 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=802 request_id=req_2b2cbdaabdb16d53dfa45a59c0490cf8 response_code=200
2025-06-19 12:22:27,569 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:22:27,682 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:22:27,689 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=921 request_id=req_6ebf96929d46d23e75372b237a814ce8 response_code=200
2025-06-19 12:22:27,828 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:22:31,257 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122231.wav, taille: 80339 bytes
2025-06-19 12:22:31,377 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122231.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:32,222 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:22:32,222 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0645\\u0627\\u0632\\u0627\\u0644 \\u064a\\u0634\\u0648\\u0641 \\u0634\\u0646\\u0648 \\u0639\\u0646\\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:22:32,227 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:22:32,235 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:22:33,287 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:22:33,287 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:22:34,123 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:22:34,127 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=845 request_id=req_3ff3ab1319d6392185f2bd3d647f9b44 response_code=200
2025-06-19 12:22:34,271 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:22:36,256 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122236.wav, taille: 80339 bytes
2025-06-19 12:22:36,362 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122236.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:37,447 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:22:37,448 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:22:40,948 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122240.wav, taille: 80339 bytes
2025-06-19 12:22:41,087 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122240.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:42,738 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:22:42,738 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:22:46,257 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122246.wav, taille: 80339 bytes
2025-06-19 12:22:46,381 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122246.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:47,988 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:22:47,988 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:22:50,952 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122250.wav, taille: 80339 bytes
2025-06-19 12:22:51,062 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122250.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:52,854 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:22:52,857 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:22:56,257 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122256.wav, taille: 80339 bytes
2025-06-19 12:22:56,370 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122256.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:22:58,619 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:22:58,619 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:22:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:23:00,957 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122300.wav, taille: 80339 bytes
2025-06-19 12:23:01,082 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122300.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:23:03,022 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:23:03,025 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:23:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:23:04,022 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_122304.wav, taille: 41699 bytes
2025-06-19 12:23:04,258 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_122304.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:23:04,609 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:23:04] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 12:23:04,922 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:23:04,923 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salut, je suis Chaima et j\'ai mal.\\"\\"\\nSegment 2: \\"\\"J\'ai mal au dos, notez cela s\'il vous pla\\u00eet.\\"\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Il m\'a dit de revenir cette semaine pour qu\'il puisse encore v\\u00e9rifier ce que j\'ai.\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 9: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:23:04,928 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:23:04,933 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:23:05,603 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:23:05,603 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:23:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:23:07,897 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:23:07,908 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1424 request_id=req_06289edf1a63b3b4c785f8df5e49f92e response_code=200
2025-06-19 12:23:07,908 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:23:07] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 12:54:31,117 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:31] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:54:31,208 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:31] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:54:31,221 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:31] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:54:31,699 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:31] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:54:39,331 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125439.wav, taille: 80339 bytes
2025-06-19 12:54:39,474 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125439.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:54:41,434 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:54:41,434 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0627\\u0645\\u064a\\u0645\\u0647\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:54:41,434 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:54:41,443 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:54:42,698 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\__init__.py', reloading
2025-06-19 12:54:42,705 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-19 12:54:42,751 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sounddevice.py', reloading
2025-06-19 12:54:42,759 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\json\\__init__.py', reloading
2025-06-19 12:54:42,762 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-19 12:54:42,767 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\blueprints.py', reloading
2025-06-19 12:54:42,771 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\config.py', reloading
2025-06-19 12:54:42,772 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\globals.py', reloading
2025-06-19 12:54:42,774 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\helpers.py', reloading
2025-06-19 12:54:42,776 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\datastructures\\__init__.py', reloading
2025-06-19 12:54:42,782 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\utils.py', reloading
2025-06-19 12:54:42,789 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\wrappers\\__init__.py', reloading
2025-06-19 12:54:42,791 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\typing.py', reloading
2025-06-19 12:54:42,792 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\scaffold.py', reloading
2025-06-19 12:54:42,793 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\sessions.py', reloading
2025-06-19 12:54:42,795 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\wrappers.py', reloading
2025-06-19 12:54:42,799 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\wrappers\\request.py', reloading
2025-06-19 12:54:42,806 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\wrappers\\response.py', reloading
2025-06-19 12:54:42,807 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\sansio\\response.py', reloading
2025-06-19 12:54:42,809 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\_internal.py', reloading
2025-06-19 12:54:42,816 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\_sounddevice.py', reloading
2025-06-19 12:54:42,840 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\sansio\\request.py', reloading
2025-06-19 12:54:42,840 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\json\\tag.py', reloading
2025-06-19 12:54:42,849 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\datetime.py', reloading
2025-06-19 12:54:42,855 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\tempfile.py', reloading
2025-06-19 12:54:42,855 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\traceback.py', reloading
2025-06-19 12:54:42,860 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\wave.py', reloading
2025-06-19 12:54:43,125 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:54:43,132 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=826 request_id=req_55f70970b5809a775aff1a4e6e6b0305 response_code=200
2025-06-19 12:54:43,587 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:54:43,975 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:54:48,261 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:54:48,270 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:54:48,404 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125448.wav, taille: 80339 bytes
2025-06-19 12:54:48,570 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125448.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:54:49,324 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125449.wav, taille: 80339 bytes
2025-06-19 12:54:49,490 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125449.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:54:52,269 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:54:52,274 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:54:52,567 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:54:52,570 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:54:54,644 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125454.wav, taille: 80339 bytes
2025-06-19 12:54:54,789 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125454.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:54:56,897 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:54:56,904 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:54:57,864 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:57] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:54:57,938 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:57] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:54:57,943 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:57] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:54:57,999 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:54:57] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:55:05,790 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125505.wav, taille: 80339 bytes
2025-06-19 12:55:05,915 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125505.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:07,913 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:55:07,913 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:10,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125510.wav, taille: 80339 bytes
2025-06-19 12:55:10,596 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125510.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:12,682 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:55:12,685 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:15,783 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125515.wav, taille: 80339 bytes
2025-06-19 12:55:15,903 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125515.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:16,967 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:55:16,971 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:20,479 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125520.wav, taille: 80339 bytes
2025-06-19 12:55:20,608 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125520.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:22,726 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:55:22,736 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:26,023 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125526.wav, taille: 84203 bytes
2025-06-19 12:55:26,156 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125526.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:28,074 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:55:28,077 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:30,663 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125530.wav, taille: 79373 bytes
2025-06-19 12:55:30,782 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125530.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:32,466 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:55:32,469 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:33,883 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:33] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 12:55:33,968 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:33] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 12:55:33,973 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:33] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 12:55:34,431 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:34] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 12:55:43,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125543.wav, taille: 80339 bytes
2025-06-19 12:55:43,474 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125543.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:46,822 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:55:46,823 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0627\\u0645\\u064a\\u0645\\u0647 \\u062c\\u064a\\u062a \\u0627\\u0644\\u064a\\u0648\\u0645\\"\\n            Fran\\u00e7ais: \\"salam aleykoum Alaoui\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:55:46,828 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:55:46,838 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:55:48,213 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:55:48,223 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=812 request_id=req_df3512bea7facbbf893aa1f9a2ca2996 response_code=200
2025-06-19 12:55:48,348 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-19 12:55:48,371 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-19 12:55:48,373 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-19 12:55:48,374 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:48,380 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-19 12:55:48,386 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-19 12:55:48,389 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-19 12:55:48,398 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-19 12:55:48,563 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 12:55:50,592 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 12:55:50,606 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 12:55:50,715 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125550.wav, taille: 80339 bytes
2025-06-19 12:55:50,838 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125550.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:53,231 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:55:53,233 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:53,633 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125553.wav, taille: 80339 bytes
2025-06-19 12:55:53,753 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125553.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:55:54,693 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:55:54,697 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:55:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:55:58,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125558.wav, taille: 80339 bytes
2025-06-19 12:55:58,468 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125558.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:00,631 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:56:00,635 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:03,964 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125603.wav, taille: 85169 bytes
2025-06-19 12:56:04,073 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125603.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:05,967 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:56:05,968 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062c\\u064a\\u062a \\u0627\\u0644\\u064a\\u0648\\u0645\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:56:05,971 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:56:05,975 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:56:07,040 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:56:07,046 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=580 request_id=req_60d831ce583a0cad2791052831c8fb20 response_code=200
2025-06-19 12:56:07,195 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:08,668 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125608.wav, taille: 80339 bytes
2025-06-19 12:56:08,783 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125608.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:09,720 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:56:09,726 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:13,653 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125613.wav, taille: 74543 bytes
2025-06-19 12:56:13,768 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125613.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:15,145 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:56:15,145 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:18,345 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125618.wav, taille: 80339 bytes
2025-06-19 12:56:18,479 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125618.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:21,233 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:56:21,233 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0627\\u0645\\u064a\\u0645\\u0647 \\u062c\\u064a\\u062a \\u0627\\u0644\\u064a\\u0648\\u0645 \\u0644\\u0644\\u0637\\u0628\\u064a\\u0628\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:56:21,233 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:56:21,243 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:56:22,453 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:56:22,453 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=798 request_id=req_082431102a712c8e4cb230c8ffb71790 response_code=200
2025-06-19 12:56:22,606 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:23,653 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125623.wav, taille: 80339 bytes
2025-06-19 12:56:23,768 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125623.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:26,976 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:56:26,976 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0628\\u0627\\u0634 \\u0646\\u0634\\u0648\\u0641 \\u0643\\u0631\\u0634\\u064a \\u0643\\u0636\\u0631\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"ben c\'est chauffeur\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:56:26,976 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:56:26,983 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:56:28,338 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125628.wav, taille: 80339 bytes
2025-06-19 12:56:28,453 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125628.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:28,766 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:56:28,766 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=604 request_id=req_ba5af6c4d1db1b2a98530f7f35cf8590 response_code=200
2025-06-19 12:56:28,912 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:30,141 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:56:30,145 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:33,653 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125633.wav, taille: 80339 bytes
2025-06-19 12:56:33,776 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125633.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:36,063 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:56:36,064 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0628\\u0627\\u0634 \\u064a\\u0639\\u0637\\u064a\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:56:36,064 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:56:36,072 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:56:37,443 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:56:37,443 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=717 request_id=req_4e37fc18d4928bfad5c0e31b46e2d380 response_code=200
2025-06-19 12:56:37,585 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:38,338 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125638.wav, taille: 80339 bytes
2025-06-19 12:56:38,463 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125638.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:40,160 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:56:40,163 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:43,643 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125643.wav, taille: 80339 bytes
2025-06-19 12:56:43,763 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125643.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:45,361 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:56:45,363 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:48,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125648.wav, taille: 80339 bytes
2025-06-19 12:56:48,453 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125648.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:50,227 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:56:50,227 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:53,644 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125653.wav, taille: 80339 bytes
2025-06-19 12:56:53,768 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125653.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:56:55,637 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:56:55,638 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062f\\u0648\\u0644\\u064a\\u0628\\u0631\\u0627\\u0646\\"\\n            Fran\\u00e7ais: \\"doliprane\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:56:55,641 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:56:55,647 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:56:56,683 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:56:56,683 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=602 request_id=req_f47fa14605f552054d2bef865af008cd response_code=200
2025-06-19 12:56:56,817 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:56:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:56:58,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125658.wav, taille: 80339 bytes
2025-06-19 12:56:58,554 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125658.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:57:01,134 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:57:01,134 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"doliprane\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:57:01,143 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:57:01,150 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:57:02,283 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:57:02,283 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=579 request_id=req_18c38c99d8f47bb77d895482ad142a81 response_code=200
2025-06-19 12:57:02,393 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'doliprane', 'fused': 'Le patient a été prescrit du Doliprane.'}
2025-06-19 12:57:02,396 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:57:03,652 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125703.wav, taille: 80339 bytes
2025-06-19 12:57:03,777 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125703.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:57:07,243 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:57:07,243 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:57:08,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125708.wav, taille: 80339 bytes
2025-06-19 12:57:08,453 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125708.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:57:11,341 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:57:11,342 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0631\\u064a\\u0646\\u0645\\u064a\\u0633\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:57:11,343 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:57:11,350 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:57:13,648 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125713.wav, taille: 80339 bytes
2025-06-19 12:57:13,763 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125713.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:57:14,025 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:57:14,026 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2392 request_id=req_002039c4055f205828a55c68ff17195b response_code=200
2025-06-19 12:57:14,169 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:57:14,790 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:57:14,793 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:57:18,650 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125718.wav, taille: 80339 bytes
2025-06-19 12:57:18,763 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125718.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:57:20,693 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:57:20,703 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"piscine au parac\\u00e9tamol\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:57:20,703 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:57:20,711 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:57:21,823 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:57:21,823 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=822 request_id=req_32202fb932c2317d33252bfefc3a434a response_code=200
2025-06-19 12:57:21,943 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'piscine au paracétamol', 'fused': 'Paracétamol.'}
2025-06-19 12:57:21,943 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:57:23,333 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125723.wav, taille: 80339 bytes
2025-06-19 12:57:23,483 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125723.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:57:25,707 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:57:25,713 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"parac\\u00e9tamol\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:57:25,713 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:57:25,713 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:57:26,923 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:57:26,933 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=879 request_id=req_0c849df0d873502205943922535e83b7 response_code=200
2025-06-19 12:57:27,040 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'paracétamol', 'fused': 'Paracétamol.'}
2025-06-19 12:57:27,043 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:57:28,648 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125728.wav, taille: 80339 bytes
2025-06-19 12:57:28,774 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125728.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:57:30,675 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:57:30,678 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:57:31,517 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_125731.wav, taille: 50393 bytes
2025-06-19 12:57:31,628 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_125731.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 12:57:32,807 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:32] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 12:57:33,024 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 12:57:33,024 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 12:57:33,123 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 12:57:33,123 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam aleykoum, je suis Oumaima, je suis venue aujourd\'hui.\\"\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 5: \\"Je suis venu aujourd\'hui.\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 8: \\"\\"Salut, je suis Oumaima, je suis venue aujourd\'hui chez le m\\u00e9decin.\\"\\"\\nSegment 9: \\"Je suis venu consulter car j\'ai mal au ventre.\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 11: \\"Pour qu\'il me prescrive un m\\u00e9dicament.\\"\\nSegment 12: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 13: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 14: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 15: \\"Le patient a mentionn\\u00e9 avoir pris du Doliprane.\\"\\nSegment 16: \\"Le patient a \\u00e9t\\u00e9 prescrit du Doliprane.\\"\\nSegment 17: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 18: \\"Il semble qu\'il y ait une erreur dans les transcriptions fournies, car la transcription en Darija est incompl\\u00e8te et celle en fran\\u00e7ais est vide. Pour fusionner correctement les transcriptions, j\'aurais besoin de plus d\'informations ou d\'un contenu plus complet pour chacune des langues mentionn\\u00e9es.\\"\\nSegment 19: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 20: \\"Parac\\u00e9tamol.\\"\\nSegment 21: \\"Parac\\u00e9tamol.\\"\\nSegment 22: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 12:57:33,123 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 12:57:33,134 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 12:57:35,923 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 12:57:35,923 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2497 request_id=req_9905bdde078352347f7ea70b355e1293 response_code=200
2025-06-19 12:57:35,923 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 12:57:35] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 14:05:01,665 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140501.wav, taille: 80339 bytes
2025-06-19 14:05:01,809 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140501.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:04,035 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-19 14:05:04,035 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 14:05:04,595 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 14:05:08,454 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 14:05:08,477 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 14:05:08,665 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140508.wav, taille: 80339 bytes
2025-06-19 14:05:08,943 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140508.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:11,346 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140511.wav, taille: 80339 bytes
2025-06-19 14:05:11,553 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140511.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:13,043 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:05:13,047 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0639\\u0637\\u0627\\u0646\\u064a \\u0627\\u0644\\u062f\\u0648\\u0644\\u064a\\u0628\\u0631\\u0627\\u0646 \\u0648\\u0627\\u0639\\u0637\\u0627\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:05:13,053 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:05:13,060 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:05:13,939 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:05:13,945 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:15,829 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:05:15,835 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1549 request_id=req_f7ef9e1266ac5c4dcac483985c9dd4c7 response_code=200
2025-06-19 14:05:15,967 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-19 14:05:16,018 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-19 14:05:16,020 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:16,025 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-19 14:05:16,034 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-19 14:05:16,046 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-19 14:05:16,047 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-19 14:05:16,049 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-19 14:05:16,776 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 14:05:19,366 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 14:05:19,376 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 14:05:19,483 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140519.wav, taille: 80339 bytes
2025-06-19 14:05:19,625 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140519.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:20,840 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140520.wav, taille: 71645 bytes
2025-06-19 14:05:20,956 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140520.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:21,861 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:05:21,864 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:22,128 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:22] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 14:05:22,456 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:05:22,456 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:22,474 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:05:22,477 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 2: \\"Il m\'a donn\\u00e9 du Doliprane.\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:05:22,481 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:05:22,486 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:05:24,340 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:05:24,360 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1047 request_id=req_0fbc6cd140133f806e002f93905557e7 response_code=200
2025-06-19 14:05:24,365 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:24] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 14:05:29,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140529.wav, taille: 80339 bytes
2025-06-19 14:05:29,739 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140529.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:32,845 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:05:32,855 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646\\u062c\\u064a\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0648\\u0643\\u0627\\u0646\\"\\n            Fran\\u00e7ais: \\"salam Anakin ou Cannes\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:05:32,860 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:05:32,864 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:05:34,323 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140534.wav, taille: 80339 bytes
2025-06-19 14:05:34,440 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140534.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:35,126 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:05:35,126 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1003 request_id=req_9a72d2b65b38942f39ca52f882772185 response_code=200
2025-06-19 14:05:35,271 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:37,260 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:05:37,260 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0627\\u0646 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a \\u0648\\u062e\\u062f\\u064a\\u062a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:05:37,262 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:05:37,265 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:05:39,465 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:39,650 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140539.wav, taille: 80339 bytes
2025-06-19 14:05:39,893 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140539.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:41,806 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:05:41,806 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"pour me calmer\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:05:41,806 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:05:41,806 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:05:42,975 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:05:43,004 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=876 request_id=req_4c570c91762e967ea0faf3f8421aa545 response_code=200
2025-06-19 14:05:43,121 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'pour me calmer', 'fused': 'Pour me calmer.'}
2025-06-19 14:05:43,125 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:44,630 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140544.wav, taille: 80339 bytes
2025-06-19 14:05:44,780 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140544.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:44,906 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_140544.wav, taille: 7889 bytes
2025-06-19 14:05:45,068 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_140544.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:05:45,865 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:45] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 14:05:45,987 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:05:45,987 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:46,188 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:05:46,188 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam, je suis venu la semaine derni\\u00e8re et j\'\\u00e9tais...\\"\\"\\nSegment 2: \\"\\u0643\\u0627\\u0646 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a \\u0648\\u062e\\u062f\\u064a\\u062a\\"\\nSegment 3: \\"Pour me calmer.\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:05:46,195 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:05:46,199 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:05:46,852 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:05:46,853 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:05:49,195 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:05:49,195 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2212 request_id=req_98a64456b3c6a5ba1f0426d706553e01 response_code=200
2025-06-19 14:05:49,195 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:05:49] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 14:48:58,747 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:48:58] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 14:48:58,853 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:48:58] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 14:48:58,909 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:48:58] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 14:48:59,337 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:48:59] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 14:49:54,891 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_144954.wav, taille: 80339 bytes
2025-06-19 14:49:56,434 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_144954.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:49:58,651 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:49:58,651 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0628\\u0648\\u0646\\u062c\\u0648\\u0631 \\u0635\\u0627\\u0641\\u0627\\"\\n            Fran\\u00e7ais: \\"bonjour \\u00e7a va\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:49:58,661 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:49:58,668 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:50:00,201 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145000.wav, taille: 80339 bytes
2025-06-19 14:50:00,341 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145000.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:00,436 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:50:00,441 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1039 request_id=req_d34981014545d3392166d68af81ff262 response_code=200
2025-06-19 14:50:00,571 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:02,481 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:50:02,481 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0634\\u064a\\u0645\\u0627\\u0621\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:50:02,481 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:50:02,481 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:50:03,491 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:50:03,497 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=713 request_id=req_379b96752630bde007f5f615bedc8038 response_code=200
2025-06-19 14:50:03,640 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:05,206 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145005.wav, taille: 80339 bytes
2025-06-19 14:50:05,326 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145005.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:07,132 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:50:07,132 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:09,891 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145009.wav, taille: 80339 bytes
2025-06-19 14:50:10,001 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145009.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:11,832 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:50:11,832 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:15,182 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145015.wav, taille: 80339 bytes
2025-06-19 14:50:15,306 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145015.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:18,341 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:50:18,341 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u0627\\u0646 \\u0627\\u0639\\u0637\\u0627\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:50:18,341 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:50:18,351 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:50:19,801 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:50:19,801 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=966 request_id=req_35d1a1a6264ed793ce7d66caa95209b6 response_code=200
2025-06-19 14:50:19,897 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145019.wav, taille: 80339 bytes
2025-06-19 14:50:19,973 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:20,073 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145019.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:22,115 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:50:22,118 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:25,201 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145025.wav, taille: 80339 bytes
2025-06-19 14:50:25,321 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145025.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:26,665 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:50:26,665 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:29,891 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145029.wav, taille: 80339 bytes
2025-06-19 14:50:30,006 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145029.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:31,815 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:50:31,815 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:35,206 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145035.wav, taille: 80339 bytes
2025-06-19 14:50:35,332 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145035.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:37,371 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:50:37,371 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0641\\u0631\\u0646\\u0633\\u0627 \\u0628\\u0632\\u0627\\u0641\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:50:37,371 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:50:37,383 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:50:38,487 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:38] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 14:50:38,584 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:38] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 14:50:38,590 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:38] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 14:50:38,772 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:38] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 14:50:38,827 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:50:38,831 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1152 request_id=req_7671202cf388523b27453a9d13e9212a response_code=200
2025-06-19 14:50:38,972 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:50,749 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145050.wav, taille: 80339 bytes
2025-06-19 14:50:50,879 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145050.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:53,412 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:50:53,412 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0634\\u0646\\u0648 \\u062c\\u0627\\u0628\\u0643 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u064a\\u0648\\u0645 \\u0634\\u064a\\u0645\\u0627\\u0621\\"\\n            Fran\\u00e7ais: \\"salam alikoum\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:50:53,412 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:50:53,419 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:50:55,030 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:50:55,039 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1315 request_id=req_1528d757212f4003bc0ef9559a4cda29 response_code=200
2025-06-19 14:50:55,173 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:50:55,431 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145055.wav, taille: 80339 bytes
2025-06-19 14:50:55,549 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145055.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:50:58,495 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:50:58,499 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:50:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:00,754 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145100.wav, taille: 80339 bytes
2025-06-19 14:51:00,863 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145100.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:03,689 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:51:03,689 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0628\\u0642\\u0649 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\"\\n            Fran\\u00e7ais: \\"des m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:51:03,699 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:51:03,704 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:51:04,949 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:51:04,949 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=634 request_id=req_2f676b9dabc0626a4db828e8d8783d19 response_code=200
2025-06-19 14:51:05,092 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:05,443 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145105.wav, taille: 80339 bytes
2025-06-19 14:51:05,563 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145105.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:08,079 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:51:08,079 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0643\\u0627\\u0646 \\u0639\\u0646\\u062f\\u0643\\"\\n            Fran\\u00e7ais: \\"d\'accord\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:51:08,079 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:51:08,079 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:51:09,839 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:51:09,849 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1367 request_id=req_17229f978c59a21671952698dae94e40 response_code=200
2025-06-19 14:51:09,990 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:10,747 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145110.wav, taille: 80339 bytes
2025-06-19 14:51:10,875 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145110.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:12,915 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:51:12,918 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:15,444 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145115.wav, taille: 80339 bytes
2025-06-19 14:51:15,569 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145115.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:17,891 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:51:17,893 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:20,749 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145120.wav, taille: 80339 bytes
2025-06-19 14:51:20,860 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145120.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:24,019 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:51:24,026 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u062a\\u0627\\u064a\\u0637\\u0644\\u0639 \\u0627\\u0644\\u0641\\u0648\\u0642 \\u0648\\u0644\\u0627\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:51:24,032 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:51:24,036 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:51:25,430 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145125.wav, taille: 80339 bytes
2025-06-19 14:51:25,554 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145125.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:27,845 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:51:27,850 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2318 request_id=req_dac65f41f3c6ed81159d1c2e35bb862f response_code=200
2025-06-19 14:51:28,014 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:29,546 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:51:29,549 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0643\\u064a\\u0641\\u0627\\u0634 \\u062f\\u0627\\u064a\\u0631\\u0647 \\u0648\\u0644\\u0627 \\u0643\\u0627\\u062a\\u0628\\u0642\\u0649\\"\\n            Fran\\u00e7ais: \\"que veut dire \\u00e0 la douleur\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:51:29,552 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:51:29,557 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:51:30,749 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145130.wav, taille: 80339 bytes
2025-06-19 14:51:30,892 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145130.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:31,343 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:51:31,349 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1404 request_id=req_8d437e1781a42421237c9d1ed0999332 response_code=200
2025-06-19 14:51:31,489 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:33,381 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:51:33,381 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"s\'arr\\u00eater\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:51:33,382 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:51:33,389 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:51:34,984 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:51:34,993 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1263 request_id=req_46732bc3848b2d8984769c588043618c response_code=200
2025-06-19 14:51:35,119 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "s'arrêter", 'fused': "Il est nécessaire de s'arrêter."}
2025-06-19 14:51:35,119 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:35,743 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145135.wav, taille: 80339 bytes
2025-06-19 14:51:35,894 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145135.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:37,277 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:51:37,279 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:40,729 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145140.wav, taille: 80339 bytes
2025-06-19 14:51:40,875 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145140.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:41,948 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:51:41,953 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:45,443 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145145.wav, taille: 80339 bytes
2025-06-19 14:51:45,714 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145145.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:47,609 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:51:47,611 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:50,749 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145150.wav, taille: 80339 bytes
2025-06-19 14:51:50,860 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145150.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:52,916 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:51:52,919 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:51:55,439 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145155.wav, taille: 80339 bytes
2025-06-19 14:51:55,569 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145155.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:51:58,109 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:51:58,109 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:51:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:52:00,749 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145200.wav, taille: 80339 bytes
2025-06-19 14:52:00,869 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145200.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:52:03,292 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:52:03,292 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:52:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:52:03,318 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145203.wav, taille: 45563 bytes
2025-06-19 14:52:03,469 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145203.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:52:04,607 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:52:04] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 14:52:04,919 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:52:04,919 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"\\"Salam alikoum, Chaima, qu\'est-ce qui t\'am\\u00e8ne chez moi aujourd\'hui ?\\"\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"J\'ai encore des douleurs malgr\\u00e9 les m\\u00e9dicaments.\\"\\nSegment 4: \\"\\"Le feu \\u00e9tait chez vous, d\'accord.\\"\\"\\nSegment 5: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"La transcription en fran\\u00e7ais est vide, donc il n\'y a rien \\u00e0 fusionner avec la transcription en darija.\\"\\nSegment 8: \\"\\"Comment vous sentez-vous et est-ce que la douleur persiste ?\\"\\"\\nSegment 9: \\"Il est n\\u00e9cessaire de s\'arr\\u00eater.\\"\\nSegment 10: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 11: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 12: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 13: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 14: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 15: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:52:04,927 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:52:04,931 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:52:04,975 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:52:04,977 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:52:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:52:14,589 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:52:14,609 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=8927 request_id=req_5b83796ae30a6b57061936b0c265daaf response_code=200
2025-06-19 14:52:14,611 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:52:14] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 14:57:42,581 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:57:42] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 14:57:42,668 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:57:42] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 14:57:42,689 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:57:42] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 14:57:43,228 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:57:43] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 14:57:50,032 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145750.wav, taille: 80339 bytes
2025-06-19 14:57:50,167 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145750.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:57:52,761 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:57:52,761 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0627\\u0646\\u0627 \\u0627\\u0645\\u064a\\u0645\\u0647 \\u062c\\u064a\\u062a\\"\\n            Fran\\u00e7ais: \\"salam aleykoum j\'\\u00e9tais\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:57:52,761 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:57:52,769 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:57:54,875 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:57:54,875 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1304 request_id=req_8d71f060f9e165828084d87e109cf20e response_code=200
2025-06-19 14:57:55,022 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:57:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:57:55,331 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145755.wav, taille: 80339 bytes
2025-06-19 14:57:55,446 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145755.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:57:58,009 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:57:58,011 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:57:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:00,332 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145800.wav, taille: 80339 bytes
2025-06-19 14:58:00,444 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145800.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:02,044 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:58:02,044 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:05,031 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145805.wav, taille: 80339 bytes
2025-06-19 14:58:05,152 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145805.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:06,702 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:58:06,702 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062c\\u064a\\u062a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:58:06,702 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:58:06,710 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:58:07,894 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:58:07,894 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=745 request_id=req_b683ea9575636b78e68df3a8ea16a881 response_code=200
2025-06-19 14:58:08,037 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:10,331 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145810.wav, taille: 80339 bytes
2025-06-19 14:58:10,444 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145810.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:13,161 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:58:13,161 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062a\\u0639\\u0637\\u064a\\u0646\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0641\\u064a \\u0631\\u062c\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:58:13,161 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:58:13,161 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:58:14,592 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:58:14,592 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1036 request_id=req_42cd22d8793be07118f3561b1956d73c response_code=200
2025-06-19 14:58:14,751 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:15,025 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145815.wav, taille: 80339 bytes
2025-06-19 14:58:15,143 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145815.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:17,250 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:58:17,252 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:20,331 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145820.wav, taille: 80339 bytes
2025-06-19 14:58:20,443 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145820.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:22,361 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:58:22,361 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0644\\u0627 \\u062a\\u0639\\"\\n            Fran\\u00e7ais: \\"non\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:58:22,361 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:58:22,361 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:58:23,709 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:58:23,711 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=521 request_id=req_f38412e0ebc8355c5601e2029653e4ae response_code=200
2025-06-19 14:58:23,853 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:25,043 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145825.wav, taille: 80339 bytes
2025-06-19 14:58:25,161 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145825.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:27,942 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:58:27,951 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u064a\\u062a\\u0627\\u0634 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0641\\u064a \\u0631\\u062c\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:58:27,951 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:58:27,961 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:58:29,631 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:58:29,641 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=774 request_id=req_51ed7af967ecf067712d3a24dba92d3f response_code=200
2025-06-19 14:58:29,785 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:30,343 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145830.wav, taille: 80339 bytes
2025-06-19 14:58:30,470 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145830.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:33,826 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:58:33,826 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062a\\u0639\\u0637\\u064a\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"Tattini des m\\u00e9dicaments\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:58:33,832 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:58:33,836 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:58:35,032 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145835.wav, taille: 80339 bytes
2025-06-19 14:58:35,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145835.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:35,791 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:58:35,797 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1352 request_id=req_1fab4a5b8f3eeb2ece69de29d539773f response_code=200
2025-06-19 14:58:35,940 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:37,926 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:58:37,927 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062d\\u064a\\u062a\\u0627\\u0634 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0631\\u064a\\u0642 \\u0641\\u064a \\u0631\\u062c\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:58:37,929 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:58:37,932 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:58:39,261 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:58:39,274 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=686 request_id=req_1985c5070a6fe6ea916628b66070414f response_code=200
2025-06-19 14:58:39,422 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:40,341 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145840.wav, taille: 80339 bytes
2025-06-19 14:58:40,482 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145840.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:42,641 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:58:42,641 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:45,031 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145845.wav, taille: 80339 bytes
2025-06-19 14:58:45,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145845.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:47,437 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:58:47,441 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:50,346 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145850.wav, taille: 80339 bytes
2025-06-19 14:58:50,458 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145850.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:52,403 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:58:52,406 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:58:55,031 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145855.wav, taille: 80339 bytes
2025-06-19 14:58:55,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145855.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:58:57,158 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:58:57,158 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062e\\u062f\\u0645\\u062a \\u0628\\u0647\\u0627 \\u0634\\u0631\\u0628\\u062a\\u0647\\u0627 \\u0645\\u064a\\u0645\\u0647 \\u062f\\u0631\\u062a \\u0644\\u064a \\u0648\\u0627\\u0644\\u0648\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:58:57,161 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:58:57,169 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:58:59,531 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:58:59,531 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2045 request_id=req_89b8f26c3a57a89b3d027d511606a1f6 response_code=200
2025-06-19 14:58:59,681 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:58:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:00,356 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145900.wav, taille: 80339 bytes
2025-06-19 14:59:00,500 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145900.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:01,957 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:01,961 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:05,032 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145905.wav, taille: 80339 bytes
2025-06-19 14:59:05,147 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145905.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:06,701 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:59:06,706 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\"\\n            Fran\\u00e7ais: \\"ma m\\u00e8re me\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:59:06,710 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:59:06,713 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:59:07,804 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:59:07,805 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=751 request_id=req_992afae657423c83a46ee49a4af4d18d response_code=200
2025-06-19 14:59:07,922 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'ma mère me', 'fused': 'Ma mère me'}
2025-06-19 14:59:07,922 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:10,346 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145910.wav, taille: 80339 bytes
2025-06-19 14:59:10,458 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145910.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:11,907 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:11,908 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:15,025 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145915.wav, taille: 80339 bytes
2025-06-19 14:59:15,131 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145915.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:19,162 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:59:19,162 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u062f\\u0648\\u0644\\u064a\\u0628\\u0631\\u0627\\u0646 \\u062f\\u064a\\u062c\\u0627 \\u0634\\u0631\\u0628\\u062a\\u0647\\u0627 \\u0645\\u064a \\u0645\\u0627 \\u062f\\u0627\\u062a \\u0644\\u064a \\u0648\\u0627\\u0644\\u0648\\"\\n            Fran\\u00e7ais: \\"de les prendre\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:59:19,162 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:59:19,162 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:59:20,341 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145920.wav, taille: 80339 bytes
2025-06-19 14:59:20,457 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145920.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:22,241 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:22,241 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:23,481 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:59:23,503 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2393 request_id=req_22b3e6c82bd9078c0bc2ba130a59fbea response_code=200
2025-06-19 14:59:23,651 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:25,340 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145925.wav, taille: 80339 bytes
2025-06-19 14:59:25,455 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145925.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:27,407 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:27,409 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:30,031 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145930.wav, taille: 80339 bytes
2025-06-19 14:59:30,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145930.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:31,938 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:31,941 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:35,341 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145935.wav, taille: 80339 bytes
2025-06-19 14:59:35,462 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145935.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:37,289 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:37,291 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:40,031 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145940.wav, taille: 80339 bytes
2025-06-19 14:59:40,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145940.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:41,989 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:41,993 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:45,347 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145945.wav, taille: 80339 bytes
2025-06-19 14:59:45,466 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145945.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:46,486 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_145946.wav, taille: 23345 bytes
2025-06-19 14:59:46,642 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_145946.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 14:59:46,746 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:46,749 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:47,585 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 14:59:47,587 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 14:59:47,791 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:47] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 14:59:48,101 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 14:59:48,101 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum, je suis Oumaima.\\"\\nSegment 2: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Je suis venu.\\"\\nSegment 5: \\"\\"Je ressens une sensation de br\\u00fblure dans ma jambe.\\"\\"\\nSegment 6: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 7: \\"Non.\\"\\nSegment 8: \\"\\"Je ressens une br\\u00fblure dans ma jambe.\\"\\"\\nSegment 9: \\"\\"Tu me donnes des m\\u00e9dicaments.\\"\\"\\nSegment 10: \\"\\"Je ressens une sensation de br\\u00fblure dans ma jambe.\\"\\"\\nSegment 11: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 12: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 13: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 14: \\"J\'ai pris le m\\u00e9dicament que ma m\\u00e8re m\'a pr\\u00e9par\\u00e9 mais cela n\'a eu aucun effet.\\"\\nSegment 15: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 16: \\"Ma m\\u00e8re me\\"\\nSegment 17: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 18: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 19: \\"J\'ai d\\u00e9j\\u00e0 pris du Doliprane mais cela n\'a eu aucun effet.\\"\\nSegment 20: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 21: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 22: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 23: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 24: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 14:59:48,101 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 14:59:48,113 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 14:59:51,092 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 14:59:51,092 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2694 request_id=req_bbefbd36f4684040d6c5270de34c85c0 response_code=200
2025-06-19 14:59:51,092 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 14:59:51] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 15:00:28,196 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:28] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 15:00:28,288 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:28] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 15:00:28,341 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:28] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 15:00:28,931 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:28] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 15:00:35,698 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150035.wav, taille: 80339 bytes
2025-06-19 15:00:35,812 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150035.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:00:39,408 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 15:00:39,408 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0644\\u0627 \\u0628\\u0627\\u0633 \\u0643\\u0644 \\u0634\\u064a\\u0621 \\u0645\\u0632\\u064a\\u0627\\u0646\\"\\n            Fran\\u00e7ais: \\"salam aleykoum la bachkou tunisienne\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 15:00:39,408 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 15:00:39,418 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 15:00:41,008 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150041.wav, taille: 80339 bytes
2025-06-19 15:00:41,113 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150041.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:00:42,458 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 15:00:42,458 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2082 request_id=req_c4538aa8843f1f2e3368238376b895ed response_code=200
2025-06-19 15:00:42,590 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:00:45,119 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 15:00:45,119 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0628\\u0627\\u0634 \\u0646\\u0634\\u0648\\u0641 \\u0627\\u0644\\u0645\\u0627\\u0633\\u0646\\u062c\\u0631\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 15:00:45,119 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 15:00:45,119 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 15:00:45,993 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150045.wav, taille: 80339 bytes
2025-06-19 15:00:46,103 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150045.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:00:46,771 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 15:00:46,771 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1051 request_id=req_62956c599ced68f5780f3c877d4a7e20 response_code=200
2025-06-19 15:00:46,918 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:00:47,522 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:00:47,527 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:00:50,993 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150050.wav, taille: 80339 bytes
2025-06-19 15:00:51,102 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150050.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:00:52,902 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:00:52,905 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:00:55,698 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150055.wav, taille: 80339 bytes
2025-06-19 15:00:55,808 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150055.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:00:57,917 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:00:57,919 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:00:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:01,008 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150101.wav, taille: 80339 bytes
2025-06-19 15:01:01,119 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150101.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:03,451 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:01:03,455 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:05,688 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150105.wav, taille: 80339 bytes
2025-06-19 15:01:05,808 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150105.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:07,134 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:01:07,138 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:11,008 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150111.wav, taille: 80339 bytes
2025-06-19 15:01:11,119 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150111.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:13,482 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:13] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 15:01:13,558 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:13] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 15:01:13,569 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:13] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 15:01:13,916 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:01:13,921 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:14,117 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:14] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 15:01:20,823 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150120.wav, taille: 80339 bytes
2025-06-19 15:01:20,953 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150120.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:23,417 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 15:01:23,417 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0639\\u0644\\u064a\\u0643\\u0645 \\u0635\\u0627\\u0641\\u0627\\"\\n            Fran\\u00e7ais: \\"salam aleykoum\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 15:01:23,423 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 15:01:23,423 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 15:01:26,133 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150126.wav, taille: 80339 bytes
2025-06-19 15:01:26,240 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150126.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:27,303 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 15:01:27,313 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1457 request_id=req_e8a161aedaffce9bdb153a16f13a58f1 response_code=200
2025-06-19 15:01:27,459 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:29,173 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 15:01:29,173 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0639\\u0641\\u0627\\u0643 \\u0628\\u063a\\u064a\\u062a \\u0646\\u0634\\u0648\\u0641 \\u0628\\u0627\\u0634 \\u0646\\u0634\\u0648\\u0641 \\u0644\\u064a \\u0639\\u0646\\u0642\\u064a \\u0631\\u0627\\u0643\\u064a \\u062d\\u0631\\u0642\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 15:01:29,173 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 15:01:29,173 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 15:01:30,873 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 15:01:30,884 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1127 request_id=req_a8fbf32f34f3c2530455e8952bc44e23 response_code=200
2025-06-19 15:01:31,022 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:31,135 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150131.wav, taille: 80339 bytes
2025-06-19 15:01:31,258 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150131.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:32,635 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:01:32,637 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:36,133 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150136.wav, taille: 80339 bytes
2025-06-19 15:01:36,234 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150136.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:37,295 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:01:37,299 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:41,133 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150141.wav, taille: 80339 bytes
2025-06-19 15:01:41,242 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_150141.wav, taille: 1127 bytes
2025-06-19 15:01:41,246 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150141.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:41,386 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_150141.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:01:41,919 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:41] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 15:01:42,233 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 15:01:42,233 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Consolide ces segments de transcription d\'une consultation m\\u00e9dicale en un paragraphe fluide et coh\\u00e9rent:\\n            \\n            Segment 1: \\"Salam aleykoum, \\u00e7a va?\\"\\nSegment 2: \\"\\"Je vous prie de m\'aider, je veux consulter pour mon cou qui me br\\u00fble.\\"\\"\\nSegment 3: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\nSegment 4: \\"Aucun contenu audio d\\u00e9tect\\u00e9\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1. FUSIONNE tous les segments en UN SEUL PARAGRAPHE FLUIDE en fran\\u00e7ais\\n            2. GARDE toutes les informations m\\u00e9dicales importantes (sympt\\u00f4mes, diagnostics, traitements) si ils sont pr\\u00e9sents\\n            3. \\u00c9LIMINE les r\\u00e9p\\u00e9titions et redondances\\n            4. ASSURE la coh\\u00e9rence temporelle et logique\\n            5. N\'AJOUTE aucune information qui n\'est pas dans les segments originaux\\n            \\n            Produis un texte fluide et professionnel qui pourra \\u00eatre modifi\\u00e9 par le m\\u00e9decin.\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 15:01:42,233 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 15:01:42,233 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 15:01:42,353 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:01:42,358 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:42,383 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:01:42,400 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:01:44,356 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 15:01:44,357 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1856 request_id=req_3cd77a3a5117f6cf5bb7d115501495d2 response_code=200
2025-06-19 15:01:44,357 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:01:44] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-19 15:10:35,518 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-19 15:10:35,559 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 15:10:37,393 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:10:44,333 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:10:44,345 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:10:51,803 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\__init__.py', reloading
2025-06-19 15:10:51,833 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-19 15:10:51,903 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\sounddevice.py', reloading
2025-06-19 15:10:52,093 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:10:55,863 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:10:55,891 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:13:32,159 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\__init__.py', reloading
2025-06-19 15:13:32,202 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py', reloading
2025-06-19 15:13:32,920 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:13:36,002 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:13:36,014 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:13:37,070 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\__init__.py', reloading
2025-06-19 15:13:37,090 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_dtype_like.py', reloading
2025-06-19 15:13:37,130 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_generic_alias.py', reloading
2025-06-19 15:13:37,184 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_shape.py', reloading
2025-06-19 15:13:37,455 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:13:41,274 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:13:41,351 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:14:13,320 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-19 15:14:13,573 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\typing.py', reloading
2025-06-19 15:14:14,997 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:14:18,415 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:14:18,422 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:17:23,832 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\__init__.py', reloading
2025-06-19 15:17:24,384 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:17:28,978 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:17:28,988 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:17:31,283 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-19 15:17:31,765 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:17:34,282 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:17:34,293 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:19:00,676 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\soundfile.py', reloading
2025-06-19 15:19:01,741 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:19:05,278 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:19:05,295 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:19:12,186 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\_soundfile.py', reloading
2025-06-19 15:19:12,376 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\_soundfile_data\\__init__.py', reloading
2025-06-19 15:19:13,306 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:19:17,275 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:19:17,301 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:19:26,850 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_arraytools.py', reloading
2025-06-19 15:19:26,903 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_nbit.py', reloading
2025-06-19 15:19:27,789 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:19:32,357 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:19:32,372 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:19:41,594 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\__init__.py', reloading
2025-06-19 15:19:41,644 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_misc.py', reloading
2025-06-19 15:19:41,750 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_basic.py', reloading
2025-06-19 15:19:41,833 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp.py', reloading
2025-06-19 15:19:41,898 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp_lu.py', reloading
2025-06-19 15:19:41,944 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp_ldl.py', reloading
2025-06-19 15:19:41,998 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp_cholesky.py', reloading
2025-06-19 15:19:42,036 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp_qr.py', reloading
2025-06-19 15:19:42,085 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp_qz.py', reloading
2025-06-19 15:19:42,121 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp_svd.py', reloading
2025-06-19 15:19:42,154 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp_schur.py', reloading
2025-06-19 15:19:42,174 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\linalg\\_decomp_polar.py', reloading
2025-06-19 15:19:42,422 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:19:49,507 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:19:49,516 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:24:52,518 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessor.py', reloading
2025-06-19 15:24:53,239 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:24:58,234 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:24:58,253 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:25:15,684 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessor.py', reloading
2025-06-19 15:25:15,684 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessor.py', reloading
2025-06-19 15:34:14,421 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.122:5000
2025-06-19 15:34:14,423 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-19 15:34:14,451 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:34:23,084 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:34:23,096 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:34:23,819 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:34:23] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 15:34:23,886 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:34:23] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 15:34:23,906 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:34:23] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 15:34:24,277 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:34:24] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 15:49:06,141 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_154906.wav, taille: 80339 bytes
2025-06-19 15:49:09,086 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\importlib\\__init__.py', reloading
2025-06-19 15:49:09,127 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-19 15:49:09,172 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-19 15:49:09,218 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-19 15:49:09,256 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-19 15:49:09,351 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 15:49:09,377 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 15:49:09,377 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,378 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 15:49:09,378 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-19 15:49:09,378 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,386 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-19 15:49:09,387 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,388 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-19 15:49:09,388 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 15:49:09,389 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-19 15:49:09,390 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 15:49:09,390 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-19 15:49:09,391 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 15:49:09,392 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 15:49:09,393 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,394 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-19 15:49:09,395 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-19 15:49:09,396 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-19 15:49:09,397 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-19 15:49:09,397 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-19 15:49:09,402 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-19 15:49:09,411 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-19 15:49:09,413 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-19 15:49:09,414 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 15:49:09,424 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-19 15:49:09,424 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-19 15:49:09,424 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-19 15:49:09,434 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-19 15:49:09,436 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-19 15:49:09,437 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-19 15:49:09,437 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-19 15:49:09,438 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 15:49:09,439 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-19 15:49:09,440 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 15:49:09,443 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-19 15:49:09,444 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-19 15:49:09,445 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-19 15:49:09,451 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,452 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 15:49:09,454 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-19 15:49:09,454 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-19 15:49:09,458 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-19 15:49:09,460 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-19 15:49:09,461 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 15:49:09,462 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,463 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,467 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 15:49:09,473 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,473 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-19 15:49:09,474 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 15:49:09,474 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,475 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,475 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-19 15:49:09,476 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,477 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-19 15:49:09,477 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-19 15:49:09,477 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,479 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-19 15:49:09,479 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-19 15:49:09,480 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-19 15:49:09,480 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-19 15:49:09,481 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-19 15:49:09,489 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-19 15:49:09,489 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 15:49:09,490 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,490 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-19 15:49:09,491 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-19 15:49:09,491 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-19 15:49:09,492 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-19 15:49:09,493 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-19 15:49:09,493 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-19 15:49:09,494 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-19 15:49:09,494 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-19 15:49:09,495 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 15:49:09,495 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-19 15:49:09,495 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-19 15:49:09,495 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-19 15:49:09,502 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-19 15:49:09,502 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 15:49:09,507 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 15:49:09,507 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,507 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-19 15:49:09,507 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-19 15:49:09,507 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,507 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-19 15:49:09,507 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-19 15:49:09,512 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,512 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-19 15:49:09,512 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-19 15:49:09,512 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-19 15:49:09,512 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 15:49:09,519 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-19 15:49:09,520 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 15:49:09,523 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-19 15:49:09,523 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-19 15:49:09,523 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-19 15:49:09,527 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,528 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:09,528 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-19 15:49:09,529 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-19 15:49:09,529 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-19 15:49:09,530 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-19 15:49:09,530 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 15:49:09,534 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,534 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,534 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:09,534 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:09,534 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,542 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-19 15:49:09,542 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 15:49:09,542 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,542 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,542 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-19 15:49:09,542 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,542 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-19 15:49:09,547 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-19 15:49:09,547 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,551 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-19 15:49:09,553 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-19 15:49:09,555 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,555 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 15:49:09,555 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 15:49:09,555 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,562 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-19 15:49:09,562 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-19 15:49:09,562 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,562 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-19 15:49:09,562 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-19 15:49:09,567 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:09,567 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:09,572 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,572 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-19 15:49:09,572 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 15:49:09,572 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,572 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 15:49:09,572 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-19 15:49:09,577 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-19 15:49:09,577 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-19 15:49:09,577 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 15:49:09,577 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-19 15:49:09,577 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 15:49:09,577 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-19 15:49:09,577 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 15:49:09,577 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-19 15:49:09,588 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-19 15:49:09,591 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-19 15:49:09,592 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 15:49:09,592 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-19 15:49:09,592 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-19 15:49:09,592 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-19 15:49:09,592 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-19 15:49:09,592 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-19 15:49:09,592 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 15:49:09,596 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:09,596 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:09,597 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-19 15:49:09,602 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 15:49:09,602 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:09,606 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 15:49:09,606 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-19 15:49:09,607 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-19 15:49:09,607 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-19 15:49:09,608 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 15:49:09,609 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-19 15:49:09,609 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 15:49:09,609 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-19 15:49:09,609 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 15:49:09,609 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-19 15:49:09,612 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-19 15:49:09,612 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-19 15:49:09,612 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 15:49:09,614 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-19 15:49:09,621 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-19 15:49:09,623 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-19 15:49:09,623 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 15:49:09,624 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-19 15:49:09,624 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 15:49:09,625 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:09,626 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 15:49:09,626 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-19 15:49:09,638 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-19 15:49:09,640 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 15:49:09,641 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 15:49:09,644 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-19 15:49:09,647 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-19 15:49:09,652 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 15:49:09,652 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-19 15:49:09,657 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-19 15:49:09,657 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-19 15:49:09,657 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 15:49:09,657 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 15:49:09,662 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-19 15:49:09,666 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-19 15:49:09,668 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-19 15:49:09,674 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 15:49:09,674 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 15:49:09,680 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-19 15:49:09,689 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 15:49:09,690 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 15:49:09,694 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-19 15:49:11,352 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:49:19,442 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:49:19,457 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:49:19,661 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_154919.wav, taille: 80339 bytes
2025-06-19 15:49:19,661 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_154919.wav, taille: 80339 bytes
2025-06-19 15:49:19,661 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_154919.wav, taille: 80339 bytes
2025-06-19 15:49:20,631 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 15:49:20,656 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 15:49:20,657 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,659 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 15:49:20,659 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-19 15:49:20,661 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,661 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-19 15:49:20,661 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,661 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-19 15:49:20,665 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 15:49:20,666 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-19 15:49:20,668 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 15:49:20,669 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-19 15:49:20,670 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 15:49:20,671 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 15:49:20,672 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,674 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-19 15:49:20,675 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-19 15:49:20,676 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-19 15:49:20,677 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-19 15:49:20,677 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-19 15:49:20,679 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-19 15:49:20,693 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-19 15:49:20,695 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-19 15:49:20,703 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 15:49:20,705 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-19 15:49:20,706 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-19 15:49:20,707 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-19 15:49:20,708 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-19 15:49:20,712 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-19 15:49:20,713 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-19 15:49:20,713 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-19 15:49:20,714 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 15:49:20,716 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-19 15:49:20,717 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 15:49:20,719 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-19 15:49:20,720 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-19 15:49:20,724 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-19 15:49:20,725 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,726 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 15:49:20,726 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-19 15:49:20,727 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-19 15:49:20,727 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-19 15:49:20,728 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-19 15:49:20,728 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 15:49:20,729 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,734 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,736 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 15:49:20,737 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,737 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-19 15:49:20,738 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 15:49:20,738 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,739 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,739 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-19 15:49:20,742 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,742 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-19 15:49:20,743 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-19 15:49:20,744 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,745 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-19 15:49:20,745 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-19 15:49:20,746 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-19 15:49:20,747 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-19 15:49:20,748 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-19 15:49:20,757 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-19 15:49:20,757 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 15:49:20,758 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,758 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-19 15:49:20,759 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-19 15:49:20,759 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-19 15:49:20,760 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-19 15:49:20,762 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-19 15:49:20,762 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-19 15:49:20,762 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-19 15:49:20,762 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-19 15:49:20,772 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 15:49:20,774 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-19 15:49:20,775 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-19 15:49:20,775 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-19 15:49:20,776 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-19 15:49:20,777 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 15:49:20,777 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 15:49:20,779 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,779 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-19 15:49:20,780 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-19 15:49:20,786 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,787 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-19 15:49:20,787 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-19 15:49:20,791 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,791 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-19 15:49:20,791 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-19 15:49:20,791 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-19 15:49:20,791 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 15:49:20,791 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-19 15:49:20,796 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 15:49:20,796 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-19 15:49:20,799 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-19 15:49:20,801 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-19 15:49:20,802 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,807 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:20,807 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-19 15:49:20,807 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-19 15:49:20,811 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-19 15:49:20,811 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-19 15:49:20,811 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 15:49:20,811 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,815 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,820 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:20,821 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:20,822 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,822 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-19 15:49:20,823 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-19 15:49:20,824 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,834 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 15:49:20,834 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 15:49:20,841 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,841 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-19 15:49:20,841 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-19 15:49:20,842 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,843 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-19 15:49:20,843 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-19 15:49:20,843 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 15:49:20,846 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:20,846 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,846 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-19 15:49:20,851 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 15:49:20,851 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,851 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 15:49:20,856 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-19 15:49:20,856 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-19 15:49:20,856 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-19 15:49:20,856 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 15:49:20,856 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-19 15:49:20,856 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 15:49:20,860 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-19 15:49:20,860 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 15:49:20,872 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-19 15:49:20,879 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-19 15:49:20,892 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-19 15:49:20,892 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 15:49:20,906 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-19 15:49:20,911 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-19 15:49:20,913 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-19 15:49:20,921 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-19 15:49:20,922 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-19 15:49:20,923 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 15:49:20,924 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:20,926 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:20,926 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-19 15:49:20,926 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 15:49:20,926 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:20,935 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 15:49:20,935 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-19 15:49:20,941 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-19 15:49:20,941 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-19 15:49:20,941 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 15:49:20,941 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-19 15:49:20,946 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 15:49:20,949 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-19 15:49:20,950 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 15:49:20,952 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-19 15:49:20,959 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-19 15:49:20,959 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-19 15:49:20,960 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 15:49:20,962 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-19 15:49:20,963 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-19 15:49:20,965 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-19 15:49:20,971 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 15:49:20,972 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-19 15:49:20,972 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 15:49:20,974 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-19 15:49:20,975 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 15:49:20,976 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-19 15:49:20,983 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-19 15:49:20,991 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 15:49:21,004 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 15:49:21,022 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-19 15:49:21,022 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-19 15:49:21,026 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 15:49:21,026 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-19 15:49:21,122 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-19 15:49:21,255 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-19 15:49:21,320 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 15:49:21,340 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 15:49:21,343 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-19 15:49:21,353 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-19 15:49:21,405 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-19 15:49:21,408 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 15:49:21,409 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 15:49:21,411 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-19 15:49:21,413 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 15:49:21,424 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 15:49:21,437 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-19 15:49:22,817 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-19 15:49:22,843 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 15:49:22,851 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:22,855 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 15:49:22,857 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-19 15:49:22,860 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:22,863 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 15:49:22,882 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:22,883 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-19 15:49:22,889 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 15:49:22,895 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 15:49:22,896 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 15:49:22,897 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 15:49:22,914 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 15:49:22,926 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-19 15:49:22,926 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-19 15:49:22,926 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 15:49:22,931 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-19 15:49:22,932 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-19 15:49:22,933 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-19 15:49:22,937 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 15:49:22,938 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-19 15:49:22,939 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-19 15:49:22,940 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-19 15:49:22,942 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 15:49:22,943 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-19 15:49:22,944 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 15:49:22,945 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-19 15:49:22,946 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-19 15:49:22,947 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-19 15:49:22,951 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 15:49:22,951 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-19 15:49:22,951 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-19 15:49:22,955 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-19 15:49:22,957 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-19 15:49:22,957 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-19 15:49:22,957 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-19 15:49:22,957 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-19 15:49:22,957 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 15:49:22,962 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 15:49:22,962 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-19 15:49:22,962 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-19 15:49:22,965 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-19 15:49:22,967 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-19 15:49:22,969 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-19 15:49:22,970 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-19 15:49:22,973 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 15:49:22,974 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 15:49:22,977 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-19 15:49:23,002 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-19 15:49:23,008 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 15:49:23,008 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 15:49:23,008 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 15:49:23,012 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-19 15:49:23,013 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:23,014 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 15:49:23,016 - numba.core.byteflow - DEBUG - stack []
2025-06-19 15:49:23,018 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-19 15:49:23,018 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 15:49:23,018 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 15:49:23,018 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 15:49:23,022 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 15:49:23,026 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 15:49:23,037 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-19 15:49:23,038 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-19 15:49:23,043 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 15:49:23,045 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-19 15:49:23,045 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-19 15:49:23,046 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-19 15:49:23,047 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 15:49:23,049 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-19 15:49:23,051 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-19 15:49:23,054 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-19 15:49:23,055 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 15:49:23,056 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-19 15:49:23,057 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 15:49:23,058 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-19 15:49:23,059 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-19 15:49:23,060 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-19 15:49:23,061 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 15:49:23,061 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-19 15:49:23,062 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-19 15:49:23,063 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-19 15:49:23,065 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-19 15:49:23,068 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-19 15:49:23,070 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-19 15:49:23,070 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-19 15:49:23,072 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 15:49:23,072 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 15:49:23,072 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-19 15:49:23,072 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-19 15:49:23,072 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-19 15:49:23,077 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-19 15:49:23,078 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-19 15:49:23,078 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-19 15:49:23,080 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 15:49:23,082 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 15:49:23,091 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-19 15:49:25,529 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_154919.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:49:25,652 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_154919.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:49:25,773 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_154919.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 15:49:28,882 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:49:28,895 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:49:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:49:29,068 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:49:29,072 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:49:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:49:29,272 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': 'Aucun contenu audio détecté'}
2025-06-19 15:49:29,311 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:49:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 15:51:38,606 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessing.py', reloading
2025-06-19 15:51:41,562 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:52:02,165 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:52:02,183 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:52:29,633 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 15:52:31,997 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:52:45,260 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:52:45,267 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:52:49,626 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessing.py', reloading
2025-06-19 15:52:50,867 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 15:53:01,926 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 15:53:01,931 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 15:57:47,507 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:57:47] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 15:57:47,576 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:57:47] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 15:57:47,643 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:57:47] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-19 15:57:48,136 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 15:57:48] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 16:00:12,592 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160012.wav, taille: 80339 bytes
2025-06-19 16:00:13,677 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 16:00:13,711 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:00:13,712 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:13,714 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:00:13,714 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-19 16:00:13,716 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,726 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-19 16:00:13,728 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,729 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-19 16:00:13,729 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:00:13,730 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-19 16:00:13,730 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:00:13,733 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-19 16:00:13,733 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:00:13,741 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 16:00:13,742 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,743 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-19 16:00:13,744 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-19 16:00:13,744 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-19 16:00:13,745 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-19 16:00:13,746 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-19 16:00:13,746 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-19 16:00:13,747 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-19 16:00:13,748 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-19 16:00:13,748 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 16:00:13,749 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-19 16:00:13,750 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-19 16:00:13,758 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-19 16:00:13,759 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-19 16:00:13,760 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-19 16:00:13,761 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-19 16:00:13,762 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-19 16:00:13,762 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 16:00:13,763 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-19 16:00:13,763 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 16:00:13,763 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-19 16:00:13,763 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-19 16:00:13,769 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-19 16:00:13,772 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,777 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:00:13,778 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-19 16:00:13,779 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-19 16:00:13,779 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-19 16:00:13,780 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-19 16:00:13,780 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 16:00:13,781 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,782 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,782 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:00:13,793 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:13,793 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-19 16:00:13,793 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 16:00:13,793 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,793 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,793 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-19 16:00:13,805 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:13,808 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-19 16:00:13,842 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-19 16:00:13,842 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,842 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-19 16:00:13,842 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-19 16:00:13,847 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-19 16:00:13,847 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-19 16:00:13,847 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-19 16:00:13,847 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-19 16:00:13,860 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 16:00:13,860 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,861 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-19 16:00:13,862 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-19 16:00:13,862 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-19 16:00:13,863 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-19 16:00:13,863 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-19 16:00:13,864 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-19 16:00:13,866 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-19 16:00:13,866 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-19 16:00:13,875 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 16:00:13,876 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-19 16:00:13,876 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-19 16:00:13,877 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-19 16:00:13,878 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-19 16:00:13,879 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 16:00:13,879 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 16:00:13,880 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:13,882 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-19 16:00:13,883 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-19 16:00:13,886 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,886 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-19 16:00:13,892 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-19 16:00:13,892 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,892 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:00:13,892 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-19 16:00:13,892 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-19 16:00:13,892 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 16:00:13,897 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-19 16:00:13,897 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 16:00:13,897 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-19 16:00:13,897 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-19 16:00:13,906 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-19 16:00:13,906 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,912 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:00:13,912 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-19 16:00:13,912 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-19 16:00:13,912 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-19 16:00:13,912 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-19 16:00:13,912 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 16:00:13,919 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,923 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,932 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:00:13,933 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:00:13,942 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:13,942 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-19 16:00:13,943 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 16:00:13,944 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,944 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,945 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-19 16:00:13,946 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:13,946 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-19 16:00:13,948 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-19 16:00:13,948 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,949 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-19 16:00:13,949 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-19 16:00:13,960 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,961 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 16:00:13,962 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 16:00:13,963 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:13,963 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-19 16:00:13,964 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-19 16:00:13,965 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,965 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-19 16:00:13,966 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-19 16:00:13,969 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:00:13,976 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:00:13,978 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:13,978 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-19 16:00:13,979 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 16:00:13,980 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:13,980 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 16:00:13,981 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-19 16:00:13,982 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-19 16:00:13,983 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-19 16:00:13,992 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 16:00:13,993 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-19 16:00:13,994 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 16:00:13,994 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-19 16:00:13,995 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 16:00:13,995 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-19 16:00:13,996 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-19 16:00:13,997 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-19 16:00:13,997 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 16:00:13,999 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-19 16:00:14,003 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-19 16:00:14,011 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-19 16:00:14,012 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-19 16:00:14,013 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-19 16:00:14,013 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:00:14,014 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:00:14,014 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:14,015 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-19 16:00:14,016 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 16:00:14,026 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:14,026 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 16:00:14,027 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-19 16:00:14,027 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-19 16:00:14,028 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-19 16:00:14,029 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 16:00:14,029 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-19 16:00:14,030 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 16:00:14,030 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-19 16:00:14,032 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 16:00:14,033 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-19 16:00:14,043 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-19 16:00:14,044 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-19 16:00:14,044 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 16:00:14,045 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-19 16:00:14,046 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-19 16:00:14,046 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-19 16:00:14,047 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 16:00:14,047 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-19 16:00:14,048 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:00:14,048 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:00:14,050 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:00:14,059 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-19 16:00:14,064 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-19 16:00:14,066 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 16:00:14,078 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 16:00:14,080 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-19 16:00:14,083 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-19 16:00:14,092 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:00:14,092 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-19 16:00:14,097 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-19 16:00:14,097 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-19 16:00:14,104 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 16:00:14,112 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 16:00:14,112 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-19 16:00:14,112 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-19 16:00:14,122 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-19 16:00:14,136 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 16:00:14,143 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 16:00:14,144 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-19 16:00:14,145 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:00:14,147 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:00:14,157 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-19 16:00:15,392 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-19 16:00:15,409 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:00:15,413 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:15,413 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:00:15,415 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-19 16:00:15,415 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:15,416 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:00:15,423 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:15,426 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-19 16:00:15,426 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:00:15,428 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:00:15,429 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:00:15,429 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:00:15,432 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:00:15,442 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-19 16:00:15,442 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-19 16:00:15,501 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:00:15,506 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-19 16:00:15,587 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-19 16:00:15,587 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-19 16:00:15,592 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:00:15,592 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-19 16:00:15,679 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-19 16:00:15,738 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-19 16:00:15,758 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:00:15,758 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-19 16:00:15,762 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:00:15,763 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-19 16:00:15,765 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-19 16:00:15,795 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-19 16:00:15,795 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:00:15,844 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-19 16:00:15,846 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-19 16:00:15,855 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-19 16:00:15,857 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-19 16:00:15,858 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-19 16:00:15,859 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-19 16:00:15,860 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-19 16:00:15,861 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:00:15,862 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:00:15,864 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-19 16:00:15,865 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-19 16:00:15,866 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:00:15,866 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:00:15,874 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-19 16:00:15,875 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-19 16:00:15,876 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:00:15,929 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:00:15,959 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-19 16:00:15,964 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-19 16:00:15,977 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:00:15,977 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:00:15,978 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:00:15,978 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-19 16:00:15,979 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:15,980 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:00:15,980 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:00:15,981 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-19 16:00:15,981 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:00:15,982 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:00:15,986 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:00:15,986 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:00:15,992 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:00:15,992 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-19 16:00:15,992 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-19 16:00:15,995 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:00:15,995 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-19 16:00:15,995 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-19 16:00:15,996 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-19 16:00:15,996 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:00:15,997 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-19 16:00:15,997 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-19 16:00:15,998 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-19 16:00:15,998 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:00:16,000 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-19 16:00:16,004 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:00:16,010 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-19 16:00:16,011 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-19 16:00:16,011 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-19 16:00:16,012 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:00:16,012 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-19 16:00:16,013 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-19 16:00:16,014 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-19 16:00:16,015 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-19 16:00:16,015 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-19 16:00:16,016 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-19 16:00:16,022 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-19 16:00:16,022 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:00:16,025 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:00:16,026 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-19 16:00:16,027 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-19 16:00:16,027 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:00:16,028 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:00:16,028 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-19 16:00:16,029 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-19 16:00:16,029 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:00:16,030 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:00:16,036 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-19 16:00:17,262 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160012.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:00:17,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160017.wav, taille: 80339 bytes
2025-06-19 16:00:17,588 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur: 'TranscriptionService' object has no attribute '_transcribe_with_retries'"}
2025-06-19 16:00:17,592 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:00:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 16:00:17,837 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160017.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:00:18,087 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur: 'TranscriptionService' object has no attribute '_transcribe_with_retries'"}
2025-06-19 16:00:18,087 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:00:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 16:00:22,592 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160022.wav, taille: 80339 bytes
2025-06-19 16:00:23,092 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160022.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:00:23,419 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur: 'TranscriptionService' object has no attribute '_transcribe_with_retries'"}
2025-06-19 16:00:23,422 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:00:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 16:00:27,283 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160027.wav, taille: 80339 bytes
2025-06-19 16:00:27,778 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160027.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:00:27,892 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160027.wav, taille: 4025 bytes
2025-06-19 16:00:28,039 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur: 'TranscriptionService' object has no attribute '_transcribe_with_retries'"}
2025-06-19 16:00:28,041 - app - WARNING - Échec de suppression du fichier temporaire: [WinError 32] The process cannot access the file because it is being used by another process: 'uploads\\audio_20250619_160027.wav'
2025-06-19 16:00:28,043 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:00:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 16:00:28,231 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160027.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:00:28,619 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': "Erreur: 'TranscriptionService' object has no attribute '_transcribe_with_retries'"}
2025-06-19 16:00:28,624 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:00:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 16:02:02,790 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 16:02:02,802 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 16:02:05,242 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 16:02:13,703 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 16:02:13,705 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 16:04:30,864 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 16:04:32,783 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 16:04:41,584 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 16:04:41,595 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 16:05:20,259 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 16:05:20,261 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-19 16:05:21,162 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 16:05:30,358 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 16:05:30,367 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 16:09:16,654 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:09:16] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 16:09:16,727 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:09:16] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 16:09:16,734 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:09:16] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 16:09:17,147 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:09:17] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-19 16:09:25,205 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160925.wav, taille: 80339 bytes
2025-06-19 16:09:26,215 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 16:09:26,256 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:09:26,256 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,257 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:09:26,258 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-19 16:09:26,261 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,265 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-19 16:09:26,266 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,267 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-19 16:09:26,268 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:09:26,268 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-19 16:09:26,269 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:09:26,269 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-19 16:09:26,269 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:09:26,269 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 16:09:26,269 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,273 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-19 16:09:26,274 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-19 16:09:26,274 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-19 16:09:26,276 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-19 16:09:26,282 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-19 16:09:26,283 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-19 16:09:26,286 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-19 16:09:26,287 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-19 16:09:26,287 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 16:09:26,289 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-19 16:09:26,290 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-19 16:09:26,291 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-19 16:09:26,294 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-19 16:09:26,298 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-19 16:09:26,300 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-19 16:09:26,300 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-19 16:09:26,301 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 16:09:26,302 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-19 16:09:26,304 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 16:09:26,304 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-19 16:09:26,305 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-19 16:09:26,305 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-19 16:09:26,306 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,307 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:09:26,308 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-19 16:09:26,310 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-19 16:09:26,312 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-19 16:09:26,313 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-19 16:09:26,314 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 16:09:26,314 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,315 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,316 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:09:26,317 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,318 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-19 16:09:26,319 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 16:09:26,319 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,320 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,323 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-19 16:09:26,335 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,336 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-19 16:09:26,338 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-19 16:09:26,349 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,349 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-19 16:09:26,352 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-19 16:09:26,353 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-19 16:09:26,353 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-19 16:09:26,354 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-19 16:09:26,354 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-19 16:09:26,355 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 16:09:26,356 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,356 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-19 16:09:26,356 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-19 16:09:26,366 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-19 16:09:26,367 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-19 16:09:26,368 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-19 16:09:26,368 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-19 16:09:26,369 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-19 16:09:26,369 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-19 16:09:26,370 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 16:09:26,370 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-19 16:09:26,373 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-19 16:09:26,373 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-19 16:09:26,374 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-19 16:09:26,376 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 16:09:26,383 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 16:09:26,384 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,384 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-19 16:09:26,385 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-19 16:09:26,386 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,386 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-19 16:09:26,387 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-19 16:09:26,387 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,389 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:09:26,390 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-19 16:09:26,390 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-19 16:09:26,391 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 16:09:26,391 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-19 16:09:26,395 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 16:09:26,400 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-19 16:09:26,401 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-19 16:09:26,402 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-19 16:09:26,402 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,403 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:26,404 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-19 16:09:26,404 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-19 16:09:26,405 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-19 16:09:26,407 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-19 16:09:26,408 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 16:09:26,415 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,417 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,418 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:26,419 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:26,420 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,421 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-19 16:09:26,427 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 16:09:26,427 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,433 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,435 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-19 16:09:26,436 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,436 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-19 16:09:26,437 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-19 16:09:26,437 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,438 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-19 16:09:26,439 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-19 16:09:26,441 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,443 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 16:09:26,449 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 16:09:26,450 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,451 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-19 16:09:26,451 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-19 16:09:26,452 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,452 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-19 16:09:26,453 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-19 16:09:26,454 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:26,457 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:26,457 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,458 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-19 16:09:26,466 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 16:09:26,466 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,467 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 16:09:26,467 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-19 16:09:26,468 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-19 16:09:26,469 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-19 16:09:26,471 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 16:09:26,471 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-19 16:09:26,472 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 16:09:26,472 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-19 16:09:26,473 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 16:09:26,474 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-19 16:09:26,474 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-19 16:09:26,483 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-19 16:09:26,484 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 16:09:26,484 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-19 16:09:26,485 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-19 16:09:26,486 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-19 16:09:26,486 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-19 16:09:26,487 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-19 16:09:26,487 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:09:26,488 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:26,488 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:26,490 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-19 16:09:26,490 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 16:09:26,491 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:26,499 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 16:09:26,499 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-19 16:09:26,500 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-19 16:09:26,500 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-19 16:09:26,501 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 16:09:26,502 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-19 16:09:26,502 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 16:09:26,504 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-19 16:09:26,505 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 16:09:26,506 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-19 16:09:26,506 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-19 16:09:26,506 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-19 16:09:26,507 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 16:09:26,507 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-19 16:09:26,515 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-19 16:09:26,516 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-19 16:09:26,517 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 16:09:26,517 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-19 16:09:26,518 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:09:26,518 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:26,520 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:09:26,521 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-19 16:09:26,532 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-19 16:09:26,534 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 16:09:26,536 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 16:09:26,536 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-19 16:09:26,545 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-19 16:09:26,550 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:09:26,551 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-19 16:09:26,552 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-19 16:09:26,554 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-19 16:09:26,555 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 16:09:26,555 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 16:09:26,557 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-19 16:09:26,565 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-19 16:09:26,567 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-19 16:09:26,568 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 16:09:26,569 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 16:09:26,570 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-19 16:09:26,571 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:09:26,571 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:09:26,586 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-19 16:09:27,705 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-19 16:09:27,724 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:09:27,724 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:27,731 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:09:27,734 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-19 16:09:27,735 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:27,735 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:09:27,736 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:27,737 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-19 16:09:27,738 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:09:27,738 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:09:27,739 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:09:27,741 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:09:27,745 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:09:27,749 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-19 16:09:27,749 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-19 16:09:27,749 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:09:27,749 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-19 16:09:27,752 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-19 16:09:27,753 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-19 16:09:27,754 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:09:27,755 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-19 16:09:27,755 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-19 16:09:27,756 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-19 16:09:27,756 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:09:27,757 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-19 16:09:27,758 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:09:27,760 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-19 16:09:27,761 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-19 16:09:27,762 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-19 16:09:27,764 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:09:27,765 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-19 16:09:27,767 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-19 16:09:27,768 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-19 16:09:27,769 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-19 16:09:27,770 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-19 16:09:27,770 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-19 16:09:27,771 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-19 16:09:27,771 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:09:27,771 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:09:27,773 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-19 16:09:27,773 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-19 16:09:27,774 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:09:27,774 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:09:27,777 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-19 16:09:27,778 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-19 16:09:27,780 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:09:27,782 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:09:27,786 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-19 16:09:27,793 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-19 16:09:27,799 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:09:27,800 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:27,800 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:09:27,801 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-19 16:09:27,801 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:27,802 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:09:27,802 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:27,803 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-19 16:09:27,803 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:09:27,804 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:09:27,805 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:09:27,807 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:09:27,811 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:09:27,813 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-19 16:09:27,814 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-19 16:09:27,816 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:09:27,816 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-19 16:09:27,817 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-19 16:09:27,818 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-19 16:09:27,818 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:09:27,819 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-19 16:09:27,820 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-19 16:09:27,821 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-19 16:09:27,822 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:09:27,822 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-19 16:09:27,837 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:09:27,838 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-19 16:09:27,838 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-19 16:09:27,840 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-19 16:09:27,841 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:09:27,848 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-19 16:09:27,848 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-19 16:09:27,848 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-19 16:09:27,852 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-19 16:09:27,853 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-19 16:09:27,853 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-19 16:09:27,854 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-19 16:09:27,855 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:09:27,855 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:09:27,856 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-19 16:09:27,860 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-19 16:09:27,862 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:09:27,864 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:09:27,865 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-19 16:09:27,866 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-19 16:09:27,867 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:09:27,868 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:09:27,872 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-19 16:09:29,186 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160925.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:09:30,516 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160930.wav, taille: 80339 bytes
2025-06-19 16:09:30,977 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160930.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:09:32,712 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 16:09:32,716 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"salam 4 minutes\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 16:09:32,716 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 16:09:32,716 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 16:09:34,795 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 16:09:34,797 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 16:09:34,797 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 16:09:34,804 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 16:09:35,386 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 16:09:35,471 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1443 request_id=req_751d281a162f19f5e4bc0f5afadc8a76 response_code=200
2025-06-19 16:09:35,521 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160935.wav, taille: 80339 bytes
2025-06-19 16:09:35,652 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-19 16:09:35,779 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:09:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 16:09:35,782 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-19 16:09:36,065 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160935.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:09:37,795 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-19 16:09:46,135 - werkzeug - WARNING -  * Debugger is active!
2025-06-19 16:09:46,145 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-19 16:09:46,335 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160946.wav, taille: 80339 bytes
2025-06-19 16:09:46,335 - app - INFO - Fichier sauvegardé: uploads\audio_20250619_160946.wav, taille: 80339 bytes
2025-06-19 16:09:47,170 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 16:09:47,196 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:09:47,197 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,197 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:09:47,198 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-19 16:09:47,198 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,199 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-19 16:09:47,199 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,200 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-19 16:09:47,203 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:09:47,204 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-19 16:09:47,205 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:09:47,205 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-19 16:09:47,206 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:09:47,208 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 16:09:47,209 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,210 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-19 16:09:47,211 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-19 16:09:47,213 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-19 16:09:47,213 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-19 16:09:47,213 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-19 16:09:47,215 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-19 16:09:47,215 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-19 16:09:47,215 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-19 16:09:47,215 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 16:09:47,215 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-19 16:09:47,219 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-19 16:09:47,219 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-19 16:09:47,220 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-19 16:09:47,221 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-19 16:09:47,221 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-19 16:09:47,222 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-19 16:09:47,222 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-19 16:09:47,222 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-19 16:09:47,223 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-19 16:09:47,225 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-19 16:09:47,225 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-19 16:09:47,226 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-19 16:09:47,228 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,230 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:09:47,231 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-19 16:09:47,231 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-19 16:09:47,232 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-19 16:09:47,232 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-19 16:09:47,233 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 16:09:47,233 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,234 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,234 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:09:47,235 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,235 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-19 16:09:47,236 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-19 16:09:47,237 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,238 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,238 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-19 16:09:47,239 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,239 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-19 16:09:47,240 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-19 16:09:47,241 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,242 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-19 16:09:47,242 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-19 16:09:47,243 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-19 16:09:47,245 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-19 16:09:47,246 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-19 16:09:47,247 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-19 16:09:47,247 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 16:09:47,248 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,248 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-19 16:09:47,249 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-19 16:09:47,249 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-19 16:09:47,250 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-19 16:09:47,251 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-19 16:09:47,251 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-19 16:09:47,251 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-19 16:09:47,251 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-19 16:09:47,256 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 16:09:47,256 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-19 16:09:47,259 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-19 16:09:47,260 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-19 16:09:47,261 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-19 16:09:47,262 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 16:09:47,264 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-19 16:09:47,265 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,265 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-19 16:09:47,266 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-19 16:09:47,266 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,267 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-19 16:09:47,268 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-19 16:09:47,274 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-19 16:09:47,275 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-19 16:09:47,276 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,277 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:47,279 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-19 16:09:47,280 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-19 16:09:47,280 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-19 16:09:47,281 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-19 16:09:47,281 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 16:09:47,282 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,282 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,283 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:47,284 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:47,285 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,285 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-19 16:09:47,286 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-19 16:09:47,286 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,286 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,286 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-19 16:09:47,286 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,286 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-19 16:09:47,286 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-19 16:09:47,290 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,292 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-19 16:09:47,292 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-19 16:09:47,293 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,294 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 16:09:47,296 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-19 16:09:47,296 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,296 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-19 16:09:47,296 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-19 16:09:47,296 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,296 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-19 16:09:47,301 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-19 16:09:47,302 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-19 16:09:47,303 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:47,303 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,304 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-19 16:09:47,304 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 16:09:47,305 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,305 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 16:09:47,306 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-19 16:09:47,306 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-19 16:09:47,306 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-19 16:09:47,308 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 16:09:47,309 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-19 16:09:47,311 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-19 16:09:47,313 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-19 16:09:47,314 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-19 16:09:47,314 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-19 16:09:47,315 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-19 16:09:47,315 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-19 16:09:47,316 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-19 16:09:47,316 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-19 16:09:47,317 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-19 16:09:47,317 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-19 16:09:47,318 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-19 16:09:47,318 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-19 16:09:47,319 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:09:47,319 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:47,320 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:47,321 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-19 16:09:47,321 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 16:09:47,322 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:47,322 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 16:09:47,322 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-19 16:09:47,323 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-19 16:09:47,325 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-19 16:09:47,326 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 16:09:47,331 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-19 16:09:47,331 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-19 16:09:47,332 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-19 16:09:47,332 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-19 16:09:47,333 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-19 16:09:47,334 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-19 16:09:47,335 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-19 16:09:47,335 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-19 16:09:47,335 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-19 16:09:47,336 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-19 16:09:47,336 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-19 16:09:47,338 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-19 16:09:47,338 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-19 16:09:47,339 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:09:47,339 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-19 16:09:47,340 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:09:47,341 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-19 16:09:47,345 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-19 16:09:47,348 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 16:09:47,351 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-19 16:09:47,361 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-19 16:09:47,364 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-19 16:09:47,368 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:09:47,371 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-19 16:09:47,377 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-19 16:09:47,380 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-19 16:09:47,380 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 16:09:47,458 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-19 16:09:47,465 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-19 16:09:47,496 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-19 16:09:47,506 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-19 16:09:47,538 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 16:09:47,544 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-19 16:09:47,545 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-19 16:09:47,547 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:09:47,586 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:09:47,641 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-19 16:09:48,865 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-19 16:09:48,899 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:09:48,900 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:48,900 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:09:48,902 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-19 16:09:48,903 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:48,904 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:09:48,904 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:48,905 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-19 16:09:48,906 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:09:48,915 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:09:48,917 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:09:48,918 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:09:48,919 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:09:48,920 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-19 16:09:48,922 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-19 16:09:48,923 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:09:48,929 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-19 16:09:48,933 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-19 16:09:48,934 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-19 16:09:48,937 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:09:48,937 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-19 16:09:48,938 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-19 16:09:48,938 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-19 16:09:48,939 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:09:48,940 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-19 16:09:48,940 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-19 16:09:48,942 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-19 16:09:48,945 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-19 16:09:48,946 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-19 16:09:48,946 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-19 16:09:48,947 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-19 16:09:48,949 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-19 16:09:48,949 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-19 16:09:48,950 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-19 16:09:48,950 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-19 16:09:48,951 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-19 16:09:48,951 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-19 16:09:48,951 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:09:48,951 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:09:48,951 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-19 16:09:48,954 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-19 16:09:48,955 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:09:48,955 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:09:48,956 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-19 16:09:48,956 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-19 16:09:48,957 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:09:48,958 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:09:48,964 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-19 16:09:48,966 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-19 16:09:48,975 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-19 16:09:48,976 - numba.core.byteflow - DEBUG - stack: []
2025-06-19 16:09:48,979 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-19 16:09:48,979 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-19 16:09:48,980 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:48,980 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:09:48,981 - numba.core.byteflow - DEBUG - stack []
2025-06-19 16:09:48,981 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-19 16:09:48,981 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-19 16:09:48,982 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:09:48,982 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-19 16:09:48,983 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:09:48,985 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-19 16:09:48,985 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-19 16:09:48,985 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-19 16:09:48,986 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:09:48,986 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-19 16:09:48,987 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-19 16:09:48,987 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-19 16:09:48,988 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:09:48,989 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-19 16:09:48,989 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-19 16:09:48,990 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-19 16:09:48,991 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:09:48,992 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-19 16:09:48,992 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-19 16:09:48,996 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-19 16:09:48,996 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-19 16:09:48,997 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-19 16:09:48,997 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-19 16:09:48,998 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-19 16:09:48,998 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-19 16:09:48,999 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-19 16:09:48,999 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-19 16:09:49,000 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-19 16:09:49,000 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-19 16:09:49,001 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-19 16:09:49,001 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-19 16:09:49,001 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-19 16:09:49,001 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-19 16:09:49,001 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-19 16:09:49,001 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:09:49,005 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-19 16:09:49,005 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-19 16:09:49,007 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-19 16:09:49,008 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-19 16:09:49,008 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-19 16:09:49,014 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-19 16:09:50,014 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160946.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:09:50,046 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250619_160946.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-19 16:09:53,510 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 16:09:53,510 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 16:09:53,510 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 16:09:53,515 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 16:09:53,681 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 16:09:53,681 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-19 16:09:53,683 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-19 16:09:53,690 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-19 16:09:55,616 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-19 16:09:55,616 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1297 request_id=req_258d9830da68697e10bce7b5c33bf5c0 response_code=200
2025-06-19 16:09:58,113 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 16:09:58,114 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 16:10:01,466 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-19 16:10:01,476 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2759 request_id=req_f5cc671dbffe1655185938773f6706c4 response_code=200
2025-06-19 16:10:01,587 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 16:10:01,588 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 16:10:03,081 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-19 16:10:03,085 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=822 request_id=req_3c4065f0c0b8946581f1bbe3424d9df5 response_code=200
2025-06-19 16:10:03,237 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:10:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 16:10:12,476 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-19 16:10:12,476 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=17631 request_id=req_112663302f7560222deacbaf0005f87c response_code=200
2025-06-19 16:10:17,821 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-19 16:10:17,832 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-19 16:10:17,852 - urllib3.connectionpool - DEBUG - Resetting dropped connection: api.openai.com
2025-06-19 16:10:17,900 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 16:10:17,918 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001FBD8889460>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 16:10:17,927 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-19 16:10:17,959 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 16:10:17,964 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001FBD8889F10>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-19 16:10:17,970 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-19 16:10:18,124 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-19 16:10:18,125 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-19 16:10:18,128 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-19 16:10:18,140 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/chat/completions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-19 16:10:18,149 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001FBCE550130>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/chat/completions
2025-06-19 16:10:18,152 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-19 16:10:18,154 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/chat/completions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-19 16:10:18,161 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001FBCE54A2E0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/chat/completions
2025-06-19 16:10:18,164 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-19 16:10:18,300 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:10:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-19 16:17:42,087 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:17:42] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-19 16:17:42,168 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:17:42] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-19 16:17:42,184 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:17:42] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-19 16:17:42,574 - werkzeug - INFO - 127.0.0.1 - - [19/Jun/2025 16:17:42] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 09:36:30,084 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.122:5000
2025-06-20 09:36:30,086 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-20 09:36:30,116 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 09:36:37,307 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 09:36:37,327 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 09:37:56,554 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:37:56] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 09:37:56,683 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:37:56] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 09:37:56,754 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:37:56] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 09:37:57,111 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:37:57] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-06-20 09:37:57,208 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:37:57] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 09:38:09,779 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093809.wav, taille: 81305 bytes
2025-06-20 09:38:13,790 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\lazy_loader\\__init__.py', reloading
2025-06-20 09:38:14,106 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\core\\audio.py', reloading
2025-06-20 09:38:15,742 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 09:39:10,003 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 09:39:10,021 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 09:39:10,391 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093910.wav, taille: 81305 bytes
2025-06-20 09:39:10,395 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093910.wav, taille: 80339 bytes
2025-06-20 09:39:10,396 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093910.wav, taille: 80339 bytes
2025-06-20 09:39:10,397 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093910.wav, taille: 80339 bytes
2025-06-20 09:39:10,409 - app - ERROR - Erreur lors du traitement audio: local variable 'wav_path' referenced before assignment
2025-06-20 09:39:10,411 - app - ERROR - Erreur lors du traitement audio: local variable 'wav_path' referenced before assignment
2025-06-20 09:39:10,421 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093910.wav, taille: 80339 bytes
2025-06-20 09:39:10,441 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093910.wav, taille: 80339 bytes
2025-06-20 09:39:10,475 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093910.wav, taille: 80339 bytes
2025-06-20 09:39:10,488 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:10] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:10,529 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:10] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:10,531 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093910.wav, taille: 32768 bytes
2025-06-20 09:39:10,540 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:10] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:10,540 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:10] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:10,540 - app - ERROR - Erreur lors du traitement audio: local variable 'wav_path' referenced before assignment
2025-06-20 09:39:10,551 - app - ERROR - Erreur lors du traitement audio: local variable 'wav_path' referenced before assignment
2025-06-20 09:39:10,551 - app - ERROR - Erreur lors du traitement audio: local variable 'wav_path' referenced before assignment
2025-06-20 09:39:10,571 - app - ERROR - Erreur lors du traitement audio: local variable 'wav_path' referenced before assignment
2025-06-20 09:39:10,681 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:10] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:10,742 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:10] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:10,833 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:10] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:10,846 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:10] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:11,911 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:11] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 09:39:12,102 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:12] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 09:39:12,144 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:12] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 09:39:12,534 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:12] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 09:39:13,934 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\importlib\\__init__.py', reloading
2025-06-20 09:39:13,985 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-20 09:39:14,033 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-20 09:39:14,074 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-20 09:39:14,126 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-20 09:39:14,162 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-20 09:39:14,206 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-20 09:39:14,319 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 09:39:14,358 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:39:14,361 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,361 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:39:14,361 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 09:39:14,366 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,369 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 09:39:14,369 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,371 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 09:39:14,379 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 09:39:14,379 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 09:39:14,381 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 09:39:14,383 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 09:39:14,383 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 09:39:14,383 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 09:39:14,383 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 09:39:14,383 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 09:39:14,389 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 09:39:14,389 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 09:39:14,391 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 09:39:14,391 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 09:39:14,391 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 09:39:14,391 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 09:39:14,391 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 09:39:14,391 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 09:39:14,391 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 09:39:14,402 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 09:39:14,402 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 09:39:14,402 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 09:39:14,402 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 09:39:14,402 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,402 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:39:14,402 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 09:39:14,410 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 09:39:14,410 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 09:39:14,412 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 09:39:14,412 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 09:39:14,412 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,412 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,417 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:39:14,420 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,422 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 09:39:14,422 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 09:39:14,422 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,422 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,422 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 09:39:14,422 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,422 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 09:39:14,430 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 09:39:14,430 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,434 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 09:39:14,434 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 09:39:14,434 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 09:39:14,434 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 09:39:14,440 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 09:39:14,440 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 09:39:14,440 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 09:39:14,442 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,442 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 09:39:14,442 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 09:39:14,442 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 09:39:14,442 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 09:39:14,450 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 09:39:14,453 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 09:39:14,453 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 09:39:14,453 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 09:39:14,453 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 09:39:14,453 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 09:39:14,453 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 09:39:14,453 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 09:39:14,461 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 09:39:14,461 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 09:39:14,467 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 09:39:14,467 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,467 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 09:39:14,471 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 09:39:14,471 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,473 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 09:39:14,473 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 09:39:14,473 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,473 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:39:14,473 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 09:39:14,478 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 09:39:14,479 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 09:39:14,479 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 09:39:14,480 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 09:39:14,482 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 09:39:14,483 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 09:39:14,483 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 09:39:14,483 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,483 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:14,483 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 09:39:14,483 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 09:39:14,491 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 09:39:14,491 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 09:39:14,493 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 09:39:14,493 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,493 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,493 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:14,500 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:14,503 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,503 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 09:39:14,503 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 09:39:14,503 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,503 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,503 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 09:39:14,503 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,511 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 09:39:14,511 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 09:39:14,511 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,513 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 09:39:14,516 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 09:39:14,516 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,521 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:14,523 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:14,531 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,531 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 09:39:14,533 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 09:39:14,533 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,533 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 09:39:14,533 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 09:39:14,533 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 09:39:14,533 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 09:39:14,541 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 09:39:14,541 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 09:39:14,543 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 09:39:14,543 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 09:39:14,543 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 09:39:14,543 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 09:39:14,543 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 09:39:14,551 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 09:39:14,553 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 09:39:14,554 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 09:39:14,555 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 09:39:14,562 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:14,564 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 09:39:14,566 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 09:39:14,566 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 09:39:14,572 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 09:39:14,572 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 09:39:14,574 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 09:39:14,574 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 09:39:14,574 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 09:39:14,574 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 09:39:14,574 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 09:39:14,574 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 09:39:14,574 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 09:39:14,574 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 09:39:14,584 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 09:39:14,584 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 09:39:14,584 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 09:39:14,584 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 09:39:14,584 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 09:39:14,584 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:39:14,584 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:14,592 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:39:14,594 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 09:39:14,604 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 09:39:14,604 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 09:39:14,612 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 09:39:14,618 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 09:39:14,622 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 09:39:14,625 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:39:14,625 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 09:39:14,625 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 09:39:14,625 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 09:39:14,633 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 09:39:14,635 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 09:39:14,635 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 09:39:14,635 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 09:39:14,643 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 09:39:14,643 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 09:39:14,645 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 09:39:14,645 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 09:39:14,645 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:39:14,650 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:39:14,662 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 09:39:16,361 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 09:39:51,991 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 09:39:52,021 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 09:39:52,587 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093952.wav, taille: 80339 bytes
2025-06-20 09:39:52,635 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093952.wav, taille: 80339 bytes
2025-06-20 09:39:52,653 - app - ERROR - Erreur lors du traitement audio: local variable 'wav_path' referenced before assignment
2025-06-20 09:39:52,666 - app - WARNING - Échec de suppression du fichier temporaire: [WinError 32] The process cannot access the file because it is being used by another process: 'uploads\\audio_20250620_093952.wav'
2025-06-20 09:39:52,674 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:52] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:52,698 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093952.wav, taille: 89999 bytes
2025-06-20 09:39:52,714 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093952.wav, taille: 89999 bytes
2025-06-20 09:39:52,719 - app - ERROR - Erreur lors du traitement audio: local variable 'wav_path' referenced before assignment
2025-06-20 09:39:52,725 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093952.wav, taille: 70679 bytes
2025-06-20 09:39:52,735 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:39:52] "[35m[1mPOST /api/transcribe/process HTTP/1.1[0m" 500 -
2025-06-20 09:39:52,789 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093952.wav, taille: 89999 bytes
2025-06-20 09:39:52,839 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093952.wav, taille: 80339 bytes
2025-06-20 09:39:55,009 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 09:39:55,126 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:39:55,184 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:55,209 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:39:55,215 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 09:39:55,328 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:55,362 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 09:39:55,405 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:55,451 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 09:39:55,508 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:39:55,521 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 09:39:55,556 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:39:55,561 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 09:39:55,591 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:39:55,711 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 09:39:55,772 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:55,804 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 09:39:55,923 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 09:39:56,006 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 09:39:56,078 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 09:39:56,152 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 09:39:56,224 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 09:39:56,270 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 09:39:56,301 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 09:39:56,320 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 09:39:56,338 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 09:39:56,349 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 09:39:56,356 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 09:39:56,388 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 09:39:56,406 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 09:39:56,459 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 09:39:56,496 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 09:39:56,509 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 09:39:56,528 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 09:39:56,539 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 09:39:56,544 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 09:39:56,545 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 09:39:56,559 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 09:39:56,569 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:56,569 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:39:56,576 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 09:39:56,578 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 09:39:56,583 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 09:39:56,589 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 09:39:56,591 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 09:39:56,592 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:56,592 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:56,621 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:39:56,627 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:56,653 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 09:39:56,687 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 09:39:56,709 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:56,722 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:56,738 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093956.wav, taille: 70679 bytes
2025-06-20 09:39:56,743 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 09:39:56,760 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:56,770 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 09:39:56,789 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 09:39:56,792 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:56,800 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 09:39:56,852 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 09:39:56,870 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 09:39:56,875 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 09:39:56,902 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 09:39:56,907 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 09:39:56,989 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 09:39:57,069 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:57,107 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 09:39:57,127 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 09:39:57,135 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 09:39:57,152 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 09:39:57,160 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 09:39:57,162 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 09:39:57,167 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 09:39:57,171 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 09:39:57,176 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 09:39:57,188 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 09:39:57,191 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 09:39:57,195 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 09:39:57,203 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 09:39:57,206 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 09:39:57,216 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 09:39:57,225 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:57,226 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 09:39:57,226 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 09:39:57,233 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:57,235 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 09:39:57,238 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 09:39:57,243 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:57,250 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:39:57,261 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 09:39:57,272 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 09:39:57,276 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 09:39:57,279 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 09:39:57,282 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 09:39:57,290 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 09:39:57,291 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 09:39:57,303 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 09:39:57,309 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:57,312 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:57,322 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 09:39:57,325 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 09:39:57,337 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 09:39:57,338 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 09:39:57,387 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 09:39:57,424 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:57,435 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:57,445 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:57,457 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:57,460 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:57,462 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 09:39:57,465 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 09:39:57,470 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:57,475 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:57,479 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 09:39:57,488 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:57,489 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 09:39:57,493 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 09:39:57,495 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:57,496 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 09:39:57,504 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 09:39:57,505 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:57,506 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 09:39:57,507 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 09:39:57,508 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:57,509 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 09:39:57,511 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 09:39:57,512 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:57,512 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 09:39:57,513 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 09:39:57,526 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:39:57,527 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:57,542 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:57,542 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 09:39:57,544 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 09:39:57,544 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:57,555 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 09:39:57,556 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 09:39:57,558 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 09:39:57,559 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 09:39:57,561 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 09:39:57,563 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 09:39:57,570 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 09:39:57,571 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 09:39:57,571 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 09:39:57,572 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 09:39:57,573 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 09:39:57,574 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 09:39:57,575 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 09:39:57,575 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 09:39:57,577 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 09:39:57,578 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 09:39:57,580 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 09:39:57,581 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 09:39:57,583 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:39:57,584 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:57,585 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:39:57,589 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 09:39:57,590 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 09:39:57,591 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:39:57,592 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 09:39:57,601 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 09:39:57,603 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 09:39:57,605 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 09:39:57,606 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 09:39:57,607 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 09:39:57,610 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 09:39:57,615 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 09:39:57,617 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 09:39:57,625 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 09:39:57,625 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 09:39:57,625 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 09:39:57,629 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 09:39:57,634 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 09:39:57,635 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 09:39:57,637 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 09:39:57,638 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 09:39:57,639 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 09:39:57,640 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:39:57,640 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:39:57,642 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:39:57,645 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 09:39:57,659 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 09:39:57,662 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 09:39:57,671 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 09:39:57,683 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 09:39:57,686 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 09:39:57,689 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:39:57,692 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 09:39:57,694 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 09:39:57,702 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 09:39:57,703 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 09:39:57,709 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 09:39:57,709 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 09:39:57,717 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 09:39:57,719 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 09:39:57,724 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 09:39:57,729 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 09:39:57,733 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 09:39:57,752 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:39:57,793 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:39:57,809 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 09:39:58,952 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_093958.wav, taille: 33971 bytes
2025-06-20 09:40:04,224 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 09:40:04,319 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:40:04,334 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:40:04,342 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:40:04,388 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 09:40:04,399 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:40:04,405 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:40:04,441 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:40:04,450 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 09:40:04,459 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:40:04,470 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:40:04,476 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:40:04,494 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:40:04,506 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:40:04,510 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 09:40:04,512 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 09:40:04,527 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:40:04,539 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 09:40:04,541 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 09:40:04,549 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 09:40:04,563 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:40:04,570 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 09:40:04,577 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 09:40:04,584 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 09:40:04,588 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:40:04,592 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 09:40:04,595 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:40:04,604 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 09:40:04,616 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 09:40:04,629 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 09:40:04,639 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:40:04,645 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 09:40:04,655 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 09:40:04,664 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 09:40:04,676 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 09:40:04,686 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 09:40:04,695 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 09:40:04,700 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 09:40:04,710 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:40:04,715 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:40:04,725 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 09:40:04,733 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 09:40:04,738 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:40:04,744 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:40:04,746 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 09:40:04,751 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 09:40:04,754 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:40:04,762 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:40:04,775 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 09:40:04,792 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 09:40:04,809 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:40:04,819 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:40:04,824 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:40:04,824 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 09:40:04,826 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:40:04,833 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:40:04,837 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:40:04,839 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 09:40:04,860 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:40:04,868 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:40:04,873 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:40:04,874 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:40:04,875 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:40:04,876 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 09:40:04,877 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 09:40:04,881 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:40:04,886 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 09:40:04,887 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 09:40:04,890 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 09:40:04,891 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:40:04,892 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 09:40:04,894 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 09:40:04,901 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 09:40:04,904 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:40:04,907 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 09:40:04,909 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:40:04,911 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 09:40:04,912 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 09:40:04,920 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 09:40:04,922 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:40:04,923 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 09:40:04,926 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 09:40:04,928 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 09:40:04,932 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 09:40:04,937 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 09:40:04,939 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 09:40:04,940 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 09:40:04,943 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:40:04,944 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:40:04,947 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 09:40:04,953 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 09:40:04,955 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:40:04,956 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:40:04,958 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 09:40:04,959 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 09:40:04,959 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:40:04,961 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:40:04,972 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 09:40:08,359 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_093958.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:40:08,440 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_093952.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:40:08,484 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_093956.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:40:08,589 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_093952.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:40:08,603 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_093952.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:40:08,694 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_093952.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:40:08,694 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_093952.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:40:11,699 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:11,703 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:40:11,713 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:40:11,718 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:11,725 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:40:11,728 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:40:11,731 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:40:11,740 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:40:11,753 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:11,775 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:40:11,779 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:11,784 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:40:11,786 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:40:11,796 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:40:11,800 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:40:11,808 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:40:11,809 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:11,813 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:40:11,819 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:40:11,827 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:40:12,008 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:12,009 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:40:12,012 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:40:12,020 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:40:12,062 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:12,071 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:40:12,072 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:40:12,079 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:40:13,739 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:40:13,739 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=757 request_id=req_11a02b5b96424d3d57ca63f495962270 response_code=200
2025-06-20 09:40:13,782 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:40:13,801 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=794 request_id=req_97ea43523ce01fe5bc0d3e9c47c441d2 response_code=200
2025-06-20 09:40:13,885 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:40:13,910 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:40:13,912 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=897 request_id=req_1c1b8533267a1059a94e2c44bc817d81 response_code=200
2025-06-20 09:40:13,912 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=986 request_id=req_02fd13252e2a39abaaf791f1cc3300f0 response_code=200
2025-06-20 09:40:14,435 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:40:14,438 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1007 request_id=req_8264151666242566f0b157d80e8fe82a response_code=200
2025-06-20 09:40:14,529 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:40:14,539 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:40:14,543 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1143 request_id=req_ab43fc0d603274bb986de4115f7a5a13 response_code=200
2025-06-20 09:40:14,556 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1135 request_id=req_4bd0bee1ad4098836ede7f2c9a64209e response_code=200
2025-06-20 09:40:16,164 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:16,169 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:40:16,557 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:40:16,563 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:40:18,869 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 09:40:18,869 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2001 request_id=req_b18bb58a6decc0ac3ee4510eb097ebaa response_code=200
2025-06-20 09:40:18,980 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:40:18,980 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"...\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:40:19,904 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:40:19,904 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=736 request_id=req_a7a85fec3e446ddcaf2ea7fe27c4ff1c response_code=200
2025-06-20 09:40:20,073 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-20 09:40:20,140 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-20 09:40:20,142 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:40:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:40:23,944 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 09:40:38,520 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 09:40:38,533 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 09:41:08,389 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:41:08] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 09:41:08,464 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:41:08] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 09:41:08,468 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:41:08] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 09:41:08,878 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:41:08] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 09:43:23,665 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094323.wav, taille: 80339 bytes
2025-06-20 09:43:25,165 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 09:43:25,231 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:43:25,233 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,234 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:43:25,241 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 09:43:25,245 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,246 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 09:43:25,247 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,248 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 09:43:25,250 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:43:25,251 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 09:43:25,251 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:43:25,252 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 09:43:25,252 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:43:25,257 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 09:43:25,261 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,261 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 09:43:25,265 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 09:43:25,265 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 09:43:25,265 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 09:43:25,265 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 09:43:25,265 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 09:43:25,265 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 09:43:25,270 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 09:43:25,270 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 09:43:25,272 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 09:43:25,276 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 09:43:25,280 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 09:43:25,281 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 09:43:25,282 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 09:43:25,282 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 09:43:25,283 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 09:43:25,283 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 09:43:25,286 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 09:43:25,286 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 09:43:25,287 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 09:43:25,290 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 09:43:25,294 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 09:43:25,296 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,297 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:43:25,298 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 09:43:25,299 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 09:43:25,299 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 09:43:25,300 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 09:43:25,300 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 09:43:25,301 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,302 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,303 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:43:25,305 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,311 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 09:43:25,312 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 09:43:25,313 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,313 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,315 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 09:43:25,315 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,316 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 09:43:25,316 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 09:43:25,317 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,317 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 09:43:25,319 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 09:43:25,319 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 09:43:25,321 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 09:43:25,328 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 09:43:25,329 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 09:43:25,330 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 09:43:25,330 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,331 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 09:43:25,332 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 09:43:25,333 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 09:43:25,333 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 09:43:25,335 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 09:43:25,336 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 09:43:25,336 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 09:43:25,337 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 09:43:25,338 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 09:43:25,343 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 09:43:25,346 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 09:43:25,347 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 09:43:25,348 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 09:43:25,349 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 09:43:25,350 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 09:43:25,351 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,352 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 09:43:25,352 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 09:43:25,353 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,353 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 09:43:25,356 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 09:43:25,359 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,361 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:43:25,362 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 09:43:25,362 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 09:43:25,363 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 09:43:25,364 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 09:43:25,364 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 09:43:25,365 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 09:43:25,368 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 09:43:25,370 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 09:43:25,373 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,376 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:43:25,377 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 09:43:25,378 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 09:43:25,378 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 09:43:25,380 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 09:43:25,381 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 09:43:25,381 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,382 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,383 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:43:25,388 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:43:25,395 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,397 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 09:43:25,397 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 09:43:25,398 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,398 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,399 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 09:43:25,400 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,400 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 09:43:25,401 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 09:43:25,402 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,402 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 09:43:25,403 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 09:43:25,403 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,411 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 09:43:25,413 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 09:43:25,414 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,414 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 09:43:25,415 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 09:43:25,415 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,416 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 09:43:25,416 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 09:43:25,417 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:43:25,418 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:43:25,419 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,419 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 09:43:25,420 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 09:43:25,421 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,425 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 09:43:25,428 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 09:43:25,429 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 09:43:25,430 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 09:43:25,431 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 09:43:25,431 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 09:43:25,432 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 09:43:25,432 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 09:43:25,433 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 09:43:25,434 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 09:43:25,435 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 09:43:25,435 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 09:43:25,436 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 09:43:25,437 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 09:43:25,439 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 09:43:25,444 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 09:43:25,445 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 09:43:25,446 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 09:43:25,447 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:43:25,448 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:43:25,465 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:25,468 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 09:43:25,478 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 09:43:25,483 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:25,484 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 09:43:25,485 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 09:43:25,485 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 09:43:25,486 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 09:43:25,486 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 09:43:25,488 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 09:43:25,490 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 09:43:25,491 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 09:43:25,494 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 09:43:25,495 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 09:43:25,496 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 09:43:25,496 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 09:43:25,497 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 09:43:25,498 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 09:43:25,498 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 09:43:25,499 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 09:43:25,500 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 09:43:25,500 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 09:43:25,501 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:43:25,502 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:43:25,503 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:43:25,506 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 09:43:25,513 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 09:43:25,514 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 09:43:25,516 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 09:43:25,525 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 09:43:25,531 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 09:43:25,533 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:43:25,534 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 09:43:25,535 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 09:43:25,536 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 09:43:25,548 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 09:43:25,552 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 09:43:25,553 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 09:43:25,565 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 09:43:25,566 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 09:43:25,566 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 09:43:25,569 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 09:43:25,574 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 09:43:25,583 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:43:25,704 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:43:25,795 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 09:43:27,345 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 09:43:27,360 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:43:27,361 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:27,361 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:43:27,362 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 09:43:27,365 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:27,365 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:43:27,367 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:27,368 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 09:43:27,368 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:43:27,369 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:43:27,373 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:43:27,375 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:43:27,377 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:43:27,377 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 09:43:27,380 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 09:43:27,380 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:43:27,380 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 09:43:27,385 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 09:43:27,386 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 09:43:27,386 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:43:27,387 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 09:43:27,388 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 09:43:27,389 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 09:43:27,391 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:43:27,396 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 09:43:27,461 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:43:27,463 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 09:43:27,465 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 09:43:27,561 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 09:43:27,665 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:43:27,755 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 09:43:27,841 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 09:43:27,862 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 09:43:27,879 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 09:43:27,900 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 09:43:27,916 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 09:43:27,916 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 09:43:27,918 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:43:27,920 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:43:27,929 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 09:43:27,931 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 09:43:27,932 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:43:27,933 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:43:27,933 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 09:43:27,936 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 09:43:27,945 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:43:27,953 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:43:27,980 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 09:43:28,018 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 09:43:28,049 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:43:28,050 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:43:28,052 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:43:28,053 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 09:43:28,061 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:28,066 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:43:28,069 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:43:28,082 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 09:43:28,085 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:43:28,086 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:43:28,089 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:43:28,096 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:43:28,098 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:43:28,099 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 09:43:28,100 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 09:43:28,113 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:43:28,113 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 09:43:28,113 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 09:43:28,115 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 09:43:28,115 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:43:28,133 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 09:43:28,138 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 09:43:28,146 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 09:43:28,162 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:43:28,167 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 09:43:28,169 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:43:28,180 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 09:43:28,181 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 09:43:28,183 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 09:43:28,184 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:43:28,187 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 09:43:28,195 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 09:43:28,202 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 09:43:28,266 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 09:43:28,283 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 09:43:28,296 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 09:43:28,296 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 09:43:28,296 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:43:28,296 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:43:28,296 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 09:43:28,301 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 09:43:28,303 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:43:28,311 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:43:28,313 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 09:43:28,314 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 09:43:28,316 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:43:28,323 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:43:28,332 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 09:43:28,365 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094328.wav, taille: 80339 bytes
2025-06-20 09:43:30,180 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094323.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:43:30,216 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094328.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:43:33,550 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:33,556 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:43:33,558 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:43:33,564 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:43:33,665 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094333.wav, taille: 80339 bytes
2025-06-20 09:43:33,850 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:43:33,878 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0643\\u0631\\u0634\\u064a \\u0648\\u0638\\u0647\\u0631\\u064a \\u0647\\u0630\\u0647 \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"salam Kidal\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:43:33,889 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:43:33,900 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:43:34,159 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094333.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:43:35,240 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:43:35,240 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=956 request_id=req_12948ce8f28aba8ecc8866e19807a9dd response_code=200
2025-06-20 09:43:35,380 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:43:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:43:35,480 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:43:35,485 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=994 request_id=req_29bf00e9ee4e6b45567f8b56aba7ef8e response_code=200
2025-06-20 09:43:36,573 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:36,575 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:43:36,576 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:43:36,582 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:43:38,365 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:38,366 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:43:38,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094338.wav, taille: 80339 bytes
2025-06-20 09:43:38,660 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:43:38,671 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1197 request_id=req_f650a6d39b24f0d69c717943d0446977 response_code=200
2025-06-20 09:43:39,110 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094338.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:43:40,973 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:43:40,973 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2007 request_id=req_f564e5d0f3349ff8df42c7b824111b45 response_code=200
2025-06-20 09:43:41,088 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:43:41,090 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:43:41,530 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:41,530 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:43:42,297 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:42,297 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:43:42,299 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:43:42,306 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:43:42,741 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:43:42,741 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:43:42,741 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=859 request_id=req_079219d3ad829897588f6934529ed454 response_code=200
2025-06-20 09:43:42,741 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1301 request_id=req_dd367b46c5a05d5c21ed4e299d597b94 response_code=200
2025-06-20 09:43:42,854 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:43:42,856 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Merci d\'avoir regard\\u00e9 cette vid\\u00e9o !\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:43:42,881 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:43:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:43:43,587 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:43:43,596 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=528 request_id=req_0a889a80cc581ea6584b6c3cfb5469c4 response_code=200
2025-06-20 09:43:43,665 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094343.wav, taille: 80339 bytes
2025-06-20 09:43:43,798 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:43:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:43:44,210 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094343.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:43:44,573 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:43:44,573 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1380 request_id=req_cf7f561e0d6ef008b17c5ef719d57b2f response_code=200
2025-06-20 09:43:47,000 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:47,005 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:43:47,008 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:43:47,012 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:43:47,600 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:47,605 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:43:48,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094348.wav, taille: 80339 bytes
2025-06-20 09:43:49,063 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:43:49,066 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1161 request_id=req_f68a2d7f09888cb1681891e7baacd03f response_code=200
2025-06-20 09:43:49,076 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094348.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:43:49,608 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:43:49,610 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1458 request_id=req_e9f99fdf24612b4d7421b6af0439c25c response_code=200
2025-06-20 09:43:49,721 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:43:49,721 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Merci d\'avoir regard\\u00e9 cette vid\\u00e9o !\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:43:51,010 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:43:51,022 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=948 request_id=req_c408f2c5a192acd21a96955c39660a00 response_code=200
2025-06-20 09:43:51,179 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:43:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:43:51,651 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:51,656 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:43:51,838 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:51,839 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:43:51,840 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:43:51,845 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:43:53,055 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:43:53,056 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=807 request_id=req_47cc76eaa55d8c322f345df3845be879 response_code=200
2025-06-20 09:43:53,161 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:43:53,161 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Merci d\'avoir regard\\u00e9 cette vid\\u00e9o !\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:43:53,661 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094353.wav, taille: 80339 bytes
2025-06-20 09:43:54,078 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094353.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:43:54,115 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:43:54,282 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1066 request_id=req_a5a33476f44a667787430b3d91135a25 response_code=200
2025-06-20 09:43:54,293 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:43:54,299 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=595 request_id=req_27e19221564e1603d9a99535f10f5ba3 response_code=200
2025-06-20 09:43:54,438 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:43:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:43:57,064 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:57,064 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:43:57,064 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:43:57,073 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:43:57,076 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:43:57,080 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:43:58,370 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 09:43:58,370 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=583 request_id=req_7e57a47220ea598c82e6fb31b3631b99 response_code=200
2025-06-20 09:43:58,437 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:43:58,440 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=806 request_id=req_f7922f8687a22f43b597bedda39d52ac response_code=200
2025-06-20 09:43:58,488 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:43:58,491 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"...\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:43:58,661 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094358.wav, taille: 80339 bytes
2025-06-20 09:43:59,130 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094358.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:43:59,435 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:43:59,442 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=730 request_id=req_95bf1b358ef1b02bd5ed28b9c8049b97 response_code=200
2025-06-20 09:43:59,579 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:43:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:01,843 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:01,845 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:02,613 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:02,613 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:02,622 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:02,630 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:03,310 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:44:03,310 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=660 request_id=req_3257ae1e97668af36c5f139828576d06 response_code=200
2025-06-20 09:44:03,422 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:03,422 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:03,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094403.wav, taille: 80339 bytes
2025-06-20 09:44:03,922 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:03,960 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=629 request_id=req_9734f8e4bb47f73736a180a0ec2c1778 response_code=200
2025-06-20 09:44:04,329 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094403.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:04,911 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:04,911 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1307 request_id=req_b11bb740655812cb53138702d0c47355 response_code=200
2025-06-20 09:44:05,038 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:06,780 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:06,786 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:07,024 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:07,025 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:07,026 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:07,030 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:07,804 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:44:07,806 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=665 request_id=req_bce35aee72178a04a4c1a66dd7193f71 response_code=200
2025-06-20 09:44:07,921 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:07,922 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:08,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094408.wav, taille: 80339 bytes
2025-06-20 09:44:08,915 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:08,926 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=529 request_id=req_c8057cfd3da3dc781680625941ced33d response_code=200
2025-06-20 09:44:09,100 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:09,297 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094408.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:10,153 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:10,160 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2139 request_id=req_0279561e84fd4f7f7050f5b4ce2ecc03 response_code=200
2025-06-20 09:44:12,505 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:12,506 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:12,510 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:12,516 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:12,778 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:12,780 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:13,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094413.wav, taille: 80339 bytes
2025-06-20 09:44:14,050 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:44:14,054 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=648 request_id=req_c0f3e606e56d335681322ff9025b293e response_code=200
2025-06-20 09:44:14,110 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094413.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:14,172 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:14,173 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:14,215 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:14,220 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1151 request_id=req_5adce879b8c713faf2ce7158717a546e response_code=200
2025-06-20 09:44:15,171 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:15,186 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=745 request_id=req_63ae86565dee7636c6db47d12d7c30bf response_code=200
2025-06-20 09:44:15,323 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:16,610 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:16,611 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:16,612 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:16,613 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:16,827 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:16,828 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:18,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094418.wav, taille: 80339 bytes
2025-06-20 09:44:18,745 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:18,753 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1047 request_id=req_d94e771f90517a3dc877e18c79b5e224 response_code=200
2025-06-20 09:44:19,090 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094418.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:21,480 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:21,488 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:21,994 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:21,995 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:21,995 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:22,004 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:22,540 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:44:22,540 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=707 request_id=req_423aa23036280d33fde4e02271792dbd response_code=200
2025-06-20 09:44:22,652 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:22,652 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:23,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094423.wav, taille: 80339 bytes
2025-06-20 09:44:24,065 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094423.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:24,273 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:24,281 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1008 request_id=req_abb75663ce864f719a02558839832fe9 response_code=200
2025-06-20 09:44:24,447 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:25,092 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:25,094 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1631 request_id=req_e9958d27a995fd20c54183d3898f9e9e response_code=200
2025-06-20 09:44:27,452 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:27,452 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0645\\u0631\\u064a\\u0636\\u0647 \\u0648\\u0643\\u0646\\u062c\\u064a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0631\\u0641\\u064a\\u062a\\u0647\\u0645 \\u0628\\u0627\\u0634\\"\\n            Fran\\u00e7ais: \\"salam Redon\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:27,452 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:27,465 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:28,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094428.wav, taille: 80339 bytes
2025-06-20 09:44:28,897 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:28,903 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:28,908 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:28,909 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=723 request_id=req_d5ad9876d21350566a953258ac31338a response_code=200
2025-06-20 09:44:29,095 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:29,217 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094428.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:30,724 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:44:30,724 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1076 request_id=req_f4f81fb591b485b1d8c6bad51f57ba79 response_code=200
2025-06-20 09:44:30,833 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:30,833 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:31,942 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:31,950 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=793 request_id=req_40ffcbee4af126e998869ca081130e21 response_code=200
2025-06-20 09:44:32,101 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:33,660 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:33,660 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:33,665 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:33,670 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094433.wav, taille: 80339 bytes
2025-06-20 09:44:33,678 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:34,137 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094433.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:35,421 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:44:35,422 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=688 request_id=req_d588e26e663194071406a9a492249f36 response_code=200
2025-06-20 09:44:37,280 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:37,280 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:37,280 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:37,288 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:37,290 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u064a\\u0634\\u0648\\u0641 \\u0634\\u0646\\u0648 \\u0639\\u0646\\u062f\\u064a \\u0642\\u0631\\u0642\\u0629 \\u0639\\u0646\\u062f\\u064a \\u0627\\u0644\\u062d\\u0644\\u0642\\u0629 \\u0645\\u0646 \\u0641\\u0648\\u0642\\"\\n            Fran\\u00e7ais: \\"\\u00e9chauffement\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:37,295 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:38,275 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:38,280 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=543 request_id=req_7c0b378acc697a3f989b3a1a8ab77869 response_code=200
2025-06-20 09:44:38,375 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:38,383 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=891 request_id=req_ce5ab154afbd23a76002cf9ff27edfae response_code=200
2025-06-20 09:44:38,533 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:38,670 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094438.wav, taille: 80339 bytes
2025-06-20 09:44:39,110 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094438.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:41,679 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:41,680 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:42,288 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:42,289 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:42,290 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:42,299 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:42,419 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:44:42,421 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=557 request_id=req_afbac68d00593ba11b6706c246c0651c response_code=200
2025-06-20 09:44:42,532 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:42,533 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Merci d\'avoir regard\\u00e9 cette vid\\u00e9o !\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:43,270 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:43,288 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=413 request_id=req_fb18b85dde4340fa9a04b126e0d854f1 response_code=200
2025-06-20 09:44:43,430 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:43,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094443.wav, taille: 80339 bytes
2025-06-20 09:44:44,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094443.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:44,240 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:44,240 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=720 request_id=req_b6b644972dcd07f3a06fc00c098fa0a4 response_code=200
2025-06-20 09:44:46,825 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:46,825 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:48,015 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:48,015 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:48,022 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:48,026 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:48,660 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094448.wav, taille: 80339 bytes
2025-06-20 09:44:49,095 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094448.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:49,271 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:49,278 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=613 request_id=req_a4738d34282f480b328628a1e1fea9a2 response_code=200
2025-06-20 09:44:51,930 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_094451.wav, taille: 52325 bytes
2025-06-20 09:44:52,347 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_094451.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:44:52,885 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:52,914 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:52,987 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:53,012 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:53,028 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:53,038 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:54,482 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:44:54,488 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=759 request_id=req_f7b51722195bcfccf44f33653259fb02 response_code=200
2025-06-20 09:44:54,595 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:44:54,595 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Merci d\'avoir regard\\u00e9 cette vid\\u00e9o !\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:44:55,404 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 09:44:55,409 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=560 request_id=req_7b719b580eae91bd88cd6e478e073116 response_code=200
2025-06-20 09:44:55,902 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:44:55,945 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=776 request_id=req_724b862a105c221104a9109030914f3e response_code=200
2025-06-20 09:44:55,994 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:55,994 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:44:55,996 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:44:56,001 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:44:56,079 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:44:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:44:57,330 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:44:57,340 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=684 request_id=req_c44367789fbdfcb30d3c1e9b565fe31d response_code=200
2025-06-20 09:44:59,005 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:59,010 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:44:59,792 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:44:59,793 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:45:00,615 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 21
2025-06-20 09:45:00,620 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1256 request_id=req_c088a6bea83342082d9591ee16752a9b response_code=200
2025-06-20 09:45:00,728 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:45:00,730 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=735 request_id=req_cff5796fcc7f42c73cf95d92717df912 response_code=200
2025-06-20 09:45:00,731 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:45:00,737 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627\\"\\n            Fran\\u00e7ais: \\"a donc au\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:45:00,849 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:45:00,850 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:45:01,320 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:45:01,330 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=330 request_id=req_238212d755c1f445641cbed8f969f81d response_code=200
2025-06-20 09:45:01,476 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:45:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:45:01,855 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:45:01,901 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=792 request_id=req_ffcbfe89b205c20d9e084cacac2f91a1 response_code=200
2025-06-20 09:45:02,038 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:45:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:45:04,485 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:45:04,490 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=827 request_id=req_b4918bc43ea22b81b319df479ed1e5d8 response_code=200
2025-06-20 09:45:04,600 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:45:04,601 - openai - DEBUG - api_version=None data='{"model": "gpt-4-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription de consultation m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions:\\n            \\n            Darija: \\"\\u0627\\u0634\\u062a\\u0631\\u0643\\u0648\\u0627 \\u0641\\u064a \\u0627\\u0644\\u0642\\u0646\\u0627\\u0629\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            INSTRUCTIONS STRICTES:\\n            1.Supprime les mots ou expressions en fran\\u00e7ais qui ne sont pas li\\u00e9s au contexte ou non pertinents au contexte m\\u00e9dical.\\n            2.FUSIONNE les deux transcriptions en une seule phrase en fran\\u00e7ais, coh\\u00e9rente et fluide\\n            3.Si un m\\u00e9dicament est mal orthographi\\u00e9, corrige-le UNIQUEMENT si tu es certain de sa forme correcte\\n            4.N\'AJOUTE AUCUN m\\u00e9dicament, dosage ou traitement qui n\'est pas explicitement mentionn\\u00e9\\n            5.GARDE le m\\u00eame niveau de d\\u00e9tail que dans les transcriptions originales\\n            "}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 09:45:05,610 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:45:05,610 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=819 request_id=req_ec05d17bafca2af918d85cb2c4855769 response_code=200
2025-06-20 09:45:05,754 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:45:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:45:19,480 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-20 09:45:19,672 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-20 09:45:20,155 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\tempfile.py', reloading
2025-06-20 09:45:20,296 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\typing.py', reloading
2025-06-20 09:45:20,458 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\__init__.py', reloading
2025-06-20 09:45:20,535 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py', reloading
2025-06-20 09:45:20,707 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-20 09:45:20,917 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\__init__.py', reloading
2025-06-20 09:45:20,995 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_dtype_like.py', reloading
2025-06-20 09:45:21,053 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_generic_alias.py', reloading
2025-06-20 09:45:21,197 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_shape.py', reloading
2025-06-20 09:51:15,120 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.122:5000
2025-06-20 09:51:15,125 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-20 09:51:15,173 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 09:51:23,526 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 09:51:23,543 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 09:51:24,306 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:51:24] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 09:51:24,385 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:51:24] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 09:51:24,479 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:51:24] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 09:51:24,936 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:51:24] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 09:51:32,699 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095132.wav, taille: 80339 bytes
2025-06-20 09:51:33,749 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 09:51:33,774 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:51:33,775 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,776 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:51:33,776 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 09:51:33,777 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,777 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 09:51:33,778 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,778 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 09:51:33,778 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:51:33,778 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 09:51:33,778 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:51:33,778 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 09:51:33,786 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:51:33,789 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 09:51:33,789 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,790 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 09:51:33,790 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 09:51:33,791 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 09:51:33,791 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 09:51:33,791 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 09:51:33,792 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 09:51:33,793 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 09:51:33,793 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 09:51:33,795 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 09:51:33,795 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 09:51:33,796 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 09:51:33,796 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 09:51:33,797 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 09:51:33,797 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 09:51:33,800 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 09:51:33,805 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 09:51:33,805 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 09:51:33,805 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 09:51:33,807 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 09:51:33,807 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 09:51:33,808 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 09:51:33,808 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 09:51:33,809 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,809 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:51:33,810 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 09:51:33,810 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 09:51:33,811 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 09:51:33,811 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 09:51:33,812 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 09:51:33,813 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,815 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,816 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:51:33,822 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,822 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 09:51:33,823 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 09:51:33,824 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,824 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,825 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 09:51:33,826 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,827 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 09:51:33,827 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 09:51:33,828 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,828 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 09:51:33,829 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 09:51:33,829 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 09:51:33,830 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 09:51:33,830 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 09:51:33,830 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 09:51:33,835 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 09:51:33,839 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,840 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 09:51:33,840 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 09:51:33,841 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 09:51:33,842 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 09:51:33,842 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 09:51:33,843 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 09:51:33,843 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 09:51:33,844 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 09:51:33,844 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 09:51:33,845 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 09:51:33,845 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 09:51:33,847 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 09:51:33,847 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 09:51:33,848 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 09:51:33,855 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 09:51:33,856 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,857 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 09:51:33,858 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 09:51:33,858 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,859 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 09:51:33,859 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 09:51:33,860 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,860 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 09:51:33,861 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 09:51:33,861 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 09:51:33,861 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 09:51:33,861 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 09:51:33,864 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 09:51:33,864 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 09:51:33,867 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 09:51:33,867 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 09:51:33,873 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,874 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:51:33,874 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 09:51:33,875 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 09:51:33,876 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 09:51:33,878 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 09:51:33,878 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 09:51:33,878 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,878 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,878 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:51:33,878 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:51:33,878 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,878 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 09:51:33,888 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 09:51:33,889 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,889 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,890 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 09:51:33,890 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,891 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 09:51:33,892 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 09:51:33,892 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,893 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 09:51:33,893 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 09:51:33,894 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,895 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 09:51:33,896 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 09:51:33,897 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,900 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 09:51:33,900 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 09:51:33,900 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,905 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 09:51:33,905 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 09:51:33,905 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 09:51:33,905 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:51:33,905 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,905 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 09:51:33,910 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 09:51:33,913 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,918 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 09:51:33,947 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 09:51:33,955 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 09:51:33,956 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 09:51:33,957 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 09:51:33,957 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 09:51:33,958 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 09:51:33,958 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 09:51:33,959 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 09:51:33,960 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 09:51:33,961 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 09:51:33,962 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 09:51:33,974 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 09:51:33,975 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 09:51:33,975 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 09:51:33,976 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 09:51:33,977 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 09:51:33,977 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 09:51:33,978 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:51:33,980 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:51:33,981 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:33,981 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 09:51:33,989 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 09:51:33,989 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:33,989 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 09:51:33,990 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 09:51:33,990 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 09:51:33,991 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 09:51:33,991 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 09:51:33,992 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 09:51:33,992 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 09:51:33,993 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 09:51:33,994 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 09:51:33,995 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 09:51:33,995 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 09:51:33,995 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 09:51:33,996 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 09:51:33,997 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 09:51:33,997 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 09:51:34,000 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 09:51:34,000 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 09:51:34,005 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 09:51:34,007 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:51:34,007 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 09:51:34,008 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:51:34,009 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 09:51:34,012 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 09:51:34,013 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 09:51:34,023 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 09:51:34,025 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 09:51:34,026 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 09:51:34,027 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:51:34,028 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 09:51:34,031 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 09:51:34,035 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 09:51:34,035 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 09:51:34,035 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 09:51:34,040 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 09:51:34,040 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 09:51:34,040 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 09:51:34,045 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 09:51:34,050 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 09:51:34,055 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 09:51:34,055 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:51:34,055 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:51:34,077 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 09:51:35,190 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 09:51:35,211 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:51:35,212 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:35,212 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:51:35,213 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 09:51:35,219 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:35,223 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:51:35,223 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:35,224 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 09:51:35,225 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:51:35,226 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:51:35,226 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:51:35,227 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:51:35,228 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:51:35,228 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 09:51:35,228 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 09:51:35,228 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:51:35,235 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 09:51:35,238 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 09:51:35,240 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 09:51:35,241 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:51:35,242 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 09:51:35,243 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 09:51:35,245 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 09:51:35,246 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:51:35,247 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 09:51:35,247 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 09:51:35,248 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 09:51:35,252 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 09:51:35,253 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 09:51:35,256 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 09:51:35,258 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 09:51:35,258 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 09:51:35,259 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 09:51:35,260 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 09:51:35,260 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 09:51:35,260 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 09:51:35,260 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 09:51:35,260 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:51:35,260 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:51:35,260 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 09:51:35,264 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 09:51:35,264 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:51:35,268 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:51:35,272 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 09:51:35,272 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 09:51:35,273 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:51:35,275 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:51:35,280 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 09:51:35,292 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 09:51:35,296 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 09:51:35,296 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 09:51:35,296 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 09:51:35,297 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 09:51:35,301 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:35,302 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:51:35,306 - numba.core.byteflow - DEBUG - stack []
2025-06-20 09:51:35,306 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 09:51:35,307 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 09:51:35,308 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:51:35,309 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 09:51:35,310 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:51:35,310 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 09:51:35,310 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 09:51:35,311 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 09:51:35,311 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:51:35,312 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 09:51:35,312 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 09:51:35,312 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 09:51:35,314 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:51:35,315 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 09:51:35,318 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 09:51:35,322 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 09:51:35,323 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:51:35,323 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 09:51:35,324 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 09:51:35,324 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 09:51:35,325 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 09:51:35,325 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 09:51:35,326 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 09:51:35,326 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 09:51:35,328 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 09:51:35,328 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 09:51:35,329 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 09:51:35,329 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 09:51:35,330 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 09:51:35,330 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 09:51:35,334 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 09:51:35,336 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 09:51:35,340 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 09:51:35,341 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 09:51:35,342 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:51:35,342 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 09:51:35,343 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 09:51:35,343 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 09:51:35,343 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 09:51:35,345 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 09:51:35,347 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 09:51:36,485 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095132.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:51:38,005 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095138.wav, taille: 80339 bytes
2025-06-20 09:51:38,430 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095138.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:51:40,369 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:51:40,369 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a \\u0647\\u0630\\u0647 \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"alarme 14h d\\u00e9cimale\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 09:51:40,369 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:51:40,375 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:51:41,538 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:51:41,539 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:51:41,540 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:51:41,545 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:51:41,949 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:51:41,951 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=454 request_id=req_aed22cd89eec5c8ec890609fee3a3fae response_code=200
2025-06-20 09:51:42,013 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:51:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:51:42,990 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095142.wav, taille: 80339 bytes
2025-06-20 09:51:43,181 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:51:43,185 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=771 request_id=req_9a8dddcb050a84a249d5643e9dfeaa64 response_code=200
2025-06-20 09:51:43,469 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095142.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:51:45,906 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:51:45,906 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:51:46,075 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:51:46,084 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:51:46,087 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:51:46,095 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:51:46,655 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:51:46,655 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=348 request_id=req_3b1d32c526ddbf397118a876928edc67 response_code=200
2025-06-20 09:51:46,769 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 09:51:46,771 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:51:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:51:47,675 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:51:47,675 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=799 request_id=req_0a6c590a9c72fd960029d121f4b3e26f response_code=200
2025-06-20 09:51:48,009 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095148.wav, taille: 80339 bytes
2025-06-20 09:51:48,465 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095148.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:51:50,153 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:51:50,154 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:51:50,855 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:51:50,869 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:51:50,870 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:51:50,877 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:51:51,595 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:51:51,599 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1236 request_id=req_83ba0009ab92e5db5d797151239c74b5 response_code=200
2025-06-20 09:51:51,720 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 09:51:51,720 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:51:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:51:52,922 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:51:52,925 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1301 request_id=req_2e15d6f9b6aae75c99f873d6bedb1654 response_code=200
2025-06-20 09:51:53,010 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095153.wav, taille: 80339 bytes
2025-06-20 09:51:53,540 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095153.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:51:55,588 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:51:55,588 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:51:56,855 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:51:56,855 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=889 request_id=req_7224d4a2dade4d805bf383a0867958f1 response_code=200
2025-06-20 09:51:56,963 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 09:51:56,965 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:51:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:51:57,336 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:51:57,338 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:51:57,339 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:51:57,340 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:51:58,010 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095158.wav, taille: 80339 bytes
2025-06-20 09:51:58,442 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095158.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:51:59,598 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:51:59,598 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=756 request_id=req_3ac753bc95b9e2e42e7d5249a61f6d77 response_code=200
2025-06-20 09:52:02,574 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:02,575 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:52:02,613 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:02,620 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:52:02,625 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:52:02,629 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:52:03,005 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095203.wav, taille: 80339 bytes
2025-06-20 09:52:03,445 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095203.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:52:03,512 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:52:03,520 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=676 request_id=req_11857198fcd652506abf0aeb136330f8 response_code=200
2025-06-20 09:52:03,635 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 09:52:03,640 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:52:04,625 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:52:04,630 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=758 request_id=req_a4db9b3d8dde9f45eaa42676b97d9c1f response_code=200
2025-06-20 09:52:08,010 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095208.wav, taille: 80339 bytes
2025-06-20 09:52:08,460 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095208.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:52:08,489 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:08,491 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:52:08,505 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:08,515 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:52:08,546 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:52:08,590 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:52:09,165 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_095209.wav, taille: 18515 bytes
2025-06-20 09:52:09,448 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_095209.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 09:52:10,185 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:52:10,185 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1295 request_id=req_82d73f6edaf6daa28a2cd90061738b84 response_code=200
2025-06-20 09:52:10,297 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 09:52:10,298 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:52:10,605 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:52:10,605 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1373 request_id=req_bcbf0738b729d300102bd741d711cfdf response_code=200
2025-06-20 09:52:12,535 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:12,536 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:52:12,537 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:52:12,539 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:12,542 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 09:52:12,542 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:52:12,544 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 09:52:12,550 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 09:52:14,332 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 09:52:14,334 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=871 request_id=req_3bf2e20eb47058371862bfabfe7a881a response_code=200
2025-06-20 09:52:14,637 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:14,638 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:52:15,282 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:15] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 09:52:15,365 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:15] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 09:52:15,373 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:15] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 09:52:15,847 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:52:15,849 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=800 request_id=req_6972220dad4962972b73648a1bf14a08 response_code=200
2025-06-20 09:52:15,882 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:15] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 09:52:15,965 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 09:52:15,968 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:52:17,379 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:17,379 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:52:18,297 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 09:52:18,297 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=623 request_id=req_b81e8196d9a0124c5b6b3277e6a8bdc9 response_code=200
2025-06-20 09:52:18,413 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 09:52:18,415 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 09:52:33,551 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 09:52:33,554 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=20069 request_id=req_fc8ce3c8b338dd9c9abfd7a662343bee response_code=200
2025-06-20 09:52:36,360 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 09:52:36,365 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 09:52:49,395 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 15
2025-06-20 09:52:49,396 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=12762 request_id=req_616a7d7aaa3a637801e80f5725ab073d response_code=200
2025-06-20 09:52:49,511 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 09:52:49,511 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627\\"\\n            Fran\\u00e7ais: \\"Bon.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 09:52:49,901 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 09:52:49,902 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=165 request_id=req_11dd275981dd83e4c0d245fd2727cc86 response_code=200
2025-06-20 09:52:49,921 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 09:52:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:02:06,388 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:02:06] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:02:06,446 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:02:06] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:02:06,655 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:02:06] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 10:02:07,090 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:02:07] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:16:13,670 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:13] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:16:13,747 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:13] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:16:13,754 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:13] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:16:14,266 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:14] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:16:23,265 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_101623.wav, taille: 80339 bytes
2025-06-20 10:16:24,289 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_101623.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:16:27,445 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:16:27,445 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"salam Keita\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:16:27,460 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:16:27,469 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:16:28,569 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_101628.wav, taille: 80339 bytes
2025-06-20 10:16:28,915 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:16:28,919 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=535 request_id=req_c0af21daf042f6eea74b4f250119a43a response_code=200
2025-06-20 10:16:28,998 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:16:29,081 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_101628.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:16:32,054 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:32,054 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:16:32,059 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:16:32,062 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:16:33,271 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:16:33,271 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=549 request_id=req_05cf476bf938c71af34b6ee98da0a4e3 response_code=200
2025-06-20 10:16:33,572 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_101633.wav, taille: 80339 bytes
2025-06-20 10:16:34,043 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_101633.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:16:36,155 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:36,159 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:16:37,173 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:37,173 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:16:37,176 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:16:37,186 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:16:38,269 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:16:38,316 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1531 request_id=req_45dae9a3a66f272a210a2983fc343ac6 response_code=200
2025-06-20 10:16:38,431 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:16:38,431 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:16:38,572 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_101638.wav, taille: 80339 bytes
2025-06-20 10:16:39,031 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_101638.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:16:39,241 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:16:39,243 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=844 request_id=req_effb532583c2922c70e93edf3c3c5ea3 response_code=200
2025-06-20 10:16:42,468 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:42,470 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:16:42,471 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:16:42,474 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:16:42,520 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:42,525 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:16:43,269 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:16:43,269 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=431 request_id=req_914441b9bc0f2fe60e868dca28714c0a response_code=200
2025-06-20 10:16:43,377 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:16:43,381 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:16:43,569 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_101643.wav, taille: 80339 bytes
2025-06-20 10:16:44,039 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_101643.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:16:44,055 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:16:44,063 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=536 request_id=req_c85da0c72880ecaa3e8ad9afa72fe302 response_code=200
2025-06-20 10:16:47,023 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:47,023 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:16:47,023 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:16:47,038 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:16:47,056 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:47,057 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:16:48,000 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:16:48,000 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=686 request_id=req_acfb5a0dfa8244a64a808376c375c6b3 response_code=200
2025-06-20 10:16:48,116 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:16:48,116 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:16:48,579 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_101648.wav, taille: 80339 bytes
2025-06-20 10:16:49,374 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_101648.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:16:49,649 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:16:49,649 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1501 request_id=req_cffa4ca3124419c9fd2d780a8a89ad85 response_code=200
2025-06-20 10:16:50,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_101650.wav, taille: 30107 bytes
2025-06-20 10:16:50,762 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_101650.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:16:52,052 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:52,053 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:16:53,379 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:53,382 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:16:53,383 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:16:53,387 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:16:53,473 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:53,474 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:16:53,475 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:16:53,484 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:16:54,364 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 12
2025-06-20 10:16:54,375 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1632 request_id=req_27549fe0ab4bd5b4f1ee78329fc4ea6c response_code=200
2025-06-20 10:16:54,399 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:16:54,409 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=499 request_id=req_376e82af44e33a6ac034cd37e468f83d response_code=200
2025-06-20 10:16:54,487 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:16:54,490 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:16:55,083 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:16:55,085 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=881 request_id=req_c4dff0ddb903a81c0821f1b7876784e1 response_code=200
2025-06-20 10:16:57,439 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:57,439 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:16:58,403 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 32
2025-06-20 10:16:58,412 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=531 request_id=req_5019b49b94f72c4a8ee103e18c52906f response_code=200
2025-06-20 10:16:58,500 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:16:58,506 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:16:58,534 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:16:58,617 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:16:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:17:00,126 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:17:00,137 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=793 request_id=req_2871c2081c1f1bf5f9fa0e2271400640 response_code=200
2025-06-20 10:17:00,252 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:17:00,258 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:17:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:22:02,545 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\__init__.py', reloading
2025-06-20 10:22:05,159 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 10:22:14,702 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 10:22:14,710 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 10:23:21,079 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:23:21] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:23:21,159 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:23:21] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:23:21,242 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:23:21] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 10:23:21,698 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:23:21] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:26:46,267 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:26:46] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:26:46,347 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:26:46] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:26:46,349 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:26:46] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:26:46,739 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:26:46] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:26:54,652 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102654.wav, taille: 80339 bytes
2025-06-20 10:26:55,836 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 10:26:55,884 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 10:26:55,884 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:55,893 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 10:26:55,894 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 10:26:55,895 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:55,896 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 10:26:55,896 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:55,897 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 10:26:55,897 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 10:26:55,898 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 10:26:55,899 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 10:26:55,900 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 10:26:55,900 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 10:26:55,901 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 10:26:55,908 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:55,909 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 10:26:55,910 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 10:26:55,910 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 10:26:55,911 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 10:26:55,912 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 10:26:55,912 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 10:26:55,913 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 10:26:55,914 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 10:26:55,914 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 10:26:55,915 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 10:26:55,915 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 10:26:55,916 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 10:26:55,917 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 10:26:55,925 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 10:26:55,926 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 10:26:55,926 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 10:26:55,927 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 10:26:55,927 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 10:26:55,928 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 10:26:55,928 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 10:26:55,929 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 10:26:55,930 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 10:26:55,930 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:55,931 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 10:26:55,932 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 10:26:55,934 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 10:26:55,934 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 10:26:55,936 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 10:26:55,941 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 10:26:55,942 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:55,942 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:55,943 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 10:26:55,944 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:55,944 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 10:26:55,945 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 10:26:55,945 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:55,945 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:55,946 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 10:26:55,948 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:55,948 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 10:26:55,949 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 10:26:55,949 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:55,950 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 10:26:55,950 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 10:26:55,954 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 10:26:55,962 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 10:26:55,962 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 10:26:55,962 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 10:26:55,996 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 10:26:55,996 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 10:26:55,996 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 10:26:55,996 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 10:26:56,004 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 10:26:56,006 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 10:26:56,007 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 10:26:56,007 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 10:26:56,009 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 10:26:56,009 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:56,010 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 10:26:56,010 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 10:26:56,012 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:56,013 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 10:26:56,013 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 10:26:56,014 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:56,015 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 10:26:56,022 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 10:26:56,022 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 10:26:56,027 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 10:26:56,027 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 10:26:56,027 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 10:26:56,027 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 10:26:56,032 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 10:26:56,042 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 10:26:56,042 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:56,047 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:26:56,047 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 10:26:56,047 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 10:26:56,047 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 10:26:56,047 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 10:26:56,059 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 10:26:56,060 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:56,060 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:56,061 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:26:56,061 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:26:56,062 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:56,062 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 10:26:56,062 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 10:26:56,065 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:56,065 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:56,066 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 10:26:56,066 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:56,067 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 10:26:56,067 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 10:26:56,068 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:56,075 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 10:26:56,076 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 10:26:56,076 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:56,077 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 10:26:56,077 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 10:26:56,079 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:56,079 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 10:26:56,080 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 10:26:56,081 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:56,081 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 10:26:56,081 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 10:26:56,083 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 10:26:56,084 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:26:56,086 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:56,093 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 10:26:56,093 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 10:26:56,094 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:56,094 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 10:26:56,095 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 10:26:56,095 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 10:26:56,096 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 10:26:56,096 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 10:26:56,097 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 10:26:56,097 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 10:26:56,098 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 10:26:56,098 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 10:26:56,099 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 10:26:56,100 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 10:26:56,100 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 10:26:56,103 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 10:26:56,109 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 10:26:56,109 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 10:26:56,110 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 10:26:56,111 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 10:26:56,111 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 10:26:56,111 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 10:26:56,112 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:26:56,112 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:56,113 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 10:26:56,114 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 10:26:56,115 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:56,115 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 10:26:56,116 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 10:26:56,116 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 10:26:56,117 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 10:26:56,117 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 10:26:56,118 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 10:26:56,124 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 10:26:56,124 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 10:26:56,125 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 10:26:56,126 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 10:26:56,126 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 10:26:56,127 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 10:26:56,127 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 10:26:56,128 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 10:26:56,129 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 10:26:56,129 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 10:26:56,130 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 10:26:56,132 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 10:26:56,133 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 10:26:56,138 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:26:56,141 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 10:26:56,142 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 10:26:56,146 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 10:26:56,148 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 10:26:56,161 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 10:26:56,164 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 10:26:56,164 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 10:26:56,164 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 10:26:56,172 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 10:26:56,176 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 10:26:56,177 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 10:26:56,178 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 10:26:56,180 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 10:26:56,182 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 10:26:56,183 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 10:26:56,186 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 10:26:56,192 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 10:26:56,193 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 10:26:56,194 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 10:26:56,194 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 10:26:56,196 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 10:26:56,208 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 10:26:57,463 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 10:26:57,483 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 10:26:57,494 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:57,496 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 10:26:57,496 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 10:26:57,496 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:57,496 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 10:26:57,496 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:57,500 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 10:26:57,501 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 10:26:57,504 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 10:26:57,510 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 10:26:57,512 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 10:26:57,512 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 10:26:57,512 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 10:26:57,512 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 10:26:57,517 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 10:26:57,518 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 10:26:57,527 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 10:26:57,528 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 10:26:57,529 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 10:26:57,530 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 10:26:57,530 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 10:26:57,533 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 10:26:57,533 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 10:26:57,534 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 10:26:57,534 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 10:26:57,540 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 10:26:57,543 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 10:26:57,544 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 10:26:57,545 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 10:26:57,545 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 10:26:57,547 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 10:26:57,548 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 10:26:57,548 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 10:26:57,549 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 10:26:57,550 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 10:26:57,551 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 10:26:57,552 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 10:26:57,559 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 10:26:57,561 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 10:26:57,562 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 10:26:57,562 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 10:26:57,563 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 10:26:57,564 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 10:26:57,564 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 10:26:57,566 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 10:26:57,566 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 10:26:57,578 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 10:26:57,587 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 10:26:57,597 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 10:26:57,598 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:26:57,602 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 10:26:57,606 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 10:26:57,608 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:57,611 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 10:26:57,611 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:26:57,612 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 10:26:57,612 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 10:26:57,613 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 10:26:57,614 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 10:26:57,614 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 10:26:57,615 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 10:26:57,615 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 10:26:57,616 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 10:26:57,616 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 10:26:57,617 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 10:26:57,618 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 10:26:57,620 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 10:26:57,624 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 10:26:57,627 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 10:26:57,627 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 10:26:57,628 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 10:26:57,629 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 10:26:57,629 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 10:26:57,629 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 10:26:57,632 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 10:26:57,633 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 10:26:57,633 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 10:26:57,634 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 10:26:57,634 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 10:26:57,640 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 10:26:57,642 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 10:26:57,643 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 10:26:57,644 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 10:26:57,645 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 10:26:57,645 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 10:26:57,646 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 10:26:57,647 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 10:26:57,648 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 10:26:57,649 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 10:26:57,649 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 10:26:57,650 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 10:26:57,653 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 10:26:57,656 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 10:26:57,659 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 10:26:57,660 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 10:26:57,665 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 10:26:58,857 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102654.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:26:59,962 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102659.wav, taille: 80339 bytes
2025-06-20 10:27:00,400 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102659.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:02,260 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:27:02,261 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"salam qui est dormi Darius\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:27:02,263 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:02,263 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:02,872 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:02,874 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:02,875 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:02,880 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:02,948 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:27:02,954 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=250 request_id=req_d3d7a9e6f38db29827f533f5605d8313 response_code=200
2025-06-20 10:27:03,013 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:04,958 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102704.wav, taille: 80339 bytes
2025-06-20 10:27:05,321 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:05,322 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1521 request_id=req_2fdab3e15b3dd5a55ab25d008d70892e response_code=200
2025-06-20 10:27:05,392 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102704.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:08,563 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:08,563 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:08,565 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:08,572 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:08,982 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:08,986 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:09,986 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102709.wav, taille: 80339 bytes
2025-06-20 10:27:10,504 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:10,513 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1190 request_id=req_ec0f18599d6f35c73594881e4d997cdf response_code=200
2025-06-20 10:27:10,588 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102709.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:10,819 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:10,823 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1567 request_id=req_c20a177084e32a609509e843c72ab85d response_code=200
2025-06-20 10:27:10,936 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:10,938 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:12,943 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:12,946 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:13,026 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:13,026 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:13,026 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:13,026 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:14,402 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:14,413 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=917 request_id=req_07b9d9f3f2f9567da082183a81df87ae response_code=200
2025-06-20 10:27:14,516 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:14,518 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:14,653 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:14,656 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=752 request_id=req_711b7b06c72227b6cc580ca6bb745ae7 response_code=200
2025-06-20 10:27:15,289 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102715.wav, taille: 85169 bytes
2025-06-20 10:27:15,993 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102715.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:17,777 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:17,778 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:18,794 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:18,794 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:18,794 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:18,805 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:19,192 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:19,197 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=866 request_id=req_e8b993f93a18da5fd1b4a9ba05e05b23 response_code=200
2025-06-20 10:27:19,313 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:19,319 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:20,293 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102720.wav, taille: 80339 bytes
2025-06-20 10:27:20,645 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:20,647 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=811 request_id=req_be73ba3bac432b15ae1bc865bc3b573d response_code=200
2025-06-20 10:27:20,650 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102720.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:23,084 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:23,086 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:23,087 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:23,091 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:23,426 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:23,426 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:24,843 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:24,843 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=828 request_id=req_492d3883db63eb9f8e6e0ad34355715e response_code=200
2025-06-20 10:27:24,954 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:24,954 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:24,979 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102724.wav, taille: 74543 bytes
2025-06-20 10:27:25,456 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102724.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:25,585 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:25] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:27:25,690 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:25] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:27:25,722 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:25] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:27:26,110 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:26] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:27:26,422 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:26,424 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1748 request_id=req_db6a6c4315669e7b38536165ae4deb13 response_code=200
2025-06-20 10:27:28,843 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:28,844 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:28,845 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:28,849 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:28,877 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:28,877 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:29,955 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:29,958 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=748 request_id=req_c196e10bc948612315d0b6520851a3a4 response_code=200
2025-06-20 10:27:30,069 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:30,072 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:31,419 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:31,419 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1465 request_id=req_9e06ed3c252f8ab970548df120ea470d response_code=200
2025-06-20 10:27:32,967 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102732.wav, taille: 80339 bytes
2025-06-20 10:27:33,459 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102732.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:34,373 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:34,374 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:36,605 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:27:36,614 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:36,617 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0643\\u0631\\u0634\\u064a \\u0648\\u0638\\u0647\\u0631\\u064a \\u0647\\u0630\\u0647 \\u0633\\u064a\\u0645\\"\\n            Fran\\u00e7ais: \\"salam qui est dernier\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:27:36,640 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2011 request_id=req_95a22d5501fad4035077142baff4cfeb response_code=200
2025-06-20 10:27:36,687 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:36,703 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:36,798 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:36,803 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:37,379 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:27:37,402 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=269 request_id=req_8b60692ee06e692ab5bbc77aeed12402 response_code=200
2025-06-20 10:27:37,462 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:38,269 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102738.wav, taille: 80339 bytes
2025-06-20 10:27:38,727 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102738.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:40,963 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:40,970 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:40,977 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:40,988 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:42,134 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:42,134 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=589 request_id=req_043f7511dbd86c261f63ab85d005a53e response_code=200
2025-06-20 10:27:42,968 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102742.wav, taille: 80339 bytes
2025-06-20 10:27:43,740 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102742.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:44,679 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:44,679 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:45,879 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:45,881 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=842 request_id=req_9a018d80ee59497747de1de86a5ba979 response_code=200
2025-06-20 10:27:45,984 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:45,987 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:46,139 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:46,140 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:46,142 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:46,146 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:47,559 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:47,569 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=954 request_id=req_ac13810e4710e575af82d12b447c41fa response_code=200
2025-06-20 10:27:48,289 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102748.wav, taille: 80339 bytes
2025-06-20 10:27:48,868 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102748.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:50,139 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:50,140 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:51,589 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:51,589 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=822 request_id=req_2521dd4be1f869d0c4adbef02f5c8eb2 response_code=200
2025-06-20 10:27:51,699 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:51,699 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:27:52,428 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:52,443 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:52,458 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:52,471 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:53,279 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102753.wav, taille: 80339 bytes
2025-06-20 10:27:54,313 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102753.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:55,019 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:55,019 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1938 request_id=req_f0318abc2d4be3e03d264063a1e777d6 response_code=200
2025-06-20 10:27:57,587 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:57,624 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:27:57,629 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:27:57,664 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:27:57,824 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:27:57,829 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:27:58,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102758.wav, taille: 80339 bytes
2025-06-20 10:27:58,704 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102758.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:27:59,254 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:27:59,280 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=723 request_id=req_4fea832e24c9c6c452b08428db343ffe response_code=200
2025-06-20 10:27:59,459 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:27:59,464 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1320 request_id=req_425a988bede25710c716fd33103e5d65 response_code=200
2025-06-20 10:27:59,583 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:27:59,583 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:27:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:02,158 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:02,159 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:02,403 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:02,487 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:02,586 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:02,595 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:03,019 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:03,024 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=527 request_id=req_f4d4a41b76c14f29bf922e9614671ae7 response_code=200
2025-06-20 10:28:03,135 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:03,142 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:03,353 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102803.wav, taille: 80339 bytes
2025-06-20 10:28:03,846 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102803.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:05,117 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:05,119 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1017 request_id=req_197d53ac25313dc1b0be16879f9dc5d3 response_code=200
2025-06-20 10:28:06,510 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:06,510 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:06,510 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:06,518 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:07,654 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:07,655 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:08,050 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:08,050 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=414 request_id=req_366ac8e22a6ff6685b50db49fa15a1f6 response_code=200
2025-06-20 10:28:08,304 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102808.wav, taille: 80339 bytes
2025-06-20 10:28:08,594 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:08,595 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=654 request_id=req_311baeac6768240423c54cb24ce67e42 response_code=200
2025-06-20 10:28:08,689 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102808.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:08,702 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:08,704 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:10,759 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:10,762 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:10,874 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:10,875 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:10,876 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:10,880 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:12,132 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:12,132 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=569 request_id=req_1a2acb30943cc2f73db70ce4db4f274e response_code=200
2025-06-20 10:28:12,250 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:12,253 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:12,623 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:12,625 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=696 request_id=req_8804b5109eb4f80657b689008df7a091 response_code=200
2025-06-20 10:28:13,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102813.wav, taille: 80339 bytes
2025-06-20 10:28:13,693 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102813.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:15,544 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:15,560 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:16,719 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:16,719 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=649 request_id=req_7afde68ba0d391e979177ec6f1c69b3d response_code=200
2025-06-20 10:28:16,836 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:16,839 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:17,142 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:17,143 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:17,144 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:17,148 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:18,219 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:18,219 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=531 request_id=req_ff55084f74c0b225fc50791e0f41af99 response_code=200
2025-06-20 10:28:18,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102818.wav, taille: 80339 bytes
2025-06-20 10:28:18,689 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102818.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:21,572 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:21,573 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:22,131 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:22,132 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:22,133 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:22,136 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:22,484 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:22,488 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=505 request_id=req_0fd3e3b861064bb02602fa8432be947f response_code=200
2025-06-20 10:28:22,590 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:22,594 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:23,289 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102823.wav, taille: 80339 bytes
2025-06-20 10:28:23,683 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102823.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:23,864 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:23,869 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=830 request_id=req_3d2e452dc3e562c7c79cebc0e3da982c response_code=200
2025-06-20 10:28:26,250 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:26,251 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:27,149 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:27,149 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=558 request_id=req_b59dd58414a1b294736b5aed673dd826 response_code=200
2025-06-20 10:28:27,261 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:27,264 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:27,396 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:27,398 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:27,399 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:27,405 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:28,288 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102828.wav, taille: 80339 bytes
2025-06-20 10:28:28,647 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:28,650 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=787 request_id=req_6b3142500d25368dcdb110ba3aab9329 response_code=200
2025-06-20 10:28:28,674 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102828.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:31,271 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:31,271 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:32,319 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:32,324 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=778 request_id=req_cc8eb3e134344bd87f07d3a47a1ba7a6 response_code=200
2025-06-20 10:28:32,434 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:32,438 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:32,922 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:32,923 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:32,924 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:32,928 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:33,299 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102833.wav, taille: 80339 bytes
2025-06-20 10:28:33,799 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102833.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:34,330 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:34,330 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=610 request_id=req_7fcf0deae17c1996d80005d8d85c117b response_code=200
2025-06-20 10:28:37,559 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:37,559 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:37,566 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:37,573 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:38,001 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:38,002 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:38,287 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102838.wav, taille: 80339 bytes
2025-06-20 10:28:38,675 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102838.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:38,909 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 42
2025-06-20 10:28:38,909 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=672 request_id=req_6d9f8ea9eabd04e0767fcae29aa34e8b response_code=200
2025-06-20 10:28:39,024 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:39,026 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:42,829 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:42,829 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:42,834 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:42,840 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:43,313 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102843.wav, taille: 80339 bytes
2025-06-20 10:28:44,085 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102843.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:44,249 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:44,253 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=969 request_id=req_be63f0779a7569ac55b9b7f477a467a9 response_code=200
2025-06-20 10:28:47,649 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:47,651 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:47,652 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:47,652 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:47,653 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:47,659 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:48,298 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102848.wav, taille: 80339 bytes
2025-06-20 10:28:48,719 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102848.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:48,763 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:48,770 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=546 request_id=req_1d7ceb0bd78f37f46853ca29ef3e9507 response_code=200
2025-06-20 10:28:50,995 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 10:28:50,996 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1831 request_id=req_edff779ba3715b944f357d63ef52d337 response_code=200
2025-06-20 10:28:51,120 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:51,120 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:51,449 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:51,449 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:52,040 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:52,040 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:52,040 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:52,047 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:52,260 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:28:52,260 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=642 request_id=req_79186cdf3a013b746c14634d2ff11919 response_code=200
2025-06-20 10:28:52,374 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:52,380 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:53,289 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102853.wav, taille: 79373 bytes
2025-06-20 10:28:53,363 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:53,373 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=550 request_id=req_6e092ff2d1a4479122699738eeebf012 response_code=200
2025-06-20 10:28:53,723 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102853.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:28:56,139 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:56,140 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:28:57,254 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:28:57,254 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:28:57,259 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:28:57,264 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:28:57,972 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 10:28:57,973 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1529 request_id=req_fb420637d1d41d3ddcf18550c95a9bfc response_code=200
2025-06-20 10:28:58,079 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:28:58,080 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:28:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:28:58,288 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102858.wav, taille: 80339 bytes
2025-06-20 10:28:58,574 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:28:58,574 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=739 request_id=req_55d8360fe6b860fd607c9b847568f7f6 response_code=200
2025-06-20 10:28:58,665 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102858.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:01,165 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:01,166 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:02,303 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:02,303 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:02,303 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:02,303 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:03,284 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102903.wav, taille: 80339 bytes
2025-06-20 10:29:03,684 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102903.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:04,816 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:04,819 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=524 request_id=req_9f83207d8849f68ee61c688407b1c869 response_code=200
2025-06-20 10:29:07,447 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:07,451 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:07,500 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:07,524 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:07,534 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:07,543 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:08,280 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102908.wav, taille: 80339 bytes
2025-06-20 10:29:08,340 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:08,340 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=6956 request_id=req_ad63ef814ac7d9c8b891f46a6fe240a4 response_code=200
2025-06-20 10:29:08,462 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:08,463 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:08,701 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102908.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:09,668 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 10:29:09,669 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1873 request_id=req_52defdcbead617d64f94601ec5439386 response_code=200
2025-06-20 10:29:09,779 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:09,783 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:10,139 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:10,148 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1215 request_id=req_a379378dc6ad5262b0620a340e177912 response_code=200
2025-06-20 10:29:12,235 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:12,236 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:12,237 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:12,243 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:13,299 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102913.wav, taille: 80339 bytes
2025-06-20 10:29:13,696 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102913.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:13,924 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:13,924 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=962 request_id=req_3a2e9d30f9d03c6042028aae96854cd0 response_code=200
2025-06-20 10:29:13,952 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:13,953 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:16,090 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 40
2025-06-20 10:29:16,090 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1732 request_id=req_a21057dca35877fb30459921b80355bf response_code=200
2025-06-20 10:29:16,203 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:16,205 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:16,239 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:16,239 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:17,829 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:17,829 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:17,829 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:17,838 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:18,289 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102918.wav, taille: 80339 bytes
2025-06-20 10:29:18,669 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102918.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:18,879 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 10:29:18,879 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2328 request_id=req_69cd78613bdc2e7af4fb72c4d7fda0f6 response_code=200
2025-06-20 10:29:18,994 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:18,994 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:20,651 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:20,653 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2029 request_id=req_d37d19b656522f168a08358727e83789 response_code=200
2025-06-20 10:29:21,522 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:21,530 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:21,534 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:21,544 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:22,874 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:22,879 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=801 request_id=req_ba8384f5143eb065770ea636847e2801 response_code=200
2025-06-20 10:29:23,284 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102923.wav, taille: 80339 bytes
2025-06-20 10:29:23,317 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:23,321 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:23,779 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102923.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:24,745 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 35
2025-06-20 10:29:24,750 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1013 request_id=req_927f5aa8ac052ac38854b68f52e8c977 response_code=200
2025-06-20 10:29:24,861 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:24,867 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:25,453 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:25,454 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:26,325 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:26,327 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:26,327 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:26,334 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:27,124 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:27,124 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1392 request_id=req_451eccc0f5bc388334cf9ae2f5c2b152 response_code=200
2025-06-20 10:29:27,235 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:27,237 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:27,829 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:27,839 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=545 request_id=req_7a080b18b1adb0e6082f692f113e00e1 response_code=200
2025-06-20 10:29:28,300 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102928.wav, taille: 80339 bytes
2025-06-20 10:29:28,700 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102928.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:30,811 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:30,814 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:31,454 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:31,454 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:31,460 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:31,464 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:31,719 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:31,719 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=657 request_id=req_5bdb5e86a888d21df09b75416c2ede77 response_code=200
2025-06-20 10:29:31,828 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:31,829 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:32,969 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:32,969 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=797 request_id=req_c8a18a94f65dd52f67526e67ee806ed3 response_code=200
2025-06-20 10:29:33,289 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102933.wav, taille: 80339 bytes
2025-06-20 10:29:33,706 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102933.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:35,759 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:35,762 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:36,469 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:36,469 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:36,474 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:36,478 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:36,630 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:36,630 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=648 request_id=req_3d6bbe356c99a6c99b5f202bd8af709b response_code=200
2025-06-20 10:29:36,746 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:36,748 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:37,589 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:37,589 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=541 request_id=req_f4c7c9cf661dc25b1e0ccad10ca7c583 response_code=200
2025-06-20 10:29:38,299 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102938.wav, taille: 80339 bytes
2025-06-20 10:29:38,734 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102938.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:40,394 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:40,396 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:41,181 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:41,183 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=445 request_id=req_0acacd6443dfa4d6fe2dd3ec33f3c22b response_code=200
2025-06-20 10:29:41,299 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:41,299 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:42,078 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:42,080 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:42,081 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:42,086 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:43,286 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102943.wav, taille: 79373 bytes
2025-06-20 10:29:43,625 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:43,629 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=742 request_id=req_c7cf0c85cd7a88299f63b097bab53171 response_code=200
2025-06-20 10:29:43,646 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102943.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:46,390 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:46,396 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:47,309 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:47,309 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:47,309 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:47,319 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:48,284 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102948.wav, taille: 80339 bytes
2025-06-20 10:29:48,651 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102948.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:49,150 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:49,150 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2300 request_id=req_300b85e8506b44e0db59ae3074581408 response_code=200
2025-06-20 10:29:49,191 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:49,193 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1334 request_id=req_bed56d82b90523f61f16f116d391c675 response_code=200
2025-06-20 10:29:49,262 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:49,265 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:51,447 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:51,448 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:51,449 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:51,452 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:51,774 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:51,774 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:52,612 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:52,625 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=523 request_id=req_f5cf4ca2195e04c5ea81c754d9047af1 response_code=200
2025-06-20 10:29:52,794 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:52,805 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=673 request_id=req_8b55ceb131c38540719e5f8651123f22 response_code=200
2025-06-20 10:29:52,918 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:52,920 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:53,279 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102953.wav, taille: 80339 bytes
2025-06-20 10:29:53,644 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102953.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:55,612 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:55,613 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:29:56,379 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:29:56,379 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=446 request_id=req_ef01a21390b732224e1e946534e80ced response_code=200
2025-06-20 10:29:56,499 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:29:56,499 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:29:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:29:57,029 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:29:57,029 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:29:57,029 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:29:57,042 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:29:58,279 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_102958.wav, taille: 80339 bytes
2025-06-20 10:29:58,886 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_102958.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:29:59,529 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:29:59,529 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2096 request_id=req_607111f482a0a3e4d570160d1479d594 response_code=200
2025-06-20 10:30:01,963 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:01,964 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:02,979 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:30:02,979 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=783 request_id=req_6303fd9ad357a47db502f5d8af04c445 response_code=200
2025-06-20 10:30:03,093 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:03,093 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:03,134 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:03,134 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:03,137 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:03,141 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:03,310 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103003.wav, taille: 80339 bytes
2025-06-20 10:30:04,144 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103003.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:04,940 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:04,940 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=726 request_id=req_4ad4db091ff8ee102a60cee160b9ab6d response_code=200
2025-06-20 10:30:07,882 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:07,882 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:07,883 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:07,884 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:07,885 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:07,892 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:08,299 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103008.wav, taille: 80339 bytes
2025-06-20 10:30:08,685 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103008.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:09,010 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:09,014 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=563 request_id=req_0adf14c6cf808ec3bc9575e85fb82762 response_code=200
2025-06-20 10:30:09,409 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 31
2025-06-20 10:30:09,412 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1060 request_id=req_76b8d3f724b569eb6f3aea45cc92fd6d response_code=200
2025-06-20 10:30:09,529 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:09,529 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:11,449 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:11,449 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:11,449 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:11,456 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:11,545 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:11,546 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:13,280 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103013.wav, taille: 79373 bytes
2025-06-20 10:30:13,651 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103013.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:13,889 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:13,889 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1761 request_id=req_ca6dafd8efb318aa33d1da1f205c4bb0 response_code=200
2025-06-20 10:30:16,289 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:16,289 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:16,877 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:16,878 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:16,880 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:16,885 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:17,097 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:30:17,099 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=523 request_id=req_3602ad68f88a3a0caac2c9a1cdaa36a8 response_code=200
2025-06-20 10:30:17,219 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:17,219 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:17,573 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 10:30:17,575 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=5660 request_id=req_1ea5572f2ec2eba52d7ac222eaed6b87 response_code=200
2025-06-20 10:30:17,679 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:17,679 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:18,299 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103018.wav, taille: 80339 bytes
2025-06-20 10:30:18,409 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:18,409 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=499 request_id=req_e421a002b1f546023ea97cf28afd3fbe response_code=200
2025-06-20 10:30:18,709 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103018.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:22,029 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:22,029 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:23,292 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103023.wav, taille: 80339 bytes
2025-06-20 10:30:23,316 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:30:23,318 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=651 request_id=req_9f211ed204ae1a475b3aa64058d594ce response_code=200
2025-06-20 10:30:23,329 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:23,334 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:23,343 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:23,351 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:23,426 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:23,429 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:23,764 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103023.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:24,244 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:24,244 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=539 request_id=req_61b09cf3b8ec30f69bf59a58cd339024 response_code=200
2025-06-20 10:30:27,018 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:27,019 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:27,725 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:27,727 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:27,728 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:27,732 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:28,070 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:30:28,071 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=688 request_id=req_566e89825ea51ab13cd647244fc1c887 response_code=200
2025-06-20 10:30:28,181 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:28,181 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:28,299 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103028.wav, taille: 80339 bytes
2025-06-20 10:30:28,818 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103028.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:29,754 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:29,756 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1181 request_id=req_0897734a77538759e409512c6c5271a5 response_code=200
2025-06-20 10:30:31,532 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:31,533 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:31,535 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:31,539 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:32,539 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:32,539 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=557 request_id=req_6e7bf2a107c0a61ea8dfbcc1a4b8add9 response_code=200
2025-06-20 10:30:33,295 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103033.wav, taille: 80339 bytes
2025-06-20 10:30:33,684 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103033.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:34,051 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:34,053 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:35,779 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:30:35,779 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1039 request_id=req_52eb0575718b6692208a6b5d38805431 response_code=200
2025-06-20 10:30:35,885 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:35,888 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:36,070 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:36,070 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:36,782 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 10:30:36,788 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=536 request_id=req_1a43412b959fb6d5a219b551eed54582 response_code=200
2025-06-20 10:30:36,909 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:36,914 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:37,969 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:37,969 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:37,972 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:37,977 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:38,279 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103038.wav, taille: 80339 bytes
2025-06-20 10:30:38,664 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103038.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:39,504 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:39,507 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=528 request_id=req_3a67ae7df00dac8d6059c8f9569ac676 response_code=200
2025-06-20 10:30:42,297 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:42,300 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:42,770 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:42,770 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:42,770 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:42,770 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:43,035 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 10:30:43,037 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=478 request_id=req_04f5a7af08c66528b409154c9e5806a9 response_code=200
2025-06-20 10:30:43,140 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:43,142 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:43,301 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103043.wav, taille: 80339 bytes
2025-06-20 10:30:43,770 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103043.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:48,300 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103048.wav, taille: 80339 bytes
2025-06-20 10:30:48,526 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:48,529 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:48,529 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:48,536 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:48,862 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103048.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:50,950 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:50,950 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1453 request_id=req_a7314902d84c6d03833a6d77ab1d7b48 response_code=200
2025-06-20 10:30:51,429 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:51,430 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:51,431 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:51,432 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:52,930 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:52,930 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=797 request_id=req_f50a30e61d9d53078d195d7af8f523b6 response_code=200
2025-06-20 10:30:53,284 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103053.wav, taille: 80339 bytes
2025-06-20 10:30:53,799 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103053.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:54,026 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:54,028 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:54,969 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:30:54,969 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=608 request_id=req_4f8527b5008a61b4097c22274a00928f response_code=200
2025-06-20 10:30:55,082 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:55,082 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:30:57,002 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:57,064 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:30:57,064 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:30:57,114 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:30:57,121 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:30:57,122 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:30:57,878 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103057.wav, taille: 73577 bytes
2025-06-20 10:30:58,071 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:30:58,073 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=405 request_id=req_280c15ac539a729eb8004e7e52a6f3fb response_code=200
2025-06-20 10:30:58,329 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103057.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:30:58,418 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 31
2025-06-20 10:30:58,421 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=829 request_id=req_af8b396698d46414c8a84b6c9ff4068b response_code=200
2025-06-20 10:30:58,530 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:30:58,533 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:30:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:31:01,102 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:31:01,112 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:31:02,531 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:31:02,613 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1169 request_id=req_4d10fa97df4b435ad9d2f20bd4a932d2 response_code=200
2025-06-20 10:31:02,619 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:31:02,627 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:31:02,631 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:31:02,640 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:31:02,732 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:31:02,738 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:31:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:31:04,474 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:31:04,484 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=821 request_id=req_7245bbd24a43c46ba0eacdcacd2f2f78 response_code=200
2025-06-20 10:31:07,654 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:31:07,659 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:31:10,129 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 31
2025-06-20 10:31:10,129 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1096 request_id=req_6ff2cc7176604e32851561c0a6e601f2 response_code=200
2025-06-20 10:31:10,242 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:31:10,242 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:31:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:32:22,750 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:32:22] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:32:22,844 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:32:22] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:32:22,922 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:32:22] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 10:32:23,272 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:32:23] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:33:38,619 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:33:38,619 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=554 request_id=req_cbd514de6754b6ee6d5b0b7815a106f8 response_code=200
2025-06-20 10:33:41,250 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:33:41,253 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:33:41,256 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:33:41,260 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:33:44,228 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 10:33:44,244 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2028 request_id=req_748d1efbdde5e721bb6fc539e664c940 response_code=200
2025-06-20 10:33:44,364 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:33:44,366 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:33:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:35:25,741 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:35:25,741 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:35:25,743 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:35:25,749 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:35:25,750 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:35:25,751 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001B2F3C83220>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:35:25,753 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 10:35:25,754 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:35:25,756 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001B2F3C83A00>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:35:25,758 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 10:35:25,877 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:35:25,879 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:35:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:35:48,430 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:35:48] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:35:48,498 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:35:48] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:35:48,502 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:35:48] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:35:48,897 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:35:48] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:36:54,382 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:36:54] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:36:54,506 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:36:54] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:36:54,514 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:36:54] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:36:54,929 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:36:54] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:37:02,427 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103702.wav, taille: 80339 bytes
2025-06-20 10:37:02,860 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103702.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:37:06,413 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:37:06,413 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"salam qui termine Harry\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:37:06,413 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:37:06,413 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:37:07,353 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:37:07,359 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=264 request_id=req_a4b3f9e3ca701b4cbfda17fc24676fde response_code=200
2025-06-20 10:37:07,552 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:37:07,781 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103707.wav, taille: 80339 bytes
2025-06-20 10:37:08,258 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103707.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:37:10,783 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:37:10,791 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0643\\u0646\\u062a \\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628\\"\\n            Fran\\u00e7ais: \\"kendji\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:37:10,796 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:37:10,799 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:37:11,436 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:37:11,438 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=335 request_id=req_9b328c07b01f466cea5effe482123991 response_code=200
2025-06-20 10:37:11,461 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:37:12,733 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103712.wav, taille: 80339 bytes
2025-06-20 10:37:13,213 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103712.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:37:17,027 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:37:17,028 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:37:17,029 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:37:17,032 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:37:17,426 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103717.wav, taille: 80339 bytes
2025-06-20 10:37:18,113 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103717.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:37:18,893 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 40
2025-06-20 10:37:18,900 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=892 request_id=req_4a8869c4a075feb32ae73ea0a10ee16c response_code=200
2025-06-20 10:37:21,265 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:37:21,265 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:37:21,265 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:37:21,278 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:37:22,713 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:37:22,713 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=889 request_id=req_171d6148b191dc13042767bc8c28b345 response_code=200
2025-06-20 10:37:22,737 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103722.wav, taille: 80339 bytes
2025-06-20 10:37:23,213 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103722.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:37:24,223 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:37:24,223 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:37:25,093 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:37:25,093 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:37:25,544 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 26
2025-06-20 10:37:25,545 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1060 request_id=req_21c028739aaa57845213e19716033b9c response_code=200
2025-06-20 10:37:25,663 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:37:25,663 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0628\\u0648\\u0643\\u0627\\u0644\\u064a\\u0648 \\u0628\\u0631\\u062c\\u0627\\u0646\\u062f\\u0648\\"\\n            Fran\\u00e7ais: \\"... Je rendsus.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:37:25,903 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:37:25,903 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:37:25,912 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:37:25,917 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:37:26,073 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:37:26,083 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=702 request_id=req_6f9b992932b40ad2babc780223eab1cf response_code=200
2025-06-20 10:37:26,193 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:37:26,193 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:37:26,373 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:37:26,373 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=528 request_id=req_b09eaeb25eaf143dc2674f6b1a07731a response_code=200
2025-06-20 10:37:26,400 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:37:26,693 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:37:26,693 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=306 request_id=req_48eaf88d7bb34f0f50f4c41b4ef406aa response_code=200
2025-06-20 10:37:27,718 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103727.wav, taille: 80339 bytes
2025-06-20 10:37:28,211 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103727.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:37:28,920 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:37:28,920 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:37:30,246 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:37:30,247 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:37:30,248 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:37:30,253 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:37:31,000 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:37:31,001 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1328 request_id=req_fb5fb269488e938b1cc6ac31e800830e response_code=200
2025-06-20 10:37:31,108 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:37:31,112 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:37:31,803 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:37:31,823 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=504 request_id=req_b84b3ced646b604c497399efe1ce50da response_code=200
2025-06-20 10:37:33,358 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103733.wav, taille: 89999 bytes
2025-06-20 10:37:34,469 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103733.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:37:34,551 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:37:34,575 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:37:35,335 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessing.py', reloading
2025-06-20 10:37:35,363 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\noisereduce\\__init__.py', reloading
2025-06-20 10:37:35,518 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\noisereduce\\noisereduce.py', reloading
2025-06-20 10:37:35,543 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-20 10:37:35,562 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessor.py', reloading
2025-06-20 10:37:35,564 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-20 10:37:35,893 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:37:35,932 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=834 request_id=req_e6528ea1b1972cabe7237c644285af30 response_code=200
2025-06-20 10:37:36,204 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:37:36,353 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:37:39,170 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 10:37:56,783 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 10:37:56,797 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 10:37:57,063 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103757.wav, taille: 0 bytes
2025-06-20 10:37:57,080 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103757.wav, taille: 71645 bytes
2025-06-20 10:37:57,126 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103757.wav, taille: 80339 bytes
2025-06-20 10:37:57,136 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103757.wav, taille: 89999 bytes
2025-06-20 10:37:57,733 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103757.wav, taille: 70679 bytes
2025-06-20 10:37:58,823 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 10:37:58,870 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 10:37:58,879 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:58,881 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 10:37:58,882 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 10:37:58,883 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:58,886 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 10:37:58,894 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:58,894 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 10:37:58,895 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 10:37:58,896 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 10:37:58,898 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 10:37:58,899 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 10:37:58,901 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 10:37:58,902 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 10:37:58,902 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:58,903 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 10:37:58,903 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 10:37:58,911 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 10:37:58,912 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 10:37:58,913 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 10:37:58,914 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 10:37:58,915 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 10:37:58,915 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 10:37:58,915 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 10:37:58,915 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 10:37:58,920 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 10:37:58,924 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 10:37:58,924 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 10:37:58,924 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 10:37:58,924 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 10:37:58,924 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 10:37:58,924 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 10:37:58,933 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 10:37:58,933 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 10:37:58,933 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 10:37:58,933 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 10:37:58,940 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 10:37:58,943 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:58,945 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 10:37:58,946 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 10:37:58,950 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 10:37:58,951 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 10:37:58,952 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 10:37:58,953 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 10:37:58,953 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:58,959 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:58,963 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 10:37:58,963 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:58,963 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:58] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:37:58,968 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 10:37:58,971 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 10:37:58,991 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:58,997 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:59,000 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 10:37:59,010 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:59,018 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 10:37:59,021 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 10:37:59,066 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,098 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 10:37:59,108 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 10:37:59,120 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:59] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:37:59,120 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 10:37:59,133 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 10:37:59,135 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:59] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:37:59,160 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 10:37:59,162 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 10:37:59,163 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 10:37:59,165 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,173 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 10:37:59,181 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 10:37:59,183 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 10:37:59,184 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 10:37:59,185 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 10:37:59,186 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 10:37:59,186 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 10:37:59,191 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 10:37:59,192 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 10:37:59,193 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 10:37:59,195 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 10:37:59,196 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 10:37:59,197 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 10:37:59,198 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 10:37:59,199 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 10:37:59,217 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:59,230 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 10:37:59,231 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 10:37:59,232 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,233 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 10:37:59,234 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 10:37:59,235 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:59,236 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 10:37:59,245 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 10:37:59,247 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 10:37:59,251 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 10:37:59,254 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 10:37:59,256 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 10:37:59,257 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 10:37:59,258 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 10:37:59,259 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 10:37:59,260 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:59,261 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:37:59,262 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 10:37:59,263 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 10:37:59,264 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 10:37:59,267 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 10:37:59,270 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 10:37:59,271 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,277 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:59,281 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:37:59,282 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:37:59,287 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:59,292 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 10:37:59,294 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 10:37:59,296 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,296 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:59,297 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 10:37:59,299 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:59,303 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 10:37:59,306 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 10:37:59,310 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,312 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 10:37:59,313 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 10:37:59,315 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:59,327 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 10:37:59,329 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 10:37:59,330 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:59,330 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 10:37:59,331 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 10:37:59,334 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,335 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 10:37:59,336 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 10:37:59,337 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 10:37:59,340 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:37:59,343 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:59,344 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 10:37:59,345 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 10:37:59,353 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,354 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 10:37:59,355 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 10:37:59,361 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 10:37:59,362 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 10:37:59,363 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 10:37:59,365 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 10:37:59,365 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 10:37:59,367 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 10:37:59,371 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 10:37:59,377 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 10:37:59,379 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 10:37:59,380 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 10:37:59,381 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 10:37:59,382 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 10:37:59,383 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 10:37:59,383 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 10:37:59,385 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 10:37:59,386 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 10:37:59,387 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 10:37:59,388 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:37:59,390 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:37:59,394 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 10:37:59,395 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 10:37:59,397 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:37:59,397 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 10:37:59,399 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 10:37:59,400 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 10:37:59,401 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 10:37:59,402 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 10:37:59,403 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 10:37:59,404 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 10:37:59,414 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 10:37:59,415 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 10:37:59,416 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 10:37:59,417 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 10:37:59,420 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 10:37:59,423 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 10:37:59,430 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 10:37:59,432 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 10:37:59,433 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 10:37:59,434 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 10:37:59,436 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 10:37:59,437 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 10:37:59,440 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 10:37:59,446 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 10:37:59,447 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 10:37:59,457 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 10:37:59,462 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 10:37:59,467 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 10:37:59,479 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 10:37:59,481 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 10:37:59,484 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 10:37:59,486 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 10:37:59,491 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 10:37:59,497 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 10:37:59,498 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 10:37:59,500 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 10:37:59,502 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 10:37:59,506 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 10:37:59,511 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 10:37:59,513 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 10:37:59,514 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 10:37:59,530 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 10:37:59,533 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 10:37:59,548 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 10:37:59,580 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 10:37:59,904 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:37:59] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:38:01,475 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 10:38:01,512 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 10:38:01,528 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:38:01,555 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 10:38:01,577 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 10:38:01,579 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:38:01,596 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 10:38:01,614 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:38:01,617 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 10:38:01,631 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 10:38:01,633 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 10:38:01,633 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 10:38:01,633 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 10:38:01,633 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 10:38:01,644 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 10:38:01,646 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 10:38:01,647 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 10:38:01,650 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 10:38:01,650 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 10:38:01,650 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 10:38:01,652 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 10:38:01,652 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 10:38:01,660 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 10:38:01,660 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 10:38:01,663 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 10:38:01,664 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 10:38:01,665 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 10:38:01,666 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 10:38:01,667 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 10:38:01,668 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 10:38:01,670 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 10:38:01,670 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 10:38:01,677 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 10:38:01,678 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 10:38:01,679 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 10:38:01,680 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 10:38:01,681 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 10:38:01,685 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 10:38:01,685 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 10:38:01,686 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 10:38:01,687 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 10:38:01,698 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 10:38:01,699 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 10:38:01,700 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 10:38:01,701 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 10:38:01,702 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 10:38:01,703 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 10:38:01,704 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 10:38:01,714 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 10:38:01,720 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 10:38:01,730 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 10:38:01,731 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 10:38:01,731 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 10:38:01,732 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 10:38:01,733 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:38:01,734 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 10:38:01,739 - numba.core.byteflow - DEBUG - stack []
2025-06-20 10:38:01,742 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 10:38:01,746 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 10:38:01,747 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 10:38:01,747 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 10:38:01,748 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 10:38:01,749 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 10:38:01,749 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 10:38:01,750 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 10:38:01,751 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 10:38:01,751 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 10:38:01,753 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 10:38:01,753 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 10:38:01,754 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 10:38:01,757 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 10:38:01,761 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 10:38:01,761 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 10:38:01,762 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 10:38:01,763 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 10:38:01,763 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 10:38:01,764 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 10:38:01,765 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 10:38:01,765 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 10:38:01,768 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 10:38:01,769 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 10:38:01,770 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 10:38:01,781 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 10:38:01,783 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 10:38:01,784 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 10:38:01,785 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 10:38:01,789 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 10:38:01,794 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 10:38:01,795 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 10:38:01,796 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 10:38:01,798 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 10:38:01,798 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 10:38:01,800 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 10:38:01,801 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 10:38:01,801 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 10:38:01,803 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 10:38:01,805 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 10:38:01,813 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 10:38:03,513 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103757.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:03,546 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103757.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:03,573 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103757.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:03,629 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103757.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:03,729 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103757.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:06,725 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:06,726 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:06,726 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:06,730 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:06,803 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:06,803 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:06,810 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:06,818 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:07,004 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103806.wav, taille: 80339 bytes
2025-06-20 10:38:07,206 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:07,209 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:07,210 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:07,226 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:07,263 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:07,268 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:07,268 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:07,272 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:07,318 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:07,328 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:07,333 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:07,347 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:07,765 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103806.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:08,015 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:38:08,019 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=713 request_id=req_c68ca076646e2fe58c082fc331e680ee response_code=200
2025-06-20 10:38:08,518 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:38:08,522 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=513 request_id=req_ecfec7906f7d284dcb28f49795adacce response_code=200
2025-06-20 10:38:09,048 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:38:09,048 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=796 request_id=req_b56f27e1d844c929d0e7cdd8611bc9e5 response_code=200
2025-06-20 10:38:10,522 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:10,523 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:38:10,870 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:38:10,871 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a \\u062a\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"salam qui est termin\\u00e9\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:38:10,877 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:10,883 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:11,314 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:11,315 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:38:11,440 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:11,441 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:38:11,729 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:38:11,730 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:38:11,733 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=833 request_id=req_91c7b0ce0ba4b5bf1eaa46200fc7c02c response_code=200
2025-06-20 10:38:11,734 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=453 request_id=req_98ebb03a59b689dbcb89c9658c89b844 response_code=200
2025-06-20 10:38:11,783 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:38:11,839 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:38:11,843 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:38:12,309 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103812.wav, taille: 80339 bytes
2025-06-20 10:38:12,513 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:38:12,513 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=638 request_id=req_ad146cda1b8f59cb15e2fbd8dce72ca5 response_code=200
2025-06-20 10:38:12,585 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:38:12,587 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=665 request_id=req_d87e429780d7de9cad2f381e0a9e4e2c response_code=200
2025-06-20 10:38:12,629 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:38:12,631 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:38:12,691 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:38:12,691 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:38:12,729 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103812.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:16,188 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:16,191 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:16,194 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:16,200 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:17,003 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103816.wav, taille: 80339 bytes
2025-06-20 10:38:17,408 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103816.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:20,928 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:20,933 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:20,935 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:20,941 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:23,278 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103823.wav, taille: 95795 bytes
2025-06-20 10:38:23,673 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103823.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:23,878 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:38:23,883 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2372 request_id=req_2776982c51ec1898368d87e0935e7f0c response_code=200
2025-06-20 10:38:26,012 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:26,013 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:38:26,567 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:26,572 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:26,575 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:26,595 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:27,238 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 10:38:27,238 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=896 request_id=req_28add260097be8801bd924d23d590ba5 response_code=200
2025-06-20 10:38:27,353 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:38:27,358 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:38:28,183 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103828.wav, taille: 78407 bytes
2025-06-20 10:38:28,578 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:38:28,578 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1293 request_id=req_65ef079871f9f15e035d0bc0f3821bc2 response_code=200
2025-06-20 10:38:28,798 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103828.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:32,171 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:32,172 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:38:32,215 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:32,216 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:38:32,217 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:38:32,222 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:38:32,899 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:38:32,903 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=483 request_id=req_ad1374bc7ec241956d28bc82699f4ad5 response_code=200
2025-06-20 10:38:33,028 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:38:33,033 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:38:33,298 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103833.wav, taille: 82271 bytes
2025-06-20 10:38:33,438 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:38:33,453 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=603 request_id=req_440a2a124cc475dc0398164b2ff59ca8 response_code=200
2025-06-20 10:38:33,783 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103833.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:35,408 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:38:35,413 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:38:38,323 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103838.wav, taille: 80339 bytes
2025-06-20 10:38:39,020 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103838.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:42,298 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103842.wav, taille: 63917 bytes
2025-06-20 10:38:42,728 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:38:42,743 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=35297 request_id=req_b2a4f23758c270d6b5e82d9e969394da response_code=200
2025-06-20 10:38:43,228 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:38:43,248 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=332 request_id=req_1c9f1f6a71dec189cc3bf83af1dfd116 response_code=200
2025-06-20 10:38:43,642 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:38:43,734 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:38:43,849 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:43] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:38:44,398 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103842.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:44,478 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:44] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:38:44,567 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:44] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:38:45,062 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:38:45] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:38:51,011 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103851.wav, taille: 80339 bytes
2025-06-20 10:38:51,441 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103851.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:38:57,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103857.wav, taille: 95795 bytes
2025-06-20 10:38:57,876 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103857.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:39:01,071 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:01,071 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:01,071 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:01,076 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:02,300 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103902.wav, taille: 80339 bytes
2025-06-20 10:39:02,597 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:02,601 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:02,605 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:02,609 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:02,609 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:02,612 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:02,616 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:02,626 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:02,852 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103902.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:39:03,082 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:03,090 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=517 request_id=req_937f7a90f34a195cb1ebc632bfba7f3e response_code=200
2025-06-20 10:39:03,637 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:03,641 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:03,644 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:03,656 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:03,726 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:03,783 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=507 request_id=req_09c1d8abc15882346ff1a01dd7b6daa1 response_code=200
2025-06-20 10:39:03,862 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:03,926 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=707 request_id=req_39903224227cb6b5d11c7280f9898c24 response_code=200
2025-06-20 10:39:05,692 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:05,694 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1020 request_id=req_1d8f8fa6df79cbe8296a554f781ebbaf response_code=200
2025-06-20 10:39:05,903 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:05,904 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:06,042 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:06,042 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:06,261 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:06,261 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:06,262 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:06,267 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:06,404 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:06,405 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:06,550 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:06,550 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:06,961 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:39:06,971 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:39:06,971 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=463 request_id=req_003c91618351d7c255fe7cd688bd3e05 response_code=200
2025-06-20 10:39:06,971 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=546 request_id=req_d63bf7160417efeeb07105591cbcf101 response_code=200
2025-06-20 10:39:07,085 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:07,085 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:07,086 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:07,086 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:07,280 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103907.wav, taille: 80339 bytes
2025-06-20 10:39:07,468 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:07,505 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=415 request_id=req_d70c7b8fd75713857622e3f9f1a4a584 response_code=200
2025-06-20 10:39:07,605 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 37
2025-06-20 10:39:07,646 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=788 request_id=req_2142fc23abe5f983532de7b0b7e5fade response_code=200
2025-06-20 10:39:07,791 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:07,805 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:08,076 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:39:08,080 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1400 request_id=req_c8896007b3a46668fe3c20093e459d6d response_code=200
2025-06-20 10:39:08,122 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:08,125 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:08,146 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103907.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:39:08,196 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:08,206 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:10,063 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:10,065 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:10,774 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:10,775 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:10,776 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:10,781 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:11,035 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:39:11,041 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=711 request_id=req_f6bcdc0418336e1bc933055b5f9cd043 response_code=200
2025-06-20 10:39:11,152 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:11,156 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:11,331 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103911.wav, taille: 64883 bytes
2025-06-20 10:39:11,672 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:39:11,676 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0644 \\u0634\\u064a\\u0621\\"\\n            Fran\\u00e7ais: \\"alarme 14h\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:39:11,681 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:11,707 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:11,991 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103911.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:39:12,317 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:39:12,326 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=246 request_id=req_1f1b812b9cb94949ef096963f95a5755 response_code=200
2025-06-20 10:39:12,414 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:12,488 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:12,493 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=977 request_id=req_0fb835a4211b9b0dfaaa9346e342e04c response_code=200
2025-06-20 10:39:15,330 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:15,330 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:16,078 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:16,111 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:16,127 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:16,178 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:16,340 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103916.wav, taille: 80339 bytes
2025-06-20 10:39:16,912 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103916.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:39:17,068 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:39:17,089 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1052 request_id=req_78ba66eba1a2222511ac26fa3663bb38 response_code=200
2025-06-20 10:39:17,205 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:17,205 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:18,495 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:18,500 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=763 request_id=req_d7720637b9912828f21336b604f54ea4 response_code=200
2025-06-20 10:39:19,686 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:19,690 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:19,690 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:19,695 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:21,050 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:39:21,050 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=12618 request_id=req_08acfce4ca2cf670e500baad4c8c748c response_code=200
2025-06-20 10:39:21,071 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:21,071 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:21,162 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:21,165 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:22,131 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:22,131 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=619 request_id=req_5b6817ba6831919b7f270dba43c8e883 response_code=200
2025-06-20 10:39:22,185 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:39:22,190 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=546 request_id=req_845c9dbb62e579940490fbc1e0283f2f response_code=200
2025-06-20 10:39:22,296 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103922.wav, taille: 95795 bytes
2025-06-20 10:39:22,307 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:22,310 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:22,889 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103922.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:39:25,156 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_103925.wav, taille: 45563 bytes
2025-06-20 10:39:25,615 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_103925.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:39:25,776 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:25,781 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:27,215 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 10:39:27,217 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1115 request_id=req_c74d98ef7e6170fd44f399f7baf4d085 response_code=200
2025-06-20 10:39:27,324 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:27,326 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:28,609 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:28,610 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:28,612 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:28,616 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:28,765 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:28,766 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:39:28,768 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:39:28,773 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:39:29,871 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:29,871 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=432 request_id=req_31221bef1461628356d154db67b1eca5 response_code=200
2025-06-20 10:39:30,982 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:39:30,982 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1676 request_id=req_1e4fa71446aaa1cd541a5dbe62c707d9 response_code=200
2025-06-20 10:39:32,369 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:32,371 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:33,680 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:39:33,680 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:39:34,661 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:39:34,661 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=490 request_id=req_0ad6f0a2fbcbd8274ee05c30365e8b6d response_code=200
2025-06-20 10:39:34,766 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:34,768 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:39:45,220 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 10:39:45,224 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=12538 request_id=req_15e17fa498119ba7e38d084a298dc552 response_code=200
2025-06-20 10:39:45,336 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:39:45,340 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:39:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:41:45,755 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:41:45] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:41:45,921 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:41:45] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:41:46,004 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:41:46] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 10:41:46,330 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:41:46] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:41:52,944 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104152.wav, taille: 80339 bytes
2025-06-20 10:41:53,641 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104152.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:41:57,613 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:41:57,614 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"salam Catalina\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:41:57,614 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:41:57,621 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:41:58,247 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104158.wav, taille: 80339 bytes
2025-06-20 10:41:58,718 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:41:58,732 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=404 request_id=req_734e0cc3c4fd189b33535298e15a48a6 response_code=200
2025-06-20 10:41:58,787 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:41:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:41:58,826 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104158.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:42:02,883 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:02,883 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:42:02,890 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:42:02,896 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:42:03,234 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104203.wav, taille: 80339 bytes
2025-06-20 10:42:03,680 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104203.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:42:04,515 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:42:04,519 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=838 request_id=req_734207ee6e87f6d227da2f33ca2e3ad7 response_code=200
2025-06-20 10:42:07,735 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:07,735 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:07,736 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:42:07,736 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:42:07,738 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:42:07,750 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:42:08,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104208.wav, taille: 81305 bytes
2025-06-20 10:42:08,696 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104208.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:42:08,970 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:42:08,975 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=588 request_id=req_4d137acec390bfec523a31eba304b667 response_code=200
2025-06-20 10:42:09,096 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:42:09,100 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:42:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:42:09,621 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:42:09,624 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=717 request_id=req_9ce517e29fcdb5dc45ea7a8c59dcaaac response_code=200
2025-06-20 10:42:11,555 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:11,555 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:42:11,562 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:42:11,569 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:42:12,655 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:12,672 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:42:12,746 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:42:12,750 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=650 request_id=req_8bb6f63d3a45e3f099db416d75df20f3 response_code=200
2025-06-20 10:42:13,250 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104213.wav, taille: 79373 bytes
2025-06-20 10:42:13,670 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 10:42:13,671 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=609 request_id=req_42d0ddfcc8d565c3d2fa318b6e88f846 response_code=200
2025-06-20 10:42:13,675 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104213.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:42:13,781 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:42:13,784 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:42:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:42:14,710 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104214.wav, taille: 23345 bytes
2025-06-20 10:42:14,785 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:14,786 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:42:15,079 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104214.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:42:16,089 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:16,090 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:42:16,093 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:42:16,146 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:42:17,942 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:17,945 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:42:17,948 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:42:17,957 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:42:18,450 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:42:18,450 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=614 request_id=req_7eb18ca4466a9b42c3fe8757ff8cd512 response_code=200
2025-06-20 10:42:19,170 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:42:19,170 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=464 request_id=req_de0c1757b71f41a2a61a1a6a49267571 response_code=200
2025-06-20 10:42:21,032 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:21,033 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:42:21,432 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:42:21,433 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:42:22,162 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:42:22,162 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=487 request_id=req_abcd1cc465c564b212aef0a47baca9a6 response_code=200
2025-06-20 10:42:22,278 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:42:22,282 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:42:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:42:22,720 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 15
2025-06-20 10:42:22,720 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1145 request_id=req_3085f40450080bdfb0420f732c633db5 response_code=200
2025-06-20 10:42:22,839 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:42:22,841 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:42:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:43:09,320 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:43:09,324 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=848 request_id=req_a7c0c1637fed0b4b9e65f5c5d4a4d55b response_code=200
2025-06-20 10:43:12,505 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:43:12,506 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:43:12,515 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:43:12,519 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:43:15,770 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:43:15,770 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2442 request_id=req_4b8af0009466ba4a7fe93fdeb672a217 response_code=200
2025-06-20 10:43:15,885 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:43:15,891 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:43:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:43:18,730 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:43:18,730 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=353 request_id=req_bdb5492d0b1fda6194e75a1ec92ac288 response_code=200
2025-06-20 10:43:21,379 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:43:21,379 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:43:21,383 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:43:21,386 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:43:23,550 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:43:23,550 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=645 request_id=req_8f8bdf03235b6e2b63b0fc5db177e15b response_code=200
2025-06-20 10:43:23,657 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:43:23,660 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:43:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:44:48,679 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:44:48] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:44:48,761 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:44:48] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:44:48,839 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:44:48] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 10:44:49,172 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:44:49] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:45:28,711 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104528.wav, taille: 80339 bytes
2025-06-20 10:45:29,226 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104528.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:45:34,027 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104534.wav, taille: 80339 bytes
2025-06-20 10:45:34,196 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:45:34,196 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u062a\\u0638\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a\\"\\n            Fran\\u00e7ais: \\"salaire\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:45:34,208 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:45:34,213 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:45:34,552 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104534.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:45:34,796 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:45:34,798 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=211 request_id=req_171df595bc835e367c302924383998c9 response_code=200
2025-06-20 10:45:34,824 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:45:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:45:37,761 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:45:37,761 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:45:37,761 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:45:37,779 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:45:38,091 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104538.wav, taille: 64883 bytes
2025-06-20 10:45:38,522 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104538.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:45:38,784 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:45:38,784 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=588 request_id=req_45586ca6cb4cd483ba2efc9bfc2b26f0 response_code=200
2025-06-20 10:45:38,837 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:45:38] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:45:38,934 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:45:38] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:45:38,945 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:45:38] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:45:39,349 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:45:39] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:45:43,163 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:45:43,165 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:45:43,166 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:45:43,168 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:45:43,198 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:45:43,199 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:45:44,556 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 42
2025-06-20 10:45:44,556 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1097 request_id=req_12482bfdcb19ada58ecd8794d981f7f2 response_code=200
2025-06-20 10:45:44,667 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:45:44,667 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:45:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:45:45,962 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 40
2025-06-20 10:45:45,962 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1987 request_id=req_34b14f29c9b7263a51e3f52f549a500b response_code=200
2025-06-20 10:45:50,088 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:45:50,088 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:45:51,168 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 46
2025-06-20 10:45:51,170 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=806 request_id=req_1ce3cf1af1db00d6b85449c7e9cad9eb response_code=200
2025-06-20 10:45:51,282 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:45:51,283 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0643\\u0644 \\u0638\\u0647\\u0631 \\u0645\\u0637\\u0644 d\\u00e9c\\u0644\\u00e9es\\"\\n            Fran\\u00e7ais: \\"Peut-\\u00eatre ? Moi, pas certain, non.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:45:51,912 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:45:51,912 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=338 request_id=req_2cfc36edc6888847beff4c7048cdb522 response_code=200
2025-06-20 10:45:51,951 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:45:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:47:17,306 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:47:17,474 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=541 request_id=req_26b59e44dd06351f1a0358c915e35a54 response_code=200
2025-06-20 10:47:17,594 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:47:17,597 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:47:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:49:08,601 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104908.wav, taille: 80339 bytes
2025-06-20 10:49:09,030 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104908.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:11,553 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:49:11,553 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\u064a \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"salam Catalina\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:49:11,557 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:49:11,565 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:49:12,725 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:49:12,725 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=644 request_id=req_686bbd570bbeaf4462f8ed4165a47d4e response_code=200
2025-06-20 10:49:12,755 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:49:13,283 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104913.wav, taille: 80339 bytes
2025-06-20 10:49:13,698 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104913.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:17,749 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:17,749 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:49:17,751 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:49:17,755 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:49:18,598 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104918.wav, taille: 80339 bytes
2025-06-20 10:49:19,068 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104918.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:19,112 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:49:19,118 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=785 request_id=req_e4eafcd8081872479a140e23f8897225 response_code=200
2025-06-20 10:49:21,828 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:21,828 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:49:21,832 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:49:21,832 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:49:22,018 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:49:22,018 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0643\\u0646\\u062a \\u062c\\u0627\\u064a\\u0633\\u0629 \\u0639\\u0646 \\u0637\\u0628\\u064a\\u0628\\u060c \\u0623\\u0639\\u0637\\u0627\\u0646\\u064a \\u062f\\u064a\\u0645\\u064a\\u062f\\u064a\\u0643\\u0627\\u0647\\u0645\\u0648\\u0646\\u060c \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639\\u064a\\u0646 \\u062f\\u0648\\u0631\\u064a\\"\\n            Fran\\u00e7ais: \\"des m\\u00e9dicaments pour gu\\u00e9rir\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:49:23,059 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:49:23,062 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=333 request_id=req_1e6de164f7b0301b797e6f3d9ac13ad8 response_code=200
2025-06-20 10:49:23,097 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:49:23,593 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104923.wav, taille: 80339 bytes
2025-06-20 10:49:24,082 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104923.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:24,306 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:49:24,309 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1990 request_id=req_755073137c02289978279d3b24a1a5af response_code=200
2025-06-20 10:49:26,454 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:26,456 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:49:27,200 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:27,200 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:49:27,201 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:49:27,206 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:49:28,601 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104928.wav, taille: 80339 bytes
2025-06-20 10:49:29,055 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:49:29,058 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2162 request_id=req_d199fbd63a12356e7d86991fcaff1911 response_code=200
2025-06-20 10:49:29,074 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104928.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:29,166 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:49:29,169 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:49:31,823 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:31,826 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:49:31,827 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:49:31,833 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:49:33,583 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104933.wav, taille: 79373 bytes
2025-06-20 10:49:33,880 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:33] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:49:33,972 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:33] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:49:33,977 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:33] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:49:34,215 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104933.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:34,388 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:34] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:49:34,593 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:49:34,596 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2136 request_id=req_bf06e8a7578260af401c8e0614750bc6 response_code=200
2025-06-20 10:49:37,246 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:37,247 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:49:37,697 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:37,697 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:49:37,697 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:49:37,701 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:49:39,780 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:49:39,786 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=840 request_id=req_4f48cba911a1acd7fc31c668650c79e5 response_code=200
2025-06-20 10:49:39,809 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:49:39,812 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1009 request_id=req_4246626519023be4af0a8fd8022cfb62 response_code=200
2025-06-20 10:49:39,892 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:49:39,895 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:49:41,273 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104941.wav, taille: 80339 bytes
2025-06-20 10:49:41,747 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104941.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:42,730 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:42,731 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:49:44,396 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:49:44,396 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1298 request_id=req_451a6a8e7030b34c5b4445604b1a7dd5 response_code=200
2025-06-20 10:49:44,506 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:49:44,506 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:49:44,907 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:49:44,917 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0639\\u0646\\u062f\\u064a \\u0639\\u0646\\u062f\\u064a 23 \\u0639\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam Alami\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:49:44,917 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:49:44,917 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:49:45,547 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:49:45,557 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=232 request_id=req_10f3c1552aa88bf2416045c2e66cb4f6 response_code=200
2025-06-20 10:49:45,597 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:49:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:49:46,583 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104946.wav, taille: 80339 bytes
2025-06-20 10:49:46,985 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104946.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:51,272 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104951.wav, taille: 80339 bytes
2025-06-20 10:49:51,674 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104951.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:49:52,429 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:49:52,430 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:49:52,432 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:49:52,435 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:49:56,577 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_104956.wav, taille: 80339 bytes
2025-06-20 10:49:56,985 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_104956.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:50:00,181 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:50:00,183 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:50:00,185 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:50:00,193 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:50:01,202 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:50:01,216 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=349 request_id=req_53090d1fef4e453c3f3b30c2321b0d4c response_code=200
2025-06-20 10:50:01,447 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:50:01,498 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0645\\u0646 \\u0628\\u0639\\u062f\\"\\n            Fran\\u00e7ais: \\"et il m\'a dit de retourner \\u00e0 la maison la semaine prochaine\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:50:01,668 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:50:01,699 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105001.wav, taille: 80339 bytes
2025-06-20 10:50:01,715 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:50:01,814 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:50:01,860 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:50:02,117 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:50:02,177 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=290 request_id=req_60c5fac390b97f4cae4609816fcbaec9 response_code=200
2025-06-20 10:50:03,345 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:50:03,747 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105001.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:50:03,950 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:50:04,088 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=879 request_id=req_c678d5b4fedc48a3708843b69675e9d8 response_code=200
2025-06-20 10:50:06,591 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105006.wav, taille: 79373 bytes
2025-06-20 10:50:07,026 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105006.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:50:07,194 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:50:07,197 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:50:07,197 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:50:07,210 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:50:09,422 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:50:09,425 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1012 request_id=req_202dc47f100d7142c6acf8a56efbea9a response_code=200
2025-06-20 10:50:09,755 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:50:09,756 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:50:09,760 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:50:09,767 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:50:10,131 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:10] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:50:10,217 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:10] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:50:10,239 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:10] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:50:10,385 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:50:10,389 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:50:10,611 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:10] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:50:11,178 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:50:11,180 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=574 request_id=req_fb32f263391f0221b6e61d61ef08ac88 response_code=200
2025-06-20 10:50:11,189 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:50:11,193 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=877 request_id=req_4be975cae47d4d16048e8faa6ce431ac response_code=200
2025-06-20 10:50:11,285 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:50:11,286 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u062a\\u0634\\u0648\\u0641 \\u0634\\u0646\\u0648 \\u0639\\u0646\\u062f\\u064a \\u0648\\u0634\\u0648\\u0641 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0629 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"Je vais voir ce que j\'ai, je vais voir cette vid\\u00e9o.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:50:11,685 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:50:11,685 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=224 request_id=req_03f2d4cfdde14fabc88628232234c3e5 response_code=200
2025-06-20 10:50:11,718 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:50:12,257 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:50:12,259 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:50:13,786 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:50:13,788 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=823 request_id=req_bacc6ef9e5c90a774a24fc092c444b9d response_code=200
2025-06-20 10:50:13,910 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:50:13,912 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:50:14,286 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:50:14,286 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:50:15,706 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:50:15,706 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1146 request_id=req_72a3fd4822819f7f662a7d5d85b6e294 response_code=200
2025-06-20 10:50:15,824 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:50:15,826 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:50:18,314 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105018.wav, taille: 58121 bytes
2025-06-20 10:50:18,713 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105018.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:50:20,319 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:50:20,320 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645\\"\\n            Fran\\u00e7ais: \\"salam\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:50:20,322 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:50:20,326 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:50:20,342 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:50:20,346 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=52436 request_id=req_b9b917bf1e8a5761a722e1e0d35472aa response_code=200
2025-06-20 10:50:20,895 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:50:20,895 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=190 request_id=req_03b1b60e58864960042504cc592508be response_code=200
2025-06-20 10:50:20,920 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:50:24,256 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:50:24,257 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:50:26,050 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:50:26,055 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1425 request_id=req_cd407f4ff6b24a47ffbfbf2c005cb63a response_code=200
2025-06-20 10:50:26,169 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:50:26,169 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:50:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:51:58,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105158.wav, taille: 80339 bytes
2025-06-20 10:51:59,036 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105158.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:00,295 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:00,295 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:00,297 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:00,307 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:00,308 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:00,309 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA500A0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:00,310 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 10:52:00,311 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:00,312 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA503D0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:00,315 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 10:52:01,525 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:01,525 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:01,539 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 10:52:01,541 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:01,543 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AE5701160>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:01,544 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 10:52:01,547 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:01,548 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AE57017F0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:01,552 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 10:52:01,669 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:01,669 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:03,315 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105203.wav, taille: 80339 bytes
2025-06-20 10:52:03,720 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105203.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:04,998 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:04,998 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:05,001 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:05,009 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:05,010 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:05,011 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AED052790>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:05,012 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 10:52:05,013 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:05,014 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA36850>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:05,015 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 10:52:06,247 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:06,248 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:06,255 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 10:52:06,255 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:06,258 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA8F0A0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:06,259 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 10:52:06,260 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:06,261 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA50760>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:06,262 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 10:52:06,369 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:06,372 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:08,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105208.wav, taille: 80339 bytes
2025-06-20 10:52:09,059 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105208.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:10,345 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:10,353 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:10,355 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:10,359 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:10,360 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:10,360 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AED020CA0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:10,362 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 10:52:10,363 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:10,363 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA509D0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:10,364 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 10:52:11,619 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:11,621 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:11,628 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 10:52:11,629 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:11,630 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AED052070>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:11,636 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 10:52:11,641 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:11,642 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AED0528E0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:11,645 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 10:52:11,750 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:11,755 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:13,317 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105213.wav, taille: 80339 bytes
2025-06-20 10:52:13,775 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105213.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:15,075 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:15,075 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:15,083 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:15,090 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:15,090 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:15,094 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA36460>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:15,096 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 10:52:15,097 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:15,097 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA0F700>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:15,098 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 10:52:16,357 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:16,358 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:16,364 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 10:52:16,373 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:16,374 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA50A00>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:16,378 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 10:52:16,379 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:16,379 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEFA8FAF0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:16,380 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 10:52:16,501 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:16,505 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:18,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105218.wav, taille: 80339 bytes
2025-06-20 10:52:19,032 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105218.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:20,357 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:20,357 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:20,357 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:20,357 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:20,365 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:20,369 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AED06E2E0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:20,374 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 10:52:20,375 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:20,376 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AED0522B0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:52:20,377 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 10:52:22,931 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:22,940 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:22,944 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 10:52:23,316 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105223.wav, taille: 80339 bytes
2025-06-20 10:52:23,899 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105223.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:26,018 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 10:52:26,020 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1844 request_id=req_408a7fec178bdf7caddb5b446981b3b4 response_code=200
2025-06-20 10:52:26,132 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:26,135 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:27,037 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:27,038 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:27,042 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:27,051 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:28,085 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:52:28,090 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=537 request_id=req_baf42dd08e9e46ded949d1a3543782bd response_code=200
2025-06-20 10:52:28,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105228.wav, taille: 80339 bytes
2025-06-20 10:52:29,055 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105228.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:30,552 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:30,555 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:31,923 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:31,925 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:31,926 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:31,930 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:32,225 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:52:32,225 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=735 request_id=req_a8be6e30c4f5803a8a272f66eb116381 response_code=200
2025-06-20 10:52:32,331 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:32,335 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:33,585 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:52:33,585 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=851 request_id=req_1cb2cd9e7d9d16984335e65cdc79bf42 response_code=200
2025-06-20 10:52:33,637 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105233.wav, taille: 80339 bytes
2025-06-20 10:52:34,054 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105233.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:36,029 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:36,029 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:37,360 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:37,360 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:37,364 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:37,369 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:38,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105238.wav, taille: 80339 bytes
2025-06-20 10:52:38,819 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:52:38,819 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=628 request_id=req_094eff3b7c906d42f7a1bfb1c4f38d4e response_code=200
2025-06-20 10:52:39,051 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105238.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:41,358 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:41,358 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:42,255 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:52:42,255 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=681 request_id=req_d10b832c35d73ac0c753da4d5ab78bed response_code=200
2025-06-20 10:52:42,366 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:42,374 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:42,387 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:42,389 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:42,389 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:42,395 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:43,350 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:52:43,350 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=604 request_id=req_f8b868a3c42737914d286644dc862903 response_code=200
2025-06-20 10:52:43,619 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105243.wav, taille: 80339 bytes
2025-06-20 10:52:44,033 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105243.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:47,488 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:47,490 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:47,490 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:47,504 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:47,505 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:47,506 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:48,340 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:52:48,341 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=562 request_id=req_0763d6211b101b959abe1c1c4593fbaf response_code=200
2025-06-20 10:52:48,447 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:52:48,448 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Fran\\u00e7ais: \\"C\'est la fin de la vid\\u00e9o, merci d\'avoir regard\\u00e9\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:52:48,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105248.wav, taille: 80339 bytes
2025-06-20 10:52:48,917 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:52:48,925 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=477 request_id=req_0c6a6db5b64d517ceb36d378277d500d response_code=200
2025-06-20 10:52:49,019 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:52:49,022 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=315 request_id=req_a65b541fef34b7bca35ad163874c213e response_code=200
2025-06-20 10:52:49,099 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:49,139 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105248.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:52,356 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:52,356 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:52,365 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:52,371 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:52,720 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:52,721 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:53,630 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105253.wav, taille: 80339 bytes
2025-06-20 10:52:54,123 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105253.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:54,579 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:52:54,585 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=864 request_id=req_dfab975fae6ab9125a3c1a9912cf37c3 response_code=200
2025-06-20 10:52:55,517 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 10:52:55,518 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2465 request_id=req_06547de382eaaeca5f1a0a3eba72d0a9 response_code=200
2025-06-20 10:52:55,624 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:55,628 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:57,642 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:57,643 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:52:57,653 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:52:57,657 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:52:57,658 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:52:57,658 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:52:58,605 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:52:58,607 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=604 request_id=req_ff83dedec261177838d706460c10db1f response_code=200
2025-06-20 10:52:58,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105258.wav, taille: 80339 bytes
2025-06-20 10:52:58,718 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:52:58,721 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:52:59,146 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:59] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:52:59,151 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:52:59,153 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105258.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:52:59,193 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=518 request_id=req_3866d9574923c880615ea6dc7dd09efd response_code=200
2025-06-20 10:52:59,267 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:59] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:52:59,307 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:59] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:52:59,893 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:52:59] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:53:02,138 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:02,139 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:03,040 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:03,056 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=578 request_id=req_8b2564a3ad5fb191b8951f72e0243f0e response_code=200
2025-06-20 10:53:03,162 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:53:03,162 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:03,537 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:03,537 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:53:03,551 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:03,556 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:05,603 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:53:05,603 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=922 request_id=req_9b9bdc05019df01af88c4bfa853b14c1 response_code=200
2025-06-20 10:53:05,700 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:05,703 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=29387 request_id=req_513a26f7fb86606dde8de449ca3a0608 response_code=200
2025-06-20 10:53:05,822 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:53:05,824 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:09,491 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:09,492 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:12,710 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 12
2025-06-20 10:53:12,710 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2875 request_id=req_1e610ee123f92a1b1d16e1e2834601ea response_code=200
2025-06-20 10:53:12,830 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:53:12,830 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Fran\\u00e7ais: \\".\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:53:13,065 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105313.wav, taille: 80339 bytes
2025-06-20 10:53:13,476 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:53:13,485 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=225 request_id=req_d68cab948bec0714bbb918b0c2e69232 response_code=200
2025-06-20 10:53:13,485 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105313.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:13,545 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:17,316 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:53:17,317 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646\\u062c\\u064a\\u0628 \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0644\\u0644\\u0641\\u064a\\u062a\\u0647 \\u062d\\u064a\\u062a\\"\\n            Fran\\u00e7ais: \\"Salam en arabe\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:53:17,319 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:17,324 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:18,097 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:53:18,105 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=329 request_id=req_98fb2bf3f2f1dd76761da65ac6a94eae response_code=200
2025-06-20 10:53:18,131 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:18,365 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105318.wav, taille: 80339 bytes
2025-06-20 10:53:18,776 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105318.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:23,305 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:23,306 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:53:23,308 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:23,315 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:23,373 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105323.wav, taille: 80339 bytes
2025-06-20 10:53:23,830 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105323.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:25,523 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:25,525 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1508 request_id=req_bd1f3b0dc77f4504033b9ee180bd8ecf response_code=200
2025-06-20 10:53:28,370 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105328.wav, taille: 80339 bytes
2025-06-20 10:53:28,797 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105328.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:30,625 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:30,632 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:30,634 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:30,640 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:31,605 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:31,605 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:53:31,615 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:31,620 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:32,346 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 35
2025-06-20 10:53:32,346 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=774 request_id=req_712f9757985c4bb41223103732f2348f response_code=200
2025-06-20 10:53:32,386 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:32,387 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:32,465 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:53:32,466 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"et tu re\\u00e7ois maintenant\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:53:32,833 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:53:32,837 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=183 request_id=req_988710a7e20f0a6e2df4c5644587a496 response_code=200
2025-06-20 10:53:32,871 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:33,365 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105333.wav, taille: 80339 bytes
2025-06-20 10:53:33,529 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:33,535 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=560 request_id=req_fcb7fc22377acacc639fd3e459bcb38b response_code=200
2025-06-20 10:53:33,560 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:53:33,563 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=772 request_id=req_6ad696bd7f829a5f6ab5cab6a2b8064a response_code=200
2025-06-20 10:53:33,647 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:53:33,647 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u064a\\u0627\\u0631\\u064a\\u0643\\u064a \\u062f\\u0631\\u0646\\u064a \\u0648\\u0643\\u0627\\u0646 \\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0642\\u0627\\u0644\\u064a \\u0637\\u0628\\u064a\\u0639\\u064a \\u0628\\u0631\\u062c\\u0627\\u0644\\"\\n            Fran\\u00e7ais: \\"Il y a des quais d\'orignal, il y a des forges, et il y a des tabacs par jambes.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:53:33,875 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105333.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:34,122 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:53:34,134 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=284 request_id=req_1716229a0028b3050496a72b9e12eae5 response_code=200
2025-06-20 10:53:34,179 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:36,851 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:36,853 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:53:36,856 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:36,859 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:37,237 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:37,239 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:38,370 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105338.wav, taille: 80339 bytes
2025-06-20 10:53:38,785 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105338.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:38,956 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:38,957 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=891 request_id=req_52b8a2b3161be1de50ec33cb6ca48ff7 response_code=200
2025-06-20 10:53:39,047 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:53:39,047 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=585 request_id=req_340160133a28dac69271a3ac4be65646 response_code=200
2025-06-20 10:53:39,079 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:53:39,085 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:42,205 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:42,205 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:42,855 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:42,855 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:53:42,858 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:42,864 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:43,240 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:43,241 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=572 request_id=req_41ebcca602c5cbc306462ccd942022e3 response_code=200
2025-06-20 10:53:43,344 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:53:43,348 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:43,376 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105343.wav, taille: 80339 bytes
2025-06-20 10:53:43,791 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105343.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:44,785 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:53:44,796 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=502 request_id=req_c98c9ef090d5fe2505ffbbd9fa6ccf53 response_code=200
2025-06-20 10:53:47,465 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:47,466 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:53:47,467 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:47,473 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:48,363 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105348.wav, taille: 80339 bytes
2025-06-20 10:53:48,505 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:48,505 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:48,798 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105348.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:48,835 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:53:48,852 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=301 request_id=req_d5ec1779617a4c4416a8475b185bb876 response_code=200
2025-06-20 10:53:49,528 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:49,530 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=782 request_id=req_0d41f3a758940cb6f0de5ca1a84ecce0 response_code=200
2025-06-20 10:53:49,643 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:53:49,643 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Fran\\u00e7ais: \\"Merci beaucoup d\'avoir regard\\u00e9 cette vid\\u00e9o, n\'h\\u00e9sitez pas \\u00e0 vous abonner \\u00e0 la chaine pour d\'autres vid\\u00e9os !\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:53:50,179 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:53:50,185 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=333 request_id=req_f2855f4e454113ddf4659b2260be81b1 response_code=200
2025-06-20 10:53:50,252 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:51,289 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:51,289 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:51,505 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:51,505 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:53:51,510 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:51,523 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:52,856 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:52,858 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1176 request_id=req_cebf24776ca088ddfa61549c6871a1e9 response_code=200
2025-06-20 10:53:52,965 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:53:52,969 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:53,265 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:53:53,265 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=724 request_id=req_146930fdcd92483e154707674bcb25c4 response_code=200
2025-06-20 10:53:53,373 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105353.wav, taille: 80339 bytes
2025-06-20 10:53:53,810 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105353.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:53:55,951 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:55,952 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:53:56,387 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:53:56,387 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:53:56,387 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:53:56,397 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:53:57,640 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:57] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:53:57,679 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:53:57,705 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1439 request_id=req_456693290c5091439f3659537f4a8ac9 response_code=200
2025-06-20 10:53:57,730 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:57] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:53:57,749 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:57] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:53:57,834 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:53:57,838 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:53:58,185 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:53:58,188 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=835 request_id=req_dcf76d57afa1b05e0e33ee5bdfd507ab response_code=200
2025-06-20 10:53:58,284 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:53:58] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:54:01,340 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:01,340 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:54:02,480 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:54:02,480 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=505 request_id=req_36821dc8f9995b1997be53439704b267 response_code=200
2025-06-20 10:54:02,595 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:54:02,595 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:54:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:54:04,778 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105404.wav, taille: 80339 bytes
2025-06-20 10:54:05,220 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105404.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:54:08,444 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:54:08,446 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0634\\u064a\\u0645\\u0627\\u0621 \\u0643\\u0627\\u0646 \\u062c\\u0627\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u0632\\u0647\\"\\n            Fran\\u00e7ais: \\"salam Ana Rachid\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:54:08,450 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:54:08,454 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:54:09,259 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:54:09,269 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=335 request_id=req_51fb7342d7fcf01f431aa98c8fd3e760 response_code=200
2025-06-20 10:54:09,304 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:54:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:54:10,080 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105410.wav, taille: 80339 bytes
2025-06-20 10:54:10,547 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105410.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:54:14,114 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:54:14,114 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0639\\u0637\\u0627\\u0646\\u064a \\u0643\\u0627\\u0646 \\u0627\\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\"\\n            Fran\\u00e7ais: \\"canap\\u00e9 chez toi\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:54:14,114 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:54:14,124 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:54:14,720 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:54:14,720 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=292 request_id=req_a32ef8fcd68cc0ac51f02a8173342ba9 response_code=200
2025-06-20 10:54:14,754 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:54:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:54:14,782 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105414.wav, taille: 80339 bytes
2025-06-20 10:54:15,221 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105414.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:54:20,101 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105420.wav, taille: 80339 bytes
2025-06-20 10:54:20,564 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105420.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:54:20,775 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:20,775 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:54:20,779 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:54:20,785 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:54:22,780 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 10:54:22,790 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1550 request_id=req_ef01fa83860b5b2f01f9dad01d6e7b42 response_code=200
2025-06-20 10:54:22,926 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:54:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:54:24,500 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:24,501 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:54:24,504 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:54:24,508 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:54:25,080 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105425.wav, taille: 80339 bytes
2025-06-20 10:54:25,564 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105425.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:54:26,444 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:54:26,444 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=778 request_id=req_22581be9856ded16f51fba5693a9d9c3 response_code=200
2025-06-20 10:54:28,933 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:54:28,935 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Fran\\u00e7ais: \\"localisation\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:54:29,400 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:54:29,400 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=211 request_id=req_0354df885117ea959c94cbef8219230c response_code=200
2025-06-20 10:54:29,456 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:29,472 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:54:29,473 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:54:29,474 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:54:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:54:29,483 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:54:30,087 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105430.wav, taille: 80339 bytes
2025-06-20 10:54:30,600 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105430.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:54:31,363 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:54:31,366 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=805 request_id=req_b0c55326cf9f62d55b822025ec634054 response_code=200
2025-06-20 10:54:33,530 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:33,530 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:54:33,530 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:54:33,530 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:54:34,702 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:34,702 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:54:34,881 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:54:34,890 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=597 request_id=req_48c12e5be870794c6e5fbe95053b6c3d response_code=200
2025-06-20 10:54:35,082 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105435.wav, taille: 80339 bytes
2025-06-20 10:54:35,570 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105435.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:54:36,022 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105436.wav, taille: 14651 bytes
2025-06-20 10:54:36,328 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105436.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:54:38,246 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:38,250 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:54:38,862 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:38,863 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:38,866 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:54:38,867 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:54:38,869 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:54:38,869 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:54:38,877 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:54:38,877 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:54:39,908 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 10:54:39,911 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=480 request_id=req_238cb3a7928f819ca47b6ca80a74f082 response_code=200
2025-06-20 10:54:41,020 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 27
2025-06-20 10:54:41,034 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1900 request_id=req_3d10679f8ad616fdc304ee3ea2e5f8db response_code=200
2025-06-20 10:54:41,156 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:54:41,171 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:54:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:54:42,312 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:54:42,366 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:54:43,544 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 10:54:43,548 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=842 request_id=req_ab59aba6eb36e5e31951df8733e5a03f response_code=200
2025-06-20 10:54:43,795 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:54:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:56:28,958 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:56:28] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:56:29,039 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:56:29] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:56:29,046 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:56:29] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:56:29,457 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:56:29] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:56:35,955 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105635.wav, taille: 80339 bytes
2025-06-20 10:56:36,415 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105635.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:56:39,672 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:56:39,672 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646 \\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Fran\\u00e7ais: \\"Salam en arabe\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:56:39,677 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:56:39,677 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:56:40,258 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:56:40,267 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=187 request_id=req_ae125f006d1d8531c0ccfc3ae96b7561 response_code=200
2025-06-20 10:56:40,302 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:56:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:56:41,257 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105641.wav, taille: 80339 bytes
2025-06-20 10:56:41,712 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105641.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:56:45,955 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105645.wav, taille: 80339 bytes
2025-06-20 10:56:46,229 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:56:46,238 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:56:46,243 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:56:46,247 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:56:46,426 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105645.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:56:47,612 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:56:47,612 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1011 request_id=req_15b256360249176ebe3d2fd10706591a response_code=200
2025-06-20 10:56:47,722 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:56:47,722 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0647\\"\\n            Fran\\u00e7ais: \\"C\'est ce qu\'il m\'a donn\\u00e9, c\'est ce qu\'il m\'a donn\\u00e9 de la douleur.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:56:48,605 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:56:48,607 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=715 request_id=req_bfe2224fd07c18222fe102f2a8746797 response_code=200
2025-06-20 10:56:48,633 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:56:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:56:51,264 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105651.wav, taille: 80339 bytes
2025-06-20 10:56:51,757 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105651.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:56:53,344 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:56:53,347 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:56:53,348 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:56:53,351 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:56:55,058 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:56:55,062 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=910 request_id=req_46dc0419eac17f963d2b719b1acfde24 response_code=200
2025-06-20 10:56:55,171 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:56:55,172 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"et il m\'a dit qu\'il reviendrait la semaine prochaine pour voir les enfants.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:56:55,638 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:56:55,638 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=286 request_id=req_e263eac5716ae330244f1dbe198c1b49 response_code=200
2025-06-20 10:56:55,675 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:56:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:56:55,991 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:56:55,991 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:56:55,993 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:56:55,997 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:56:56,267 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105656.wav, taille: 80339 bytes
2025-06-20 10:56:56,753 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105656.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:56:57,563 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:56:57,565 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1098 request_id=req_37f6571119043f1dfd9b7d87d140e0cb response_code=200
2025-06-20 10:56:59,380 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:56:59,381 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:56:59,382 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:56:59,395 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:00,974 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:57:00,982 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1031 request_id=req_e4d60e4d11050618d17b7b4c70d921cb response_code=200
2025-06-20 10:57:01,088 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:01,097 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:01,347 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105701.wav, taille: 80339 bytes
2025-06-20 10:57:02,032 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:02,050 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=646 request_id=req_56a1efd45167b4d2be1dfcb0cb253179 response_code=200
2025-06-20 10:57:02,147 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105701.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:57:02,181 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 10:57:02,202 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Fran\\u00e7ais: \\"Et on va d\\u00e9dier \\u00e0 l\'\\u00e9quilibre l\\u00e0-dessus.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 10:57:02,760 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 10:57:02,766 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=315 request_id=req_dafa6b31dd766b72a5e5f0c14b156d84 response_code=200
2025-06-20 10:57:02,817 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:57:03,291 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:03,295 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:04,061 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:04,062 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=514 request_id=req_f85eabe834b7cf552623ea3e9c1aa511 response_code=200
2025-06-20 10:57:04,175 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:57:04,179 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:57:04,857 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:04,857 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:57:04,863 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:57:04,867 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:05,875 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:57:05,880 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=481 request_id=req_5915e511a69b299ef9fc2635ba43dece response_code=200
2025-06-20 10:57:06,272 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105706.wav, taille: 80339 bytes
2025-06-20 10:57:07,091 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105706.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:57:08,641 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:08,724 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:09,922 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:09,926 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=803 request_id=req_8fb8aa4cdd45a42dd53316afb5b0c95c response_code=200
2025-06-20 10:57:10,047 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:57:10,055 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:57:10,279 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:10,289 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:57:10,293 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:57:10,300 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:11,275 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105711.wav, taille: 80339 bytes
2025-06-20 10:57:12,208 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:57:12,211 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105711.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:57:12,214 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=748 request_id=req_cc58514f5d8dec6c59ee3a935cb0b9b7 response_code=200
2025-06-20 10:57:15,627 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:15,629 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:16,057 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:16,059 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:57:16,061 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:57:16,066 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:16,276 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105716.wav, taille: 80339 bytes
2025-06-20 10:57:17,034 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105716.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:57:17,428 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:57:17,429 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=520 request_id=req_bea56dfcd80ca45cb9c79f033df7731c response_code=200
2025-06-20 10:57:17,530 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:17,533 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1426 request_id=req_7ecf77b4039a17eec2e5b7471666970d response_code=200
2025-06-20 10:57:17,649 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:57:17,662 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:57:20,757 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:20,763 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:57:20,767 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:57:20,789 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:20,789 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:20,789 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:21,270 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105721.wav, taille: 80339 bytes
2025-06-20 10:57:21,622 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:21,624 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=554 request_id=req_6f398d2fe89703214deb2b470ae3008e response_code=200
2025-06-20 10:57:21,744 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:57:21,749 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:57:21,877 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105721.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:57:21,960 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:57:21,969 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=317 request_id=req_27e16c283bd0eea0a2cab3769a9f0c46 response_code=200
2025-06-20 10:57:24,956 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:24,959 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:57:24,959 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:57:24,959 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:24,994 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:24,997 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:25,657 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:25,657 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=420 request_id=req_3d23f509ce63ff7e399992021b9a5f4e response_code=200
2025-06-20 10:57:25,770 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:57:25,770 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:57:26,257 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105726.wav, taille: 80339 bytes
2025-06-20 10:57:26,703 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105726.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:57:26,878 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:26,878 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1066 request_id=req_75da390f6964ff7cc00612bf92934ddc response_code=200
2025-06-20 10:57:29,043 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:29,082 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:57:29,101 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:57:29,114 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:29,825 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:29,827 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:31,282 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105731.wav, taille: 80339 bytes
2025-06-20 10:57:31,822 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105731.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:57:32,804 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:32,827 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2518 request_id=req_32844bdd782854fedbc4a2ad517e1bbe response_code=200
2025-06-20 10:57:32,940 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:57:32,943 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:57:34,843 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:34,844 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:57:34,845 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:57:34,854 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:36,263 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:57:36,283 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=807 request_id=req_d196db8ce4bbf312598e49f05f32a561 response_code=200
2025-06-20 10:57:36,312 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105736.wav, taille: 80339 bytes
2025-06-20 10:57:37,072 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105736.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:57:37,238 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:37] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:57:37,305 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:37] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:57:37,449 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:37] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 10:57:38,131 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:38] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:57:38,898 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:38,899 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:40,212 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:40,212 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:57:40,212 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:57:40,212 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:57:41,268 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:41,269 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2033 request_id=req_d80e36640f2de2f67e72930d16ca0853 response_code=200
2025-06-20 10:57:41,385 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:57:41,387 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:57:41,586 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 10:57:41,586 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=810 request_id=req_b1d8f804c1e193643b468bea325520f9 response_code=200
2025-06-20 10:57:44,281 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:57:44,282 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 10:57:45,348 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 10:57:45,348 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=812 request_id=req_94ffb964b180e780306dc42a6ea1258b response_code=200
2025-06-20 10:57:45,466 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 10:57:45,469 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:57:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 10:58:35,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105835.wav, taille: 80339 bytes
2025-06-20 10:58:35,780 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105835.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:58:39,981 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105839.wav, taille: 80339 bytes
2025-06-20 10:58:40,445 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105839.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:58:45,270 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105845.wav, taille: 80339 bytes
2025-06-20 10:58:45,790 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105845.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:58:50,288 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105850.wav, taille: 80339 bytes
2025-06-20 10:58:50,856 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105850.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:58:55,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105855.wav, taille: 80339 bytes
2025-06-20 10:58:55,734 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105855.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:00,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105900.wav, taille: 80339 bytes
2025-06-20 10:59:00,775 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105900.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:06,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105906.wav, taille: 80339 bytes
2025-06-20 10:59:06,679 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105906.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:10,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105910.wav, taille: 80339 bytes
2025-06-20 10:59:10,801 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105910.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:15,304 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105915.wav, taille: 80339 bytes
2025-06-20 10:59:16,073 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105915.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:20,292 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105920.wav, taille: 80339 bytes
2025-06-20 10:59:21,075 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105920.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:25,425 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105925.wav, taille: 80339 bytes
2025-06-20 10:59:25,877 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105925.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:30,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105930.wav, taille: 80339 bytes
2025-06-20 10:59:30,849 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105930.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:35,310 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_105935.wav, taille: 80339 bytes
2025-06-20 10:59:35,975 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_105935.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 10:59:39,851 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:59:39] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 10:59:39,950 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:59:39] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 10:59:39,958 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:59:39] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 10:59:40,272 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:59:40,273 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:59:40,274 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:59:40,284 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:59:40,440 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 10:59:40] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 10:59:45,004 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:59:45,004 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:59:45,004 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:59:45,018 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:59:50,186 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:59:50,186 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:59:50,186 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:59:50,197 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:59:55,453 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:59:55,455 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:59:55,457 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:59:55,466 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:59:59,733 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 10:59:59,734 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 10:59:59,736 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:59:59,740 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 10:59:59,741 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:59:59,743 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B22AC0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:59:59,747 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 10:59:59,752 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 10:59:59,753 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B22520>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 10:59:59,754 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 11:00:00,351 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:00,354 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 11:00:00,368 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:00,391 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:00,397 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:00,400 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B179D0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:00,402 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 11:00:00,404 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:00,406 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B40670>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:00,407 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 11:00:01,017 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:01,017 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:01,017 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 11:00:01,032 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:01,034 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B2E7C0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:01,036 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 11:00:01,039 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:01,040 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B2E940>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:01,041 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 11:00:01,163 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:01,166 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:01,446 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:01,446 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000025AF0B22EB0>: Failed to establish a new connection: [WinError 10065] A socket operation was attempted to an unreachable host')': /v1/audio/transcriptions
2025-06-20 11:00:01,446 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 11:00:01,446 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:01,446 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEF9E2940>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:01,455 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 11:00:01,670 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:01,671 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:01,674 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 11:00:01,675 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:01,676 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B40F10>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:01,680 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 11:00:01,681 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:01,683 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B40970>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:01,684 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 11:00:01,796 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:01,798 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:02,695 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:02,696 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:02,696 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 11:00:02,696 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:02,696 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEF9E28E0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:02,704 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 11:00:02,706 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:02,706 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AEF9E2820>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:02,708 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 11:00:02,828 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:02,832 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:04,668 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:04,669 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 11:00:04,670 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:04,671 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:04,671 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:04,678 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B4ACD0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:04,680 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 11:00:04,683 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:04,684 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000025AF0B4AE80>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 11:00:04,686 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 11:00:05,493 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:05,493 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 11:00:05,508 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:05,516 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:05,586 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:05,587 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 11:00:05,587 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:05,587 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:06,499 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:06,517 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:06,521 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 11:00:06,978 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 11:00:06,993 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=757 request_id=req_9ed7bb8ee39189f2f90f9f58fe71ce78 response_code=200
2025-06-20 11:00:07,048 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:07,051 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=905 request_id=req_58cae87f77d473e25c1f9fcd61c1b5ee response_code=200
2025-06-20 11:00:08,041 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:08,071 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=775 request_id=req_8cca82ead1eefdbab7fec83ac84197b5 response_code=200
2025-06-20 11:00:08,212 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 11:00:08,275 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2081 request_id=req_19484e035670b9d3101ede44ca9ccc1f response_code=200
2025-06-20 11:00:08,278 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "Sous-titres réalisés para la communauté d'Amara.org", 'fused': "Sous-titres réalisés para la communauté d'Amara.org", 'segment_id': 27}
2025-06-20 11:00:08,529 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:09,203 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:09,206 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 11:00:09,208 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:09,215 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:09,657 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:09,658 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 11:00:09,659 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:09,665 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:09,836 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:09,837 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:10,016 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:10,030 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 11:00:10,034 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:10,040 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:10,049 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:10,049 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:10,049 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:10,064 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:10,329 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:10,329 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=3679 request_id=req_8bc74d8ba1b2ead69fa2faf3f85dec22 response_code=200
2025-06-20 11:00:10,427 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 11:00:10,430 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=688 request_id=req_843b44489aa22f002d52a90c7fd61bfe response_code=200
2025-06-20 11:00:10,550 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:10,555 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=814 request_id=req_99efbb3c86bcd9cf0aa75b379e24ef28 response_code=200
2025-06-20 11:00:10,652 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 11:00:10,654 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=607 request_id=req_09db24254e39d48b30f3861aa91d8d48 response_code=200
2025-06-20 11:00:10,662 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:10,666 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:10,944 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:10,947 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=816 request_id=req_cbd9a660ac51bf92a3028ebc01c465a7 response_code=200
2025-06-20 11:00:10,965 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:10,967 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:11,053 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:11,058 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:11,463 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:11,463 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=784 request_id=req_f23f88b9f516f49e0576f13c05fdba8b response_code=200
2025-06-20 11:00:11,597 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:11,597 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:11,845 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 11:00:11,848 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=601 request_id=req_ee04f5525a7d630c45516636b770c0bf response_code=200
2025-06-20 11:00:11,975 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 11:00:11,980 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=847 request_id=req_02fadc8674f824f617bf15b9064350d9 response_code=200
2025-06-20 11:00:12,357 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:12,359 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=849 request_id=req_133dff9d85614f51e6bd39bc5ae6cfd4 response_code=200
2025-06-20 11:00:12,475 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:12,479 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:12,908 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:12,915 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:13,322 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'booking cette semaine des médicaments', 'fused': 'booking cette semaine des médicaments', 'segment_id': 28}
2025-06-20 11:00:13,324 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:13,819 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:13,834 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:14,232 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:14,268 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:14,450 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:14,453 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:15,000 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:15,001 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=419 request_id=req_98663e968db85f65b794945b821eb1f5 response_code=200
2025-06-20 11:00:15,066 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:15,070 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=764 request_id=req_b44404ebf24064ee9a9864c18cc85534 response_code=200
2025-06-20 11:00:15,104 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:15,107 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:15,179 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:15,183 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:15,185 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 11:00:15,190 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:15,191 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:15,216 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:15,232 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:15,236 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2035 request_id=req_8d81aac3323bbc52a212acf95d212aa0 response_code=200
2025-06-20 11:00:15,340 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:15,345 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:15,500 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:15,507 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=686 request_id=req_62898a5ac257ba3b0f1a2345aff5ab01 response_code=200
2025-06-20 11:00:15,614 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:15,618 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:16,643 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 11:00:16,648 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=771 request_id=req_8743c593b51e3bc3646229183037fead response_code=200
2025-06-20 11:00:17,226 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:17,231 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:18,596 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:18,602 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=887 request_id=req_4e71cc3bbcac3228cf5a026218631f29 response_code=200
2025-06-20 11:00:18,711 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 11:00:18,714 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0627\\u0644\\u0633\\u0645\\u0627\\u0646\\u0629\\"\\n            Fran\\u00e7ais: \\"Et le m\\u00e9decin m\'a dit qu\'il avait de la semaine.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 11:00:19,400 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 11:00:19,402 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=299 request_id=req_2af225e8cf4c17f1c4c808668895574c response_code=200
2025-06-20 11:00:19,491 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:19,747 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:19,754 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:20,716 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:20,719 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=595 request_id=req_0428f6138a89974ed2452c40ccc58578 response_code=200
2025-06-20 11:00:20,832 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:20,833 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:00:52,196 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 11:00:52,196 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=35945 request_id=req_a7796e19c7886f826b78b4b205396d3b response_code=200
2025-06-20 11:00:54,628 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:00:54,628 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:00:54,642 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 11:00:54,648 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 11:00:56,739 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:00:56,741 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1521 request_id=req_09a5ac3b88c7bb478b12f5586fb6d940 response_code=200
2025-06-20 11:00:56,858 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 11:00:56,860 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:00:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 11:02:46,228 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 11:02:46,229 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 11:02:46,236 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 11:02:47,568 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 11:02:47,570 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=819 request_id=req_1ebb9a5f598aefa4c8ed98607bf3cfcf response_code=200
2025-06-20 11:02:47,686 - app - DEBUG - Résultat transcription: {'darija': '', 'french': "et je vous souhaite d'y aller qu'il vous plaît.", 'fused': "et je vous souhaite d'y aller qu'il vous plaît.", 'segment_id': 30}
2025-06-20 11:02:47,688 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 11:02:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:07:18,174 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessing.py', reloading
2025-06-20 12:07:18,287 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\noisereduce\\__init__.py', reloading
2025-06-20 12:07:18,385 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\soundfile.py', reloading
2025-06-20 12:07:18,430 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\noisereduce\\noisereduce.py', reloading
2025-06-20 12:07:18,447 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\_cache.py', reloading
2025-06-20 12:07:18,490 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\core\\audio.py', reloading
2025-06-20 12:07:18,503 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\audioread\\__init__.py', reloading
2025-06-20 12:07:18,556 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\lazy_loader\\__init__.py', reloading
2025-06-20 12:07:18,561 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\typing\\__init__.py', reloading
2025-06-20 12:07:18,614 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\__init__.py', reloading
2025-06-20 12:07:18,630 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\audioread\\base.py', reloading
2025-06-20 12:07:18,685 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py', reloading
2025-06-20 12:07:18,688 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_shape.py', reloading
2025-06-20 12:07:18,696 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_dtype_like.py', reloading
2025-06-20 12:07:18,745 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_generic_alias.py', reloading
2025-06-20 12:07:18,759 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\__init__.py', reloading
2025-06-20 12:07:18,808 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py', reloading
2025-06-20 12:07:18,881 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-20 12:07:18,888 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessor.py', reloading
2025-06-20 12:07:18,901 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-20 12:07:22,109 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 12:08:00,716 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 12:08:00,717 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 12:10:37,789 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121037.wav, taille: 80339 bytes
2025-06-20 12:10:40,271 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\importlib\\__init__.py', reloading
2025-06-20 12:10:40,398 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-20 12:10:40,464 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-20 12:10:40,529 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-20 12:10:40,609 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-20 12:10:40,655 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-20 12:10:40,696 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-20 12:10:40,869 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 12:10:40,929 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:10:40,976 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:41,005 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:10:41,020 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 12:10:42,258 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 12:10:53,109 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 12:10:53,124 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 12:10:53,349 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121053.wav, taille: 0 bytes
2025-06-20 12:10:53,350 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121053.wav, taille: 0 bytes
2025-06-20 12:10:53,357 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121053.wav, taille: 80339 bytes
2025-06-20 12:10:54,438 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 12:10:54,456 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:10:54,457 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:54,457 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:10:54,458 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 12:10:54,458 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,460 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 12:10:54,460 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,460 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 12:10:54,460 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:10:54,460 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 12:10:54,460 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:10:54,460 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 12:10:54,464 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:10:54,464 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 12:10:54,464 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,465 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 12:10:54,465 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 12:10:54,466 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 12:10:54,467 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 12:10:54,468 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 12:10:54,470 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 12:10:54,472 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 12:10:54,472 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 12:10:54,473 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 12:10:54,473 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 12:10:54,474 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 12:10:54,474 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 12:10:54,474 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 12:10:54,475 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 12:10:54,476 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 12:10:54,476 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 12:10:54,476 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 12:10:54,479 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 12:10:54,479 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 12:10:54,479 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 12:10:54,479 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 12:10:54,479 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 12:10:54,482 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,483 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:10:54,484 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 12:10:54,488 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 12:10:54,490 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 12:10:54,490 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 12:10:54,491 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 12:10:54,492 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,492 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,493 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:10:54,493 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:54,494 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 12:10:54,494 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 12:10:54,495 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,495 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,496 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 12:10:54,497 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:54,497 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 12:10:54,498 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 12:10:54,498 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,499 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 12:10:54,501 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 12:10:54,503 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 12:10:54,504 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 12:10:54,505 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 12:10:54,505 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 12:10:54,506 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 12:10:54,507 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,507 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 12:10:54,508 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 12:10:54,508 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 12:10:54,508 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 12:10:54,510 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 12:10:54,510 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 12:10:54,510 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 12:10:54,510 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 12:10:54,514 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 12:10:54,515 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 12:10:54,516 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 12:10:54,521 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 12:10:54,523 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 12:10:54,534 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 12:10:54,559 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 12:10:54,574 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:54,577 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 12:10:54,589 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 12:10:54,590 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,590 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 12:10:54,590 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 12:10:54,597 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,598 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:10:54,599 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 12:10:54,599 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 12:10:54,601 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 12:10:54,601 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 12:10:54,607 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 12:10:54,608 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 12:10:54,608 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 12:10:54,609 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 12:10:54,610 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,612 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:10:54,612 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 12:10:54,619 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 12:10:54,624 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 12:10:54,624 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 12:10:54,629 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 12:10:54,649 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,670 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,695 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:10:54,697 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:10:54,710 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:54,715 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 12:10:54,725 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 12:10:54,728 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,729 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,745 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 12:10:54,749 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:54,751 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 12:10:54,756 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 12:10:54,758 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,759 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 12:10:54,759 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 12:10:54,763 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,763 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 12:10:54,769 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 12:10:54,769 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:54,774 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 12:10:54,775 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 12:10:54,778 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,781 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 12:10:54,791 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 12:10:54,792 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:10:54,820 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:10:54,830 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:54,858 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 12:10:54,864 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 12:10:54,874 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:54,882 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 12:10:54,888 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 12:10:54,890 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 12:10:54,890 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 12:10:54,891 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 12:10:54,892 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 12:10:54,893 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 12:10:54,897 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 12:10:54,898 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 12:10:54,900 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 12:10:54,906 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 12:10:54,920 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 12:10:54,924 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 12:10:54,930 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 12:10:54,938 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 12:10:54,944 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 12:10:54,975 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 12:10:54,994 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 12:10:55,009 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:10:55,012 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:10:55,023 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:55,025 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 12:10:55,026 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 12:10:55,028 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:55,029 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 12:10:55,033 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 12:10:55,038 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 12:10:55,043 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 12:10:55,044 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 12:10:55,046 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 12:10:55,047 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 12:10:55,047 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 12:10:55,056 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 12:10:55,060 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 12:10:55,062 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 12:10:55,064 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 12:10:55,076 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 12:10:55,079 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 12:10:55,081 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 12:10:55,088 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 12:10:55,090 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 12:10:55,090 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 12:10:55,092 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:10:55,094 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:10:55,097 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:10:55,098 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 12:10:55,111 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 12:10:55,114 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 12:10:55,124 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 12:10:55,128 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 12:10:55,131 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 12:10:55,138 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:10:55,139 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 12:10:55,141 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 12:10:55,146 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 12:10:55,148 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 12:10:55,155 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 12:10:55,157 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 12:10:55,160 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 12:10:55,162 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 12:10:55,163 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 12:10:55,165 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 12:10:55,166 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 12:10:55,180 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:10:55,190 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:10:55,206 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 12:10:57,799 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 12:10:57,824 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:10:57,826 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:57,829 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:10:57,829 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 12:10:57,830 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:57,831 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:10:57,831 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:57,832 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 12:10:57,840 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:10:57,841 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:10:57,842 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:10:57,846 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:10:57,855 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:10:57,857 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 12:10:57,861 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 12:10:57,863 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:10:57,865 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 12:10:57,866 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 12:10:57,869 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 12:10:57,879 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:10:57,879 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 12:10:57,883 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 12:10:57,890 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 12:10:57,890 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:10:57,894 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 12:10:57,896 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:10:57,897 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 12:10:57,897 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 12:10:57,898 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 12:10:57,899 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:10:57,903 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 12:10:57,907 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 12:10:57,908 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 12:10:57,911 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 12:10:57,912 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 12:10:57,914 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 12:10:57,915 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 12:10:57,921 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:10:57,923 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:10:57,923 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 12:10:57,924 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 12:10:57,925 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:10:57,926 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:10:57,927 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 12:10:57,927 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 12:10:57,929 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:10:57,930 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:10:57,933 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 12:10:57,943 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 12:10:57,948 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:10:57,949 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:10:57,949 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:10:57,953 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 12:10:57,955 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:57,956 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:10:57,957 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:10:57,957 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 12:10:57,958 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:10:57,960 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:10:57,962 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:10:57,963 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:10:57,964 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:10:57,966 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 12:10:57,975 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 12:10:57,977 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:10:57,978 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 12:10:57,979 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 12:10:57,980 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 12:10:57,982 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:10:57,983 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 12:10:57,984 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 12:10:57,985 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 12:10:57,986 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:10:57,987 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 12:10:57,988 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:10:57,994 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 12:10:57,995 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 12:10:57,996 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 12:10:57,997 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:10:57,998 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 12:10:57,998 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 12:10:58,003 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 12:10:58,005 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 12:10:58,005 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 12:10:58,006 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 12:10:58,007 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 12:10:58,007 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:10:58,008 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:10:58,009 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 12:10:58,010 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 12:10:58,011 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:10:58,012 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:10:58,013 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 12:10:58,013 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 12:10:58,014 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:10:58,015 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:10:58,024 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 12:10:58,300 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121058.wav, taille: 79373 bytes
2025-06-20 12:11:00,104 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121053.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:00,104 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121058.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:00,104 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121053.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:00,179 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121053.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:03,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121103.wav, taille: 80339 bytes
2025-06-20 12:11:03,730 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121103.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:04,853 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:04,853 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:04,855 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:04,859 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:04,859 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:04,859 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:04,876 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:04,877 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:04,877 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:04,877 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:04,879 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:04,879 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:04,879 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:04,879 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:04,896 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:04,899 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:06,910 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:11:06,912 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=840 request_id=req_2c3e2920c2dd8a6ccc8485a133c9070f response_code=200
2025-06-20 12:11:06,919 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:11:06,924 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=857 request_id=req_77d2245712ccced8f98f52978925406e response_code=200
2025-06-20 12:11:07,039 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:11:07,056 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=988 request_id=req_f7ea0922ad4d514efec180f6b724197f response_code=200
2025-06-20 12:11:07,462 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:07,462 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:07,462 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:07,469 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:07,605 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:11:07,609 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1761 request_id=req_50a8926a83e594ee17ac9b8f0c7e305c response_code=200
2025-06-20 12:11:08,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121108.wav, taille: 80339 bytes
2025-06-20 12:11:08,749 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121108.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:09,299 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:11:09,305 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1205 request_id=req_bcae68b2fd66c0ac55a760f5daa27134 response_code=200
2025-06-20 12:11:09,899 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:09,899 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:10,275 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:10,275 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:10,363 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:10,363 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:10,764 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:10,765 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:10,947 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:11:10,948 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=314 request_id=req_e6245449297f394d14202c5662760ee9 response_code=200
2025-06-20 12:11:11,066 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:11:11,069 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:11,449 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 12:11:11,449 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=774 request_id=req_04935a1837571e7b259e1cdb896b22a8 response_code=200
2025-06-20 12:11:11,543 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 12:11:11,545 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=890 request_id=req_eb2ec38b070ae5a0f625bda618e61ca7 response_code=200
2025-06-20 12:11:11,566 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:11:11,568 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:11,651 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:11:11,653 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:12,035 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:11:12,043 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1041 request_id=req_ca5c54c88ce62b9814a8ee7d38bedb38 response_code=200
2025-06-20 12:11:12,149 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:11:12,152 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:12,605 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:12,607 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:12,608 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:12,613 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:13,029 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:13,029 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:13,299 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121113.wav, taille: 80339 bytes
2025-06-20 12:11:13,849 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:11:13,900 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=507 request_id=req_25df183dbec5eb9382adf3f28c129e3c response_code=200
2025-06-20 12:11:14,015 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121113.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:14,379 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:11:14,389 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=907 request_id=req_eb65eec50a225c99f9e8511e869a7758 response_code=200
2025-06-20 12:11:14,528 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:11:14,532 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:17,959 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121117.wav, taille: 71645 bytes
2025-06-20 12:11:18,602 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:18,771 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:18,773 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:18,779 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:18,792 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:18,821 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:19,302 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121117.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:19,442 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121119.wav, taille: 25277 bytes
2025-06-20 12:11:19,769 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121119.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:19,957 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 12:11:19,958 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=961 request_id=req_ef87bdaef9e2ff1c4f4ec66ece445964 response_code=200
2025-06-20 12:11:20,079 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:11:20,079 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:21,629 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:11:21,629 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1381 request_id=req_c51631fcc5064d5077e550a47e429819 response_code=200
2025-06-20 12:11:22,493 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:22,494 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:22,496 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:22,506 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:22,986 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:22,986 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:11:22,987 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:22,991 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:23,968 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:11:23,972 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=869 request_id=req_f5b8c50b5b1ea2f58aeacb3c617140a9 response_code=200
2025-06-20 12:11:24,518 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 12:11:24,522 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=680 request_id=req_53152ea00518f0d812364df3282665a8 response_code=200
2025-06-20 12:11:24,829 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:24] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:11:24,908 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:24] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:11:24,978 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:24] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 12:11:25,463 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:25,464 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:25,478 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:25] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:11:26,851 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 12:11:26,851 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=852 request_id=req_b891fa0f97107bb21a4b245925077cee response_code=200
2025-06-20 12:11:26,965 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:11:26,969 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:27,233 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:27,234 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:27,870 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:11:27,871 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:11:27,950 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 12:11:27,950 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=485 request_id=req_b5fd1bb3d42a2c0daecad8ce4f79f2a0 response_code=200
2025-06-20 12:11:28,066 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:11:28,066 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627\\"\\n            Fran\\u00e7ais: \\"Merci.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:11:28,887 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:11:28,889 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=613 request_id=req_bc518fa439cb6a9faabd5a69b48d1c27 response_code=200
2025-06-20 12:11:29,001 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:11:29,005 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:29,429 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:11:29,477 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=144 request_id=req_d0639eca9bf48bf22c4b26ab9bc086a8 response_code=200
2025-06-20 12:11:29,578 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-20 12:11:30,076 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-20 12:11:30,076 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:11:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:11:31,334 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 12:11:41,629 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 12:11:41,644 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 12:11:42,302 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121142.wav, taille: 80339 bytes
2025-06-20 12:11:44,729 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 12:11:44,758 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:11:44,759 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:44,760 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:11:44,766 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 12:11:44,767 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:44,768 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 12:11:44,769 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:44,778 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 12:11:44,779 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:11:44,784 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 12:11:44,788 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:11:44,789 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 12:11:44,791 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:11:44,792 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 12:11:44,796 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:44,799 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 12:11:44,802 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 12:11:44,806 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 12:11:44,807 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 12:11:44,809 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 12:11:44,810 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 12:11:44,813 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 12:11:44,821 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 12:11:44,828 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 12:11:44,830 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 12:11:44,834 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 12:11:44,838 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 12:11:44,860 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 12:11:44,865 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 12:11:44,868 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 12:11:44,869 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 12:11:44,870 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 12:11:44,877 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 12:11:44,878 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 12:11:44,879 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 12:11:44,882 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 12:11:44,884 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 12:11:44,886 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:44,894 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:11:44,901 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 12:11:44,904 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 12:11:44,909 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 12:11:44,910 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 12:11:44,911 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 12:11:44,912 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:44,913 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:44,918 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:11:44,919 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:44,920 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 12:11:44,922 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 12:11:44,922 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:44,929 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:44,945 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 12:11:44,949 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:44,957 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 12:11:44,959 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 12:11:44,960 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:44,961 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 12:11:44,963 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 12:11:44,969 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 12:11:44,970 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 12:11:44,970 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 12:11:44,976 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 12:11:44,978 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 12:11:44,979 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:44,980 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 12:11:44,983 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 12:11:44,985 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 12:11:44,989 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 12:11:44,992 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 12:11:44,995 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 12:11:44,996 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 12:11:45,016 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 12:11:45,018 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 12:11:45,022 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 12:11:45,026 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 12:11:45,030 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 12:11:45,045 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 12:11:45,046 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 12:11:45,050 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 12:11:45,052 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:45,053 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 12:11:45,054 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 12:11:45,056 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:45,057 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 12:11:45,059 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 12:11:45,061 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:45,063 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:11:45,064 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 12:11:45,068 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 12:11:45,069 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 12:11:45,071 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 12:11:45,072 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 12:11:45,073 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 12:11:45,085 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 12:11:45,091 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 12:11:45,101 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:45,103 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:11:45,105 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 12:11:45,106 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 12:11:45,107 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 12:11:45,110 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 12:11:45,111 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 12:11:45,112 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:45,113 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:45,119 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:11:45,121 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:11:45,121 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:45,123 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 12:11:45,124 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 12:11:45,126 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:45,126 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:45,128 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 12:11:45,129 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:45,130 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 12:11:45,132 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 12:11:45,135 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:45,139 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 12:11:45,142 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 12:11:45,143 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:45,144 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 12:11:45,146 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 12:11:45,146 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:45,150 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 12:11:45,152 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 12:11:45,153 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:45,157 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 12:11:45,158 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 12:11:45,159 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:11:45,161 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:11:45,162 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:45,163 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 12:11:45,168 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 12:11:45,169 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:45,170 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 12:11:45,171 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 12:11:45,171 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 12:11:45,172 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 12:11:45,173 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 12:11:45,175 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 12:11:45,179 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 12:11:45,184 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 12:11:45,185 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 12:11:45,187 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 12:11:45,188 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 12:11:45,189 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 12:11:45,190 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 12:11:45,191 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 12:11:45,193 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 12:11:45,194 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 12:11:45,195 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 12:11:45,196 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 12:11:45,201 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:11:45,202 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:11:45,205 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:45,206 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 12:11:45,207 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 12:11:45,208 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:45,210 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 12:11:45,212 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 12:11:45,214 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 12:11:45,216 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 12:11:45,217 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 12:11:45,218 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 12:11:45,222 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 12:11:45,223 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 12:11:45,223 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 12:11:45,224 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 12:11:45,225 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 12:11:45,228 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 12:11:45,228 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 12:11:45,229 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 12:11:45,230 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 12:11:45,235 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 12:11:45,242 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 12:11:45,243 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 12:11:45,245 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:11:45,245 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:11:45,246 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:11:45,249 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 12:11:45,261 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 12:11:45,269 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 12:11:45,277 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 12:11:45,286 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 12:11:45,290 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 12:11:45,296 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:11:45,297 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 12:11:45,303 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 12:11:45,307 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 12:11:45,318 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 12:11:45,321 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 12:11:45,327 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 12:11:45,334 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 12:11:45,336 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 12:11:45,338 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 12:11:45,338 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 12:11:45,338 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 12:11:45,338 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:11:45,354 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:11:45,370 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 12:11:47,003 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121146.wav, taille: 80339 bytes
2025-06-20 12:11:48,924 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 12:11:48,974 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:11:48,994 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:49,011 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:11:49,042 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 12:11:49,058 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:49,073 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:11:49,097 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:49,176 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 12:11:49,278 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:11:49,291 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:11:49,293 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:11:49,295 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:11:49,296 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:11:49,305 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 12:11:49,311 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 12:11:49,325 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:11:49,327 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 12:11:49,328 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 12:11:49,329 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 12:11:49,344 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:11:49,356 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 12:11:49,358 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 12:11:49,360 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 12:11:49,361 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:11:49,368 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 12:11:49,374 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:11:49,375 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 12:11:49,376 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 12:11:49,377 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 12:11:49,378 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:11:49,380 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 12:11:49,393 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 12:11:49,394 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 12:11:49,395 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 12:11:49,395 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 12:11:49,401 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 12:11:49,409 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 12:11:49,411 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:11:49,412 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:11:49,424 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 12:11:49,426 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 12:11:49,428 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:11:49,429 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:11:49,433 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 12:11:49,439 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 12:11:49,441 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:11:49,443 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:11:49,461 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 12:11:49,522 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 12:11:49,579 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:11:49,592 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:11:49,593 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:11:49,594 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 12:11:49,595 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:49,595 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:11:49,596 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:11:49,606 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 12:11:49,608 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:11:49,611 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:11:49,613 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:11:49,625 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:11:49,626 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:11:49,628 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 12:11:49,629 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 12:11:49,641 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:11:49,642 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 12:11:49,643 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 12:11:49,644 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 12:11:49,646 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:11:49,651 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 12:11:49,657 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 12:11:49,661 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 12:11:49,673 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:11:49,677 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 12:11:49,678 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:11:49,679 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 12:11:49,680 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 12:11:49,688 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 12:11:49,690 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:11:49,691 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 12:11:49,692 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 12:11:49,695 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 12:11:49,697 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 12:11:49,708 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 12:11:49,709 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 12:11:49,710 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 12:11:49,712 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:11:49,723 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:11:49,725 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 12:11:49,726 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 12:11:49,728 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:11:49,734 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:11:49,742 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 12:11:49,743 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 12:11:49,744 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:11:49,745 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:11:49,761 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 12:11:52,330 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121152.wav, taille: 80339 bytes
2025-06-20 12:11:53,587 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121142.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:53,861 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121146.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:54,577 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121152.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:11:57,312 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:11:57,355 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u0636\\u0631\\u0646\\u064a \\u0643\\u0631\\u0634\\u064a \\u0648\\u0638\\u0647\\u0631\\u064a\\"\\n            Fran\\u00e7ais: \\"salami\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:11:57,522 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:11:57,720 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:11:57,793 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121157.wav, taille: 85169 bytes
2025-06-20 12:11:59,819 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:11:59,977 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=339 request_id=req_35304cab500c35f1a00a74ab587d9300 response_code=200
2025-06-20 12:12:00,637 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:02,142 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:02,654 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:02,655 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:02,716 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:02,719 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:02,734 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:02,861 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:02,925 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:02,954 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121157.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:03,359 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121203.wav, taille: 91931 bytes
2025-06-20 12:12:04,632 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:04,640 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=951 request_id=req_dc9fdc868fbac3b50317e14c0ae70ed3 response_code=200
2025-06-20 12:12:06,110 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121203.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:07,310 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121207.wav, taille: 63917 bytes
2025-06-20 12:12:08,072 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121207.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:08,221 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:08,241 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1649 request_id=req_ab42e36b0f57f0babda625b9a97b1e02 response_code=200
2025-06-20 12:12:10,723 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:10,777 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:11,376 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:11,386 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:11,388 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:11,398 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:12,039 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:12,070 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:12,156 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:12,234 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:12,257 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:12,262 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:12,278 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:12,300 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:12,310 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:12,338 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121212.wav, taille: 80339 bytes
2025-06-20 12:12:12,370 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:12,658 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:12:12,680 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1140 request_id=req_7bf02788295910074906f11b957e70dc response_code=200
2025-06-20 12:12:12,785 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:12,795 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=829 request_id=req_431b2788c3a28394d1b9f739659eb33d response_code=200
2025-06-20 12:12:13,326 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:13,962 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:13,975 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=673 request_id=req_3c14a735e6f725ddc3521dbd8c5ffa9a response_code=200
2025-06-20 12:12:14,161 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121212.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:14,554 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:14,573 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=437 request_id=req_78d1c2a3d549638fe45b9f68d3e99f11 response_code=200
2025-06-20 12:12:14,915 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 12:12:14,922 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1988 request_id=req_dd31db8291173c9605f7de4326e9cc60 response_code=200
2025-06-20 12:12:15,089 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:12:15,094 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:16,539 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:16,556 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:17,248 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:12:17,354 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0641\\u064a\\u0646 \\u0645\\u0634\\u064a\\u062a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628\\"\\n            Fran\\u00e7ais: \\"salam Kinshasa\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:12:17,424 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:17,438 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121217.wav, taille: 80339 bytes
2025-06-20 12:12:17,444 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:17,669 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:17,705 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:18,287 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:12:18,293 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1146 request_id=req_a0b054e87b03fd613341f9d0e13d8dd8 response_code=200
2025-06-20 12:12:18,304 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:12:18,308 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=266 request_id=req_7653999a9706448e81c662bce1e33145 response_code=200
2025-06-20 12:12:18,407 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:12:19,060 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 12:12:19,065 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121217.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:19,201 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:19,667 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=997 request_id=req_2078dcb750a9c31002954fa5c5494b70 response_code=200
2025-06-20 12:12:19,670 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:19,673 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:19,723 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:19,890 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:12:19,987 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:20,571 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 12:12:20,578 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=360 request_id=req_6f6cf96846127c44d94e511ec763bed0 response_code=200
2025-06-20 12:12:20,702 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:12:20,807 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:22,293 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121222.wav, taille: 80339 bytes
2025-06-20 12:12:22,889 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121222.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:23,989 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:12:23,990 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0627\\u0639\\u0637\\u0627\\u0646\\u064a\\"\\n            Fran\\u00e7ais: \\"d\'ann\\u00e9e des m\\u00e9dicaments\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:12:24,004 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:24,010 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:25,070 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:12:25,073 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=233 request_id=req_11ff981129769fcc88d883d619fa0361 response_code=200
2025-06-20 12:12:25,119 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:26,738 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:26,740 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:26,741 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:26,753 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:27,304 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121227.wav, taille: 80339 bytes
2025-06-20 12:12:27,820 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121227.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:28,272 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:28,277 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=668 request_id=req_d3491d4f19fcdd2779711567e62bbe19 response_code=200
2025-06-20 12:12:31,823 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:31,836 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:31,836 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:31,841 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:32,301 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121232.wav, taille: 80339 bytes
2025-06-20 12:12:32,745 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121232.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:34,011 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:34,027 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:34,503 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:34,506 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1163 request_id=req_583bb537f2b9112e16e5edf55ed1665a response_code=200
2025-06-20 12:12:36,457 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:36,457 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:36,457 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:36,467 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:37,292 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121237.wav, taille: 80339 bytes
2025-06-20 12:12:37,381 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 28
2025-06-20 12:12:37,386 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=3089 request_id=req_e8509ad356d4e4fbee6ced4a8040191c response_code=200
2025-06-20 12:12:37,496 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:12:37,498 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Fran\\u00e7ais: \\"un peu de ciment.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:12:37,750 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121237.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:37,986 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:12:37,986 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=222 request_id=req_fe43ec4c5998e3e5b335f9875fbc67c2 response_code=200
2025-06-20 12:12:38,024 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:38,083 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:38,084 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:38,181 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:38,183 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=524 request_id=req_4aab407c2649dbd48da7507961131dd6 response_code=200
2025-06-20 12:12:39,106 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:12:39,112 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=324 request_id=req_c41dd20181520ec6d5d81e415abe508a response_code=200
2025-06-20 12:12:39,229 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:12:39,232 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:41,303 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:41,304 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:41,305 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:41,314 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:42,288 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121242.wav, taille: 80339 bytes
2025-06-20 12:12:42,385 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:42,394 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:42,771 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121242.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:43,306 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:12:43,306 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=477 request_id=req_b9b46d1c3055e67c8597ca50b14cf511 response_code=200
2025-06-20 12:12:43,432 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:12:43,433 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:43,616 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_121243.wav, taille: 21413 bytes
2025-06-20 12:12:43,929 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_121243.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:12:45,116 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 12:12:45,129 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2593 request_id=req_7ea70cd32ff030956dfc3642bb89320c response_code=200
2025-06-20 12:12:46,275 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:46,276 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:46,278 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:46,286 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:46,328 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:46,334 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:12:46,335 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:12:46,339 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:12:47,250 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:47,252 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=618 request_id=req_c69d8595021356c74333fd76cfd5bf76 response_code=200
2025-06-20 12:12:48,567 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:12:48,567 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=889 request_id=req_11d35f848c56c0f60347fa4dc127b0ab response_code=200
2025-06-20 12:12:49,392 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:49,397 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:49,575 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:49,576 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:50,556 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:12:50,562 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:12:50,563 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=717 request_id=req_1c940a67565c201b722e0c51230c47bf response_code=200
2025-06-20 12:12:50,566 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=723 request_id=req_39f57158e1306cbe3237725bb94a997d response_code=200
2025-06-20 12:12:50,675 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:12:50,677 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:12:50,693 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627\\"\\n            Fran\\u00e7ais: \\"Voil\\u00e0. Et voil\\u00e0. C\'est bon. C\'est bon. C\'est bon.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:12:50,754 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:51,397 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:12:51,407 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=417 request_id=req_c5f140e58fdbce98f92492924fb99c6e response_code=200
2025-06-20 12:12:51,476 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:12:52,220 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:12:52,221 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:12:54,234 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:12:54,234 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1312 request_id=req_22510d436ca42bb3170ee01ae322b54b response_code=200
2025-06-20 12:12:54,346 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:12:54,349 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:12:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:20:14,602 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:20:14] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:20:14,677 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:20:14] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:20:14,810 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:20:14] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 12:20:15,209 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:20:15] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:21:57,310 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:21:57] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:21:57,390 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:21:57] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:21:57,401 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:21:57] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 12:21:57,789 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:21:57] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:23:45,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122345.wav, taille: 80339 bytes
2025-06-20 12:23:46,003 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122345.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:23:50,483 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122350.wav, taille: 80339 bytes
2025-06-20 12:23:50,907 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122350.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:23:52,373 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:23:52,374 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:23:52,374 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:23:52,378 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:23:54,499 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:23:54,503 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1074 request_id=req_a643ec80a622cd9fd53ad1df34a2aefc response_code=200
2025-06-20 12:23:54,617 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:23:54,618 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0643\\u0631\\u0634\\u064a \\u0648\\u0638\\u0647\\u0631\\u064a \\u0647\\u0630\\u0647 \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Fran\\u00e7ais: \\"Salut, je suis dans mon quartier d\'h\\u00f4tel cette semaine.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:23:54,905 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:23:54,906 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:23:54,907 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:23:54,910 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:23:55,283 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:23:55,313 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=401 request_id=req_34123408c79b181d30a35a8ef76407d1 response_code=200
2025-06-20 12:23:55,341 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:23:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:23:55,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122355.wav, taille: 80339 bytes
2025-06-20 12:23:55,903 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122355.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:23:57,681 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:23:57,683 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1283 request_id=req_1ef3db9b7ea86872ae46eb2bfb1d6125 response_code=200
2025-06-20 12:24:00,354 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:00,355 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:00,357 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:00,357 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:00,453 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:24:00,453 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0642\\u0646\\u0634 \\u0633\\u0627\\u0646\\u062a\\u0648\\u0628\\u064a\\u0644 \\u0628\\u0648\\u0637\\u0627\\u0646\\u0648 \\u064a\\u0648\\u062a\\u064a\\u0648\\u0645 \\u0627\\u064a\\u062f\\u064a\\u0643\\u0645\\u0648\\"\\n            Fran\\u00e7ais: \\"des m\\u00e9dicaments\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:24:00,486 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122400.wav, taille: 80339 bytes
2025-06-20 12:24:00,903 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122400.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:00,968 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:24:00,971 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=236 request_id=req_d7fa6d5248f41db7b69bd876c9e48956 response_code=200
2025-06-20 12:24:01,024 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:02,093 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:24:02,100 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=767 request_id=req_2a8b1061a2f3e0bdd99b2806ce017a86 response_code=200
2025-06-20 12:24:05,273 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:05,273 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:05,278 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:05,285 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:05,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122405.wav, taille: 80339 bytes
2025-06-20 12:24:05,990 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122405.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:07,293 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:24:07,293 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=619 request_id=req_26d3faa80223fc52f2d54f0d340435d0 response_code=200
2025-06-20 12:24:08,053 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:08,054 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:10,423 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:24:10,433 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1780 request_id=req_ce105f425642bae2ef584f17400187c7 response_code=200
2025-06-20 12:24:10,468 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122410.wav, taille: 80339 bytes
2025-06-20 12:24:10,548 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:24:10,553 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Fran\\u00e7ais: \\"On est enfin \\u00e0 10h00 et on verra la s\\u00e9curit\\u00e9 ?\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:24:10,915 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122410.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:11,142 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:11,143 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:11,348 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:24:11,349 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=259 request_id=req_e558bf9851ad6e5a7a538a457bd20faf response_code=200
2025-06-20 12:24:11,382 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:11,423 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:11,428 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:11,430 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:11,444 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:14,683 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:24:14,683 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2977 request_id=req_e53da6fe52c1c5a3c7f0798164d72d54 response_code=200
2025-06-20 12:24:14,753 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:14,753 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:14,754 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:14,758 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:14,793 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:24:14,793 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:15,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122415.wav, taille: 80339 bytes
2025-06-20 12:24:15,906 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122415.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:16,283 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 12:24:16,283 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=845 request_id=req_a48f7be1819379d1b3412f7cde8d42c0 response_code=200
2025-06-20 12:24:17,025 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:24:17,031 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2421 request_id=req_1e5cb9db8c36ab713c183f250cb53838 response_code=200
2025-06-20 12:24:20,000 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:20,005 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:20,005 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:20,011 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:20,108 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:20,108 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:20,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122420.wav, taille: 80339 bytes
2025-06-20 12:24:20,774 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:20,786 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:21,275 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122420.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:21,526 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:24:21,528 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=838 request_id=req_5ef05ca8c03f6dab52dbfe9e6dbab7d2 response_code=200
2025-06-20 12:24:21,633 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:24:21,633 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627\\"\\n            Fran\\u00e7ais: \\"C\'est la chambre de base. Voil\\u00e0, c\'est la chambre priv\\u00e9e.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:24:22,003 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:24:22,003 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=219 request_id=req_37a333ae75923177f8b0a9de16bf52f6 response_code=200
2025-06-20 12:24:22,043 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:23,798 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:24:23,803 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2676 request_id=req_d35e0f320e1502210b8f528562830fe7 response_code=200
2025-06-20 12:24:23,915 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:24:23,915 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:24,612 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:24,615 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:24,617 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:24,624 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:25,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122425.wav, taille: 80339 bytes
2025-06-20 12:24:25,906 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122425.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:26,123 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 39
2025-06-20 12:24:26,127 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=4911 request_id=req_cd6efc284fb7d7df671d01eff23f21f1 response_code=200
2025-06-20 12:24:26,237 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:24:26,237 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=818 request_id=req_ccd56c218caa96251dfa8b9f6ef151ad response_code=200
2025-06-20 12:24:28,558 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:28,560 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:29,254 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:29,254 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:29,261 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:29,267 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:29,739 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:29,740 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:29,745 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:24:29,754 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=940 request_id=req_655c9052f1017f1a75ecfc0b66b82897 response_code=200
2025-06-20 12:24:29,864 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:24:29,864 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:30,479 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122430.wav, taille: 80339 bytes
2025-06-20 12:24:31,188 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122430.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:31,367 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 33
2025-06-20 12:24:31,376 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1078 request_id=req_67b490cb16b94717ef4b91c6a6d426d4 response_code=200
2025-06-20 12:24:31,498 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:24:31,498 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0646\\u0639\\u0645 \\u062e\\u0637\\u064a\\u0637. \\u0633\\u0627\\u0639\\u062a\\u064a.\\"\\n            Fran\\u00e7ais: \\"Eh bien, \\u00e7a c\'est....\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:24:32,063 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:24:32,065 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=891 request_id=req_1df67d3bb0e652a759e72db1cc0ade2d response_code=200
2025-06-20 12:24:32,066 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:24:32,071 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=295 request_id=req_f808e531926769ac550fa35cc0e772dc response_code=200
2025-06-20 12:24:32,114 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:34,837 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:34,843 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:34,843 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:34,850 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:35,056 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:35,056 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:35,489 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122435.wav, taille: 80339 bytes
2025-06-20 12:24:35,952 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122435.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:36,181 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:24:36,193 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=797 request_id=req_fac74d0290ae9eb76439438af850214c response_code=200
2025-06-20 12:24:36,499 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:24:36,503 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=992 request_id=req_91424f48eb96a03a8e15f189669b0ee6 response_code=200
2025-06-20 12:24:36,614 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:24:36,618 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:39,766 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:39,774 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:39,794 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:39,803 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:39,807 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:39,816 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:40,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122440.wav, taille: 80339 bytes
2025-06-20 12:24:40,918 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122440.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:41,249 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:24:41,249 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1039 request_id=req_8534fafd02b030e3c618a6984cf679a2 response_code=200
2025-06-20 12:24:41,253 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:24:41,260 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=627 request_id=req_365ffe64c53a7249d43fb2e4ea92287a response_code=200
2025-06-20 12:24:41,363 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:24:41,363 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:44,207 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:44,207 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:44,497 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:44,498 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:44,499 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:44,505 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:45,474 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122445.wav, taille: 80339 bytes
2025-06-20 12:24:45,835 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:24:45,839 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=819 request_id=req_6792020703f6172eb118f841e7bd0a84 response_code=200
2025-06-20 12:24:45,905 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122445.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:46,104 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 31
2025-06-20 12:24:46,104 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1177 request_id=req_a021b4af1579bb6543acfa507941eb40 response_code=200
2025-06-20 12:24:46,232 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:24:46,237 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:49,391 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:49,392 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:49,393 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:49,469 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:49,688 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:49,696 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:50,473 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122450.wav, taille: 80339 bytes
2025-06-20 12:24:50,909 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122450.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:51,297 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:24:51,299 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1263 request_id=req_4ea83eaa3d2b7a5c8e44b402f3915c84 response_code=200
2025-06-20 12:24:51,414 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:24:51,414 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:24:54,373 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:54,376 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:24:54,391 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:24:54,412 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:24:55,774 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:24:55,812 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=600 request_id=req_a043324664fb2abad932cbd91049a813 response_code=200
2025-06-20 12:24:56,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122456.wav, taille: 93863 bytes
2025-06-20 12:24:57,323 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122456.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:24:58,498 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:24:58,504 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:24:59,303 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:24:59,305 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=527 request_id=req_0849a893cbfdc6f5ca696d0764426170 response_code=200
2025-06-20 12:24:59,414 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:24:59,419 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:24:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:25:01,184 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:01,185 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:25:01,186 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:25:01,190 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:25:01,283 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122501.wav, taille: 80339 bytes
2025-06-20 12:25:01,683 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122501.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:25:02,569 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:25:02,570 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=657 request_id=req_9cab2adc98cf15aff660207ceca2f4cc response_code=200
2025-06-20 12:25:04,574 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:04,575 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:25:04,576 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:25:04,581 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:25:04,988 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:04,988 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:25:05,847 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:25:05,851 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=600 request_id=req_deee15fc929509324329bba7d216c453 response_code=200
2025-06-20 12:25:06,303 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122506.wav, taille: 80339 bytes
2025-06-20 12:25:06,915 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122506.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:25:07,413 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:25:07,425 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2136 request_id=req_1b662bbc4369c9a42434eb5a0dd2d9a9 response_code=200
2025-06-20 12:25:07,533 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:25:07,533 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:25:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:25:07,926 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:07,926 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:25:08,846 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:25:08,853 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=540 request_id=req_b3effa24c39fc547fb1817f146cdea32 response_code=200
2025-06-20 12:25:08,964 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:25:08,967 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:25:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:25:09,474 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:09,475 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:25:09,475 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:25:09,480 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:25:11,349 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122511.wav, taille: 80339 bytes
2025-06-20 12:25:12,366 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122511.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:25:15,308 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:15,309 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:25:15,312 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:25:15,319 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:25:16,283 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122516.wav, taille: 79373 bytes
2025-06-20 12:25:16,743 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122516.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:25:17,140 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:25:17,142 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=820 request_id=req_46cd176f1420b0a4bd353e31a9706093 response_code=200
2025-06-20 12:25:19,487 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:19,508 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:25:20,303 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:20,303 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:25:20,313 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:25:20,322 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:25:20,468 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122520.wav, taille: 66815 bytes
2025-06-20 12:25:20,703 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_122520.wav, taille: 3059 bytes
2025-06-20 12:25:20,933 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122520.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:25:21,147 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_122520.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:25:21,272 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:25:21,276 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1489 request_id=req_0a14bab4248a8f69d1ce13a177e9d734 response_code=200
2025-06-20 12:25:21,395 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:25:21,397 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:25:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:25:21,896 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:25:21,899 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=12020 request_id=req_a9bdb92d33296ea43710771a6b62defe response_code=200
2025-06-20 12:25:22,006 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:25:22,008 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1214 request_id=req_8c633e122aa21f7503c3935b3313970a response_code=200
2025-06-20 12:25:23,053 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:23,054 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:25:23,055 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:25:23,065 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:25:23,503 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:23,503 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:25:23,510 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:25:23,519 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:25:24,235 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:24,236 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:25:24,282 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:24,283 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:25:25,145 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:25:25,149 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=538 request_id=req_33c2db6de88919711149b7371529b77e response_code=200
2025-06-20 12:25:25,283 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:25:25,283 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:25:25,283 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=677 request_id=req_062a923e45d401693c8a34d4b1df9b14 response_code=200
2025-06-20 12:25:25,283 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1135 request_id=req_fd5bd4cd33cb490aedf1c31dcd20508d response_code=200
2025-06-20 12:25:25,396 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:25:25,398 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:25:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:25:25,784 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:25:25,804 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1273 request_id=req_fd0c6d08aa31dd435f9890ca67d2d29c response_code=200
2025-06-20 12:25:25,911 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:25:25,916 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:25:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:25:26,959 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:26,960 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:25:27,723 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:25:27,733 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:25:28,447 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:25:28,453 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=955 request_id=req_2a04971d0bda1a581580cd6e5db9031e response_code=200
2025-06-20 12:25:28,568 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:25:28,580 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:25:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:25:28,753 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:25:28,773 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=857 request_id=req_d781a6343b90c8bd100dd6026803299e response_code=200
2025-06-20 12:25:28,891 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:25:28,896 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:25:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:30:25,284 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:30:25] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:30:25,367 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:30:25] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:30:25,454 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:30:25] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 12:30:25,865 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:30:25] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:30:44,306 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:30:44,307 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:30:44,308 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:30:44,315 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:30:44,316 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:30:44,317 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC024DF10>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:30:44,319 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 12:30:44,320 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:30:44,322 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC024DCA0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:30:44,336 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 12:30:44,462 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:30:44,463 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:30:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:34:57,724 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123457.wav, taille: 80339 bytes
2025-06-20 12:34:58,164 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123457.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:35:01,264 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:35:01,264 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0643\\u0631\\u0634\\"\\n            Fran\\u00e7ais: \\"salam Kader nid d\'amour\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:35:01,273 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:35:01,280 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:35:02,037 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:35:02,037 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=350 request_id=req_bdfd6934349e97545619e525ff00d3df response_code=200
2025-06-20 12:35:02,080 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:35:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:35:02,723 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123502.wav, taille: 80339 bytes
2025-06-20 12:35:03,149 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123502.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:35:06,482 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:35:06,483 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0637\\u0628\\u064a\\u0628 \\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647\\"\\n            Fran\\u00e7ais: \\"brocante escalier Argento\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:35:06,487 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:35:06,494 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:35:07,044 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:35:07,049 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=223 request_id=req_59b330b2009667a7189d967fc45e5d43 response_code=200
2025-06-20 12:35:07,098 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:35:07] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:35:07,414 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123507.wav, taille: 80339 bytes
2025-06-20 12:35:07,823 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123507.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:35:10,802 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:35:10,803 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:35:10,804 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:35:10,814 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:35:12,439 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:35:12,444 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=933 request_id=req_026430be7d03df396ac2f1878f25cd78 response_code=200
2025-06-20 12:35:12,725 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123512.wav, taille: 80339 bytes
2025-06-20 12:35:13,147 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123512.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:35:15,185 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:35:15,187 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:35:15,274 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123515.wav, taille: 40733 bytes
2025-06-20 12:35:15,569 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123515.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:35:15,619 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:35:15,621 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:35:15,622 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:35:15,627 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:35:17,555 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:35:17,555 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=870 request_id=req_2241ebdbdd93364219eb3448bb9a681d response_code=200
2025-06-20 12:35:19,716 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:35:19,717 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:35:19,718 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:35:19,723 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:35:20,439 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:35:20,439 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:35:21,186 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:35:21,189 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=469 request_id=req_51eef8142c1727f6b0a0d9ba89e7d3f3 response_code=200
2025-06-20 12:35:21,300 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:35:21,302 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:35:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:35:21,804 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:35:21,804 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=993 request_id=req_57d92df6b22c261a3047a682b67b630c response_code=200
2025-06-20 12:35:24,844 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:35:24,845 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:35:26,094 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:35:26,094 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=771 request_id=req_858fb7078ec7191536d4ebb8c27a3917 response_code=200
2025-06-20 12:35:26,216 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:35:26,216 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:35:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:35:34,234 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:35:34,234 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=18796 request_id=req_b888e52e69bb5857ac1c5cf7837f1e0f response_code=200
2025-06-20 12:35:34,355 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:35:34,357 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:35:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:35:59,784 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:35:59] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:35:59,876 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:35:59] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:35:59,878 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:35:59] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 12:36:00,251 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:36:00] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:37:28,136 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123728.wav, taille: 80339 bytes
2025-06-20 12:37:30,825 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123728.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:37:32,831 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123732.wav, taille: 80339 bytes
2025-06-20 12:37:33,331 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123732.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:37:36,470 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:36,470 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:37:36,478 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:37:36,486 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:37:37,424 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:37,424 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:37:37,425 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:37:37,436 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:37:38,136 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123738.wav, taille: 80339 bytes
2025-06-20 12:37:38,650 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123738.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:37:38,884 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:37:38,884 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=639 request_id=req_ebcb3eacf06a3e2a90a7b560c5a0fd36 response_code=200
2025-06-20 12:37:39,520 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:37:39,520 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1721 request_id=req_e96d0b23e06dae699660c5328fe00665 response_code=200
2025-06-20 12:37:42,713 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:42,713 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:37:42,733 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:42,735 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:37:42,736 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:37:42,741 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:37:43,130 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123743.wav, taille: 80339 bytes
2025-06-20 12:37:43,597 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:43,599 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:37:43,630 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123743.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:37:44,455 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:37:44,463 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=703 request_id=req_304e4b5db724d1b9f10e924573656ff2 response_code=200
2025-06-20 12:37:44,536 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:37:44,537 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1503 request_id=req_1d6f27a1a0ccbdb92d65188ec9dea2f3 response_code=200
2025-06-20 12:37:44,644 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:37:44,644 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:37:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:37:46,931 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:37:46,931 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2759 request_id=req_86f16dc9c210b7b951d013d4b8c9b39f response_code=200
2025-06-20 12:37:47,044 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:37:47,044 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0646\\u0631\\u0649 \\u0645\\u0627\\u0630\\u0627 \\u0646\\u0641\\u0639\\u0644 \\u0628\\u0639\\u062f \\u0630\\u0644\\u0643 \\u0646\\u0631\\u0649 \\u0645\\u0627 \\u064a\\u062c\\u0628 \\u0623\\u0646 \\u0646\\u0641\\u0639\\u0644 \\u0646\\u0642\\u0633\\u0637\\"\\n            Fran\\u00e7ais: \\"Sous-titres r\\u00e9alis\\u00e9s para la communaut\\u00e9 d\'Amara.org\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:37:47,552 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:47,552 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:37:47,552 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:37:47,552 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:37:47,744 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:37:47,744 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=314 request_id=req_e6c52acc504f5d9d71fe181046ea3542 response_code=200
2025-06-20 12:37:47,786 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:47,795 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:37:47,798 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:37:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:37:48,131 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123748.wav, taille: 80339 bytes
2025-06-20 12:37:48,585 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123748.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:37:49,485 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:37:49,487 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=636 request_id=req_fb05d3b18d01c145cf76412c95b09811 response_code=200
2025-06-20 12:37:51,014 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:37:51,016 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2807 request_id=req_1f449d002c7581c6d273d2558cd4f35b response_code=200
2025-06-20 12:37:51,121 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:37:51,122 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0639\\u0646\\u062f\\u0646\\u0627 \\u0645\\u0634\\u0643\\u0644 \\u0643\\u0628\\u064a\\u0631 \\u0628\\u0627\\u0644\\u0645\\u062e\\u062a\\u0644\\u0627\\u0644\\u0627\\u062a \\u0627\\u0644\\u063a\\u0636\\u0628 \\u0627\\u0644\\u0636\\u0631\\u0641\\u064a\\u0629\\"\\n            Fran\\u00e7ais: \\"On a beaucoup de soucis envers la \\uc774\\uac70\\ub97c.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:37:51,644 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:37:51,679 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=316 request_id=req_c3f5fe447ae047cdd4364284942fe85d response_code=200
2025-06-20 12:37:51,708 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:37:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:37:52,095 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:52,097 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:37:52,601 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:52,603 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:37:52,604 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:37:52,616 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:37:52,994 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:37:53,001 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=485 request_id=req_639ec0f4e7c0fd0f72b06296712c869c response_code=200
2025-06-20 12:37:53,110 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:37:53,110 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:37:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:37:53,136 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123753.wav, taille: 80339 bytes
2025-06-20 12:37:53,621 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123753.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:37:55,356 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:37:55,356 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2063 request_id=req_8fd76190463aaf8748bb57b08cf9d039 response_code=200
2025-06-20 12:37:57,871 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:37:57,871 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:37:57,871 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:37:57,879 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:37:58,134 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123758.wav, taille: 80339 bytes
2025-06-20 12:37:58,599 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123758.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:38:00,235 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:00,236 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:38:02,560 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:38:02,561 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:38:02,562 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1655 request_id=req_d20dadc8b3d3824335a75dd7ae4ac841 response_code=200
2025-06-20 12:38:02,565 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1289 request_id=req_32a6b457127a261dd451dc3a54f60f1f response_code=200
2025-06-20 12:38:02,710 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:02] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:38:03,131 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123803.wav, taille: 80339 bytes
2025-06-20 12:38:03,499 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:03,500 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:38:03,503 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:03,520 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:38:03,683 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123803.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:38:06,771 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:06,772 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:38:06,773 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:06,778 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:38:06,839 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:06,840 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:38:08,131 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123808.wav, taille: 80339 bytes
2025-06-20 12:38:08,601 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:38:08,606 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=982 request_id=req_e4ef0f4299ab235f56e8fc25d8a31c90 response_code=200
2025-06-20 12:38:08,606 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123808.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:38:08,631 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:38:08,636 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=863 request_id=req_2d7e333ed2876ce87090a9f501f68933 response_code=200
2025-06-20 12:38:08,712 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:38:08,712 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0644\\u0643\\u0646 \\u0636\\u0631\\u0648\\u0631\\u064a \\u0623\\u0646 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\\u0627\\u062a \\u0643\\u0644\\u0647\\u0627 \\u0645\\u0645\\u064a\\u0632\\u0629\\"\\n            Fran\\u00e7ais: \\"mais c\'est n\\u00e9cessaire que toutes ces marques puissent fonctionner.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:38:09,161 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:38:09,161 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=253 request_id=req_cd32f2d1c7925a53c0cc2a889c7e49bd response_code=200
2025-06-20 12:38:09,206 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:38:09,542 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:38:09,543 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=5186 request_id=req_9fa6900786392131ea1532777ca6d1c6 response_code=200
2025-06-20 12:38:12,462 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:12,463 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:38:13,130 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123813.wav, taille: 80339 bytes
2025-06-20 12:38:13,315 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:38:13,321 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=643 request_id=req_97dceb557e26d099932ba0c076849cc3 response_code=200
2025-06-20 12:38:13,339 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:13,340 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:38:13,343 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:13,357 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:38:13,446 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:38:13,447 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0645\\u0635\\u0637\\u0641\\u0649 \\u064a\\u0628\\u062f\\u0623 \\u0628\\u062c\\u0639\\u0644 \\u0627\\u0644\\u0634\\u062c\\u0631\\u0629 \\u0639\\u0644\\u0649 \\u0634\\u0643\\u0644 \\u062a\\u062a\\u0644\\u0642\\u0649.\\"\\n            Fran\\u00e7ais: \\"C\'est ce qu\'il y a, c\'est ce qu\'il y a, c\'est ce qu\'il y a.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:38:13,715 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123813.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:38:13,782 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:13,786 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:38:14,061 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:38:14,070 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=370 request_id=req_84789e5dc4a35de0eb56a5c2b81a4b11 response_code=200
2025-06-20 12:38:14,100 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:38:16,486 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:38:16,488 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1553 request_id=req_ec68240f2cf5645314386f639dc986cf response_code=200
2025-06-20 12:38:16,593 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:38:16,594 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0623\\u0631\\u064a\\u062f \\u0623\\u0646 \\u0623\\u062e\\u0644\\u0635 \\u0645\\u0646 \\u0645\\u0634\\u0643\\u0644\\u0629 \\u0627\\u0644\\u0625\\u0646\\u0641\\u062c\\u0627\\u0631\\"\\n            Fran\\u00e7ais: \\"Je dois \\u00e9liminer un probl\\u00e8me import\\u00e9 au B\\u00e9b\\u00e9.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:38:17,428 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:38:17,486 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=652 request_id=req_5cbceee69fc200462186a5e52fb7eb08 response_code=200
2025-06-20 12:38:17,521 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:38:17,625 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:17,626 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:38:17,629 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:17,636 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:38:18,131 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123818.wav, taille: 80339 bytes
2025-06-20 12:38:18,421 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:38:18,428 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=4327 request_id=req_28603a96fe1782aa106ecdcafc92aff6 response_code=200
2025-06-20 12:38:18,535 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123818.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:38:22,960 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123822.wav, taille: 77441 bytes
2025-06-20 12:38:23,363 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123822.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:38:25,387 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:25,387 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:38:25,389 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:25,397 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:38:25,403 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:25,410 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC021A310>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:25,417 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 12:38:25,421 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:25,427 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC0247790>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:25,436 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 12:38:25,515 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:25,516 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:38:25,521 - urllib3.connectionpool - DEBUG - Resetting dropped connection: api.openai.com
2025-06-20 12:38:25,526 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:25,527 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC022A400>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:25,531 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 12:38:25,533 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:25,535 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC020A250>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:25,536 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 12:38:25,664 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:38:26,025 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:26,025 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:38:26,031 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:26,036 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:38:26,036 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:26,039 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC028FD00>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:26,040 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 12:38:26,042 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:26,043 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC028F370>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:26,046 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 12:38:26,115 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:26,116 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:38:26,127 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 12:38:26,129 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:26,131 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC028FC40>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:26,132 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 12:38:26,134 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:26,135 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC028FF40>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:26,137 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 12:38:26,256 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:38:26,258 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:38:26,735 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:26,736 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:38:26,740 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 12:38:26,743 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:26,746 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC0204640>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:26,748 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 12:38:26,749 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:26,750 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC020A520>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:26,751 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 12:38:26,858 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:38:26,860 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:38:27,291 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:38:27,292 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:38:27,297 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 12:38:27,299 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:27,300 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC0285610>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:27,301 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 12:38:27,302 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:38:27,303 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001BBC02853D0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 12:38:27,304 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 12:38:27,422 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:38:27,425 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:38:40,632 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:40] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:38:40,722 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:40] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:38:40,796 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:40] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 12:38:41,209 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:38:41] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:39:09,649 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123909.wav, taille: 80339 bytes
2025-06-20 12:39:10,107 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123909.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:13,474 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:39:13,474 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u064a\\u0646 \\u0634\\u064a \\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u062d\\u064a\\u062a \\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0638\\u0647\\"\\n            Fran\\u00e7ais: \\"salam \\u00e0 laquelle cette semaine\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:39:13,474 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:13,484 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:14,319 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:39:14,323 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=299 request_id=req_21499aa66b12d578b3668b6c5c274319 response_code=200
2025-06-20 12:39:14,345 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123914.wav, taille: 80339 bytes
2025-06-20 12:39:14,385 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:39:14,944 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123914.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:19,649 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123919.wav, taille: 80339 bytes
2025-06-20 12:39:20,084 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123919.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:21,284 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:21,285 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:39:21,285 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:21,298 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:24,649 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123924.wav, taille: 80339 bytes
2025-06-20 12:39:25,084 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123924.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:26,440 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:39:26,444 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1391 request_id=req_909ea763b2f0056f56faf1936d655c00 response_code=200
2025-06-20 12:39:26,556 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:39:26,556 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0634\\u0627\\u0641 \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0639\\u0646\\u0642 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0648\\u0644\\u0642\\"\\n            Fran\\u00e7ais: \\"et j\'ai vu sa t\\u00eate dans l\'encre et j\'ai cru que c\'\\u00e9tait elle.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:39:26,994 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:39:26,994 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=207 request_id=req_9e551e705a348e4b49e11f96241cda3e response_code=200
2025-06-20 12:39:27,029 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:39:27,445 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:27,446 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:39:27,446 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:27,446 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:28,892 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:28,893 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:39:28,894 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:28,903 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:29,654 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123929.wav, taille: 80339 bytes
2025-06-20 12:39:30,227 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123929.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:30,268 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:39:30,284 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2010 request_id=req_c788d4451bd3cf6c38162f26832fc7a9 response_code=200
2025-06-20 12:39:30,428 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:39:32,307 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 38
2025-06-20 12:39:32,308 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2382 request_id=req_49bf837ac56e2a675d1d601c7dfe9d64 response_code=200
2025-06-20 12:39:33,664 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:33,664 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:39:33,671 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:33,678 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:34,644 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123934.wav, taille: 80339 bytes
2025-06-20 12:39:35,094 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123934.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:35,278 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:39:35,280 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=651 request_id=req_f09cd6154e2de9aae70586b1fa5d53c3 response_code=200
2025-06-20 12:39:36,584 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:36,585 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:39:37,794 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 38
2025-06-20 12:39:37,794 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=560 request_id=req_41caf11b6e84cc1d11d79e1f72eccce9 response_code=200
2025-06-20 12:39:37,826 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:37,827 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:39:37,908 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:39:37,908 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u062f\\u064a\\u0627\\u0646\\u064a \\u0643\\u064a\\u0645\\u0628\\u0627\\u0644\\u0627\\u062a\\"\\n            Fran\\u00e7ais: \\"D\'y aller, qui me l\'a dit ?\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:39:38,557 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:39:38,562 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=213 request_id=req_917d353fad076477682e7e4fcca58c2e response_code=200
2025-06-20 12:39:38,565 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:38,567 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:39:38,591 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:38,592 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:39:38,613 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:39,290 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:39:39,294 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=849 request_id=req_0da5504d6cc40d3796f13b81f2823e2b response_code=200
2025-06-20 12:39:39,406 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:39:39,406 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:39:39,645 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123939.wav, taille: 80339 bytes
2025-06-20 12:39:40,089 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123939.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:40,804 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:39:40,807 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1054 request_id=req_a9179cf8ca3a27a44abfb25977af1f0c response_code=200
2025-06-20 12:39:43,194 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:43,204 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:39:43,206 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:43,214 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:43,249 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:43,249 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:39:43,858 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:39:43,858 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=329 request_id=req_dc4be76cab1f8205bd9916e729132cf0 response_code=200
2025-06-20 12:39:43,973 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:39:43,974 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:39:44,644 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123944.wav, taille: 80339 bytes
2025-06-20 12:39:44,824 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:39:44,832 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=648 request_id=req_904856245e2bf832ff3dee3611b6f6e4 response_code=200
2025-06-20 12:39:45,124 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123944.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:48,419 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:48,431 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:39:48,452 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:48,454 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:39:48,462 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:48,467 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:49,654 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123949.wav, taille: 80339 bytes
2025-06-20 12:39:50,068 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123949.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:51,064 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:39:51,064 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2097 request_id=req_180744db7d30ae4954a3272559e39385 response_code=200
2025-06-20 12:39:51,265 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:39:51,279 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2418 request_id=req_85003cb567bf85733d023215db2c8719 response_code=200
2025-06-20 12:39:51,391 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:39:51,394 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:39:54,329 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:54,329 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:39:54,333 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:54,344 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:54,578 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_123954.wav, taille: 79373 bytes
2025-06-20 12:39:54,926 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:54,928 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:39:55,090 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_123954.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:39:56,052 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:39:56,056 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=473 request_id=req_501c1e0a00daf7d4751cdd7f09e2e8eb response_code=200
2025-06-20 12:39:57,607 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:39:57,607 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2323 request_id=req_720ec74168e6f9e3e39b9728cc197f0e response_code=200
2025-06-20 12:39:57,723 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:39:57,726 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:39:57,922 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:57] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:39:58,022 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:58] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:39:58,027 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:58] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 12:39:58,392 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:58,393 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:39:58,394 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:39:58,403 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:39:58,516 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:58] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:39:58,695 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:39:58,696 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:39:59,744 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:39:59,755 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=639 request_id=req_f40accf08a9b1098b6fdaa1b103495c2 response_code=200
2025-06-20 12:39:59,871 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:39:59,871 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:39:59] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:40:00,055 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:40:00,055 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1155 request_id=req_4714ee5cc5c5775e63600241e4e10234 response_code=200
2025-06-20 12:40:02,587 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:40:02,587 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:40:03,930 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:40:03,930 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=648 request_id=req_1a9749b2619da375dc25244eb2b05ee0 response_code=200
2025-06-20 12:40:04,053 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:40:04,053 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:40:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:42:05,008 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:42:05] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:42:05,075 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:42:05] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:42:05,077 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:42:05] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 12:42:05,445 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:42:05] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:45:39,006 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124539.wav, taille: 70679 bytes
2025-06-20 12:45:39,465 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124539.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:45:43,479 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:45:43,480 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:45:43,481 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:45:43,487 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:45:45,676 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:45:45,676 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=855 request_id=req_f9a29d5f565f4d91034ab0b0ea9c8a18 response_code=200
2025-06-20 12:45:49,436 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:45:49,436 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:45:51,551 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:45:51,551 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=879 request_id=req_f349c0536c994b2753f1adb6550aacb4 response_code=200
2025-06-20 12:45:51,656 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:45:51,656 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0645\\u0634\\u0643\\u0644\\u0629 \\u0639\\u0646\\u062f\\u064a \\u0647\\u0648\\u062f\\u064a \\u062e\\u0635\\u0646\\u064a \\u0623\\u0646 \\u0646\\u0634\\u0631\\u0628 \\u0647\\u0630\\u0627\\"\\n            Fran\\u00e7ais: \\"J\'ai un probl\\u00e8me, j\'ai besoin d\'un verre d\'huile.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:45:52,166 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:45:52,166 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=263 request_id=req_db7e01290fbf20409d5b18c685c9ad65 response_code=200
2025-06-20 12:45:52,196 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:45:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:46:17,833 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:17] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:46:17,927 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:17] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:46:17,941 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:17] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 12:46:18,457 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:18] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:46:24,824 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124624.wav, taille: 80339 bytes
2025-06-20 12:46:25,225 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124624.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:46:28,489 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:46:28,489 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646\\u0634\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628\\"\\n            Fran\\u00e7ais: \\"salam Anakin cette semaine\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:46:28,495 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:46:28,500 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:46:29,195 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124629.wav, taille: 64883 bytes
2025-06-20 12:46:29,220 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:46:29,223 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=322 request_id=req_453ba3f202e486ce530615f3ed94dfb0 response_code=200
2025-06-20 12:46:29,269 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:46:29,612 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124629.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:46:32,664 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:46:32,664 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:46:32,666 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:46:32,673 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:46:34,953 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 12:46:34,955 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1639 request_id=req_80333e0afa053b4dea37b64de6b33aac response_code=200
2025-06-20 12:46:38,965 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:46:38,969 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:46:40,120 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 12:46:40,120 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=701 request_id=req_d35910c0006d8be77c47afd7ca170ba9 response_code=200
2025-06-20 12:46:40,235 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:46:40,235 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0643\\u0631\\u0634\\u064a\\"\\n            Fran\\u00e7ais: \\"Merci.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:46:40,605 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:46:40,605 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=205 request_id=req_ff807e808662c4a37ba36449327cd34d response_code=200
2025-06-20 12:46:40,632 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:46:49,520 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:49] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:46:49,608 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:49] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:46:49,620 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:49] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 12:46:50,037 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:46:50] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:46:57,348 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124657.wav, taille: 80339 bytes
2025-06-20 12:46:57,761 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124657.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:00,433 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:47:00,435 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0644\\u0649\\"\\n            Fran\\u00e7ais: \\"salam Anakin\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:47:00,440 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:00,443 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:01,452 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:47:01,455 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=626 request_id=req_a05e87d09f3acf462692dcb0ed0e328f response_code=200
2025-06-20 12:47:01,483 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:47:02,663 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124702.wav, taille: 80339 bytes
2025-06-20 12:47:03,123 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124702.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:07,349 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124707.wav, taille: 80339 bytes
2025-06-20 12:47:07,833 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124707.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:12,703 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124712.wav, taille: 80339 bytes
2025-06-20 12:47:13,228 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124712.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:15,893 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:15,893 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:15,895 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:15,896 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:15,896 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:15,896 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:15,910 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:15,912 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:16,822 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:16,824 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:16,825 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:16,828 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:17,665 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124717.wav, taille: 80339 bytes
2025-06-20 12:47:18,096 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:47:18,099 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1574 request_id=req_475011dfccb44686b6486f100e8eca1c response_code=200
2025-06-20 12:47:18,127 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124717.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:19,769 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:47:19,773 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=888 request_id=req_fb5f0537e29a604ba35e8aa296788ea7 response_code=200
2025-06-20 12:47:21,133 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:47:21,151 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:21,178 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=4180 request_id=req_b6088756b50963e4165d14bb7af89ec7 response_code=200
2025-06-20 12:47:21,184 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:21,206 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:21,238 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:21,816 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:47:22,769 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:47:23,021 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=763 request_id=req_fe19b312776d45577075c85bbcd7f643 response_code=200
2025-06-20 12:47:23,526 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124723.wav, taille: 82271 bytes
2025-06-20 12:47:24,607 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:24,615 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:24,758 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124723.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:26,404 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:26,412 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:26,805 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:26,823 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:27,972 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:47:27,988 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=932 request_id=req_d401db1460f5dba9abd19290895e8744 response_code=200
2025-06-20 12:47:28,113 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:47:28,119 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:47:28,262 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:47:28,263 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=616 request_id=req_884ecf06df86b27b4729bd545a201145 response_code=200
2025-06-20 12:47:28,294 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:28,299 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:28,302 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:28,306 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124728.wav, taille: 88067 bytes
2025-06-20 12:47:28,313 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:28,371 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:47:28,374 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0639\\u0646\\u062f\\u0645\\u0627 \\u064a\\u0631\\u062c\\u0639 \\u0625\\u0644\\u0649 \\u0627\\u0644\\u0628\\u064a\\u062a \\u0633\\u064a\\u0645\\u0627\\u0646\\u0629 \\u064a\\u0634\\u0648\\u0641 \\u0627\\u0644\\u062d\\u0627\\u0644\\u0629 \\u062f\\u064a\\u0627\\u0644\\u0647\\"\\n            Fran\\u00e7ais: \\"et qu\'il revienne \\u00e0 Potsima pour voir son \\u00e9tat.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:47:28,780 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124728.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:28,993 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:47:28,998 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=352 request_id=req_f535ef3f1af3a4c6fa02fbcd94f36422 response_code=200
2025-06-20 12:47:29,037 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:47:30,235 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:47:30,237 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=889 request_id=req_55d11e12ee0f7b997a2933f9609fba9b response_code=200
2025-06-20 12:47:31,282 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:31,282 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:31,284 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:31,289 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:32,752 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:47:32,753 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=833 request_id=req_b0ea2f4788b8aaf8d2dafd195440a358 response_code=200
2025-06-20 12:47:32,776 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:32,777 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:33,283 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124733.wav, taille: 80339 bytes
2025-06-20 12:47:33,719 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124733.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:33,724 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:47:33,728 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=438 request_id=req_82cf38123c62a015fb8ef7dfe9a83ff5 response_code=200
2025-06-20 12:47:33,836 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:47:33,843 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:47:36,729 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:36,747 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:37,662 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124737.wav, taille: 69713 bytes
2025-06-20 12:47:37,890 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:47:37,901 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=844 request_id=req_666078a4d4dbe64bad97c4c082bbb4ce response_code=200
2025-06-20 12:47:37,902 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:37,911 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:37,913 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:37,919 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:38,026 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:47:38,026 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:47:38,152 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124737.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:39,503 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:47:39,503 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=529 request_id=req_33fea19c49b86512fd67dadc81d3296a response_code=200
2025-06-20 12:47:42,073 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:42,075 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:42,076 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:42,084 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:42,663 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124742.wav, taille: 80339 bytes
2025-06-20 12:47:43,108 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124742.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:43,458 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:43,459 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:44,793 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 12:47:44,798 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=726 request_id=req_4e672c0c9e3aa92f3ff67460cd5d7d06 response_code=200
2025-06-20 12:47:44,905 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:47:44,909 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:47:45,273 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:47:45,276 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2101 request_id=req_6eefb2ead2845fe273e35fbc34f6b329 response_code=200
2025-06-20 12:47:46,597 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:46,598 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:46,599 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:46,608 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:48,103 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:48,103 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:48,283 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124748.wav, taille: 89999 bytes
2025-06-20 12:47:48,718 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_124748.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:47:48,828 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:47:48,833 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=739 request_id=req_701f0e22dcd20a23c56a986ac6162dd0 response_code=200
2025-06-20 12:47:49,854 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 12:47:49,856 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1191 request_id=req_38202a38b42c38dfc998fc4f5a55098e response_code=200
2025-06-20 12:47:49,973 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:47:49,978 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:47:51,802 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:51,802 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:47:52,533 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:47:52,533 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:47:52,540 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:47:52,544 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:47:53,222 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 12:47:53,223 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1145 request_id=req_c2ae8323e0bd3b96ddd101cd191e9552 response_code=200
2025-06-20 12:47:53,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_124753.wav, taille: 80339 bytes
2025-06-20 12:47:53,333 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 12:47:53,336 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:47:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:58:47,938 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.122:5000
2025-06-20 12:58:47,938 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-06-20 12:58:47,973 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 12:58:55,607 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 12:58:55,622 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 12:59:16,851 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:59:16] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 12:59:16,930 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:59:16] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 12:59:17,016 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:59:17] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 12:59:17,454 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:59:17] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 12:59:34,293 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_125934.wav, taille: 80339 bytes
2025-06-20 12:59:36,703 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 12:59:36,733 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:59:36,742 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,743 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:59:36,744 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 12:59:36,744 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,745 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 12:59:36,746 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,746 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 12:59:36,748 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:59:36,748 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 12:59:36,749 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:59:36,754 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 12:59:36,757 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:59:36,758 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 12:59:36,759 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,760 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 12:59:36,760 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 12:59:36,761 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 12:59:36,762 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 12:59:36,763 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 12:59:36,764 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 12:59:36,765 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 12:59:36,766 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 12:59:36,772 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 12:59:36,774 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 12:59:36,775 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 12:59:36,775 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 12:59:36,776 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 12:59:36,777 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 12:59:36,778 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 12:59:36,778 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 12:59:36,780 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 12:59:36,781 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 12:59:36,781 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 12:59:36,782 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 12:59:36,782 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 12:59:36,792 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 12:59:36,793 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,794 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:59:36,794 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 12:59:36,797 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 12:59:36,798 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 12:59:36,798 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 12:59:36,799 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 12:59:36,799 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,805 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,807 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:59:36,808 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,808 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 12:59:36,810 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 12:59:36,810 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,811 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,812 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 12:59:36,828 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,830 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 12:59:36,843 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 12:59:36,843 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,844 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 12:59:36,844 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 12:59:36,845 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 12:59:36,847 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 12:59:36,847 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 12:59:36,847 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 12:59:36,847 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 12:59:36,853 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,858 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 12:59:36,859 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 12:59:36,859 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 12:59:36,860 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 12:59:36,861 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 12:59:36,861 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 12:59:36,862 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 12:59:36,863 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 12:59:36,863 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 12:59:36,873 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 12:59:36,873 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 12:59:36,878 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 12:59:36,879 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 12:59:36,880 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 12:59:36,880 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 12:59:36,881 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,881 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 12:59:36,882 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 12:59:36,882 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,883 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 12:59:36,885 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 12:59:36,891 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,891 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 12:59:36,893 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 12:59:36,893 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 12:59:36,894 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 12:59:36,894 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 12:59:36,895 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 12:59:36,895 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 12:59:36,895 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 12:59:36,896 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 12:59:36,897 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,898 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:59:36,899 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 12:59:36,899 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 12:59:36,901 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 12:59:36,908 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 12:59:36,909 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 12:59:36,909 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,910 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,911 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:59:36,912 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:59:36,913 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,914 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 12:59:36,914 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 12:59:36,915 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,915 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,923 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 12:59:36,923 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,923 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 12:59:36,923 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 12:59:36,923 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,923 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 12:59:36,923 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 12:59:36,923 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,928 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 12:59:36,932 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 12:59:36,932 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,933 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 12:59:36,936 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 12:59:36,936 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,936 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 12:59:36,936 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 12:59:36,936 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 12:59:36,943 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:59:36,943 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,943 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 12:59:36,943 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 12:59:36,943 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,943 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 12:59:36,948 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 12:59:36,949 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 12:59:36,957 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 12:59:36,957 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 12:59:36,958 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 12:59:36,958 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 12:59:36,959 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 12:59:36,960 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 12:59:36,961 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 12:59:36,961 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 12:59:36,962 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 12:59:36,962 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 12:59:36,963 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 12:59:36,963 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 12:59:36,963 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 12:59:36,963 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 12:59:36,963 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 12:59:36,966 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:59:36,973 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:59:36,974 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:36,975 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 12:59:36,976 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 12:59:36,977 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:36,978 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 12:59:36,980 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 12:59:36,981 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 12:59:36,982 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 12:59:36,983 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 12:59:36,992 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 12:59:36,993 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 12:59:36,994 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 12:59:36,995 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 12:59:36,995 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 12:59:36,996 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 12:59:36,996 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 12:59:36,997 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 12:59:36,998 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 12:59:36,999 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 12:59:37,007 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 12:59:37,007 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 12:59:37,008 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 12:59:37,008 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:59:37,009 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 12:59:37,010 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:59:37,010 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 12:59:37,014 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 12:59:37,016 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 12:59:37,024 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 12:59:37,027 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 12:59:37,028 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 12:59:37,029 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:59:37,029 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 12:59:37,041 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 12:59:37,042 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 12:59:37,044 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 12:59:37,045 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 12:59:37,047 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 12:59:37,048 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 12:59:37,056 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 12:59:37,057 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 12:59:37,058 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 12:59:37,059 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 12:59:37,060 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:59:37,061 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:59:37,078 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 12:59:38,334 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 12:59:38,344 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:59:38,345 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:38,345 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:59:38,345 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 12:59:38,360 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:38,362 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:59:38,363 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:38,363 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 12:59:38,364 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:59:38,365 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:59:38,365 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:59:38,367 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:59:38,376 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:59:38,377 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 12:59:38,377 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 12:59:38,378 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:59:38,379 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 12:59:38,380 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 12:59:38,382 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 12:59:38,383 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:59:38,391 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 12:59:38,392 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 12:59:38,392 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 12:59:38,393 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:59:38,393 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 12:59:38,394 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 12:59:38,394 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 12:59:38,395 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 12:59:38,396 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 12:59:38,396 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 12:59:38,397 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 12:59:38,397 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 12:59:38,398 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 12:59:38,398 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 12:59:38,399 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 12:59:38,404 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 12:59:38,406 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 12:59:38,406 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:59:38,408 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:59:38,409 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 12:59:38,409 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 12:59:38,410 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:59:38,410 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:59:38,411 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 12:59:38,412 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 12:59:38,412 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:59:38,413 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:59:38,420 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 12:59:38,428 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 12:59:38,436 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 12:59:38,436 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 12:59:38,436 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 12:59:38,436 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 12:59:38,436 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - stack []
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 12:59:38,443 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 12:59:38,448 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 12:59:38,448 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:59:38,448 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 12:59:38,448 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 12:59:38,453 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 12:59:38,455 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:59:38,455 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 12:59:38,455 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 12:59:38,455 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 12:59:38,461 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:59:38,461 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 12:59:38,462 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 12:59:38,463 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 12:59:38,464 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 12:59:38,465 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 12:59:38,465 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 12:59:38,465 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 12:59:38,468 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 12:59:38,474 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 12:59:38,475 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 12:59:38,475 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 12:59:38,476 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 12:59:38,477 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 12:59:38,477 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 12:59:38,478 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 12:59:38,478 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 12:59:38,479 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 12:59:38,479 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:59:38,479 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 12:59:38,479 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 12:59:38,481 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 12:59:38,481 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 12:59:38,482 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 12:59:38,494 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 12:59:39,613 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_125939.wav, taille: 80339 bytes
2025-06-20 12:59:40,328 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_125939.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:59:40,344 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_125934.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:59:43,873 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:59:43,873 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u0646\\u062c\\u064a \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628\\"\\n            Fran\\u00e7ais: \\"salam kendji\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:59:43,873 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:59:43,887 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:59:44,243 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:59:44,243 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0646\\u0642\\u064a \\u0643\\u0627\\u0646\\u0641\\u0648\\u062e \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0631\\u062c\\u0639\\"\\n            Fran\\u00e7ais: \\"American four galerie\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:59:44,243 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:59:44,254 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:59:44,657 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:59:44,666 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=238 request_id=req_4563713674b82b5473c3f3256bf42b5f response_code=200
2025-06-20 12:59:44,751 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:59:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:59:45,153 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:59:45,163 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=559 request_id=req_881f7b93fb4c47fd48c0136bdf5778e1 response_code=200
2025-06-20 12:59:45,183 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:59:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:59:45,293 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_125945.wav, taille: 90965 bytes
2025-06-20 12:59:45,723 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_125945.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:59:49,603 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_125949.wav, taille: 69713 bytes
2025-06-20 12:59:50,085 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_125949.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:59:53,234 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:59:53,235 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 12:59:53,236 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:59:53,243 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:59:54,393 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:59:54,393 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:59:54,436 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:59:54,447 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:59:54,610 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_125954.wav, taille: 80339 bytes
2025-06-20 12:59:55,037 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_125954.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 12:59:55,334 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 44
2025-06-20 12:59:55,336 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1414 request_id=req_e7471d17d25d0f1ab8c05a5d8cf3dbed response_code=200
2025-06-20 12:59:55,449 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 12:59:55,450 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"Je vois que le havre est h\\u00e9ri...\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 12:59:55,916 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 12:59:55,916 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=210 request_id=req_f4cf4c79ff2e5313268b7e2c3c2cada4 response_code=200
2025-06-20 12:59:55,944 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 12:59:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 12:59:57,743 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 12:59:57,743 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1459 request_id=req_1fab94f969b65b53979b84da5b4f4260 response_code=200
2025-06-20 12:59:58,593 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 12:59:58,593 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 12:59:58,602 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 12:59:58,604 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 12:59:59,603 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_125959.wav, taille: 80339 bytes
2025-06-20 13:00:00,006 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:00:00,010 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=628 request_id=req_c58b6cd63b9bcafa94aca41f20cc4b85 response_code=200
2025-06-20 13:00:00,108 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_125959.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:00,255 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:00,255 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:00:00,408 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:00] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:00:00,518 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:00] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:00:00,560 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:00] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:00:00,970 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:00] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:00:01,024 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 13:00:01,025 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=510 request_id=req_e7cd03f4f51d0527ec748b4046cb293b response_code=200
2025-06-20 13:00:01,131 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:00:01,134 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:02,277 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:02,277 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:00:03,109 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:03,117 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:00:03,121 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:03,124 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:05,573 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:00:05,595 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=530 request_id=req_d70110a1f375c288b3744f0a508da809 response_code=200
2025-06-20 13:00:06,089 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:00:06,089 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=3513 request_id=req_68a10cb6ae0616717cbea86721b0e749 response_code=200
2025-06-20 13:00:06,200 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:00:06,200 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:07,466 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130007.wav, taille: 80339 bytes
2025-06-20 13:00:07,924 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130007.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:08,724 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:08,725 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:00:11,089 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:00:11,089 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2031 request_id=req_1b9497ac141d16bcea8375e66b4ef28f response_code=200
2025-06-20 13:00:11,200 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:00:11,200 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:11,669 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:00:11,669 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u0627\\u064a\\u0646 \\u0634\\u064a \\u0633\\u0627\\u0646 \\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Fran\\u00e7ais: \\"salam Kensi sant\\u00e9\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:00:11,669 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:11,682 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:12,776 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130012.wav, taille: 80339 bytes
2025-06-20 13:00:13,329 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130012.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:13,548 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:00:13,618 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=739 request_id=req_ff2f7bbedcfa035e7568a9e984382935 response_code=200
2025-06-20 13:00:13,640 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:16,989 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:00:16,989 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0643\\u0631\\u0634\\u064a \\u0648\\u0641\\u064a \\u0638\\u0647\\u0631\\u064a \\u0648\\u0639\\u0646\\u0642\\u064a\\"\\n            Fran\\u00e7ais: \\"cachet Paris\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:00:16,989 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:17,004 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:17,769 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130017.wav, taille: 80339 bytes
2025-06-20 13:00:17,911 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:00:17,915 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=273 request_id=req_b12186a281a950d3a82775acd5f3f512 response_code=200
2025-06-20 13:00:18,027 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:18,342 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130017.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:22,774 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130022.wav, taille: 80339 bytes
2025-06-20 13:00:22,929 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:22,940 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:00:22,943 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:22,969 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:23,289 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130022.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:25,402 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:00:25,404 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=735 request_id=req_8d38275b339e1643a40b25d90580a209 response_code=200
2025-06-20 13:00:27,199 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:00:27,199 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648 \\u0623\\u0639\\u0637\\u0627\\u0646\\u064a \\u0643\\u0646\\u0627 \\u062a\\u0627\\u0646\\u064a \\u062f\\u064a\\u0645\\u064a \\u062f\\u064a \\u0643\\u0627\\u0645\\u0648 \\u0643\\u064a \\u062f\\u064a \\u0631\\u062c\\u0639\\u064a\\u0646 \\u062f\\u0648\\u064a\\u062a \\u0633\\u064a\\u0645\\u0627\\u0646\\u0648\\"\\n            Fran\\u00e7ais: \\"Watani kanatani des m\\u00e9dicaments\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:00:27,775 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130027.wav, taille: 80339 bytes
2025-06-20 13:00:27,965 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:00:27,968 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=379 request_id=req_eb20852129ce58bffd543973d6a1e15d response_code=200
2025-06-20 13:00:28,033 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:28,379 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:00:28,384 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0646\\u0634\\u0648\\u0641 \\u0634\\u0646\\u0648 \\u0639\\u0646\\u062f\\u064a\\"\\n            Fran\\u00e7ais: \\"canap\\u00e9 doliprane pour\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:00:28,396 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:28,413 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:28,430 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130027.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:29,069 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:00:29,072 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=277 request_id=req_7c413637ce78851cc0858eca341f1194 response_code=200
2025-06-20 13:00:29,100 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:32,779 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130032.wav, taille: 80339 bytes
2025-06-20 13:00:33,216 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130032.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:36,686 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:36,688 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:00:36,692 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:36,696 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:37,139 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:37,139 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:00:37,145 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:37,152 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:37,769 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130037.wav, taille: 80339 bytes
2025-06-20 13:00:38,239 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130037.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:38,491 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:00:38,493 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=827 request_id=req_5c0848b2ed7e8068bac353902bad0e96 response_code=200
2025-06-20 13:00:40,009 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 34
2025-06-20 13:00:40,009 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1908 request_id=req_f1c84b0736487b1e386ca0acd9fe1863 response_code=200
2025-06-20 13:00:40,132 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:00:40,133 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u062e\\u0631\\u064a\\u0646\\"\\n            Fran\\u00e7ais: \\"Vous suivrez ce \\uace0\\ubbfc.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:00:40,740 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:00:40,747 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=255 request_id=req_8620c54991ed0ef2cbb2293dc5c5a64a response_code=200
2025-06-20 13:00:40,809 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:42,003 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:42,004 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:00:42,005 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:42,011 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:42,052 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:42,055 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:00:42,776 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130042.wav, taille: 80339 bytes
2025-06-20 13:00:42,990 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:00:42,990 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=760 request_id=req_4585a35164ffa00134fd66e92e579d5b response_code=200
2025-06-20 13:00:43,095 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:00:43,098 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:43,250 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130042.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:43,514 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:00:43,516 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=999 request_id=req_8d725bbcccf2d2cfc03b159b6a1e5780 response_code=200
2025-06-20 13:00:45,905 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:45,905 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:00:46,782 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:46,813 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:00:46,834 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:46,839 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:47,776 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130047.wav, taille: 80339 bytes
2025-06-20 13:00:48,205 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130047.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:00:48,921 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:00:48,921 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2712 request_id=req_9095005bda52783f2d38013f0dccdd1f response_code=200
2025-06-20 13:00:49,056 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:49,534 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:00:49,539 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1420 request_id=req_1253beeaf0a42753887ac88228a05f4a response_code=200
2025-06-20 13:00:51,035 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:51] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:00:51,129 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:51] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:00:51,137 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:51] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:00:51,321 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:51,323 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:00:51,324 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:00:51,337 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:00:51,619 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:51] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:00:52,352 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:52,353 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:00:53,845 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 16
2025-06-20 13:00:53,845 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1042 request_id=req_d7d180316460cde8874018a8291a0e25 response_code=200
2025-06-20 13:00:53,966 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:00:53,969 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:00:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:00:54,018 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 41
2025-06-20 13:00:54,018 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1989 request_id=req_e32b7e2aa8644d240a291e5a6a9aad81 response_code=200
2025-06-20 13:00:56,584 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:00:56,585 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:00:57,967 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:00:57,968 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1069 request_id=req_4192c64aed92bee0d1a6e49377f1e160 response_code=200
2025-06-20 13:00:58,072 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:00:58,073 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u062a\\u0631\\u062c\\u0645\\u0629 \\u0646\\u0627\\u0646\\u0633\\u064a \\u0642\\u0646\\u0642\\u0631\\"\\n            Fran\\u00e7ais: \\"Donc, l\'id\\u00e9e, c\'est qu\'on va faire des choses comme \\u00e7a, c\'est-\\u00e0-dire qu\'on va faire des choses comme \\u00e7a.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:00:58,167 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130058.wav, taille: 80339 bytes
2025-06-20 13:00:58,620 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130058.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:01,334 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:01:01,334 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=379 request_id=req_d59f182f05f99d88d8dc34e8aaa31d19 response_code=200
2025-06-20 13:01:01,366 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:02,464 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:01:02,464 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u0646 \\u062c\\u064a\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Fran\\u00e7ais: \\"salam kendji mana Fay\\u00e7al\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:01:02,464 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:02,475 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:03,144 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:01:03,147 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=283 request_id=req_8c7f9a8e2f3659e80c9fac781f9aa85c response_code=200
2025-06-20 13:01:03,239 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:03,474 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130103.wav, taille: 80339 bytes
2025-06-20 13:01:03,987 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130103.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:08,211 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:01:08,212 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0639\\u0644\\u0649 \\u0638\\u0647\\u0631\\u064a \\u0648\\u0645\\u0646 \\u0628\\u0639\\u062f \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u062f\\u0633\\u062a\\"\\n            Fran\\u00e7ais: \\"comedia\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:01:08,217 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:08,221 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:08,474 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130108.wav, taille: 80339 bytes
2025-06-20 13:01:08,904 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130108.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:09,109 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:01:09,120 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=299 request_id=req_b428304ca3c3fdb5bd006bf0196e7b80 response_code=200
2025-06-20 13:01:09,191 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:13,470 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130113.wav, taille: 80339 bytes
2025-06-20 13:01:13,897 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130113.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:13,997 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:01:14,004 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u064a\\u0634\\u0648\\u0641 \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0648\\u0627\\u0634 \\u062a\\u062d\\"\\n            Fran\\u00e7ais: \\"localisation\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:01:14,010 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:14,024 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:15,015 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:01:15,018 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=186 request_id=req_03b4736d6064a9d3e8796317a256f479 response_code=200
2025-06-20 13:01:15,046 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:18,004 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:18,005 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:01:18,006 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:18,019 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:18,464 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130118.wav, taille: 80339 bytes
2025-06-20 13:01:18,883 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130118.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:19,520 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 44
2025-06-20 13:01:19,522 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=662 request_id=req_709911c93c3ea54fcbd88c41a2c516e2 response_code=200
2025-06-20 13:01:22,405 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:22,405 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:01:22,410 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:22,418 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:23,464 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130123.wav, taille: 80339 bytes
2025-06-20 13:01:23,543 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:23,544 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:01:23,951 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130123.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:24,137 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:01:24,145 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=760 request_id=req_1c73a2efe043d49ff9af593ed9b30883 response_code=200
2025-06-20 13:01:24,744 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 13:01:24,745 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=554 request_id=req_9c5e2aa9d6f461adf69617b7dbdb6ccc response_code=200
2025-06-20 13:01:24,864 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:01:24,866 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629.\\"\\n            Fran\\u00e7ais: \\"de l\'an.\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:01:25,615 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:01:25,615 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=478 request_id=req_9ddcd31b9b782bfdd2cf89d74db4e8b4 response_code=200
2025-06-20 13:01:25,644 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:26,819 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:26,824 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:01:26,826 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:26,833 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:27,118 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:27,118 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:01:28,224 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 13:01:28,224 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=542 request_id=req_fa1358fc9a8bd031fcae7fd5ee64416f response_code=200
2025-06-20 13:01:28,347 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:01:28,351 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:28,469 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130128.wav, taille: 80339 bytes
2025-06-20 13:01:28,889 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:01:28,889 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=718 request_id=req_c67464fd4918cbc25e7817b043fe772e response_code=200
2025-06-20 13:01:28,974 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130128.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:31,314 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:31,316 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:01:31,933 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:31,934 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:01:31,935 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:31,936 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:32,314 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:01:32,314 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=523 request_id=req_74127535b9b0a993a670e4d39c9826a0 response_code=200
2025-06-20 13:01:32,430 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:01:32,432 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:33,474 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130133.wav, taille: 80339 bytes
2025-06-20 13:01:33,674 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:01:33,680 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=638 request_id=req_0ce3a8af51ef96c1c9a33caee13dccfa response_code=200
2025-06-20 13:01:33,934 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130133.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:36,430 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:36,432 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:01:36,945 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:36,946 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:01:36,948 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:36,956 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:38,004 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:01:38,004 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1051 request_id=req_69d419a3810599b3539eea4e5b59d25a response_code=200
2025-06-20 13:01:38,125 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:01:38,127 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:38,469 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130138.wav, taille: 80339 bytes
2025-06-20 13:01:38,898 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130138.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:39,126 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:01:39,131 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1126 request_id=req_94d0ff7692e4365592b1e4b3008c98ed response_code=200
2025-06-20 13:01:41,317 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:41,318 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:01:41,624 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:41,631 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:01:41,633 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:41,637 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:43,468 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130143.wav, taille: 80339 bytes
2025-06-20 13:01:44,028 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130143.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:01:44,114 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 34
2025-06-20 13:01:44,139 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:01:44,139 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1741 request_id=req_c47aa82e9a0e85ec098dff7aa075ff00 response_code=200
2025-06-20 13:01:44,159 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=796 request_id=req_f4eb351bd7e023589e83e9ea14f00673 response_code=200
2025-06-20 13:01:44,285 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:01:44,288 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:44,580 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:44] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:01:44,662 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:44] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:01:44,662 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:44] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:01:45,163 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:45] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:01:47,299 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:47,300 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:01:47,890 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:47,892 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:01:47,894 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:01:47,900 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:01:48,994 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:01:49,009 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=339 request_id=req_d393539af408754f0f021f75d67d88e6 response_code=200
2025-06-20 13:01:50,102 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:01:50,102 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1571 request_id=req_4eac8892dc387e4cc3a7b37b78dffd01 response_code=200
2025-06-20 13:01:50,226 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:01:50,228 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:01:52,683 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:01:52,683 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:01:55,138 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:01:55,144 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2167 request_id=req_5086e061601c775269a21085fb5c196a response_code=200
2025-06-20 13:01:55,260 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:01:55,260 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:01:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:02:09,862 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130209.wav, taille: 80339 bytes
2025-06-20 13:02:10,306 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130209.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:13,506 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:02:13,507 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0643\\u0646\\u062a \\u062f\\u0631\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0645\\u0644\\u064a\\u0647\\"\\n            Fran\\u00e7ais: \\"Salaman\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:02:13,509 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:13,516 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:14,288 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:02:14,298 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=380 request_id=req_c4ced32595995987ec1dd5d2390e95be response_code=200
2025-06-20 13:02:14,354 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:02:15,166 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130215.wav, taille: 80339 bytes
2025-06-20 13:02:15,615 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130215.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:18,877 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:02:18,884 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u062e\\u0627\\u0635\\u0646\\u064a \\u062a\\u062e\\u064a\\u0637\\u0645\\u0648\\u0646\\"\\n            Fran\\u00e7ais: \\"aucun drame traitement\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:02:18,884 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:18,884 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:19,859 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130219.wav, taille: 80339 bytes
2025-06-20 13:02:20,277 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130219.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:20,417 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:02:20,421 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=637 request_id=req_110b9bd2294e52c6f8569492a5114450 response_code=200
2025-06-20 13:02:20,486 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:02:22,994 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:02:22,994 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces transcriptions en privil\\u00e9giant le sens m\\u00e9dical et en \\u00e9vitant toute phrase g\\u00e9n\\u00e9rique ou hors contexte:\\n            Darija: \\"\\u0634\\u0648\\u0641 \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Fran\\u00e7ais: \\"votre b\\u00e9b\\u00e9\\"\\n            \\n            Instructions:\\n            - Garde uniquement le contenu pertinent \\u00e0 la consultation\\n            - Ignore les phrases g\\u00e9n\\u00e9riques ou de politesse\\n            - Pr\\u00e9serve les termes m\\u00e9dicaux sp\\u00e9cifiques\\n            - Retourne une phrase vide si le contenu n\'est pas pertinent\\n            "}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:02:22,994 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:23,004 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:23,674 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:02:23,677 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=291 request_id=req_931c0d16b84782ef66669c92e0d52531 response_code=200
2025-06-20 13:02:23,708 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:02:25,166 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130225.wav, taille: 80339 bytes
2025-06-20 13:02:25,609 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130225.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:29,128 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:29,129 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:02:29,130 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:29,137 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:29,859 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130229.wav, taille: 80339 bytes
2025-06-20 13:02:30,283 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130229.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:30,342 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:02:30,348 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=628 request_id=req_868996893a7f62ad21cde2991db4bad0 response_code=200
2025-06-20 13:02:33,316 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:33,316 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:02:34,131 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:34,131 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:02:34,133 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:34,140 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:34,543 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:02:34,545 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=805 request_id=req_57f27b26ea27cfac33fe34298d4308d0 response_code=200
2025-06-20 13:02:34,661 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:02:34,664 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:02:35,164 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130235.wav, taille: 80339 bytes
2025-06-20 13:02:35,604 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130235.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:36,165 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:02:36,165 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=592 request_id=req_9095e0ddf1517d603904ec4dd5b8aac4 response_code=200
2025-06-20 13:02:38,234 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:38,234 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:02:38,241 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:38,246 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:38,980 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:38,981 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:02:40,064 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:02:40,064 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=503 request_id=req_9fdc892a0c552636c7f11fea2b3a4691 response_code=200
2025-06-20 13:02:40,170 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130240.wav, taille: 80339 bytes
2025-06-20 13:02:40,176 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:02:40,182 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:02:40,184 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1334 request_id=req_d6510bb203ec289d7891b542747093b4 response_code=200
2025-06-20 13:02:40,184 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:02:40,665 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130240.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:43,164 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:43,164 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:02:44,348 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:02:44,354 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=948 request_id=req_7e75d535eb6fe144b69e65ee8d34cacc response_code=200
2025-06-20 13:02:44,384 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:44,386 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:02:44,387 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:44,396 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:44,464 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:02:44,469 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:02:45,164 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130245.wav, taille: 80339 bytes
2025-06-20 13:02:45,634 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130245.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:46,094 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:02:46,094 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=814 request_id=req_32a5d189c908d4231b6103259ec575b3 response_code=200
2025-06-20 13:02:46,444 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_130246.wav, taille: 20447 bytes
2025-06-20 13:02:46,762 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_130246.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:02:47,473 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:47] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:02:47,611 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:47] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:02:47,633 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:47] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:02:48,095 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:48] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:02:48,286 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:48,286 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:02:49,204 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 31
2025-06-20 13:02:49,206 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=358 request_id=req_6e2dc3dd93ba15438d5d849fe5973ff4 response_code=200
2025-06-20 13:02:49,326 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:02:49,329 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:02:49,963 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:49,984 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:49,996 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:02:50,016 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:02:50,031 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:50,057 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:02:50,133 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:50,135 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:02:51,493 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:02:51,502 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=491 request_id=req_f22535a63979e4588db5352838f1a107 response_code=200
2025-06-20 13:02:52,359 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 13:02:52,399 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1629 request_id=req_e704db31ce8fd248df88643d53ca1ee4 response_code=200
2025-06-20 13:02:53,919 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:53,920 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:02:55,344 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:02:55,348 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1115 request_id=req_e1e786b68131144a6735b368d91fa949 response_code=200
2025-06-20 13:02:55,389 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:02:55,393 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:02:55,462 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:02:55,462 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:02:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:05:01,363 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:05:01,426 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:05:04,293 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:05:15,638 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:05:15,652 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:05:23,634 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:05:23,652 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:05:24,931 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:05:37,683 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:05:37,719 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:06:46,169 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:06:48,307 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:06:59,108 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:06:59,117 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:07:00,679 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:07:00,681 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:07:02,418 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:07:15,716 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:07:15,735 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:07:20,018 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:07:20,052 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessing.py', reloading
2025-06-20 13:07:20,090 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\noisereduce\\__init__.py', reloading
2025-06-20 13:07:20,135 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\soundfile.py', reloading
2025-06-20 13:07:20,151 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\noisereduce\\noisereduce.py', reloading
2025-06-20 13:07:20,155 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\_cache.py', reloading
2025-06-20 13:07:20,157 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\core\\audio.py', reloading
2025-06-20 13:07:20,161 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\audioread\\__init__.py', reloading
2025-06-20 13:07:20,168 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\lazy_loader\\__init__.py', reloading
2025-06-20 13:07:20,171 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\typing\\__init__.py', reloading
2025-06-20 13:07:20,198 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\__init__.py', reloading
2025-06-20 13:07:20,211 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\audioread\\base.py', reloading
2025-06-20 13:07:20,255 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\overrides.py', reloading
2025-06-20 13:07:20,259 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_shape.py', reloading
2025-06-20 13:07:20,268 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_dtype_like.py', reloading
2025-06-20 13:07:20,278 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\app.py', reloading
2025-06-20 13:07:20,292 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_preprocessor.py', reloading
2025-06-20 13:07:20,295 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\audio_processor.py', reloading
2025-06-20 13:07:20,303 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_typing\\_generic_alias.py', reloading
2025-06-20 13:07:20,306 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\__init__.py', reloading
2025-06-20 13:07:20,340 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py', reloading
2025-06-20 13:07:22,117 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:07:34,235 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:07:34,243 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:07:35,158 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\openai\\__init__.py', reloading
2025-06-20 13:07:35,189 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py', reloading
2025-06-20 13:07:35,465 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\__init__.py', reloading
2025-06-20 13:07:35,472 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\audio_segment.py', reloading
2025-06-20 13:07:35,564 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py', reloading
2025-06-20 13:07:36,846 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:07:52,128 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:07:52,197 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:07:54,118 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:07:54,118 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:07:55,256 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:08:13,766 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:08:13,782 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:08:14,611 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:08:14,628 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:08:16,556 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:08:31,348 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:08:31,352 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:08:48,603 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:08:48,603 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:08:50,453 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:09:05,368 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:09:05,378 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:09:14,039 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:09:14,047 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:09:16,442 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:09:26,395 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:09:26,401 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:12:15,295 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:12:18,075 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:12:29,104 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:12:29,121 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:12:39,340 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:12:39,351 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:12:40,883 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:12:55,890 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:12:55,911 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:12:56,416 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:12:56,464 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:12:58,274 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:13:07,585 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:13:07,590 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:13:13,219 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:13:13,220 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:13:14,556 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:13:23,470 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:13:23,482 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:13:35,496 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:13:35,500 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:13:37,697 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:13:46,521 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:13:46,529 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:14:00,350 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:14:01,942 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:14:10,462 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:14:10,483 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:16:15,945 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:16:15,965 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:16:17,673 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:16:27,741 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:16:27,753 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:16:36,749 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:16:36,765 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:16:37,936 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:16:46,792 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:16:46,792 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:16:54,269 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:16:54,326 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:16:56,572 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:17:04,945 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:17:04,968 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:17:07,479 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:17:07] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:17:07,566 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:17:07] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:17:07,566 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:17:07] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:17:08,058 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:17:08] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:17:17,964 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131717.wav, taille: 80339 bytes
2025-06-20 13:17:19,664 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\importlib\\__init__.py', reloading
2025-06-20 13:17:19,669 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\flask\\app.py', reloading
2025-06-20 13:17:19,676 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\debug\\__init__.py', reloading
2025-06-20 13:17:19,680 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\werkzeug\\serving.py', reloading
2025-06-20 13:17:19,688 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\http\\server.py', reloading
2025-06-20 13:17:19,699 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\socketserver.py', reloading
2025-06-20 13:17:19,709 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\threading.py', reloading
2025-06-20 13:17:19,827 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:17:19,845 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:17:19,846 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:19,848 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:17:19,848 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 13:17:19,849 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:19,849 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 13:17:19,850 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:19,850 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 13:17:19,851 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:17:19,857 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 13:17:19,859 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:17:19,859 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 13:17:19,860 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:17:19,860 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:17:19,861 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:19,861 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 13:17:19,862 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 13:17:19,862 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 13:17:19,862 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 13:17:19,864 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 13:17:19,864 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 13:17:19,864 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 13:17:19,865 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 13:17:19,865 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:17:19,866 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 13:17:19,866 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 13:17:19,867 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 13:17:19,874 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:17:19,875 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 13:17:19,876 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 13:17:19,877 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 13:17:19,877 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:17:19,878 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 13:17:19,879 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:17:19,879 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 13:17:19,880 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 13:17:19,881 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 13:17:19,881 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:19,882 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:19,883 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 13:17:19,883 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 13:17:19,884 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 13:17:19,884 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 13:17:19,892 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:17:19,893 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:19,894 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:19,894 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:19,894 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:19,894 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 13:17:19,894 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:17:19,894 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:19,894 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:19,894 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 13:17:19,900 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:19,900 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 13:17:19,901 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 13:17:19,903 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:19,905 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 13:17:19,906 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 13:17:19,907 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 13:17:19,907 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 13:17:19,908 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 13:17:19,909 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 13:17:19,909 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:17:19,910 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:19,910 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 13:17:19,911 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 13:17:19,912 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 13:17:19,912 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 13:17:19,913 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 13:17:19,913 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 13:17:19,915 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 13:17:19,922 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 13:17:19,924 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:17:19,924 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 13:17:19,925 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 13:17:19,926 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 13:17:19,927 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:17:19,927 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:17:19,928 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:17:19,929 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:19,930 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 13:17:19,930 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 13:17:19,931 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:19,934 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 13:17:19,942 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 13:17:19,943 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:19,946 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:19,950 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 13:17:19,954 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 13:17:19,958 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:17:19,959 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 13:17:20,814 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:17:29,866 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:17:29,878 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:17:30,114 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131730.wav, taille: 80339 bytes
2025-06-20 13:17:30,114 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131730.wav, taille: 80339 bytes
2025-06-20 13:17:31,213 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:17:31,232 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:17:31,233 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,233 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:17:31,238 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 13:17:31,241 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,242 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 13:17:31,243 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,243 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 13:17:31,244 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:17:31,244 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 13:17:31,245 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 13:17:31,246 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 13:17:31,257 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 13:17:31,258 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 13:17:31,260 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 13:17:31,261 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:17:31,261 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 13:17:31,262 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 13:17:31,262 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 13:17:31,263 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:17:31,263 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 13:17:31,264 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 13:17:31,265 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 13:17:31,265 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:17:31,266 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 13:17:31,266 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:17:31,267 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 13:17:31,271 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 13:17:31,275 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 13:17:31,275 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,277 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:31,278 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 13:17:31,278 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 13:17:31,279 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 13:17:31,279 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 13:17:31,279 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:17:31,279 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,279 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,283 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:31,283 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,284 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 13:17:31,287 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:17:31,292 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,292 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,293 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 13:17:31,293 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,294 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 13:17:31,294 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 13:17:31,295 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,296 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 13:17:31,296 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 13:17:31,296 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 13:17:31,296 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 13:17:31,296 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 13:17:31,364 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 13:17:31,364 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:17:31,373 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,374 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 13:17:31,375 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 13:17:31,376 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 13:17:31,376 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 13:17:31,378 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 13:17:31,379 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 13:17:31,382 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 13:17:31,383 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 13:17:31,383 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:17:31,392 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 13:17:31,392 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 13:17:31,393 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 13:17:31,394 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:17:31,396 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:17:31,399 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:17:31,414 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,414 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 13:17:31,424 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 13:17:31,447 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,454 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 13:17:31,459 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 13:17:31,459 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,480 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:31,493 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 13:17:31,496 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 13:17:31,497 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:17:31,499 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 13:17:31,508 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:17:31,523 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 13:17:31,526 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 13:17:31,527 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 13:17:31,530 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,543 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:31,545 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 13:17:31,548 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 13:17:31,549 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 13:17:31,561 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 13:17:31,562 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 13:17:31,563 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,563 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,564 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:31,566 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:31,566 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,571 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 13:17:31,577 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 13:17:31,578 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,579 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,580 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 13:17:31,581 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,582 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 13:17:31,583 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 13:17:31,584 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,598 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 13:17:31,599 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 13:17:31,600 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,605 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 13:17:31,609 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 13:17:31,609 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,609 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 13:17:31,609 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 13:17:31,614 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,616 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 13:17:31,616 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 13:17:31,626 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:31,630 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:31,631 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,632 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 13:17:31,632 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 13:17:31,633 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,633 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 13:17:31,644 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 13:17:31,645 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 13:17:31,646 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 13:17:31,646 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 13:17:31,647 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 13:17:31,647 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 13:17:31,648 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 13:17:31,649 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 13:17:31,649 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 13:17:31,659 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 13:17:31,659 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 13:17:31,659 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 13:17:31,659 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 13:17:31,664 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 13:17:31,664 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 13:17:31,665 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 13:17:31,665 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 13:17:31,666 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:17:31,667 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:31,677 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:31,678 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 13:17:31,678 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 13:17:31,679 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:31,680 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 13:17:31,680 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 13:17:31,681 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 13:17:31,681 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 13:17:31,682 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 13:17:31,683 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 13:17:31,693 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 13:17:31,694 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 13:17:31,694 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 13:17:31,695 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 13:17:31,696 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 13:17:31,696 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 13:17:31,697 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 13:17:31,698 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 13:17:31,700 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 13:17:31,708 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 13:17:31,710 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:17:31,710 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 13:17:31,711 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:17:31,711 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:31,712 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:17:31,713 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 13:17:31,728 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 13:17:31,729 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 13:17:31,733 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 13:17:31,745 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 13:17:31,746 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 13:17:31,747 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:17:31,749 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 13:17:31,759 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 13:17:31,759 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 13:17:31,764 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 13:17:31,771 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 13:17:31,779 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 13:17:31,782 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 13:17:31,783 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 13:17:31,790 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 13:17:31,794 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 13:17:31,794 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 13:17:31,794 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:17:31,813 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:17:31,824 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 13:17:32,968 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131732.wav, taille: 80339 bytes
2025-06-20 13:17:34,620 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 13:17:34,650 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:17:34,661 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:34,670 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:17:34,672 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 13:17:34,680 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:34,681 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:17:34,682 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:34,685 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 13:17:34,688 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:17:34,689 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:17:34,690 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:17:34,691 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:17:34,693 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:17:34,697 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 13:17:34,697 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 13:17:34,698 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:17:34,699 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 13:17:34,699 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 13:17:34,700 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 13:17:34,701 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:17:34,702 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 13:17:34,703 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 13:17:34,703 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 13:17:34,704 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:17:34,705 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 13:17:34,705 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:17:34,706 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 13:17:34,706 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 13:17:34,707 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 13:17:34,709 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:17:34,710 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 13:17:34,711 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 13:17:34,712 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 13:17:34,714 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 13:17:34,714 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 13:17:34,715 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 13:17:34,716 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 13:17:34,716 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:17:34,717 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:17:34,718 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 13:17:34,719 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 13:17:34,723 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:17:34,727 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:17:34,727 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 13:17:34,728 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 13:17:34,732 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:17:34,732 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:17:34,742 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 13:17:34,757 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 13:17:34,771 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:17:34,772 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:34,773 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:17:34,776 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 13:17:34,780 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:34,781 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:17:34,781 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:34,783 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 13:17:34,786 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:17:34,787 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:17:34,788 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:17:34,789 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:17:34,790 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:17:34,790 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 13:17:34,791 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 13:17:34,798 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:17:34,799 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 13:17:34,799 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 13:17:34,800 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 13:17:34,801 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:17:34,803 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 13:17:34,804 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 13:17:34,805 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 13:17:34,806 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:17:34,807 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 13:17:34,808 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:17:34,811 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 13:17:34,812 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 13:17:34,813 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 13:17:34,814 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:17:34,814 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 13:17:34,816 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 13:17:34,816 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 13:17:34,818 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 13:17:34,819 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 13:17:34,820 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 13:17:34,820 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 13:17:34,821 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:17:34,821 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:17:34,823 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 13:17:34,824 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 13:17:34,827 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:17:34,829 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:17:34,830 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 13:17:34,831 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 13:17:34,831 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:17:34,832 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:17:34,839 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 13:17:37,466 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131730.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:17:37,516 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131730.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:17:37,583 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131732.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:17:37,983 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131737.wav, taille: 80339 bytes
2025-06-20 13:17:38,811 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131737.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:17:42,104 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:17:42,104 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u0627\\u0639\\u0637\\u064a\\u0646\\u064a \\u0643\\u0627\\u0645\\u0648 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"maternit\\u00e9 m\\u00e9dicament organisation\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:17:42,114 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:17:42,125 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:17:42,279 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:17:42,279 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u064a\\u0634\\u0648\\u0641 \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0648\\u0627\\u0634 \\u0645\\u0632\\u064a\\u0627\\u0646 \\u0648\\u0644\\u0627 \\u0644\\u0627\\"\\n            Transcription Fran\\u00e7aise: \\"maintenant il chauffeur\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:17:42,279 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:17:42,290 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:17:42,435 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:17:42,435 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u0627\\u0639\\u0637\\u064a\\u0646\\u064a \\u0643\\u0627\\u0645\\u0648 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"maternit\\u00e9 m\\u00e9dicament organisation\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:17:42,435 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:17:42,444 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:17:42,483 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:17:42,490 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:17:42,494 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:17:42,502 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:17:42,964 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131742.wav, taille: 80339 bytes
2025-06-20 13:17:43,357 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:17:43,362 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:17:43,363 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=413 request_id=req_bd5447f07c39a0f1e0d4e7de2a3be06d response_code=200
2025-06-20 13:17:43,371 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=277 request_id=req_4c82a84a60de871a4064f540e58b63f5 response_code=200
2025-06-20 13:17:43,395 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\logging\\__init__.py', reloading
2025-06-20 13:17:43,423 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131742.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:17:43,430 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:17:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:17:43,459 - werkzeug - INFO -  * Detected change in 'C:\\Program Files\\Python39\\Lib\\encodings\\cp1252.py', reloading
2025-06-20 13:17:43,459 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:17:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:17:43,559 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:17:43,562 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=242 request_id=req_0f6da828bb814e122e9785c8cea0e88f response_code=200
2025-06-20 13:17:43,596 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:17:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:17:44,045 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:17:44,046 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=452 request_id=req_946103343bd985e43b06d3f0d6c5d948 response_code=200
2025-06-20 13:17:45,487 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:17:54,427 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:17:54,439 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:17:54,687 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131754.wav, taille: 80339 bytes
2025-06-20 13:17:54,702 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131754.wav, taille: 80339 bytes
2025-06-20 13:17:55,824 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:17:55,844 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:17:55,844 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:55,844 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:17:55,844 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 13:17:55,844 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:55,849 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 13:17:55,849 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:55,852 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 13:17:55,854 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:17:55,855 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 13:17:55,856 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:17:55,856 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 13:17:55,859 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:17:55,860 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:17:55,862 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:55,863 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 13:17:55,864 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 13:17:55,865 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 13:17:55,871 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 13:17:55,873 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 13:17:55,873 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 13:17:55,876 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 13:17:55,878 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 13:17:55,879 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:17:55,881 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 13:17:55,882 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 13:17:55,885 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 13:17:55,890 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:17:55,893 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 13:17:55,894 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 13:17:55,894 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 13:17:55,895 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:17:55,895 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 13:17:55,895 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:17:55,895 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 13:17:55,895 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 13:17:55,895 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 13:17:55,899 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:55,905 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:55,910 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 13:17:55,910 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 13:17:55,912 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 13:17:55,912 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 13:17:55,912 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:17:55,914 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:55,914 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:55,920 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:55,925 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:55,926 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 13:17:55,927 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:17:55,928 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:55,928 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:55,929 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 13:17:55,930 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:55,931 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 13:17:55,931 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 13:17:55,932 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:55,932 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 13:17:55,934 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 13:17:55,937 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 13:17:55,938 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 13:17:55,938 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 13:17:55,939 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 13:17:55,941 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:17:55,944 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:55,945 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 13:17:55,946 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 13:17:55,946 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 13:17:55,949 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 13:17:55,949 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 13:17:55,954 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 13:17:55,957 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 13:17:55,957 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 13:17:55,964 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:17:55,970 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 13:17:55,971 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 13:17:55,973 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 13:17:55,974 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:17:55,976 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:17:55,980 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:17:55,981 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:55,982 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 13:17:55,988 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 13:17:55,989 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:55,989 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 13:17:55,990 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 13:17:55,990 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:55,994 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:17:55,994 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 13:17:55,994 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 13:17:55,994 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:17:55,994 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 13:17:56,001 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:17:56,002 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 13:17:56,004 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 13:17:56,008 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 13:17:56,008 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:56,008 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:56,014 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 13:17:56,014 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 13:17:56,018 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 13:17:56,019 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 13:17:56,021 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 13:17:56,027 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:56,028 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:56,029 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:56,029 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:56,030 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:56,031 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 13:17:56,032 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 13:17:56,038 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:56,040 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:56,042 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 13:17:56,044 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:56,044 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 13:17:56,045 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 13:17:56,045 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:56,046 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 13:17:56,046 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 13:17:56,047 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:56,048 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 13:17:56,049 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 13:17:56,053 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:56,056 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 13:17:56,058 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 13:17:56,058 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:56,059 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 13:17:56,060 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 13:17:56,061 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:17:56,061 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:56,062 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:56,062 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 13:17:56,064 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 13:17:56,064 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:56,064 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 13:17:56,066 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 13:17:56,069 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 13:17:56,070 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 13:17:56,072 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 13:17:56,073 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 13:17:56,073 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 13:17:56,075 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 13:17:56,076 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 13:17:56,077 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 13:17:56,079 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 13:17:56,079 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 13:17:56,080 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 13:17:56,080 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 13:17:56,081 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 13:17:56,081 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 13:17:56,081 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 13:17:56,082 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 13:17:56,082 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:17:56,087 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:56,088 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:56,089 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 13:17:56,090 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 13:17:56,092 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:56,094 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 13:17:56,095 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 13:17:56,095 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 13:17:56,096 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 13:17:56,096 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 13:17:56,096 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 13:17:56,098 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 13:17:56,098 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 13:17:56,099 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 13:17:56,099 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 13:17:56,102 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 13:17:56,105 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 13:17:56,106 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 13:17:56,106 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 13:17:56,109 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 13:17:56,110 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 13:17:56,112 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:17:56,112 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 13:17:56,113 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:17:56,113 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:17:56,114 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:17:56,115 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 13:17:56,123 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 13:17:56,126 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 13:17:56,126 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 13:17:56,130 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 13:17:56,132 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 13:17:56,136 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:17:56,138 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 13:17:56,142 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 13:17:56,144 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 13:17:56,144 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 13:17:56,144 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 13:17:56,144 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 13:17:56,144 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 13:17:56,152 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 13:17:56,153 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 13:17:56,159 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 13:17:56,161 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 13:17:56,204 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:17:56,215 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:17:56,233 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 13:17:57,579 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 13:17:57,610 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:17:57,612 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:57,623 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:17:57,626 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 13:17:57,627 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:57,629 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:17:57,631 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:57,641 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 13:17:57,643 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:17:57,645 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:17:57,647 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:17:57,647 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:17:57,656 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:17:57,658 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 13:17:57,661 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 13:17:57,677 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:17:57,679 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 13:17:57,680 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 13:17:57,681 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 13:17:57,682 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:17:57,696 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 13:17:57,698 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 13:17:57,704 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 13:17:57,709 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:17:57,710 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 13:17:57,711 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:17:57,712 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 13:17:57,714 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 13:17:57,715 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 13:17:57,718 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:17:57,722 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 13:17:57,724 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 13:17:57,725 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 13:17:57,726 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 13:17:57,727 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 13:17:57,727 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 13:17:57,728 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 13:17:57,729 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:17:57,730 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:17:57,731 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 13:17:57,732 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 13:17:57,732 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:17:57,736 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:17:57,739 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 13:17:57,739 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 13:17:57,741 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:17:57,741 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:17:57,746 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 13:17:57,759 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 13:17:57,773 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:17:57,774 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:17:57,775 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:17:57,776 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 13:17:57,777 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:57,777 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:17:57,778 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:17:57,779 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 13:17:57,779 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:17:57,780 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:17:57,781 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:17:57,782 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:17:57,791 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:17:57,792 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 13:17:57,793 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 13:17:57,793 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:17:57,794 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 13:17:57,795 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 13:17:57,796 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 13:17:57,797 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:17:57,797 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 13:17:57,798 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 13:17:57,799 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 13:17:57,807 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:17:57,807 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 13:17:57,808 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:17:57,809 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 13:17:57,809 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 13:17:57,810 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 13:17:57,811 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:17:57,811 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 13:17:57,812 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 13:17:57,814 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 13:17:57,815 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 13:17:57,820 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 13:17:57,824 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 13:17:57,824 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 13:17:57,825 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:17:57,826 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:17:57,827 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 13:17:57,827 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 13:17:57,828 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:17:57,830 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:17:57,830 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 13:17:57,831 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 13:17:57,831 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:17:57,832 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:17:57,841 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 13:17:57,974 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131757.wav, taille: 80339 bytes
2025-06-20 13:17:59,630 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131757.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:17:59,630 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131754.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:17:59,664 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131754.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:01,753 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:01] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:18:01,826 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:01] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:18:01,832 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:01] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:18:02,334 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:02] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:18:03,276 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:03,278 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:18:03,279 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:03,290 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:03,301 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:03,302 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:18:03,304 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:03,307 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:03,409 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:03,410 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:18:03,411 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:03,417 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:05,022 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:18:05,022 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1272 request_id=req_ffcb83aa87284eb258ea50a371f161b0 response_code=200
2025-06-20 13:18:05,438 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:18:05,438 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1194 request_id=req_cf50a2bd115929f9364f659c8973ccfd response_code=200
2025-06-20 13:18:05,917 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:18:05,998 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1472 request_id=req_3ab6715b768326d04548894049339b87 response_code=200
2025-06-20 13:18:08,092 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:08,093 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:18:08,427 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:08,428 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:18:08,441 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:08,444 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:18:09,567 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:18:09,569 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=800 request_id=req_b18f6b8cc937fcb15ecc4c705537c315 response_code=200
2025-06-20 13:18:09,636 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:18:09,639 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=932 request_id=req_45c10d0e45932a4312300f1a18870d90 response_code=200
2025-06-20 13:18:09,683 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:18:09,690 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:09,741 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:18:09,741 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:10,485 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 37
2025-06-20 13:18:10,485 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1153 request_id=req_9cedee92fb75b4fc1a1607827825e90c response_code=200
2025-06-20 13:18:10,601 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:18:10,603 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:13,302 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131813.wav, taille: 80339 bytes
2025-06-20 13:18:14,096 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131813.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:17,811 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:18:17,811 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u062c\\u064a\\u062a \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0639\\u0644\\u0649 \\u062d\\u0633\\u0627\\u0628 \\u0638\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:18:17,811 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:17,824 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:17,917 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131817.wav, taille: 80339 bytes
2025-06-20 13:18:18,341 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131817.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:18,391 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:18:18,396 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=213 request_id=req_7cc342c84fabae643d07718364a33f8a response_code=200
2025-06-20 13:18:18,472 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:18] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:21,512 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:18:21,512 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0639\\u0646\\u0642 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0648\\u0642\\u0644\\u062a \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0642\\u0644\\u062a \\u0644\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"Hollande radiateur\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:18:21,520 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:21,524 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:22,183 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:18:22,183 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=365 request_id=req_e8fe024ee4e7393c7320edea9c5879b6 response_code=200
2025-06-20 13:18:22,224 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:23,228 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131823.wav, taille: 80339 bytes
2025-06-20 13:18:23,701 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131823.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:27,916 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131827.wav, taille: 80339 bytes
2025-06-20 13:18:28,025 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:28,025 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:18:28,025 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:28,053 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:28,397 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131827.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:29,422 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:18:29,432 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=921 request_id=req_35dd886c5a190bf39bfc21adf719bed9 response_code=200
2025-06-20 13:18:31,566 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:18:31,566 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u0648\\u0643\\u0627\\u0646 \\u0627\\u0639\\u0637\\u0627\\u0646\\u064a \\u0627\\u0644\\u062f\\u0648\\u0627\\u0621 \\u0648\\u0644\\u0643\\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"au Canada network walking\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:18:31,571 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:31,576 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:32,025 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:18:32,032 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=223 request_id=req_731ada836505962507370a2821f0d919 response_code=200
2025-06-20 13:18:32,061 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:33,241 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131833.wav, taille: 80339 bytes
2025-06-20 13:18:33,716 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131833.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:35,111 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:35,111 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:18:36,132 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:18:36,133 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=639 request_id=req_8291e52167daea504fedbf9caec1dc0b response_code=200
2025-06-20 13:18:36,251 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:18:36,251 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u0642\\u0644\\u062a \\u0644\\u064a \\u0647\\u064a \\u0642\\u0635 \\u0627\\u0644\\u0639\\u0646\\u0642 \\u062f\\u064a\\u0627\\u0644\\u064a \\u064a\\u0634\\u0648\\u0641 \\u0648\\u062c\\u0647 \\u0645\\u0632\\u064a\\u0627\\u0646 \\u0648\\u0644\\u0642\\u0627\\u0647\\u0627 \\u0645\\u0646 \\u0641\\u0648\\u0642\\"\\n            Transcription Fran\\u00e7aise: \\"et je lui ai dit que je pouvais voir bien son visage et je l\'ai trouv\\u00e9 en haut.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:18:36,772 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:18:36,772 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=342 request_id=req_39f09d2dc82092c8e24765c71f53e381 response_code=200
2025-06-20 13:18:36,811 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:37,369 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:18:37,369 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u0645\\u0627 \\u062f\\u0627\\u0631 \\u0644\\u064a \\u0648\\u0627\\u0644\\u0648 \\u0645\\u0627\\u0632\\u0627\\u0644 \\u0639\\u0646\\u0642 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0628\\u063a\\u064a\\u062a \\u062f\\u0627\\u0628\\u0627 \\u064a\\u0634\\u0648\\u0641\\u0648\\u0627 \\u0644\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"Magali all\\u00f4 all\\u00f4\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:18:37,371 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:37,381 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:37,967 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:18:37,969 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=255 request_id=req_d4e34b6f1e210d13365e014153f372b7 response_code=200
2025-06-20 13:18:37,996 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:37] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:38,231 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131838.wav, taille: 80339 bytes
2025-06-20 13:18:38,703 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131838.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:41,423 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:41,424 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:18:41,424 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:41,424 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:42,782 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:18:42,782 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=777 request_id=req_e72dac03b10c3d55d70c88e9057c9044 response_code=200
2025-06-20 13:18:43,221 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131843.wav, taille: 80339 bytes
2025-06-20 13:18:43,663 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131843.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:45,539 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:45,541 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:18:47,183 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:18:47,184 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1145 request_id=req_356a15432df4b082deac0acdfae77aa5 response_code=200
2025-06-20 13:18:47,300 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:18:47,301 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:47,787 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:47,788 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:18:47,789 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:47,792 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:48,244 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131848.wav, taille: 80339 bytes
2025-06-20 13:18:48,688 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131848.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:50,799 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 40
2025-06-20 13:18:50,801 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2302 request_id=req_44312b08a442e8aa01f43a6024d8b29c response_code=200
2025-06-20 13:18:50,916 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:18:50,916 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais :\\n\\n            Transcription Darija: \\"\\u0642\\u0635\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"Oui, subons, clairs le choix.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:18:51,260 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:18:51,269 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=191 request_id=req_4d8986b1700f13784a9103eee22c5c4f response_code=200
2025-06-20 13:18:51,385 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:51,923 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:51,923 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:18:51,923 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:51,934 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:53,238 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131853.wav, taille: 80339 bytes
2025-06-20 13:18:53,403 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:18:53,417 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=682 request_id=req_040bb8b106c6b039d2fbabbf45ec4272 response_code=200
2025-06-20 13:18:53,716 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131853.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:55,986 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:55,992 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:18:56,871 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:18:56,871 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=508 request_id=req_c6d3cb61899e58ea8c99546d709719ea response_code=200
2025-06-20 13:18:56,982 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:18:56,982 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:18:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:18:57,190 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:18:57,191 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:18:57,192 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:18:57,195 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:18:58,221 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131858.wav, taille: 80339 bytes
2025-06-20 13:18:58,622 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131858.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:18:58,771 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:18:58,776 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=472 request_id=req_15024cd9c3b378ec634bd48dd1cceab9 response_code=200
2025-06-20 13:19:01,087 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:01,087 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:19:01,091 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:19:01,094 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:19:02,116 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:02,119 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:19:02,937 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:19:02,941 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1017 request_id=req_6356a328936696943b67f3dfa5b7b7d1 response_code=200
2025-06-20 13:19:03,226 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131903.wav, taille: 80339 bytes
2025-06-20 13:19:03,426 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 13:19:03,430 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1043 request_id=req_5ce7d7c18114639e971db1e228957dc7 response_code=200
2025-06-20 13:19:03,548 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:19:03,551 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:19:03,727 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131903.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:19:05,621 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:05,629 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:19:06,511 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 13:19:06,515 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=637 request_id=req_937d47bd9aa56d0812db22ad656d3f5b response_code=200
2025-06-20 13:19:06,618 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:19:06,621 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:19:06,916 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:06,917 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:19:06,918 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:19:06,926 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:19:08,222 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131908.wav, taille: 80339 bytes
2025-06-20 13:19:08,501 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:19:08,501 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=594 request_id=req_a4f4698111856416c41fdd81e938aea3 response_code=200
2025-06-20 13:19:08,664 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131908.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:19:10,553 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:10,553 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:19:11,672 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:19:11,688 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=809 request_id=req_74cd358723d77c36af2c072c56c63854 response_code=200
2025-06-20 13:19:11,744 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:11,748 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:19:11,750 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:19:11,760 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:19:11,804 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:19:11,804 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:19:13,031 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:19:13,036 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=526 request_id=req_98fdd0155903ff380034bd3399cba7c7 response_code=200
2025-06-20 13:19:13,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131913.wav, taille: 80339 bytes
2025-06-20 13:19:14,092 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131913.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:19:15,191 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:15,191 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:19:16,023 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:19:16,035 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=637 request_id=req_aa609777fb3d55962b100be2a2f94d84 response_code=200
2025-06-20 13:19:16,140 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:19:16,143 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:19:17,012 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:17,012 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:19:17,015 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:19:17,021 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:19:18,083 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:19:18,083 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=638 request_id=req_32f546593fcfcb2d06c9fe46ac8eed8c response_code=200
2025-06-20 13:19:18,241 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_131918.wav, taille: 80339 bytes
2025-06-20 13:19:18,631 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:18] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:19:18,766 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:18] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:19:18,776 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:18] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:19:18,939 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_131918.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:19:19,339 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:19] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:19:20,310 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:20,311 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:19:21,558 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:21,570 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:19:21,614 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:19:21,646 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:19:21,654 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:19:21,672 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1104 request_id=req_71ec81e7ea6e58a127f82252369c8be7 response_code=200
2025-06-20 13:19:21,790 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:19:21,795 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:21] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:19:23,734 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:19:23,734 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1593 request_id=req_430df3bd1458f3571fd6ac1a3f2a203a response_code=200
2025-06-20 13:19:26,657 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:19:26,658 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:19:27,845 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 14
2025-06-20 13:19:27,845 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=784 request_id=req_96b73a4003f7b96af94ad109a99101ca response_code=200
2025-06-20 13:19:27,964 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:19:27,967 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:19:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:19:29,017 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:19:29,054 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:19:30,696 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:19:44,766 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:19:44,782 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:19:48,234 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:19:48,236 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:19:49,472 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:19:58,384 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:19:58,397 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:20:05,530 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:20:05,530 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:20:06,490 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:20:15,993 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:20:15,997 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:20:30,956 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:20:30] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:20:31,035 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:20:31] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:20:31,039 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:20:31] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:20:31,396 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:20:31] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:20:39,882 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132039.wav, taille: 80339 bytes
2025-06-20 13:20:40,902 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:20:40,932 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:20:40,934 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:40,935 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:20:40,935 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 13:20:40,936 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:40,936 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 13:20:40,937 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:40,937 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 13:20:40,938 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:20:40,938 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 13:20:40,939 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:20:40,940 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 13:20:40,940 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:20:40,940 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:20:40,941 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:40,948 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 13:20:40,949 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 13:20:40,950 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 13:20:40,951 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 13:20:40,951 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 13:20:40,952 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 13:20:40,952 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 13:20:40,953 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 13:20:40,953 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:20:40,954 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 13:20:40,955 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 13:20:40,956 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 13:20:40,956 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:20:40,957 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 13:20:40,957 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 13:20:40,958 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 13:20:40,965 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:20:40,966 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 13:20:40,967 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:20:40,968 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 13:20:40,969 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 13:20:40,970 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 13:20:40,971 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:40,972 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:20:40,973 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 13:20:40,973 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 13:20:40,974 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 13:20:40,974 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 13:20:40,974 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:20:40,982 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:40,983 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:40,984 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:20:40,984 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:40,985 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 13:20:40,985 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:20:40,986 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:40,986 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:40,986 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 13:20:40,986 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:40,986 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 13:20:40,989 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 13:20:40,989 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:40,990 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 13:20:40,990 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 13:20:40,991 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 13:20:40,991 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 13:20:40,992 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 13:20:40,998 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 13:20:40,999 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:20:41,000 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:41,001 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 13:20:41,002 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 13:20:41,003 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 13:20:41,004 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 13:20:41,005 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 13:20:41,006 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 13:20:41,007 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 13:20:41,020 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 13:20:41,022 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:20:41,022 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 13:20:41,032 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 13:20:41,039 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 13:20:41,040 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:20:41,049 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:20:41,050 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:20:41,051 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:41,051 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 13:20:41,052 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 13:20:41,052 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:41,053 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 13:20:41,056 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 13:20:41,057 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:41,058 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:20:41,059 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 13:20:41,068 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 13:20:41,069 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:20:41,069 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 13:20:41,070 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:20:41,070 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 13:20:41,071 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 13:20:41,072 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 13:20:41,072 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:41,075 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:20:41,081 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 13:20:41,084 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 13:20:41,084 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 13:20:41,085 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 13:20:41,086 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 13:20:41,086 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:41,087 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:41,087 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:20:41,090 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:20:41,091 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:41,091 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 13:20:41,101 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 13:20:41,101 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:41,102 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:41,103 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 13:20:41,105 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:41,105 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 13:20:41,107 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 13:20:41,107 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:41,112 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 13:20:41,112 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 13:20:41,112 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:41,118 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 13:20:41,119 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 13:20:41,120 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:41,121 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 13:20:41,121 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 13:20:41,122 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:41,123 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 13:20:41,124 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 13:20:41,125 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:20:41,129 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:20:41,133 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:41,134 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 13:20:41,135 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 13:20:41,135 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:41,136 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 13:20:41,136 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 13:20:41,137 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 13:20:41,139 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 13:20:41,139 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 13:20:41,140 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 13:20:41,140 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 13:20:41,141 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 13:20:41,141 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 13:20:41,144 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 13:20:41,144 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 13:20:41,144 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 13:20:41,144 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 13:20:41,151 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 13:20:41,152 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 13:20:41,153 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 13:20:41,154 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 13:20:41,154 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 13:20:41,155 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:20:41,156 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:20:41,156 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:41,157 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 13:20:41,162 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 13:20:41,162 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:41,167 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 13:20:41,167 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 13:20:41,167 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 13:20:41,167 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 13:20:41,167 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 13:20:41,167 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 13:20:41,172 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 13:20:41,172 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 13:20:41,181 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 13:20:41,187 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 13:20:41,200 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 13:20:41,215 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 13:20:41,219 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 13:20:41,222 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 13:20:41,232 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 13:20:41,235 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 13:20:41,235 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:20:41,236 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 13:20:41,238 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:20:41,250 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:20:41,251 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:20:41,252 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 13:20:41,255 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 13:20:41,257 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 13:20:41,268 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 13:20:41,270 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 13:20:41,272 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 13:20:41,273 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:20:41,274 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 13:20:41,281 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 13:20:41,281 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 13:20:41,281 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 13:20:41,286 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 13:20:41,286 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 13:20:41,295 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 13:20:41,301 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 13:20:41,301 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 13:20:41,301 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 13:20:41,306 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 13:20:41,319 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:20:41,328 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:20:41,352 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 13:20:42,482 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 13:20:42,499 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:20:42,499 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:42,503 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:20:42,504 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 13:20:42,504 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:42,505 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:20:42,506 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:42,507 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 13:20:42,515 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:20:42,515 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:20:42,515 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:20:42,515 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:20:42,515 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:20:42,515 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 13:20:42,515 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 13:20:42,515 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:20:42,522 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 13:20:42,522 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 13:20:42,523 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 13:20:42,524 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:20:42,525 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 13:20:42,534 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 13:20:42,535 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 13:20:42,536 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:20:42,537 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 13:20:42,538 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:20:42,539 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 13:20:42,540 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 13:20:42,540 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 13:20:42,541 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:20:42,541 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 13:20:42,542 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 13:20:42,546 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 13:20:42,547 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 13:20:42,550 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 13:20:42,551 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 13:20:42,552 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 13:20:42,552 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:20:42,553 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:20:42,553 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 13:20:42,554 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 13:20:42,555 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:20:42,555 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:20:42,555 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 13:20:42,557 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 13:20:42,558 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:20:42,558 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:20:42,569 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 13:20:42,575 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 13:20:42,585 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:20:42,586 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:20:42,591 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:20:42,591 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:20:42,592 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:20:42,600 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 13:20:42,600 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 13:20:42,601 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:20:42,602 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 13:20:42,602 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 13:20:42,603 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 13:20:42,603 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:20:42,604 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 13:20:42,604 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 13:20:42,605 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 13:20:42,605 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:20:42,606 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 13:20:42,606 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:20:42,607 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 13:20:42,607 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 13:20:42,608 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 13:20:42,610 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:20:42,615 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 13:20:42,617 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 13:20:42,618 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 13:20:42,620 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 13:20:42,621 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 13:20:42,621 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 13:20:42,622 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 13:20:42,623 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:20:42,623 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:20:42,624 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 13:20:42,625 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 13:20:42,633 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:20:42,634 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:20:42,635 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 13:20:42,635 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 13:20:42,635 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:20:42,635 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:20:42,642 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 13:20:43,818 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132039.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:20:44,887 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132044.wav, taille: 80339 bytes
2025-06-20 13:20:45,342 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132044.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:20:49,882 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132049.wav, taille: 80339 bytes
2025-06-20 13:20:50,337 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132049.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:20:54,882 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132054.wav, taille: 80339 bytes
2025-06-20 13:20:55,352 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132054.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:20:59,862 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132059.wav, taille: 80339 bytes
2025-06-20 13:21:00,380 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132059.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:04,884 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132104.wav, taille: 80339 bytes
2025-06-20 13:21:05,352 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132104.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:09,892 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132109.wav, taille: 80339 bytes
2025-06-20 13:21:10,344 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132109.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:15,284 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132115.wav, taille: 87101 bytes
2025-06-20 13:21:15,875 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132115.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:19,976 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132119.wav, taille: 73577 bytes
2025-06-20 13:21:20,752 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132119.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:21,596 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:21:21] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:21:21,711 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:21:21] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:21:21,712 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:21:21] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:21:22,114 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:21:22] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:21:29,010 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132129.wav, taille: 80339 bytes
2025-06-20 13:21:29,619 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132129.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:34,009 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132134.wav, taille: 80339 bytes
2025-06-20 13:21:34,430 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132134.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:39,304 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132139.wav, taille: 85169 bytes
2025-06-20 13:21:39,727 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132139.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:44,177 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132144.wav, taille: 75509 bytes
2025-06-20 13:21:45,099 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132144.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:21:45,480 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:21:45] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:21:45,569 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:21:45] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:21:45,571 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:21:45] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:21:45,924 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:21:45] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:21:48,274 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:21:48,276 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:21:48,277 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:21:48,281 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:21:49,746 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:21:49,746 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:21:49,763 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:21:49,766 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:21:54,696 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:21:54,696 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:21:54,713 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:21:54,718 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:21:59,822 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:21:59,822 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:21:59,839 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:21:59,846 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:04,837 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:04,837 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:04,854 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:04,860 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:09,712 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:09,714 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:09,715 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:09,720 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:14,780 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:14,782 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:14,784 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:14,787 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:20,277 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:20,279 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:20,281 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:20,285 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:25,244 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:25,245 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:25,246 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:25,252 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:30,400 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:30,400 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026025E378B0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:22:30,400 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:22:31,838 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:31,838 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030158FA0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:22:31,838 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:22:34,041 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:34,042 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:34,042 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:34,049 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:36,790 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:36,790 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030173490>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:22:36,790 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:22:38,864 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:38,867 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:38,868 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:38,873 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:41,920 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:41,923 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030191D60>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:22:41,925 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:22:44,004 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132244.wav, taille: 80339 bytes
2025-06-20 13:22:44,212 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:44,213 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:44,214 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:44,219 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:44,462 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132244.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:22:46,938 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:46,940 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002603016DD60>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:22:46,940 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:22:49,310 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132249.wav, taille: 80339 bytes
2025-06-20 13:22:49,564 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:22:49,574 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:22:49,576 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:49,582 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:22:49,824 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132249.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:22:51,836 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:51,837 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002603016D7C0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:22:51,840 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:22:54,310 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132254.wav, taille: 80339 bytes
2025-06-20 13:22:54,790 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132254.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:22:56,872 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:22:56,872 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030184670>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:22:56,872 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:22:59,389 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132259.wav, taille: 79373 bytes
2025-06-20 13:23:01,714 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132259.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:02,467 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:02,473 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002603016D430>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:23:02,480 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:23:04,323 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132304.wav, taille: 79373 bytes
2025-06-20 13:23:04,948 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132304.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:07,448 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:07,539 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030168D00>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:23:07,682 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:23:10,324 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132310.wav, taille: 95795 bytes
2025-06-20 13:23:11,212 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132310.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:12,779 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:12,781 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030168C40>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:23:12,784 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 13:23:13,985 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:14,008 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030168580>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:23:14,028 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 13:23:15,315 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132315.wav, taille: 80339 bytes
2025-06-20 13:23:15,465 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:15,468 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:15,482 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 13:23:15,487 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:15,493 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000026031236F70>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 13:23:15,496 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 13:23:15,499 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:15,500 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002603123D160>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 13:23:15,511 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 13:23:15,640 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:15,649 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:15] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:16,034 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132315.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:16,100 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:16,102 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030168730>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:23:16,110 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:23:16,111 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:16,112 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x0000026031236AF0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 13:23:16,117 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 13:23:17,380 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:17,380 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:17,393 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:17,396 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:23:17,397 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:17,397 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 13:23:17,400 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:17,404 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002603123DBE0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 13:23:17,408 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:17,411 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (5): api.openai.com:443
2025-06-20 13:23:17,412 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:17,412 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:17,412 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002603123D4C0>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 13:23:17,413 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002603122FE50>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 13:23:17,415 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:23:17,415 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (6): api.openai.com:443
2025-06-20 13:23:17,415 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:17,425 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000002603122F730>: Failed to resolve 'api.openai.com' ([Errno 11001] getaddrinfo failed)")': /v1/audio/transcriptions
2025-06-20 13:23:17,426 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 13:23:17,538 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:17,541 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:19,085 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:19,085 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000260301686A0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:23:19,085 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 13:23:20,295 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132320.wav, taille: 80339 bytes
2025-06-20 13:23:20,704 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132320.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:20,772 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 41
2025-06-20 13:23:20,774 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=780 request_id=req_e5f867f330e1cc9c0951afa3d2e62643 response_code=200
2025-06-20 13:23:21,215 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:21,230 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000260301589A0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:23:21,257 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2025-06-20 13:23:22,355 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:22,358 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:22,366 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (4): api.openai.com:443
2025-06-20 13:23:22,415 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:22,421 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=764 request_id=req_0998e09e950664c5aff4e84d0a7985b7 response_code=200
2025-06-20 13:23:23,460 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:23:23,460 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u062a\\u0631\\u062c\\u0645\\u0629 \\u0646\\u0627\\u0646\\u0633\\u064a \\u0642\\u0646\\u0642\\u0631\\"\\n            Transcription Fran\\u00e7aise: \\"mets Virgin Radio\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:23:24,220 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:23:24,222 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=528 request_id=req_83b145cace481231355e327401fcc605 response_code=200
2025-06-20 13:23:24,293 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:24,303 - urllib3.util.retry - DEBUG - Incremented Retry for (url='/v1/audio/transcriptions'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:24,307 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000026030150D90>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond')': /v1/audio/transcriptions
2025-06-20 13:23:24,309 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2025-06-20 13:23:24,355 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:24,360 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=508 request_id=req_fdda994c06cd121e440ef1212989661e response_code=200
2025-06-20 13:23:24,425 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:24,428 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=474 request_id=req_974937142d47bcdfb2634a9cf5da9e7b response_code=200
2025-06-20 13:23:24,559 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:24,564 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:23:24,564 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:24,577 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:24,688 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:24,693 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=998 request_id=req_c9252d5b45bce309d385e87dc9bc9abd response_code=200
2025-06-20 13:23:24,704 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 47
2025-06-20 13:23:24,707 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1472 request_id=req_1003f69788f7d512d6536c0ffa7bc97f response_code=200
2025-06-20 13:23:24,766 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:24,770 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=545 request_id=req_fe28f34c4c030f0d4eb2d0c82f103242 response_code=200
2025-06-20 13:23:24,818 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:24,826 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:25,284 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132325.wav, taille: 80339 bytes
2025-06-20 13:23:25,615 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:23:25,620 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=788 request_id=req_b23fb6f9a5540bc5cde7cdb6f0c1a4ec response_code=200
2025-06-20 13:23:25,930 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132325.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:25,932 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:25,945 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:23:25,950 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:25,964 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:26,490 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:26,490 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1459 request_id=req_3a0e1449c46e6af809591248cca6ea0d response_code=200
2025-06-20 13:23:26,524 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:23:26,525 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646 \\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0628\\u0627\\u0628 \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0648\\u0634\\u0627\\u0641 \\u0627\\u0644\\u0639\\"\\n            Transcription Fran\\u00e7aise: \\"salam Ana kendji s\'appelle\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:23:26,528 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:26,532 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:26,720 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:26,721 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:27,224 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:27,228 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:23:27,245 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=758 request_id=req_1b71e178b9c0fd9531dff1bb05bb891d response_code=200
2025-06-20 13:23:27,255 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=390 request_id=req_8582bcde7c93e2063fa7efa51c9c75f8 response_code=200
2025-06-20 13:23:27,263 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:27,297 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=867 request_id=req_ddc1b0b9b060f4d948b4711c31a9e8d5 response_code=200
2025-06-20 13:23:27,322 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:27,558 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:27,561 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:27] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:27,610 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:27,620 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:27,730 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:27,731 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:27,845 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:27,849 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:23:27,851 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:27,861 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:28,450 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:23:28,450 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=619 request_id=req_9d703dc026581205f812b950c20043b3 response_code=200
2025-06-20 13:23:28,568 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:28,570 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:28,740 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:23:28,745 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=893 request_id=req_4833299e7da158dcc1b353d803e3c38b response_code=200
2025-06-20 13:23:28,850 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:28,854 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:28] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:28,959 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:28,961 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=686 request_id=req_ec711ba49ad3fb6946c34837c4788867 response_code=200
2025-06-20 13:23:29,005 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:29,008 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:29,024 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:23:29,025 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=818 request_id=req_c88558a78f5a66bc9be821cdc8b7f5dc response_code=200
2025-06-20 13:23:29,088 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 37
2025-06-20 13:23:29,090 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2185 request_id=req_d59c360711fef019b9c24f880d92af10 response_code=200
2025-06-20 13:23:29,121 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:29,121 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:23:29,130 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:29,131 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:29,147 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:29,154 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:29,205 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:29,210 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:29,332 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:29,333 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:29,335 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:29,343 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:29,616 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:29,617 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:29,637 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:29,640 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:29,732 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:29,733 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:30,125 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:30,211 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=472 request_id=req_c7dc345127ffd3da1a67e1ff467fb915 response_code=200
2025-06-20 13:23:30,245 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:30,272 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:23:30,274 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:30,300 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:30,336 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132330.wav, taille: 80339 bytes
2025-06-20 13:23:30,457 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:23:30,460 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=611 request_id=req_22a55dad1b132d968e001a290a97815c response_code=200
2025-06-20 13:23:30,564 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:30,570 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:31,004 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132330.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:31,124 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:23:31,127 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1278 request_id=req_c9ff5be49bcfe6c94a54b36a00686426 response_code=200
2025-06-20 13:23:31,181 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:23:31,192 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1951 request_id=req_8279168a9c6e3d6e90187737d353a1df response_code=200
2025-06-20 13:23:31,241 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:31,245 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:31,288 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 13:23:31,292 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1392 request_id=req_63891563e20dce776aed933cd5d93d0a response_code=200
2025-06-20 13:23:31,306 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:31,309 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:31,405 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:31,408 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:31,483 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:31,490 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:32,138 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:32,140 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:32,459 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:32,463 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:33,014 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 13:23:33,017 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=704 request_id=req_7d5ceb70ee392a82d2a2550e12e7c417 response_code=200
2025-06-20 13:23:33,135 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:33,140 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:33,242 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:23:33,243 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1569 request_id=req_2c13a188a5af8f7ea56ea2f10fe40921 response_code=200
2025-06-20 13:23:33,397 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:33] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:34,075 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 13:23:34,078 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1300 request_id=req_15622f9354c5956d61dc83cae5b9e66c response_code=200
2025-06-20 13:23:34,079 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:34] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:23:34,187 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:34] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:23:34,188 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:34,214 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:34,215 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:34] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:23:34,297 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:34,305 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:23:34,310 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:34,317 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:34,363 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:34] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:23:35,489 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:35,490 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:35,496 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:35,501 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:36,056 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:36,056 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=783 request_id=req_3ef8abf09ec95147f1b704ae754215a9 response_code=200
2025-06-20 13:23:37,904 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:23:37,904 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1493 request_id=req_d8fae862eb9d9bc8f87d22b1e1ac2979 response_code=200
2025-06-20 13:23:38,046 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:38] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:39,508 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:39,512 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:41,019 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:23:41,022 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1236 request_id=req_fe53c19b97ade1cbe4335128ab73f1c8 response_code=200
2025-06-20 13:23:41,135 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:41,135 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:44,312 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132344.wav, taille: 80339 bytes
2025-06-20 13:23:44,752 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132344.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:46,135 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:23:46,142 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=16241 request_id=req_06fccc9a5f53e8f084bfbade577e4a9a response_code=200
2025-06-20 13:23:46,204 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:23:46,204 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1092 request_id=req_bb719f645d5f4f0cd9a12415f7393b1c response_code=200
2025-06-20 13:23:46,255 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:23:46,256 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0648\\u0627\\u0634 \\u062a\\u062d\\u0633\\u0646\\u062a \\u0648\\u0644\\u0627 \\u0644\\u0627\\"\\n            Transcription Fran\\u00e7aise: \\"avec l\'argent \\u00e0 l\'approvisionnement.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:23:46,744 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:23:46,752 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=289 request_id=req_cd36abe5f032fca309341fb28ad6705d response_code=200
2025-06-20 13:23:46,781 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:48,592 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:23:48,592 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0627\\u0646 \\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0648\\u0634\\u0627\\u0641 \\u0627\\u0644\\u0639\\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:23:48,607 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:48,613 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:49,312 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132349.wav, taille: 80339 bytes
2025-06-20 13:23:49,648 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:23:49,663 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=454 request_id=req_458e25aeac4103257061244931729e5b response_code=200
2025-06-20 13:23:49,731 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:49,781 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132349.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:49,806 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:23:49,810 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:23:52,276 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 25
2025-06-20 13:23:52,276 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2133 request_id=req_c3bcbeff11a561f861acc24d15ff20af response_code=200
2025-06-20 13:23:52,386 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:23:52,387 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:52,892 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:23:52,892 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0648\\u0631\\u0642\\u0647 \\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0639\\u0646\\u062f\\u0643 \\u0628\\u062e\\u0648\\u0628\\u0644\\u064a\\u0645\\"\\n            Transcription Fran\\u00e7aise: \\"probl\\u00e8me\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:23:52,892 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:23:52,892 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:23:53,401 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:23:53,405 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=265 request_id=req_3a09317c049e00c796b1ed61d4529ce7 response_code=200
2025-06-20 13:23:53,442 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:23:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:23:54,303 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132354.wav, taille: 80339 bytes
2025-06-20 13:23:54,735 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132354.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:23:59,000 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132358.wav, taille: 80339 bytes
2025-06-20 13:23:59,412 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132358.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:00,532 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:00,541 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:24:00,543 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:00,558 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:02,503 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 16
2025-06-20 13:24:02,503 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1422 request_id=req_e8200a0fd1180795ec3a65266dc935dc response_code=200
2025-06-20 13:24:02,619 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:24:02,619 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0641\\u064a \\u0627\\u0644\\u062d\\u0631\\u0642\\"\\n            Transcription Fran\\u00e7aise: \\"c\'est\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:24:02,986 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:24:02,986 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=172 request_id=req_b08b97bc7c5509a008d3aeceaafa57bc response_code=200
2025-06-20 13:24:03,017 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:03] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:04,312 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132404.wav, taille: 80339 bytes
2025-06-20 13:24:04,762 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132404.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:08,071 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:08,072 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:24:08,073 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:08,079 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:08,518 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:08,519 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:24:08,520 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:08,531 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:09,312 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132409.wav, taille: 80339 bytes
2025-06-20 13:24:09,787 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 36
2025-06-20 13:24:09,792 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=751 request_id=req_ef1e83f927e2ae15aeb465c3489813ec response_code=200
2025-06-20 13:24:09,810 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132409.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:10,210 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:24:10,212 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1102 request_id=req_22e92563d091d4ad7d41b32c8851b83d response_code=200
2025-06-20 13:24:10,320 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:24:10,342 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0627 \\u0627\\u0644\\u0633\\"\\n            Transcription Fran\\u00e7aise: \\"auquel il y a d\\u00e9j\\u00e0 un peu de semaine, d\\u00e9j\\u00e0 un peu de semaine, je vais\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:24:10,392 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:10] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:24:10,486 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:10] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:24:10,493 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:10] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:24:10,849 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:24:10,853 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=262 request_id=req_6f5c0143f0c048e8f7acbad661cb684d response_code=200
2025-06-20 13:24:10,885 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:10,910 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:10] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:24:12,439 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:12,441 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:24:12,444 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:12,452 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:13,678 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:24:13,679 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=698 request_id=req_185845252ff288f73569bfb71c2f7582 response_code=200
2025-06-20 13:24:14,221 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:14,223 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:24:15,842 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:15,842 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:24:16,018 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 28
2025-06-20 13:24:16,018 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1404 request_id=req_fa0cbe2dc636be19fc1c5f29883337cb response_code=200
2025-06-20 13:24:16,134 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:24:16,135 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0644\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Transcription Fran\\u00e7aise: \\"Je m\'arr\\u00eate ici.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:24:16,475 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:24:16,478 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=152 request_id=req_e8b4ea4cc9ced258ab0a1c6c452619d8 response_code=200
2025-06-20 13:24:16,508 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:17,138 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:24:17,138 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=998 request_id=req_c1d06c9b65886c9740b85f5c7d77e317 response_code=200
2025-06-20 13:24:17,253 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:24:17,256 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:17,623 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132417.wav, taille: 80339 bytes
2025-06-20 13:24:18,069 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132417.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:21,250 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:24:21,253 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0639\\u0646\\u062f \\u0628\\u0627\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u064a\\u0633 \\u0634\\u0627\\u0641 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:24:21,262 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:21,286 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:21,983 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:24:21,988 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=334 request_id=req_134c5659a36d7981e37baf9c21a4b0fa response_code=200
2025-06-20 13:24:22,044 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:22,308 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132422.wav, taille: 80339 bytes
2025-06-20 13:24:23,028 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132422.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:27,619 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132427.wav, taille: 80339 bytes
2025-06-20 13:24:28,128 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132427.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:31,361 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:31,361 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:24:31,363 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:31,373 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:32,628 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132432.wav, taille: 80339 bytes
2025-06-20 13:24:33,123 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132432.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:34,238 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:24:34,249 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1226 request_id=req_dfb60b3207d986cbe1396f9ddbaf1d25 response_code=200
2025-06-20 13:24:34,367 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:24:34,368 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0642\\u0644\\u0628\\u0647 \\u0648\\u0644\\u0642\\u0627\\u0647 \\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0639\\u0646\\u062f\\u0643\\"\\n            Transcription Fran\\u00e7aise: \\"et je lui ai dit que j\'avais un probl\\u00e8me.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:24:34,899 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:24:34,908 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=300 request_id=req_06f0311167551ea213d0326275be078a response_code=200
2025-06-20 13:24:34,967 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:37,633 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132437.wav, taille: 80339 bytes
2025-06-20 13:24:37,638 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:37,639 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:24:37,642 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:37,652 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:38,134 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132437.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:39,368 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:39,368 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:24:39,372 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:39,378 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:40,353 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:24:40,353 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1260 request_id=req_cbd2d4938407aede2ba1d47fe371f008 response_code=200
2025-06-20 13:24:40,908 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:40,908 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:24:40,915 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:40,925 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:42,168 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:24:42,168 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2162 request_id=req_01a77703e7600f505390693101aee17c response_code=200
2025-06-20 13:24:42,184 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:24:42,186 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0634\\u0643\\u0631\\u0627 \\u0639\\u0644\\u0649 \\u0627\\u0644\\u0645\\u0634\\u0627\\u0647\\u062f\\u0629\\"\\n            Transcription Fran\\u00e7aise: \\"cherche Lorenzi\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:24:42,283 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:24:42,284 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u062d\\u0644\\u0642\\u0647 \\u0647\\u0648 \\u0643\\u0627\\u064a\\u0639\\u0637\\u064a\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\"\\n            Transcription Fran\\u00e7aise: \\"Le dernier jour, il m\'a donn\\u00e9 une douche et il m\'a dit qu\'il reviendrait en deux semaines.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:24:42,628 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132442.wav, taille: 80339 bytes
2025-06-20 13:24:42,632 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:24:42,637 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=559 request_id=req_25cc2c6f06c3b0350438b58a3423dc64 response_code=200
2025-06-20 13:24:42,642 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:24:42,658 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=221 request_id=req_1a5c02ac57290bce62dfb3813807876b response_code=200
2025-06-20 13:24:42,742 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:42,848 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:24:42,860 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=364 request_id=req_8e69d4d0f68321b17e2431752a7f696b response_code=200
2025-06-20 13:24:42,963 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:43,343 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132442.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:45,009 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:45,009 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:24:46,226 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:46,227 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:24:46,229 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:46,237 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:46,568 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:24:46,569 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1216 request_id=req_5007e44b04994162f83d9aa094e956ac response_code=200
2025-06-20 13:24:46,680 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:24:46,683 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:47,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132447.wav, taille: 80339 bytes
2025-06-20 13:24:47,743 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:24:47,749 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=784 request_id=req_0a096d74ed12a9149c89744289df0efc response_code=200
2025-06-20 13:24:48,143 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132447.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:50,469 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:50,469 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:24:51,595 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:24:51,606 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=937 request_id=req_d68a7268bfb373602e82f9eb40ecc186 response_code=200
2025-06-20 13:24:51,715 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:24:51,726 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:24:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:24:52,165 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:24:52,166 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:24:52,174 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:24:52,191 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:24:53,304 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132453.wav, taille: 90965 bytes
2025-06-20 13:24:53,651 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:24:53,655 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=713 request_id=req_7e5d7f12338719fc5b4ca33624a2c17a response_code=200
2025-06-20 13:24:53,845 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132453.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:24:58,288 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132458.wav, taille: 80339 bytes
2025-06-20 13:24:58,717 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132458.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:00,045 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:00,072 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:01,020 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:01,023 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=342 request_id=req_8219dc1c9b29373be327e39b653d1320 response_code=200
2025-06-20 13:25:01,053 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:01,056 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:01,059 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:01,070 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:01,132 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:01,135 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:02,670 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:02,685 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:02,687 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:02,703 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:03,355 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132503.wav, taille: 80339 bytes
2025-06-20 13:25:03,617 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:25:03,621 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=721 request_id=req_ed00c64453e31db0940638a6d27b5004 response_code=200
2025-06-20 13:25:03,969 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132503.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:05,398 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:25:05,408 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1938 request_id=req_1fdef20285c828bd4c35d625c846c029 response_code=200
2025-06-20 13:25:06,391 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:06,393 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:06,395 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:06,406 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:07,414 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:07,414 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:08,308 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132508.wav, taille: 80339 bytes
2025-06-20 13:25:08,438 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:25:08,441 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=804 request_id=req_19868b667b44ec94646ff6d2bf6645b0 response_code=200
2025-06-20 13:25:08,529 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:08,557 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:08,893 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132508.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:09,125 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:09,128 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1285 request_id=req_3d1759b45464e2f4903702a9944d3abf response_code=200
2025-06-20 13:25:09,249 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:09,252 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:10,828 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:10,828 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1979 request_id=req_c7367245d0a79b7c8ed9257d093cfe2d response_code=200
2025-06-20 13:25:10,938 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:10,938 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:11,410 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:11,412 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:12,298 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:12,308 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=562 request_id=req_07b793ce89a987d5ddcd9929b4d51937 response_code=200
2025-06-20 13:25:12,418 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:12,418 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:12,764 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:12,765 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:12,766 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:12,773 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:13,288 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132513.wav, taille: 80339 bytes
2025-06-20 13:25:13,966 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132513.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:14,273 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 19
2025-06-20 13:25:14,279 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1016 request_id=req_c39f5c6934893042b0cc7f50ad4a913b response_code=200
2025-06-20 13:25:17,391 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:17,392 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:17,980 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:17,981 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:17,982 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:17,986 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:18,280 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132518.wav, taille: 80339 bytes
2025-06-20 13:25:18,638 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132518.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:19,168 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:19,168 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1314 request_id=req_4d3395f4980fe1222fdb2b0203ddd77a response_code=200
2025-06-20 13:25:19,288 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:19,288 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:21,628 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:21,628 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2608 request_id=req_80d04086a426a7ef3126239aa4ef0f39 response_code=200
2025-06-20 13:25:22,424 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:22,424 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:22,428 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:22,430 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:23,286 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132523.wav, taille: 80339 bytes
2025-06-20 13:25:23,684 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132523.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:24,498 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:24,498 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1116 request_id=req_0e29f49616cde14447277ebc5cfb6a4e response_code=200
2025-06-20 13:25:27,871 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:27,871 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:27,873 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:27,876 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:28,288 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132528.wav, taille: 80339 bytes
2025-06-20 13:25:28,880 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132528.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:28,898 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:28,903 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:29,602 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 41
2025-06-20 13:25:29,604 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=652 request_id=req_bf58ed8d0ae46919d12eb206b690e688 response_code=200
2025-06-20 13:25:29,636 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:29,637 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:30,938 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:30,938 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=856 request_id=req_f4367eb2f0c3007569febc6ecb8ac1b4 response_code=200
2025-06-20 13:25:31,050 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:25:31,051 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u064a\\u062c\\u0628 \\u0623\\u0646 \\u0646\\u062a\\u062d\\u062f\\u062b \\u0639\\u0646 \\u0627\\u0644\\u062a\\u062d\\u0633\\u0646 \\u0645\\u0646 \\u062e\\u0644\\u0627\\u0644 \\u0627\\u0644\\u062a\\u0648\\u0627\\u0635\\u0644 \\u0627\\u0644\\u0625\\u062c\\u062a\\u0645\\u0627\\u0639\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"C\'est pour \\u00e7a qu\'on a choisi l\'Universit\\u00e9 d\'Ottawa.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:25:31,398 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:31,401 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2245 request_id=req_43d6a96c144c29d2f600aeb280c045f3 response_code=200
2025-06-20 13:25:31,519 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:25:31,521 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0646\\u0642\\u0644\\u0647\\u0627 \\u0648\\u0646\\u0636\\u0639\\u0647\\u0627 \\u0644\\u062a\\u062d\\u062f\\u064a\\u062f \\u0627\\u0644\\u0641\\u0631\\u0645\\u0627\\u062a \\u0627\\u0644\\u0633\\u064a\\u0626\\u0629\\"\\n            Transcription Fran\\u00e7aise: \\"On peut le faire, on peut le faire, il n\'y a pas de difficult\\u00e9, il n\'y a pas de formations.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:25:31,751 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:25:31,753 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=450 request_id=req_d0aab223e0a57caa11875dc0f66be99e response_code=200
2025-06-20 13:25:31,776 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:32,303 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:25:32,305 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=283 request_id=req_e885a8dabd05654bffebca6eae10504d response_code=200
2025-06-20 13:25:32,329 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:32,815 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:32,818 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:32,818 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:32,818 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:33,308 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132533.wav, taille: 80339 bytes
2025-06-20 13:25:33,718 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132533.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:34,142 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:34,143 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:34,450 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:34,458 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=770 request_id=req_50db5ec26b9fd2d3a9ebdface91cff23 response_code=200
2025-06-20 13:25:35,045 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 18
2025-06-20 13:25:35,046 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=724 request_id=req_7ace50db703a18d8729f1077085c76d3 response_code=200
2025-06-20 13:25:35,148 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:25:35,149 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u062a\\u0631\\u062c\\u0645\\u0629 \\u0646\\u0627\\u0646\\u0633\\u064a \\u0642\\u0646\\u0642\\u0631\\"\\n            Transcription Fran\\u00e7aise: \\"\\u00c9cran.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:25:35,954 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:25:35,958 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=290 request_id=req_8ba235e5b7443a591236a7c5541206f5 response_code=200
2025-06-20 13:25:36,035 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:37,084 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:37,088 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:37,088 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:37,088 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:38,238 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:38,245 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:38,285 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132538.wav, taille: 80339 bytes
2025-06-20 13:25:38,706 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132538.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:39,949 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:25:39,992 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2089 request_id=req_70bc00b753f8a40906c5a8bd88e846f3 response_code=200
2025-06-20 13:25:41,990 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:41,990 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:41,994 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:42,001 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:42,198 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 41
2025-06-20 13:25:42,198 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=3781 request_id=req_4568750dcbee901c43df067d5c86b647 response_code=200
2025-06-20 13:25:42,313 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:25:42,314 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0633\\u0628\\u062d\\u0627\\u0646\\u0643 \\u0627\\u0644\\u0644\\u0647\\u0645 \\u0648\\u0628\\u062d\\u0645\\u062f\\u0643 \\u0627\\u0634\\u0647\\u062f \\u0627\\u0646 \\u0644\\u0627 \\u0627\\u0644\\u0647 \\u0627\\u0644\\u0627 \\u0627\\u0646\\u062a \\u0627\\u0633\\u062a\\u063a\\u0641\\u0631\\u0643 \\u0648\\u0627\\u062a\\u0648\\u0628 \\u0627\\u0644\\u064a\\u0643\\"\\n            Transcription Fran\\u00e7aise: \\"Vous y allez \\u00e0 zup d\\u00e9chirer.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:25:42,621 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132542.wav, taille: 69713 bytes
2025-06-20 13:25:42,950 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:25:42,952 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=418 request_id=req_401853c47e38c2a26b6ce2e893fe464d response_code=200
2025-06-20 13:25:43,006 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:43,194 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132542.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:43,407 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:25:43,410 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=836 request_id=req_8640673f44fee1bfde2833b245ed9213 response_code=200
2025-06-20 13:25:44,164 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:44,166 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:45,605 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 37
2025-06-20 13:25:45,608 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1108 request_id=req_fe0e5663a2fbf849691dbf7eded4cea1 response_code=200
2025-06-20 13:25:45,712 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:45,712 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:45] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:46,936 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:46,937 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:46,937 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:46,938 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:47,122 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:47,122 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:47,625 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132547.wav, taille: 80339 bytes
2025-06-20 13:25:48,079 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132547.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:48,277 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:48,280 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=753 request_id=req_b78f67d72ad5f76abc903d460ebf75f7 response_code=200
2025-06-20 13:25:48,396 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:48,398 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:48] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:48,630 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 30
2025-06-20 13:25:48,630 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1290 request_id=req_8ee0d42a98cc194ae13de81e4cf0e6f0 response_code=200
2025-06-20 13:25:49,908 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132549.wav, taille: 35903 bytes
2025-06-20 13:25:50,233 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132549.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:25:51,106 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:51,109 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:51,110 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:51,118 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:52,135 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:52,138 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:52,242 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:25:52,244 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=527 request_id=req_27456e9cfa1f60950aaf6e452b9712b5 response_code=200
2025-06-20 13:25:53,150 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:53,150 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:25:53,150 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:25:53,161 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:25:54,218 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:25:54,218 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=466 request_id=req_a940cb3e629e4f5cd1f67e1543796a33 response_code=200
2025-06-20 13:25:54,232 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 32
2025-06-20 13:25:54,234 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1699 request_id=req_0679738cc3de743529c53de04e565245 response_code=200
2025-06-20 13:25:54,348 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:25:54,348 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0643\\u0631\\u0627\\u0648\\u0632 \\u062c\\u0648\\u0644\\u062a\\"\\n            Transcription Fran\\u00e7aise: \\"Comme vous le voyez..\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:25:54,438 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:54,438 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:54,858 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:25:54,858 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=357 request_id=req_15c344b96181d671e521bec6ac019020 response_code=200
2025-06-20 13:25:54,888 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:54] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:55,813 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:55,813 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=962 request_id=req_014a4a2750db922da91686f15023299b response_code=200
2025-06-20 13:25:55,918 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:55,918 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:25:56,292 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:25:56,293 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:25:57,028 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:25:57,031 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=472 request_id=req_fea076d3ce6e993c3efecede6d3c1eff response_code=200
2025-06-20 13:25:57,144 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:25:57,147 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:25:57] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:26:12,406 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'salam à la cantine', 'fused': 'salam à la cantine', 'segment_id': 20}
2025-06-20 13:26:12,410 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:26:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:26:14,748 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:26:14,749 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:26:14,749 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:26:14,754 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:26:16,938 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 13
2025-06-20 13:26:16,938 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1125 request_id=req_5cffe357edfcaa300b957151e01541bb response_code=200
2025-06-20 13:26:17,057 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '»', 'fused': '»', 'segment_id': 21}
2025-06-20 13:26:17,058 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:26:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:26:24,348 - app - DEBUG - Résultat transcription: {'darija': '', 'french': 'Slimane chauffage', 'fused': 'Slimane chauffage', 'segment_id': 22}
2025-06-20 13:26:24,348 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:26:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:26:57,267 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:26:57] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:26:57,368 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:26:57] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:26:57,376 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:26:57] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:26:57,877 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:26:57] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:27:07,009 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132707.wav, taille: 80339 bytes
2025-06-20 13:27:07,465 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132707.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:11,425 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:27:11,425 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646 \\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0648\\u0634\\u0627\\u0641 \\u0645\\u0639\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"salam Ana kendji centre b\\u00e9b\\u00e9\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:27:11,433 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:11,437 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:12,155 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:27:12,155 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=342 request_id=req_269529fd07cf50484d31f420cec4b185 response_code=200
2025-06-20 13:27:12,183 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:12] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:12,314 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132712.wav, taille: 80339 bytes
2025-06-20 13:27:12,745 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132712.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:16,427 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:27:16,427 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0628\\u0627\\u0634 \\u064a\\u0634\\u0648\\u0641\\"\\n            Transcription Fran\\u00e7aise: \\"ok Google\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:27:16,427 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:16,437 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:17,051 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:27:17,053 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=283 request_id=req_826217b0443bf3c0e3d8807622712780 response_code=200
2025-06-20 13:27:17,075 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:17,315 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132717.wav, taille: 80339 bytes
2025-06-20 13:27:17,750 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132717.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:22,046 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:27:22,047 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:27:22,047 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:22,087 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:22,315 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132722.wav, taille: 80339 bytes
2025-06-20 13:27:22,896 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132722.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:23,295 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:27:23,295 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=921 request_id=req_450e0bf27c89c1d0ce0b883ba3cb823e response_code=200
2025-06-20 13:27:25,435 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:27:25,435 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u062c\\u0648\\u062c\\u0644 \\u0628\\u0644\\u064a\\u0644\\u0647 \\u0646\\u0632\\u064a\\u062f \\u0639\\u0644\\u064a \\u0627\\u0644\\u062d\\u0627\\u0644 \\u063a\\u0627\\u062f\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"Google\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:27:25,447 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:25,450 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:25,963 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:27:25,965 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=210 request_id=req_4bf2911f9751b8cf74661b2600b57b32 response_code=200
2025-06-20 13:27:25,993 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:27,315 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132727.wav, taille: 80339 bytes
2025-06-20 13:27:27,735 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132727.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:29,510 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:27:29,511 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:27:30,475 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:27:30,475 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0636\\u0631\\u0648\\u0631\\u064a \\u0646\\u062f\\u064a\\u0631\\u0648\\u0627 \\u0627\\u0648\\u0628\\u064a\\u0631\\u0627\\u0633\\u064a\\u0648\\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"op\\u00e9ration\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:27:30,484 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:30,499 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:31,021 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:27:31,025 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=198 request_id=req_b3fe8743919a914434820034030127d8 response_code=200
2025-06-20 13:27:31,051 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:31,645 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:27:31,645 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1946 request_id=req_b079110254a08ef9af9740c4e169d75c response_code=200
2025-06-20 13:27:31,796 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:32,316 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132732.wav, taille: 80339 bytes
2025-06-20 13:27:32,754 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132732.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:35,279 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:27:35,280 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:27:35,282 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:35,286 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:37,007 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132736.wav, taille: 80339 bytes
2025-06-20 13:27:37,110 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:27:37,115 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=658 request_id=req_0ca037697200a898e1cf11994191cb3b response_code=200
2025-06-20 13:27:37,445 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132736.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:39,398 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:27:39,398 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:27:39,901 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:27:39,902 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:27:39,903 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:39,911 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:40,395 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132740.wav, taille: 49427 bytes
2025-06-20 13:27:40,615 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:27:40,620 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=301 request_id=req_8f3e3b649081433bc4540adc94a6ad65 response_code=200
2025-06-20 13:27:40,780 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132740.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:41,170 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:41] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:27:41,238 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:27:41,245 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1538 request_id=req_a888ff445d167c36515bc38d99389851 response_code=200
2025-06-20 13:27:41,271 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:41] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:27:41,286 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:41] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:27:41,385 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:27:41,389 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:41] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:41,677 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:41] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:27:42,931 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:27:42,932 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:27:43,138 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:27:43,139 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:27:43,142 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:43,150 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:44,178 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 13:27:44,179 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=599 request_id=req_2ec4b1d094e1c6370b0bb7ba1baf97cc response_code=200
2025-06-20 13:27:44,231 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:27:44,233 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=538 request_id=req_d6ea8c1f9f424a6abc2d00247f31125d response_code=200
2025-06-20 13:27:44,294 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:27:44,297 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:46,491 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:27:46,493 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:27:47,587 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 31
2025-06-20 13:27:47,590 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=736 request_id=req_6bc1de7e4da39d9ebcfa250b2b88043e response_code=200
2025-06-20 13:27:47,707 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:27:47,711 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:48,108 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132748.wav, taille: 80339 bytes
2025-06-20 13:27:48,524 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132748.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:52,395 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:27:52,396 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646 \\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0634\\u0627\\u0641 \\u0645\\u0639\\u064a \\u0627\\u0644\\u0639\\u0646\\u0642 \\u062f\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:27:52,398 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:27:52,403 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:27:53,380 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:27:53,385 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=372 request_id=req_efcbfd454643fbffa182f518f9cd0a16 response_code=200
2025-06-20 13:27:53,417 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132753.wav, taille: 80339 bytes
2025-06-20 13:27:53,431 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:27:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:27:53,845 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132753.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:27:58,411 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132758.wav, taille: 80339 bytes
2025-06-20 13:27:58,831 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132758.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:28:03,399 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132803.wav, taille: 80339 bytes
2025-06-20 13:28:03,825 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132803.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:28:04,310 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:04,310 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:28:04,310 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:28:04,330 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:28:05,821 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:28:05,823 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=967 request_id=req_e03ef6f2b4b1427f11bd1f8bd501fc88 response_code=200
2025-06-20 13:28:05,941 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:28:05,942 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0643\\u0627\\u0646 \\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"Et il m\'a donn\\u00e9 un doigt et il m\'a dit qu\'il allait revenir deux semaines.\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:28:06,457 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:28:06,460 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=333 request_id=req_ca395aa864fcff84abf8ee5d9d7ac640 response_code=200
2025-06-20 13:28:06,509 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:28:06] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:28:07,412 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:28:07,412 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0645\\u0627 \\u0643\\u0627\\u0646\\u062a\\u0634 \\u063a\\u0627\\u062f\\u064a \\u0636\\u0631\\u0648\\u0631\\u064a \\u0646\\u062f\\u064a\\u0631\\u0648\\u0627 \\u0627\\u0648\\u0628\\u064a\\u0631\\u0627\\u0633\\u064a\\u0648\\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"Macan sur Radio op\\u00e9ration\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:28:07,412 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:28:07,421 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:28:08,032 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:28:08,032 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=215 request_id=req_7106f6a61ac15e71213491b0a50291bc response_code=200
2025-06-20 13:28:08,060 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:28:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:28:08,402 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132808.wav, taille: 80339 bytes
2025-06-20 13:28:08,685 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:08,686 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:28:08,687 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:28:08,698 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:28:08,861 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132808.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:28:11,690 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:28:11,690 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2521 request_id=req_5e0f64fc4983751073a96834be7c0b2b response_code=200
2025-06-20 13:28:11,835 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:28:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:28:12,057 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:12,058 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:28:12,059 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:28:12,068 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:28:13,406 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:28:13,422 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=635 request_id=req_a766e72705f906462a169803bbd35a11 response_code=200
2025-06-20 13:28:13,514 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132813.wav, taille: 80339 bytes
2025-06-20 13:28:14,222 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132813.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:28:15,759 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:15,762 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:28:16,539 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:16,541 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:28:16,546 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:28:16,561 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:28:16,875 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 37
2025-06-20 13:28:16,877 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=884 request_id=req_6abe705ffa7696e6be48b3a4bf50d787 response_code=200
2025-06-20 13:28:16,990 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:28:16,993 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:28:16] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:28:18,401 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132818.wav, taille: 80339 bytes
2025-06-20 13:28:18,828 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132818.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:28:21,200 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:21,214 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:28:21,219 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:28:21,243 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:28:22,595 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:28:22,595 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=721 request_id=req_8fb47e5f7c411a8516eda9610e739f9d response_code=200
2025-06-20 13:28:23,416 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132823.wav, taille: 80339 bytes
2025-06-20 13:28:23,846 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132823.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:28:24,819 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:24,819 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:28:25,219 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_132825.wav, taille: 28175 bytes
2025-06-20 13:28:25,545 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_132825.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:28:25,978 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:25,980 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:28:25,982 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:28:25,986 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:28:26,868 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 28
2025-06-20 13:28:26,868 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1721 request_id=req_e5b0b90604301c6138a06ba6b2be86fa response_code=200
2025-06-20 13:28:26,909 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:28:26,911 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=617 request_id=req_1db54ef35065fc2ebaaeaaf5cc968d12 response_code=200
2025-06-20 13:28:26,985 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:28:26,988 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:28:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:28:27,658 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:27,660 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:28:27,661 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:28:27,664 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:28:28,920 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:28,930 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:28:29,137 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:28:29,141 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1107 request_id=req_074304ae9d6189a20ff57c4df3fdb58b response_code=200
2025-06-20 13:28:29,765 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:28:29,767 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=624 request_id=req_e132a361d063980662ee643518cb8cbe response_code=200
2025-06-20 13:28:29,872 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:28:29,875 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:28:29] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:28:31,436 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:28:31,436 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:28:32,873 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 37
2025-06-20 13:28:32,873 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1227 request_id=req_0c114555dfcf77fefb46ad7d87d31113 response_code=200
2025-06-20 13:28:32,988 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:28:32,991 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:28:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:28:59,811 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:28:59,811 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=42285 request_id=req_d1da59fce725f5f75b08317466e573a4 response_code=200
2025-06-20 13:29:02,507 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:29:02,509 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:29:04,321 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:29:04,321 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1539 request_id=req_aee3cda0168029468f86174cba06acef response_code=200
2025-06-20 13:29:04,441 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:29:04,441 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:29:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:31:43,801 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:31:43] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:31:43,923 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:31:43] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:31:44,007 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:31:44] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 13:31:44,351 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:31:44] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:31:50,812 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133150.wav, taille: 80339 bytes
2025-06-20 13:31:51,539 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133150.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:31:55,829 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:31:55,829 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0639\\u0646\\u062f \\u0637\\u0628\\u064a\\u0628 \\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0641\\u0627\\u064a\\u062a\\u0647 \\u0634\\u0627\\u0641 \\u0645\\u0639\\u064a \\u0627\\u0644\\u062d\\u0631\\u0642\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin J5\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:31:55,841 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:31:55,852 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:31:56,116 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133156.wav, taille: 80339 bytes
2025-06-20 13:31:56,566 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:31:56,566 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=265 request_id=req_1e81a1fc395ccac9aaf2cf96b7aa0fa1 response_code=200
2025-06-20 13:31:56,571 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133156.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:31:56,604 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:31:56] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:32:00,904 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:32:00,904 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0648\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0646\\u0634\\u0648\\u0641\\"\\n            Transcription Fran\\u00e7aise: \\"attends je suis devant\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:32:00,906 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:32:00,912 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:32:01,116 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133201.wav, taille: 80339 bytes
2025-06-20 13:32:01,546 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:32:01,551 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=219 request_id=req_8b4b6fe8b5cdc8480f18d38effe2c0fa response_code=200
2025-06-20 13:32:01,591 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:32:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:32:01,591 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133201.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:32:06,124 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133206.wav, taille: 80339 bytes
2025-06-20 13:32:06,566 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133206.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:32:08,813 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:32:08,814 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0636\\u0631\\u0648\\u0631\\u064a \\u0646\\u062f\\u064a\\u0631\\u0648\\u0627\\"\\n            Transcription Fran\\u00e7aise: \\"restaurant op\\u00e9ration\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:32:08,820 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:32:08,825 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:32:09,540 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:32:09,549 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=439 request_id=req_f4c7280813d3de5d6e153ed164fc52eb response_code=200
2025-06-20 13:32:09,592 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:32:09] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:32:09,864 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:32:09,865 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:32:09,866 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:32:09,869 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:32:11,244 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133211.wav, taille: 81305 bytes
2025-06-20 13:32:11,716 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133211.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:32:13,262 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 16
2025-06-20 13:32:13,266 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2329 request_id=req_5755539bec5f29991946b0368115135d response_code=200
2025-06-20 13:32:13,751 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:32:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:32:14,849 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:32:14,849 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:32:14,849 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:32:14,856 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:32:15,966 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:32:15,966 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=649 request_id=req_ecdae603479b2318af131513388704f8 response_code=200
2025-06-20 13:32:16,118 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133216.wav, taille: 78406 bytes
2025-06-20 13:32:16,644 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133216.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:32:18,500 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:32:18,502 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:32:20,101 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:32:20,102 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:32:20,104 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:32:20,109 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:32:20,125 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:32:20,134 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1414 request_id=req_1773dcf1c841f0f096f84969f2cf149d response_code=200
2025-06-20 13:32:20,246 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:32:20,246 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:32:20] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:32:21,136 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133221.wav, taille: 80339 bytes
2025-06-20 13:32:21,733 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133221.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:32:21,955 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:32:21,957 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1056 request_id=req_f6468978815c07335fe84c1a76865f9e response_code=200
2025-06-20 13:32:24,925 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:32:24,926 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:32:25,318 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:32:25,319 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:32:25,320 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:32:25,325 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:32:26,159 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133226.wav, taille: 80339 bytes
2025-06-20 13:32:26,307 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:32:26,352 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1165 request_id=req_26fd0b28fc1d0afa34e05839040d15d2 response_code=200
2025-06-20 13:32:26,480 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:32:26,496 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:32:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:32:27,167 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:32:27,181 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=896 request_id=req_c04248fedcface7d920ff9e49db85cd5 response_code=200
2025-06-20 13:32:27,497 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133226.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:32:30,118 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:32:30,118 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:32:30,977 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:32:30,977 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=517 request_id=req_b9afd487a823b23cfb9aa7c241c0d279 response_code=200
2025-06-20 13:32:31,006 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:32:31,011 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:32:31,016 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:32:31,023 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:32:31,101 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:32:31,108 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:32:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:32:31,143 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133231.wav, taille: 80339 bytes
2025-06-20 13:32:31,253 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133231.wav, taille: 1127 bytes
2025-06-20 13:32:31,415 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\signal\\_spectral_py.py', reloading
2025-06-20 13:32:31,657 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133231.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:32:31,726 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133231.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:32:33,261 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:32:43,488 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:32:43,501 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:32:43,676 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:32:43] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:32:44,027 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:32:44] "[35m[1mPOST /api/transcription/consolidate HTTP/1.1[0m" 500 -
2025-06-20 13:35:34,396 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:35:36,622 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:35:45,598 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:35:45,609 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:36:15,737 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:36:15,758 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:36:18,363 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:36:27,612 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:36:27,626 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:38:21,870 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:38:21,872 - werkzeug - INFO -  * Detected change in 'C:\\Users\\shaim\\OneDrive\\Desktop\\transcription\\interfaceweb\\backend\\transcription_service.py', reloading
2025-06-20 13:38:24,131 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2025-06-20 13:38:33,671 - werkzeug - WARNING -  * Debugger is active!
2025-06-20 13:38:33,683 - werkzeug - INFO -  * Debugger PIN: 429-800-626
2025-06-20 13:38:34,438 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:38:34] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:38:34,512 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:38:34] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:38:34,618 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:38:34] "GET /assets/script.js HTTP/1.1" 200 -
2025-06-20 13:38:35,065 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:38:35] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:39:15,501 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133915.wav, taille: 80339 bytes
2025-06-20 13:39:17,764 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1137)
           2	LOAD_FAST(arg=0, lineno=1140)
           4	LOAD_CONST(arg=1, lineno=1140)
           6	BINARY_SUBSCR(arg=None, lineno=1140)
           8	STORE_FAST(arg=3, lineno=1140)
          10	LOAD_FAST(arg=1, lineno=1141)
          12	UNARY_NEGATIVE(arg=None, lineno=1141)
          14	LOAD_FAST(arg=3, lineno=1141)
          16	DUP_TOP(arg=None, lineno=1141)
          18	ROT_THREE(arg=None, lineno=1141)
          20	COMPARE_OP(arg=1, lineno=1141)
          22	POP_JUMP_IF_FALSE(arg=32, lineno=1141)
          24	LOAD_FAST(arg=1, lineno=1141)
          26	COMPARE_OP(arg=1, lineno=1141)
          28	POP_JUMP_IF_FALSE(arg=40, lineno=1141)
          30	JUMP_FORWARD(arg=4, lineno=1141)
>         32	POP_TOP(arg=None, lineno=1141)
          34	JUMP_FORWARD(arg=4, lineno=1141)
>         36	LOAD_CONST(arg=1, lineno=1142)
          38	STORE_FAST(arg=3, lineno=1142)
>         40	LOAD_FAST(arg=0, lineno=1144)
          42	LOAD_CONST(arg=2, lineno=1144)
          44	BINARY_SUBSCR(arg=None, lineno=1144)
          46	STORE_FAST(arg=4, lineno=1144)
          48	LOAD_FAST(arg=1, lineno=1145)
          50	UNARY_NEGATIVE(arg=None, lineno=1145)
          52	LOAD_FAST(arg=4, lineno=1145)
          54	DUP_TOP(arg=None, lineno=1145)
          56	ROT_THREE(arg=None, lineno=1145)
          58	COMPARE_OP(arg=1, lineno=1145)
          60	POP_JUMP_IF_FALSE(arg=70, lineno=1145)
          62	LOAD_FAST(arg=1, lineno=1145)
          64	COMPARE_OP(arg=1, lineno=1145)
          66	POP_JUMP_IF_FALSE(arg=78, lineno=1145)
          68	JUMP_FORWARD(arg=4, lineno=1145)
>         70	POP_TOP(arg=None, lineno=1145)
          72	JUMP_FORWARD(arg=4, lineno=1145)
>         74	LOAD_CONST(arg=1, lineno=1146)
          76	STORE_FAST(arg=4, lineno=1146)
>         78	LOAD_FAST(arg=2, lineno=1148)
          80	POP_JUMP_IF_FALSE(arg=102, lineno=1148)
          82	LOAD_GLOBAL(arg=0, lineno=1149)
          84	LOAD_METHOD(arg=1, lineno=1149)
          86	LOAD_FAST(arg=3, lineno=1149)
          88	CALL_METHOD(arg=1, lineno=1149)
          90	LOAD_GLOBAL(arg=0, lineno=1149)
          92	LOAD_METHOD(arg=1, lineno=1149)
          94	LOAD_FAST(arg=4, lineno=1149)
          96	CALL_METHOD(arg=1, lineno=1149)
          98	COMPARE_OP(arg=3, lineno=1149)
         100	RETURN_VALUE(arg=None, lineno=1149)
>        102	LOAD_GLOBAL(arg=0, lineno=1151)
         104	LOAD_METHOD(arg=2, lineno=1151)
         106	LOAD_FAST(arg=3, lineno=1151)
         108	CALL_METHOD(arg=1, lineno=1151)
         110	LOAD_GLOBAL(arg=0, lineno=1151)
         112	LOAD_METHOD(arg=2, lineno=1151)
         114	LOAD_FAST(arg=4, lineno=1151)
         116	CALL_METHOD(arg=1, lineno=1151)
         118	COMPARE_OP(arg=3, lineno=1151)
         120	RETURN_VALUE(arg=None, lineno=1151)
         122	LOAD_CONST(arg=3, lineno=1151)
         124	RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:39:17,785 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:39:17,786 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:17,786 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:39:17,787 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1137)
2025-06-20 13:39:17,788 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:17,789 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1140)
2025-06-20 13:39:17,790 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:17,797 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1140)
2025-06-20 13:39:17,799 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:39:17,822 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1140)
2025-06-20 13:39:17,832 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:39:17,833 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=STORE_FAST(arg=3, lineno=1140)
2025-06-20 13:39:17,834 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:39:17,834 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:39:17,835 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:17,837 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=UNARY_NEGATIVE(arg=None, lineno=1141)
2025-06-20 13:39:17,840 - numba.core.byteflow - DEBUG - stack ['$threshold10.3']
2025-06-20 13:39:17,844 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=LOAD_FAST(arg=3, lineno=1141)
2025-06-20 13:39:17,848 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4']
2025-06-20 13:39:17,849 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=DUP_TOP(arg=None, lineno=1141)
2025-06-20 13:39:17,849 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5']
2025-06-20 13:39:17,850 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=ROT_THREE(arg=None, lineno=1141)
2025-06-20 13:39:17,851 - numba.core.byteflow - DEBUG - stack ['$12unary_negative.4', '$x014.5', '$16dup_top.6']
2025-06-20 13:39:17,851 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:39:17,852 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$12unary_negative.4', '$x014.5']
2025-06-20 13:39:17,852 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=POP_JUMP_IF_FALSE(arg=32, lineno=1141)
2025-06-20 13:39:17,853 - numba.core.byteflow - DEBUG - stack ['$16dup_top.6', '$20compare_op.7']
2025-06-20 13:39:17,854 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=24, stack=('$16dup_top.6',), blockstack=(), npush=0), Edge(pc=32, stack=('$16dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:39:17,854 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=24 nstack_initial=1), State(pc_initial=32 nstack_initial=1)])
2025-06-20 13:39:17,855 - numba.core.byteflow - DEBUG - stack: ['$phi24.0']
2025-06-20 13:39:17,856 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=24 nstack_initial=1)
2025-06-20 13:39:17,856 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_FAST(arg=1, lineno=1141)
2025-06-20 13:39:17,866 - numba.core.byteflow - DEBUG - stack ['$phi24.0']
2025-06-20 13:39:17,867 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=COMPARE_OP(arg=1, lineno=1141)
2025-06-20 13:39:17,868 - numba.core.byteflow - DEBUG - stack ['$phi24.0', '$threshold24.1']
2025-06-20 13:39:17,869 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=POP_JUMP_IF_FALSE(arg=40, lineno=1141)
2025-06-20 13:39:17,870 - numba.core.byteflow - DEBUG - stack ['$26compare_op.2']
2025-06-20 13:39:17,871 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=30, stack=(), blockstack=(), npush=0), Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:17,872 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=32 nstack_initial=1), State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:39:17,887 - numba.core.byteflow - DEBUG - stack: ['$phi32.0']
2025-06-20 13:39:17,888 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=32 nstack_initial=1)
2025-06-20 13:39:17,889 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=POP_TOP(arg=None, lineno=1141)
2025-06-20 13:39:17,889 - numba.core.byteflow - DEBUG - stack ['$phi32.0']
2025-06-20 13:39:17,898 - numba.core.byteflow - DEBUG - dispatch pc=34, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:39:17,899 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:17,899 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:17,901 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=30 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:39:17,905 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:17,905 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=30 nstack_initial=0)
2025-06-20 13:39:17,906 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=JUMP_FORWARD(arg=4, lineno=1141)
2025-06-20 13:39:17,906 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:17,914 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=36, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:17,916 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0)])
2025-06-20 13:39:17,918 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:17,918 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=40 nstack_initial=0)
2025-06-20 13:39:17,922 - numba.core.byteflow - DEBUG - dispatch pc=40, inst=LOAD_FAST(arg=0, lineno=1144)
2025-06-20 13:39:17,923 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:17,936 - numba.core.byteflow - DEBUG - dispatch pc=42, inst=LOAD_CONST(arg=2, lineno=1144)
2025-06-20 13:39:17,952 - numba.core.byteflow - DEBUG - stack ['$x40.0']
2025-06-20 13:39:17,953 - numba.core.byteflow - DEBUG - dispatch pc=44, inst=BINARY_SUBSCR(arg=None, lineno=1144)
2025-06-20 13:39:17,953 - numba.core.byteflow - DEBUG - stack ['$x40.0', '$const42.1']
2025-06-20 13:39:17,954 - numba.core.byteflow - DEBUG - dispatch pc=46, inst=STORE_FAST(arg=4, lineno=1144)
2025-06-20 13:39:17,955 - numba.core.byteflow - DEBUG - stack ['$44binary_subscr.2']
2025-06-20 13:39:17,956 - numba.core.byteflow - DEBUG - dispatch pc=48, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:39:17,957 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:17,964 - numba.core.byteflow - DEBUG - dispatch pc=50, inst=UNARY_NEGATIVE(arg=None, lineno=1145)
2025-06-20 13:39:17,965 - numba.core.byteflow - DEBUG - stack ['$threshold48.3']
2025-06-20 13:39:17,967 - numba.core.byteflow - DEBUG - dispatch pc=52, inst=LOAD_FAST(arg=4, lineno=1145)
2025-06-20 13:39:17,968 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4']
2025-06-20 13:39:17,968 - numba.core.byteflow - DEBUG - dispatch pc=54, inst=DUP_TOP(arg=None, lineno=1145)
2025-06-20 13:39:17,969 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5']
2025-06-20 13:39:17,969 - numba.core.byteflow - DEBUG - dispatch pc=56, inst=ROT_THREE(arg=None, lineno=1145)
2025-06-20 13:39:17,970 - numba.core.byteflow - DEBUG - stack ['$50unary_negative.4', '$x152.5', '$54dup_top.6']
2025-06-20 13:39:17,982 - numba.core.byteflow - DEBUG - dispatch pc=58, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:39:17,983 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$50unary_negative.4', '$x152.5']
2025-06-20 13:39:17,984 - numba.core.byteflow - DEBUG - dispatch pc=60, inst=POP_JUMP_IF_FALSE(arg=70, lineno=1145)
2025-06-20 13:39:17,985 - numba.core.byteflow - DEBUG - stack ['$54dup_top.6', '$58compare_op.7']
2025-06-20 13:39:17,986 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=62, stack=('$54dup_top.6',), blockstack=(), npush=0), Edge(pc=70, stack=('$54dup_top.6',), blockstack=(), npush=0)]
2025-06-20 13:39:17,987 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:39:17,988 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=36 nstack_initial=0), State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1)])
2025-06-20 13:39:17,988 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:17,989 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=36 nstack_initial=0)
2025-06-20 13:39:17,989 - numba.core.byteflow - DEBUG - dispatch pc=36, inst=LOAD_CONST(arg=1, lineno=1142)
2025-06-20 13:39:17,990 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:17,999 - numba.core.byteflow - DEBUG - dispatch pc=38, inst=STORE_FAST(arg=3, lineno=1142)
2025-06-20 13:39:18,000 - numba.core.byteflow - DEBUG - stack ['$const36.0']
2025-06-20 13:39:18,001 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=40, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:18,001 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=62 nstack_initial=1), State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0)])
2025-06-20 13:39:18,002 - numba.core.byteflow - DEBUG - stack: ['$phi62.0']
2025-06-20 13:39:18,004 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=62 nstack_initial=1)
2025-06-20 13:39:18,004 - numba.core.byteflow - DEBUG - dispatch pc=62, inst=LOAD_FAST(arg=1, lineno=1145)
2025-06-20 13:39:18,005 - numba.core.byteflow - DEBUG - stack ['$phi62.0']
2025-06-20 13:39:18,016 - numba.core.byteflow - DEBUG - dispatch pc=64, inst=COMPARE_OP(arg=1, lineno=1145)
2025-06-20 13:39:18,017 - numba.core.byteflow - DEBUG - stack ['$phi62.0', '$threshold62.1']
2025-06-20 13:39:18,018 - numba.core.byteflow - DEBUG - dispatch pc=66, inst=POP_JUMP_IF_FALSE(arg=78, lineno=1145)
2025-06-20 13:39:18,019 - numba.core.byteflow - DEBUG - stack ['$64compare_op.2']
2025-06-20 13:39:18,019 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=68, stack=(), blockstack=(), npush=0), Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:18,020 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=70 nstack_initial=1), State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:39:18,021 - numba.core.byteflow - DEBUG - stack: ['$phi70.0']
2025-06-20 13:39:18,021 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=70 nstack_initial=1)
2025-06-20 13:39:18,023 - numba.core.byteflow - DEBUG - dispatch pc=70, inst=POP_TOP(arg=None, lineno=1145)
2025-06-20 13:39:18,032 - numba.core.byteflow - DEBUG - stack ['$phi70.0']
2025-06-20 13:39:18,034 - numba.core.byteflow - DEBUG - dispatch pc=72, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 13:39:18,036 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:18,036 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:18,037 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=40 nstack_initial=0), State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:39:18,038 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=68 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:39:18,039 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:18,039 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=68 nstack_initial=0)
2025-06-20 13:39:18,040 - numba.core.byteflow - DEBUG - dispatch pc=68, inst=JUMP_FORWARD(arg=4, lineno=1145)
2025-06-20 13:39:18,047 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:18,049 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=74, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:18,049 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0)])
2025-06-20 13:39:18,050 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:18,051 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=78 nstack_initial=0)
2025-06-20 13:39:18,051 - numba.core.byteflow - DEBUG - dispatch pc=78, inst=LOAD_FAST(arg=2, lineno=1148)
2025-06-20 13:39:18,052 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:18,053 - numba.core.byteflow - DEBUG - dispatch pc=80, inst=POP_JUMP_IF_FALSE(arg=102, lineno=1148)
2025-06-20 13:39:18,055 - numba.core.byteflow - DEBUG - stack ['$zero_pos78.0']
2025-06-20 13:39:18,055 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=82, stack=(), blockstack=(), npush=0), Edge(pc=102, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:18,056 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0), State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 13:39:18,057 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=74 nstack_initial=0), State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0)])
2025-06-20 13:39:18,066 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:18,067 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=74 nstack_initial=0)
2025-06-20 13:39:18,067 - numba.core.byteflow - DEBUG - dispatch pc=74, inst=LOAD_CONST(arg=1, lineno=1146)
2025-06-20 13:39:18,068 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:18,069 - numba.core.byteflow - DEBUG - dispatch pc=76, inst=STORE_FAST(arg=4, lineno=1146)
2025-06-20 13:39:18,069 - numba.core.byteflow - DEBUG - stack ['$const74.0']
2025-06-20 13:39:18,070 - numba.core.byteflow - DEBUG - end state. edges=[Edge(pc=78, stack=(), blockstack=(), npush=0)]
2025-06-20 13:39:18,072 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=82 nstack_initial=0), State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:39:18,073 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:18,080 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=82 nstack_initial=0)
2025-06-20 13:39:18,081 - numba.core.byteflow - DEBUG - dispatch pc=82, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 13:39:18,082 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:18,082 - numba.core.byteflow - DEBUG - dispatch pc=84, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 13:39:18,084 - numba.core.byteflow - DEBUG - stack ['$82load_global.0']
2025-06-20 13:39:18,085 - numba.core.byteflow - DEBUG - dispatch pc=86, inst=LOAD_FAST(arg=3, lineno=1149)
2025-06-20 13:39:18,086 - numba.core.byteflow - DEBUG - stack ['$84load_method.1']
2025-06-20 13:39:18,088 - numba.core.byteflow - DEBUG - dispatch pc=88, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 13:39:18,088 - numba.core.byteflow - DEBUG - stack ['$84load_method.1', '$x086.2']
2025-06-20 13:39:18,089 - numba.core.byteflow - DEBUG - dispatch pc=90, inst=LOAD_GLOBAL(arg=0, lineno=1149)
2025-06-20 13:39:18,113 - numba.core.byteflow - DEBUG - stack ['$88call_method.3']
2025-06-20 13:39:18,117 - numba.core.byteflow - DEBUG - dispatch pc=92, inst=LOAD_METHOD(arg=1, lineno=1149)
2025-06-20 13:39:18,119 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$90load_global.4']
2025-06-20 13:39:18,119 - numba.core.byteflow - DEBUG - dispatch pc=94, inst=LOAD_FAST(arg=4, lineno=1149)
2025-06-20 13:39:18,120 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5']
2025-06-20 13:39:18,121 - numba.core.byteflow - DEBUG - dispatch pc=96, inst=CALL_METHOD(arg=1, lineno=1149)
2025-06-20 13:39:18,122 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$92load_method.5', '$x194.6']
2025-06-20 13:39:18,123 - numba.core.byteflow - DEBUG - dispatch pc=98, inst=COMPARE_OP(arg=3, lineno=1149)
2025-06-20 13:39:18,123 - numba.core.byteflow - DEBUG - stack ['$88call_method.3', '$96call_method.7']
2025-06-20 13:39:18,135 - numba.core.byteflow - DEBUG - dispatch pc=100, inst=RETURN_VALUE(arg=None, lineno=1149)
2025-06-20 13:39:18,136 - numba.core.byteflow - DEBUG - stack ['$98compare_op.8']
2025-06-20 13:39:18,138 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:39:18,138 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=102 nstack_initial=0), State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:39:18,140 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:18,147 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=102 nstack_initial=0)
2025-06-20 13:39:18,148 - numba.core.byteflow - DEBUG - dispatch pc=102, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 13:39:18,150 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:18,151 - numba.core.byteflow - DEBUG - dispatch pc=104, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 13:39:18,152 - numba.core.byteflow - DEBUG - stack ['$102load_global.0']
2025-06-20 13:39:18,153 - numba.core.byteflow - DEBUG - dispatch pc=106, inst=LOAD_FAST(arg=3, lineno=1151)
2025-06-20 13:39:18,166 - numba.core.byteflow - DEBUG - stack ['$104load_method.1']
2025-06-20 13:39:18,167 - numba.core.byteflow - DEBUG - dispatch pc=108, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 13:39:18,168 - numba.core.byteflow - DEBUG - stack ['$104load_method.1', '$x0106.2']
2025-06-20 13:39:18,168 - numba.core.byteflow - DEBUG - dispatch pc=110, inst=LOAD_GLOBAL(arg=0, lineno=1151)
2025-06-20 13:39:18,169 - numba.core.byteflow - DEBUG - stack ['$108call_method.3']
2025-06-20 13:39:18,172 - numba.core.byteflow - DEBUG - dispatch pc=112, inst=LOAD_METHOD(arg=2, lineno=1151)
2025-06-20 13:39:18,173 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$110load_global.4']
2025-06-20 13:39:18,173 - numba.core.byteflow - DEBUG - dispatch pc=114, inst=LOAD_FAST(arg=4, lineno=1151)
2025-06-20 13:39:18,181 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5']
2025-06-20 13:39:18,182 - numba.core.byteflow - DEBUG - dispatch pc=116, inst=CALL_METHOD(arg=1, lineno=1151)
2025-06-20 13:39:18,182 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$112load_method.5', '$x1114.6']
2025-06-20 13:39:18,183 - numba.core.byteflow - DEBUG - dispatch pc=118, inst=COMPARE_OP(arg=3, lineno=1151)
2025-06-20 13:39:18,183 - numba.core.byteflow - DEBUG - stack ['$108call_method.3', '$116call_method.7']
2025-06-20 13:39:18,184 - numba.core.byteflow - DEBUG - dispatch pc=120, inst=RETURN_VALUE(arg=None, lineno=1151)
2025-06-20 13:39:18,184 - numba.core.byteflow - DEBUG - stack ['$118compare_op.8']
2025-06-20 13:39:18,185 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:39:18,185 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=78 nstack_initial=0)])
2025-06-20 13:39:18,187 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:39:18,188 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>,
            {State(pc_initial=0 nstack_initial=0): set(),
             State(pc_initial=24 nstack_initial=1): {'$phi24.0'},
             State(pc_initial=30 nstack_initial=0): set(),
             State(pc_initial=32 nstack_initial=1): set(),
             State(pc_initial=36 nstack_initial=0): set(),
             State(pc_initial=40 nstack_initial=0): set(),
             State(pc_initial=62 nstack_initial=1): {'$phi62.0'},
             State(pc_initial=68 nstack_initial=0): set(),
             State(pc_initial=70 nstack_initial=1): set(),
             State(pc_initial=74 nstack_initial=0): set(),
             State(pc_initial=78 nstack_initial=0): set(),
             State(pc_initial=82 nstack_initial=0): set(),
             State(pc_initial=102 nstack_initial=0): set()})
2025-06-20 13:39:18,201 - numba.core.byteflow - DEBUG - defmap: {'$phi24.0': State(pc_initial=0 nstack_initial=0),
 '$phi32.0': State(pc_initial=0 nstack_initial=0),
 '$phi62.0': State(pc_initial=40 nstack_initial=0),
 '$phi70.0': State(pc_initial=40 nstack_initial=0)}
2025-06-20 13:39:18,202 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 13:39:18,205 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>,
            {'$phi24.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi32.0': {('$16dup_top.6',
                           State(pc_initial=0 nstack_initial=0))},
             '$phi62.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))},
             '$phi70.0': {('$54dup_top.6',
                           State(pc_initial=40 nstack_initial=0))}})
2025-06-20 13:39:18,218 - numba.core.byteflow - DEBUG - keep phismap: {'$phi24.0': {('$16dup_top.6', State(pc_initial=0 nstack_initial=0))},
 '$phi62.0': {('$54dup_top.6', State(pc_initial=40 nstack_initial=0))}}
2025-06-20 13:39:18,220 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>,
            {State(pc_initial=0 nstack_initial=0): {'$phi24.0': '$16dup_top.6'},
             State(pc_initial=40 nstack_initial=0): {'$phi62.0': '$54dup_top.6'}})
2025-06-20 13:39:18,228 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:39:18,232 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'value': '$6binary_subscr.2'}), (10, {'res': '$threshold10.3'}), (12, {'value': '$threshold10.3', 'res': '$12unary_negative.4'}), (14, {'res': '$x014.5'}), (16, {'orig': ['$x014.5'], 'duped': ['$16dup_top.6']}), (20, {'lhs': '$12unary_negative.4', 'rhs': '$x014.5', 'res': '$20compare_op.7'}), (22, {'pred': '$20compare_op.7'})), outgoing_phis={'$phi24.0': '$16dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={24: ('$16dup_top.6',), 32: ('$16dup_top.6',)})
2025-06-20 13:39:18,238 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=24 nstack_initial=1):
AdaptBlockInfo(insts=((24, {'res': '$threshold24.1'}), (26, {'lhs': '$phi24.0', 'rhs': '$threshold24.1', 'res': '$26compare_op.2'}), (28, {'pred': '$26compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={30: (), 40: ()})
2025-06-20 13:39:18,240 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=30 nstack_initial=0):
AdaptBlockInfo(insts=((30, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={36: ()})
2025-06-20 13:39:18,249 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=32 nstack_initial=1):
AdaptBlockInfo(insts=((34, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 13:39:18,250 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=36 nstack_initial=0):
AdaptBlockInfo(insts=((36, {'res': '$const36.0'}), (38, {'value': '$const36.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={40: ()})
2025-06-20 13:39:18,251 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=40 nstack_initial=0):
AdaptBlockInfo(insts=((40, {'res': '$x40.0'}), (42, {'res': '$const42.1'}), (44, {'index': '$const42.1', 'target': '$x40.0', 'res': '$44binary_subscr.2'}), (46, {'value': '$44binary_subscr.2'}), (48, {'res': '$threshold48.3'}), (50, {'value': '$threshold48.3', 'res': '$50unary_negative.4'}), (52, {'res': '$x152.5'}), (54, {'orig': ['$x152.5'], 'duped': ['$54dup_top.6']}), (58, {'lhs': '$50unary_negative.4', 'rhs': '$x152.5', 'res': '$58compare_op.7'}), (60, {'pred': '$58compare_op.7'})), outgoing_phis={'$phi62.0': '$54dup_top.6'}, blockstack=(), active_try_block=None, outgoing_edgepushed={62: ('$54dup_top.6',), 70: ('$54dup_top.6',)})
2025-06-20 13:39:18,253 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=62 nstack_initial=1):
AdaptBlockInfo(insts=((62, {'res': '$threshold62.1'}), (64, {'lhs': '$phi62.0', 'rhs': '$threshold62.1', 'res': '$64compare_op.2'}), (66, {'pred': '$64compare_op.2'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={68: (), 78: ()})
2025-06-20 13:39:18,261 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=68 nstack_initial=0):
AdaptBlockInfo(insts=((68, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={74: ()})
2025-06-20 13:39:18,269 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=70 nstack_initial=1):
AdaptBlockInfo(insts=((72, {}),), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 13:39:18,271 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=74 nstack_initial=0):
AdaptBlockInfo(insts=((74, {'res': '$const74.0'}), (76, {'value': '$const74.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={78: ()})
2025-06-20 13:39:18,272 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=78 nstack_initial=0):
AdaptBlockInfo(insts=((78, {'res': '$zero_pos78.0'}), (80, {'pred': '$zero_pos78.0'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={82: (), 102: ()})
2025-06-20 13:39:18,284 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=82 nstack_initial=0):
AdaptBlockInfo(insts=((82, {'res': '$82load_global.0'}), (84, {'item': '$82load_global.0', 'res': '$84load_method.1'}), (86, {'res': '$x086.2'}), (88, {'func': '$84load_method.1', 'args': ['$x086.2'], 'res': '$88call_method.3'}), (90, {'res': '$90load_global.4'}), (92, {'item': '$90load_global.4', 'res': '$92load_method.5'}), (94, {'res': '$x194.6'}), (96, {'func': '$92load_method.5', 'args': ['$x194.6'], 'res': '$96call_method.7'}), (98, {'lhs': '$88call_method.3', 'rhs': '$96call_method.7', 'res': '$98compare_op.8'}), (100, {'retval': '$98compare_op.8', 'castval': '$100return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:39:18,294 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=102 nstack_initial=0):
AdaptBlockInfo(insts=((102, {'res': '$102load_global.0'}), (104, {'item': '$102load_global.0', 'res': '$104load_method.1'}), (106, {'res': '$x0106.2'}), (108, {'func': '$104load_method.1', 'args': ['$x0106.2'], 'res': '$108call_method.3'}), (110, {'res': '$110load_global.4'}), (112, {'item': '$110load_global.4', 'res': '$112load_method.5'}), (114, {'res': '$x1114.6'}), (116, {'func': '$112load_method.5', 'args': ['$x1114.6'], 'res': '$116call_method.7'}), (118, {'lhs': '$108call_method.3', 'rhs': '$116call_method.7', 'res': '$118compare_op.8'}), (120, {'retval': '$118compare_op.8', 'castval': '$120return_value.9'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:39:18,333 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    threshold = arg(1, name=threshold)       ['threshold']
    zero_pos = arg(2, name=zero_pos)         ['zero_pos']
    $const4.1 = const(int, 0)                ['$const4.1']
    x0 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$const4.1', 'x', 'x0']
    $12unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$12unary_negative.4', 'threshold']
    $20compare_op.7 = $12unary_negative.4 <= x0 ['$12unary_negative.4', '$20compare_op.7', 'x0']
    bool22 = global(bool: <class 'bool'>)    ['bool22']
    $22pred = call bool22($20compare_op.7, func=bool22, args=(Var($20compare_op.7, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$20compare_op.7', '$22pred', 'bool22']
    $phi24.0 = x0                            ['$phi24.0', 'x0']
    branch $22pred, 24, 32                   ['$22pred']
label 24:
    $26compare_op.2 = $phi24.0 <= threshold  ['$26compare_op.2', '$phi24.0', 'threshold']
    bool28 = global(bool: <class 'bool'>)    ['bool28']
    $28pred = call bool28($26compare_op.2, func=bool28, args=(Var($26compare_op.2, audio.py:1141),), kws=(), vararg=None, varkwarg=None, target=None) ['$26compare_op.2', '$28pred', 'bool28']
    branch $28pred, 30, 40                   ['$28pred']
label 30:
    jump 36                                  []
label 32:
    jump 40                                  []
label 36:
    x0 = const(int, 0)                       ['x0']
    jump 40                                  []
label 40:
    $const42.1 = const(int, -1)              ['$const42.1']
    x1 = getitem(value=x, index=$const42.1, fn=<built-in function getitem>) ['$const42.1', 'x', 'x1']
    $50unary_negative.4 = unary(fn=<built-in function neg>, value=threshold) ['$50unary_negative.4', 'threshold']
    $58compare_op.7 = $50unary_negative.4 <= x1 ['$50unary_negative.4', '$58compare_op.7', 'x1']
    bool60 = global(bool: <class 'bool'>)    ['bool60']
    $60pred = call bool60($58compare_op.7, func=bool60, args=(Var($58compare_op.7, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$58compare_op.7', '$60pred', 'bool60']
    $phi62.0 = x1                            ['$phi62.0', 'x1']
    branch $60pred, 62, 70                   ['$60pred']
label 62:
    $64compare_op.2 = $phi62.0 <= threshold  ['$64compare_op.2', '$phi62.0', 'threshold']
    bool66 = global(bool: <class 'bool'>)    ['bool66']
    $66pred = call bool66($64compare_op.2, func=bool66, args=(Var($64compare_op.2, audio.py:1145),), kws=(), vararg=None, varkwarg=None, target=None) ['$64compare_op.2', '$66pred', 'bool66']
    branch $66pred, 68, 78                   ['$66pred']
label 68:
    jump 74                                  []
label 70:
    jump 78                                  []
label 74:
    x1 = const(int, 0)                       ['x1']
    jump 78                                  []
label 78:
    bool80 = global(bool: <class 'bool'>)    ['bool80']
    $80pred = call bool80(zero_pos, func=bool80, args=(Var(zero_pos, audio.py:1137),), kws=(), vararg=None, varkwarg=None, target=None) ['$80pred', 'bool80', 'zero_pos']
    branch $80pred, 82, 102                  ['$80pred']
label 82:
    $82load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$82load_global.0']
    $84load_method.1 = getattr(value=$82load_global.0, attr=signbit) ['$82load_global.0', '$84load_method.1']
    $88call_method.3 = call $84load_method.1(x0, func=$84load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$84load_method.1', '$88call_method.3', 'x0']
    $90load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$90load_global.4']
    $92load_method.5 = getattr(value=$90load_global.4, attr=signbit) ['$90load_global.4', '$92load_method.5']
    $96call_method.7 = call $92load_method.5(x1, func=$92load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$92load_method.5', '$96call_method.7', 'x1']
    $98compare_op.8 = $88call_method.3 != $96call_method.7 ['$88call_method.3', '$96call_method.7', '$98compare_op.8']
    $100return_value.9 = cast(value=$98compare_op.8) ['$100return_value.9', '$98compare_op.8']
    return $100return_value.9                ['$100return_value.9']
label 102:
    $102load_global.0 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$102load_global.0']
    $104load_method.1 = getattr(value=$102load_global.0, attr=sign) ['$102load_global.0', '$104load_method.1']
    $108call_method.3 = call $104load_method.1(x0, func=$104load_method.1, args=[Var(x0, audio.py:1140)], kws=(), vararg=None, varkwarg=None, target=None) ['$104load_method.1', '$108call_method.3', 'x0']
    $110load_global.4 = global(np: <module 'numpy' from 'C:\\Users\\shaim\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\__init__.py'>) ['$110load_global.4']
    $112load_method.5 = getattr(value=$110load_global.4, attr=sign) ['$110load_global.4', '$112load_method.5']
    $116call_method.7 = call $112load_method.5(x1, func=$112load_method.5, args=[Var(x1, audio.py:1144)], kws=(), vararg=None, varkwarg=None, target=None) ['$112load_method.5', '$116call_method.7', 'x1']
    $118compare_op.8 = $108call_method.3 != $116call_method.7 ['$108call_method.3', '$116call_method.7', '$118compare_op.8']
    $120return_value.9 = cast(value=$118compare_op.8) ['$118compare_op.8', '$120return_value.9']
    return $120return_value.9                ['$120return_value.9']

2025-06-20 13:39:19,759 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1023)
           2	LOAD_FAST(arg=0, lineno=1026)
           4	LOAD_CONST(arg=1, lineno=1026)
           6	BINARY_SUBSCR(arg=None, lineno=1026)
           8	LOAD_FAST(arg=0, lineno=1026)
          10	LOAD_CONST(arg=2, lineno=1026)
          12	BINARY_SUBSCR(arg=None, lineno=1026)
          14	COMPARE_OP(arg=4, lineno=1026)
          16	LOAD_FAST(arg=0, lineno=1026)
          18	LOAD_CONST(arg=1, lineno=1026)
          20	BINARY_SUBSCR(arg=None, lineno=1026)
          22	LOAD_FAST(arg=0, lineno=1026)
          24	LOAD_CONST(arg=3, lineno=1026)
          26	BINARY_SUBSCR(arg=None, lineno=1026)
          28	COMPARE_OP(arg=5, lineno=1026)
          30	BINARY_AND(arg=None, lineno=1026)
          32	RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 13:39:19,783 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:39:19,784 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:19,784 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:39:19,785 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1023)
2025-06-20 13:39:19,787 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:19,787 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:39:19,788 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:19,789 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 13:39:19,790 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:39:19,796 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:39:19,802 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:39:19,805 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:39:19,816 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:39:19,819 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1026)
2025-06-20 13:39:19,820 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 13:39:19,821 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:39:19,823 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 13:39:19,832 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=4, lineno=1026)
2025-06-20 13:39:19,833 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 13:39:19,835 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:39:19,836 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 13:39:19,837 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1026)
2025-06-20 13:39:19,839 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 13:39:19,844 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:39:19,848 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 13:39:19,849 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1026)
2025-06-20 13:39:19,849 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 13:39:19,850 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1026)
2025-06-20 13:39:19,850 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 13:39:19,851 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1026)
2025-06-20 13:39:19,851 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 13:39:19,852 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=5, lineno=1026)
2025-06-20 13:39:19,852 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 13:39:19,853 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1026)
2025-06-20 13:39:19,853 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 13:39:19,854 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1026)
2025-06-20 13:39:19,855 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 13:39:19,855 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:39:19,855 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:39:19,856 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 13:39:19,857 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 13:39:19,864 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:39:19,866 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:39:19,866 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 13:39:19,867 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 13:39:19,868 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:39:19,868 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:39:19,877 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 > $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 >= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 13:39:19,896 - numba.core.byteflow - DEBUG - bytecode dump:
>          0	NOP(arg=None, lineno=1029)
           2	LOAD_FAST(arg=0, lineno=1032)
           4	LOAD_CONST(arg=1, lineno=1032)
           6	BINARY_SUBSCR(arg=None, lineno=1032)
           8	LOAD_FAST(arg=0, lineno=1032)
          10	LOAD_CONST(arg=2, lineno=1032)
          12	BINARY_SUBSCR(arg=None, lineno=1032)
          14	COMPARE_OP(arg=0, lineno=1032)
          16	LOAD_FAST(arg=0, lineno=1032)
          18	LOAD_CONST(arg=1, lineno=1032)
          20	BINARY_SUBSCR(arg=None, lineno=1032)
          22	LOAD_FAST(arg=0, lineno=1032)
          24	LOAD_CONST(arg=3, lineno=1032)
          26	BINARY_SUBSCR(arg=None, lineno=1032)
          28	COMPARE_OP(arg=1, lineno=1032)
          30	BINARY_AND(arg=None, lineno=1032)
          32	RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 13:39:19,901 - numba.core.byteflow - DEBUG - pending: deque([State(pc_initial=0 nstack_initial=0)])
2025-06-20 13:39:19,904 - numba.core.byteflow - DEBUG - stack: []
2025-06-20 13:39:19,907 - numba.core.byteflow - DEBUG - state.pc_initial: State(pc_initial=0 nstack_initial=0)
2025-06-20 13:39:19,917 - numba.core.byteflow - DEBUG - dispatch pc=0, inst=NOP(arg=None, lineno=1029)
2025-06-20 13:39:19,918 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:19,919 - numba.core.byteflow - DEBUG - dispatch pc=2, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:39:19,920 - numba.core.byteflow - DEBUG - stack []
2025-06-20 13:39:19,920 - numba.core.byteflow - DEBUG - dispatch pc=4, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 13:39:19,921 - numba.core.byteflow - DEBUG - stack ['$x2.0']
2025-06-20 13:39:19,921 - numba.core.byteflow - DEBUG - dispatch pc=6, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:39:19,922 - numba.core.byteflow - DEBUG - stack ['$x2.0', '$const4.1']
2025-06-20 13:39:19,922 - numba.core.byteflow - DEBUG - dispatch pc=8, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:39:19,923 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2']
2025-06-20 13:39:19,932 - numba.core.byteflow - DEBUG - dispatch pc=10, inst=LOAD_CONST(arg=2, lineno=1032)
2025-06-20 13:39:19,933 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3']
2025-06-20 13:39:19,934 - numba.core.byteflow - DEBUG - dispatch pc=12, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:39:19,934 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$x8.3', '$const10.4']
2025-06-20 13:39:19,935 - numba.core.byteflow - DEBUG - dispatch pc=14, inst=COMPARE_OP(arg=0, lineno=1032)
2025-06-20 13:39:19,935 - numba.core.byteflow - DEBUG - stack ['$6binary_subscr.2', '$12binary_subscr.5']
2025-06-20 13:39:19,936 - numba.core.byteflow - DEBUG - dispatch pc=16, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:39:19,937 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6']
2025-06-20 13:39:19,938 - numba.core.byteflow - DEBUG - dispatch pc=18, inst=LOAD_CONST(arg=1, lineno=1032)
2025-06-20 13:39:19,940 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7']
2025-06-20 13:39:19,940 - numba.core.byteflow - DEBUG - dispatch pc=20, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:39:19,949 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$x16.7', '$const18.8']
2025-06-20 13:39:19,950 - numba.core.byteflow - DEBUG - dispatch pc=22, inst=LOAD_FAST(arg=0, lineno=1032)
2025-06-20 13:39:19,951 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9']
2025-06-20 13:39:19,951 - numba.core.byteflow - DEBUG - dispatch pc=24, inst=LOAD_CONST(arg=3, lineno=1032)
2025-06-20 13:39:19,952 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10']
2025-06-20 13:39:19,953 - numba.core.byteflow - DEBUG - dispatch pc=26, inst=BINARY_SUBSCR(arg=None, lineno=1032)
2025-06-20 13:39:19,953 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$x22.10', '$const24.11']
2025-06-20 13:39:19,955 - numba.core.byteflow - DEBUG - dispatch pc=28, inst=COMPARE_OP(arg=1, lineno=1032)
2025-06-20 13:39:19,956 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$20binary_subscr.9', '$26binary_subscr.12']
2025-06-20 13:39:19,962 - numba.core.byteflow - DEBUG - dispatch pc=30, inst=BINARY_AND(arg=None, lineno=1032)
2025-06-20 13:39:19,965 - numba.core.byteflow - DEBUG - stack ['$14compare_op.6', '$28compare_op.13']
2025-06-20 13:39:19,966 - numba.core.byteflow - DEBUG - dispatch pc=32, inst=RETURN_VALUE(arg=None, lineno=1032)
2025-06-20 13:39:19,967 - numba.core.byteflow - DEBUG - stack ['$30binary_and.14']
2025-06-20 13:39:19,968 - numba.core.byteflow - DEBUG - end state. edges=[]
2025-06-20 13:39:19,970 - numba.core.byteflow - DEBUG - -------------------------Prune PHIs-------------------------
2025-06-20 13:39:19,984 - numba.core.byteflow - DEBUG - Used_phis: defaultdict(<class 'set'>, {State(pc_initial=0 nstack_initial=0): set()})
2025-06-20 13:39:19,985 - numba.core.byteflow - DEBUG - defmap: {}
2025-06-20 13:39:19,987 - numba.core.byteflow - DEBUG - phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:39:19,988 - numba.core.byteflow - DEBUG - changing phismap: defaultdict(<class 'set'>, {})
2025-06-20 13:39:19,999 - numba.core.byteflow - DEBUG - keep phismap: {}
2025-06-20 13:39:20,000 - numba.core.byteflow - DEBUG - new_out: defaultdict(<class 'dict'>, {})
2025-06-20 13:39:20,001 - numba.core.byteflow - DEBUG - ----------------------DONE Prune PHIs-----------------------
2025-06-20 13:39:20,001 - numba.core.byteflow - DEBUG - block_infos State(pc_initial=0 nstack_initial=0):
AdaptBlockInfo(insts=((0, {}), (2, {'res': '$x2.0'}), (4, {'res': '$const4.1'}), (6, {'index': '$const4.1', 'target': '$x2.0', 'res': '$6binary_subscr.2'}), (8, {'res': '$x8.3'}), (10, {'res': '$const10.4'}), (12, {'index': '$const10.4', 'target': '$x8.3', 'res': '$12binary_subscr.5'}), (14, {'lhs': '$6binary_subscr.2', 'rhs': '$12binary_subscr.5', 'res': '$14compare_op.6'}), (16, {'res': '$x16.7'}), (18, {'res': '$const18.8'}), (20, {'index': '$const18.8', 'target': '$x16.7', 'res': '$20binary_subscr.9'}), (22, {'res': '$x22.10'}), (24, {'res': '$const24.11'}), (26, {'index': '$const24.11', 'target': '$x22.10', 'res': '$26binary_subscr.12'}), (28, {'lhs': '$20binary_subscr.9', 'rhs': '$26binary_subscr.12', 'res': '$28compare_op.13'}), (30, {'lhs': '$14compare_op.6', 'rhs': '$28compare_op.13', 'res': '$30binary_and.14'}), (32, {'retval': '$30binary_and.14', 'castval': '$32return_value.15'})), outgoing_phis={}, blockstack=(), active_try_block=None, outgoing_edgepushed={})
2025-06-20 13:39:20,012 - numba.core.interpreter - DEBUG - label 0:
    x = arg(0, name=x)                       ['x']
    $const4.1 = const(int, 0)                ['$const4.1']
    $6binary_subscr.2 = getitem(value=x, index=$const4.1, fn=<built-in function getitem>) ['$6binary_subscr.2', '$const4.1', 'x']
    $const10.4 = const(int, -1)              ['$const10.4']
    $12binary_subscr.5 = getitem(value=x, index=$const10.4, fn=<built-in function getitem>) ['$12binary_subscr.5', '$const10.4', 'x']
    $14compare_op.6 = $6binary_subscr.2 < $12binary_subscr.5 ['$12binary_subscr.5', '$14compare_op.6', '$6binary_subscr.2']
    $const18.8 = const(int, 0)               ['$const18.8']
    $20binary_subscr.9 = getitem(value=x, index=$const18.8, fn=<built-in function getitem>) ['$20binary_subscr.9', '$const18.8', 'x']
    $const24.11 = const(int, 1)              ['$const24.11']
    $26binary_subscr.12 = getitem(value=x, index=$const24.11, fn=<built-in function getitem>) ['$26binary_subscr.12', '$const24.11', 'x']
    $28compare_op.13 = $20binary_subscr.9 <= $26binary_subscr.12 ['$20binary_subscr.9', '$26binary_subscr.12', '$28compare_op.13']
    $30binary_and.14 = $14compare_op.6 & $28compare_op.13 ['$14compare_op.6', '$28compare_op.13', '$30binary_and.14']
    $32return_value.15 = cast(value=$30binary_and.14) ['$30binary_and.14', '$32return_value.15']
    return $32return_value.15                ['$32return_value.15']

2025-06-20 13:39:20,193 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133920.wav, taille: 80339 bytes
2025-06-20 13:39:21,794 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133915.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:39:21,854 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133920.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:39:25,537 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133925.wav, taille: 80339 bytes
2025-06-20 13:39:25,554 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:39:25,555 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u062f\\u064a\\u0627\\u0644\\u064a \\u0643\\u0627\\u0646 \\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0643\\u064a\\u0636\\u0631\\u0646\\u064a \\u0648\\u0643\\u0627\\u0646\\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621\\"\\n            Transcription Fran\\u00e7aise: \\"au Canada chez toi\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:39:25,571 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:39:25,581 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:39:26,188 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133925.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:39:26,305 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:39:26,308 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=390 request_id=req_3f8e18dfd0cae93358d26b6794a92454 response_code=200
2025-06-20 13:39:26,387 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:39:30,178 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:39:30,179 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"meilleur jeu de simana\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:39:30,181 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:39:30,187 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:39:30,502 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133930.wav, taille: 80339 bytes
2025-06-20 13:39:31,106 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133930.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:39:31,215 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:39:31,272 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:39:31,273 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=380 request_id=req_79f5678dd85b05d14f35ef9fb9cb2dc8 response_code=200
2025-06-20 13:39:31,285 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646 \\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0634\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin J5\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:39:31,322 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:39:31,423 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:39:31,430 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:39:32,175 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:39:32,179 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=330 request_id=req_58131dbf145c5332962b20b3071067f4 response_code=200
2025-06-20 13:39:32,252 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:32] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:39:35,295 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:39:35,296 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0648\\u0627\\u0644\\u0627 \\u062a\\u062d\\u0633\\u0646\\u062a \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0645\\u0632\\u064a\\u0627\\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"o\\u00f9 est la Tasmanie\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:39:35,298 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:39:35,302 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:39:35,510 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133935.wav, taille: 80339 bytes
2025-06-20 13:39:36,029 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:39:36,038 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=317 request_id=req_a70238bd5f5471c92944f0f8f0ffa5a1 response_code=200
2025-06-20 13:39:36,183 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:36] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:39:36,335 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133935.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:39:40,518 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133940.wav, taille: 80339 bytes
2025-06-20 13:39:40,754 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:39:40,754 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:39:40,759 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:39:40,769 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:39:41,086 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133940.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:39:43,476 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:39:43,480 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:39:43,481 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:39:43,485 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:39:43,504 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133943.wav, taille: 47495 bytes
2025-06-20 13:39:43,935 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133943.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:39:44,251 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:44] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:39:44,356 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:44] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:39:44,458 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:44] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:39:44,567 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:44] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:39:45,155 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:45] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:39:45,417 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:39:45,420 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1493 request_id=req_573ec06b39aeef596cd11e46ceda26a6 response_code=200
2025-06-20 13:39:46,565 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:39:46,576 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:39:46,580 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:39:46,587 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:39:47,008 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 33
2025-06-20 13:39:47,024 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=5394 request_id=req_cc43f766045acc281b411f6cfb347487 response_code=200
2025-06-20 13:39:47,978 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:39:47,978 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=930 request_id=req_a43fe1d38edba78c821299e69cd3d665 response_code=200
2025-06-20 13:39:47,999 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:39:47,999 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:39:49,483 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 17
2025-06-20 13:39:49,486 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1280 request_id=req_1c2317f2f5d967f0facda089f279faea response_code=200
2025-06-20 13:39:49,589 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:39:49,592 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:39:50,346 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:39:50,346 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u060c \\u0644\\u0627 \\u0644\\u0627 \\u0644\\u0627 \\u0644\\u0627\\"\\n            Transcription Fran\\u00e7aise: \\"non non non non non non non\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:39:50,785 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:39:50,786 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:39:50,787 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:39:50,796 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=179 request_id=req_fdb348650a759e8024da18f3caee6d45 response_code=200
2025-06-20 13:39:50,835 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:50] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:39:52,184 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:39:52,186 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1032 request_id=req_080c1f98725b1abd768f9ce16fdd5c92 response_code=200
2025-06-20 13:39:52,301 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:39:52,303 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:39:52] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:39:56,975 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_133956.wav, taille: 80339 bytes
2025-06-20 13:39:57,515 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_133956.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:00,477 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:40:00,478 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0639\\u0646\\u062f \\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0634\\u0627\\u0641 \\u0627\\u0644\\u0639\\u0646\\u0642 \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin J5\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:40:00,484 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:00,493 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:01,326 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:40:01,329 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=450 request_id=req_0877460c593e05132c905276654e4ae0 response_code=200
2025-06-20 13:40:01,393 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:01] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:02,274 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134002.wav, taille: 80339 bytes
2025-06-20 13:40:02,835 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134002.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:06,976 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134006.wav, taille: 80339 bytes
2025-06-20 13:40:07,282 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:40:07,284 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0648\\u0627\\u0644\\u0642\\u0647 \\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0643\\u0627\\u0646 \\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0628\\u0627\\u0634 \\u064a\\u062d\\"\\n            Transcription Fran\\u00e7aise: \\"Carrefour au Canada chez toi ma ch\\u00e9rie\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:40:07,288 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:07,300 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:07,533 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134006.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:08,710 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:40:08,714 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=502 request_id=req_1672cf8c4f46d8d6e20510fd9f35ec13 response_code=200
2025-06-20 13:40:08,783 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:08] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:10,362 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:40:10,363 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0645\\u0634\\u0627\\u0647\\u064a\\u0631 \\u0627\\u0644\\u0642\\u064a\\u062d\\"\\n            Transcription Fran\\u00e7aise: \\"oh ma ch\\u00e9rie\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:40:10,366 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:10,374 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:11,324 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:40:11,332 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=202 request_id=req_439fd746c7eb48d35314b8b433c03318 response_code=200
2025-06-20 13:40:11,382 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:11] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:12,285 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134012.wav, taille: 80339 bytes
2025-06-20 13:40:12,816 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134012.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:16,977 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134016.wav, taille: 80339 bytes
2025-06-20 13:40:16,986 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:40:17,013 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u062a\\u062d\\u0633\\u0646\\u062a \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0645\\u0632\\u064a\\u0627\\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"merci maintenant\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:40:17,089 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:17,134 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:17,779 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134016.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:17,823 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:40:17,835 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=316 request_id=req_f8daa743ab716c296119feae424e6814 response_code=200
2025-06-20 13:40:17,920 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:17] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:21,386 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:40:21,387 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u063a\\u0627\\u062f\\u064a \\u063a\\u0627\\u062f\\u064a \\u0646\\u062d\\u062a\\u0627\\u062c\\u0648\\u0627 \\u0646\\u062f\\u064a\\u0631\\u0648\\u0627 \\u0627\\u0648\\u0628\\u064a\\u0631\\u0627\\u0633\\u064a\\u0648\\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"op\\u00e9ration\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:40:21,396 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:21,408 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:22,109 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:40:22,111 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=257 request_id=req_e3869781e3e8a3ffba1763a7702ff946 response_code=200
2025-06-20 13:40:22,173 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:22] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:22,292 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134022.wav, taille: 80339 bytes
2025-06-20 13:40:22,967 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134022.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:26,231 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:26,233 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:40:26,234 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:26,250 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:27,285 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134027.wav, taille: 80339 bytes
2025-06-20 13:40:27,829 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134027.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:28,286 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:40:28,289 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1098 request_id=req_553ddb041108e4c67da6391af42496b6 response_code=200
2025-06-20 13:40:30,236 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:30,236 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:40:30,242 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:30,248 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:30,404 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:30,416 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:40:31,131 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:40:31,134 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=396 request_id=req_d4d60a31bdc9a4b35059138b0a02fe29 response_code=200
2025-06-20 13:40:32,294 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134032.wav, taille: 80339 bytes
2025-06-20 13:40:32,906 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134032.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:33,441 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:33,444 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:40:34,478 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:40:34,480 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=851 request_id=req_ca8e7c1e685743517f7c6ce2926a5399 response_code=200
2025-06-20 13:40:34,596 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:40:34,598 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:34] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:35,369 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:35,370 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:40:35,381 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:35,391 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:36,914 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:40:36,916 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=625 request_id=req_927ffff217f732b7242160a7c946435a response_code=200
2025-06-20 13:40:37,290 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134037.wav, taille: 80339 bytes
2025-06-20 13:40:37,882 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134037.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:38,719 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134038.wav, taille: 22379 bytes
2025-06-20 13:40:39,098 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134038.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:40:39,397 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:39,398 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:40:39,552 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:39] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:40:39,708 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:39] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:40:39,863 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:40:39,864 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Consolide ces segments de transcription en respectant leur ordre et leur sens original :\\n\\n            Segment 1: \\"J\'\\u00e9tais chez le m\\u00e9decin la semaine derni\\u00e8re, il a examin\\u00e9 mon cou.\\"\\nSegment 2: \\"\\"Oh ma ch\\u00e9rie\\"\\"\\nSegment 3: \\"Nous devons faire une op\\u00e9ration.\\"\\n\\n            Instructions :\\n            1. GARDE l\'ordre chronologique des segments\\n            2. FUSIONNE les segments en gardant leur sens original\\n            3. \\u00c9VITE les r\\u00e9p\\u00e9titions tout en conservant les informations importantes\\n            4. N\'AJOUTE aucune information qui n\'est pas dans les segments\\n            5. RETOURNE le texte consolid\\u00e9 en paragraphes si n\\u00e9cessaire\\n\\n            Format : Texte fluide en fran\\u00e7ais, respectant la chronologie des segments."}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 13:40:39,869 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:39,880 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:40,036 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:40:40,038 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Consolide ces segments de transcription en respectant leur ordre et leur sens original :\\n\\n            Segment 1: \\"J\'\\u00e9tais chez le m\\u00e9decin la semaine derni\\u00e8re, il a examin\\u00e9 mon cou.\\"\\nSegment 2: \\"\\"Oh ma ch\\u00e9rie\\"\\"\\nSegment 3: \\"Nous devons faire une op\\u00e9ration.\\"\\n\\n            Instructions :\\n            1. GARDE l\'ordre chronologique des segments\\n            2. FUSIONNE les segments en gardant leur sens original\\n            3. \\u00c9VITE les r\\u00e9p\\u00e9titions tout en conservant les informations importantes\\n            4. N\'AJOUTE aucune information qui n\'est pas dans les segments\\n            5. RETOURNE le texte consolid\\u00e9 en paragraphes si n\\u00e9cessaire\\n\\n            Format : Texte fluide en fran\\u00e7ais, respectant la chronologie des segments."}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 13:40:40,052 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:40,061 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:40,654 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:40:40,655 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=750 request_id=req_556f103f4300898c4bd00306865f9981 response_code=200
2025-06-20 13:40:40,763 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:40:40,765 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:40] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:40,992 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:40:40,995 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=632 request_id=req_159bdb741b5051244ea48664fdd68233 response_code=200
2025-06-20 13:40:40,996 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:40] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:40:41,070 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:41,078 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:40:41,080 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:41,086 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:41,169 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:40:41,172 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=754 request_id=req_6da06172962a490c6dfd1a3a1aef13c9 response_code=200
2025-06-20 13:40:41,174 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:41] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:40:41,563 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:41,563 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:40:41,565 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:40:41,568 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:40:42,461 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:40:42,463 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=643 request_id=req_d036a3f6865b6833ef4a9ed42051c962 response_code=200
2025-06-20 13:40:43,373 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:40:43,382 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=630 request_id=req_5fbfe47ea35623c59442216ec6c702ef response_code=200
2025-06-20 13:40:45,139 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:45,144 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:40:45,723 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:40:45,724 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:40:47,267 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:40:47,269 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:40:47,271 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:40:47,314 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:47,333 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:40:47,339 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:40:47] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:41:21,567 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:41:21] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:41:21,727 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:41:21] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:41:21,728 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:41:21] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:41:22,265 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:41:22] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:41:35,983 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134135.wav, taille: 80339 bytes
2025-06-20 13:41:36,562 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134135.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:41:40,667 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134140.wav, taille: 80339 bytes
2025-06-20 13:41:41,326 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134140.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:41:42,655 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:41:42,656 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0639\\u0646\\u062f \\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647 \\u0634\\u0627\\u0641 \\u0627\\u0644\\u0639\\u0646\\u0642 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0644\\u0642\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:41:42,660 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:41:42,665 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:41:43,316 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:41:43,320 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=305 request_id=req_ca21838a058a30faf4f132efd60c3dc6 response_code=200
2025-06-20 13:41:43,386 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:41:43] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:41:45,979 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134145.wav, taille: 80339 bytes
2025-06-20 13:41:46,493 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134145.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:41:49,296 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:41:49,298 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:41:49,299 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:41:49,308 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:41:50,655 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:41:50,660 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0642\\u0627\\u0644 \\u0644\\u064a \\u0631\\u062c\\u0639 \\u0639\\u0646\\u062f\\u0647 \\u0647\\u0630\\u0647 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u064a\\u0634\\u0648\\u0641 \\u0648\\u0627\\u0634\\"\\n            Transcription Fran\\u00e7aise: \\"et chauffage\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:41:50,668 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:41:50,686 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:41:50,976 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134150.wav, taille: 80339 bytes
2025-06-20 13:41:51,261 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:41:51,264 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=274 request_id=req_c61510cd29e4c8a79b07d350ea17d75a response_code=200
2025-06-20 13:41:51,328 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:41:51] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:41:51,594 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134150.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:41:52,885 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:41:52,888 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=3111 request_id=req_058a8ad8a6e0aa341278ff9de196069e response_code=200
2025-06-20 13:41:53,062 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:41:53] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:41:55,975 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134155.wav, taille: 80339 bytes
2025-06-20 13:41:56,105 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:41:56,113 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:41:56,115 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:41:56,123 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:41:56,609 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134155.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:41:57,183 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:41:57,191 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=598 request_id=req_df918367448b57dfbdf980a93c63ff7e response_code=200
2025-06-20 13:41:59,179 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:41:59,180 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:41:59,181 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:41:59,193 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:41:59,622 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:41:59,643 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0625\\u0630\\u0627 \\u0644\\u0645 \\u062a\\u0646\\u062c\\u062d \\u0627\\u0644\\u0648\\u0638\\u064a\\u0641\\u0629 \\u060c \\u0633\\u062a\\u062d\\u062a\\u0627\\u062c \\u0625\\u0644\\u0649 \\u0639\\u0645\\u0644\\u064a\\u0629 \\u0627\\u0644\\u062a\\u0639\\u0628\\u064a\\u0631\\"\\n            Transcription Fran\\u00e7aise: \\"op\\u00e9ration\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:42:00,123 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:42:00,127 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=284 request_id=req_a36b1649b8aa6711b5a1a5682bc796c4 response_code=200
2025-06-20 13:42:00,181 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:00] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:42:00,980 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134200.wav, taille: 80339 bytes
2025-06-20 13:42:01,589 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134200.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:42:01,854 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:42:01,856 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2127 request_id=req_98e375c4beda166dde0de5dbec3ba71b response_code=200
2025-06-20 13:42:03,945 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:03,949 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:42:04,977 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:04,979 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:42:04,980 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:42:04,994 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:42:04,995 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:42:04,998 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=762 request_id=req_21b75e2fad99cb7fad570e5ea3269807 response_code=200
2025-06-20 13:42:05,111 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:42:05,121 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:05] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:42:06,004 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134205.wav, taille: 80339 bytes
2025-06-20 13:42:06,542 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:42:06,546 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1018 request_id=req_d7a841eebeaecd2b853b74609512bc1e response_code=200
2025-06-20 13:42:06,816 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134205.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:42:08,814 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:08,815 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:42:09,260 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:09,261 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:42:09,262 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:42:09,266 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:42:10,194 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:42:10,196 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=421 request_id=req_06b100254114357d554ea705b0585eb0 response_code=200
2025-06-20 13:42:10,455 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 28
2025-06-20 13:42:10,456 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1179 request_id=req_91846d2d219bed528bf5d576062a5e10 response_code=200
2025-06-20 13:42:10,566 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:42:10,570 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:10] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:42:10,990 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134210.wav, taille: 80339 bytes
2025-06-20 13:42:11,725 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134210.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:42:12,578 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:12,579 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:42:13,695 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:42:13,698 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=834 request_id=req_d523981e6341e1c362e47faf06146aa1 response_code=200
2025-06-20 13:42:13,813 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:42:13,820 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:13] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:42:14,030 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:14,031 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:42:14,043 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:42:14,060 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:42:14,915 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134214.wav, taille: 62951 bytes
2025-06-20 13:42:15,447 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134214.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:42:15,595 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:15] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:42:15,597 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:42:15,611 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=534 request_id=req_be7331c511cbf290b81b8b86442df8b9 response_code=200
2025-06-20 13:42:15,905 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:15] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:42:15,909 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:42:15,910 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Consolide ces segments de transcription en respectant leur ordre et leur sens original :\\n\\n            Segment 1: \\"\\u0641\\u064a \\u0631\\u0642\\u064a\\u062d \\u0648\\u0627\\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0628\\u0627\\u0634 \\u064a\\u062d\\u064a\\u062f \\u0627\\u0644\\u0642\\u064a\\u062d\\"\\nSegment 2: \\"Si la fonction ne r\\u00e9ussit pas, une op\\u00e9ration d\'expression sera n\\u00e9cessaire.\\"\\n\\n            Instructions :\\n            1. GARDE l\'ordre chronologique des segments\\n            2. FUSIONNE les segments en gardant leur sens original\\n            3. \\u00c9VITE les r\\u00e9p\\u00e9titions tout en conservant les informations importantes\\n            4. N\'AJOUTE aucune information qui n\'est pas dans les segments\\n            5. RETOURNE le texte consolid\\u00e9 en paragraphes si n\\u00e9cessaire\\n\\n            Format : Texte fluide en fran\\u00e7ais, respectant la chronologie des segments."}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 13:42:15,915 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:42:15,921 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:42:16,233 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:42:16,236 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Consolide ces segments de transcription en respectant leur ordre et leur sens original :\\n\\n            Segment 1: \\"\\u0641\\u064a \\u0631\\u0642\\u064a\\u062d \\u0648\\u0627\\u0639\\u0637\\u0627\\u0646\\u064a \\u0634\\u064a \\u062f\\u0648\\u0627\\u0621 \\u0628\\u0627\\u0634 \\u064a\\u062d\\u064a\\u062f \\u0627\\u0644\\u0642\\u064a\\u062d\\"\\nSegment 2: \\"Si la fonction ne r\\u00e9ussit pas, une op\\u00e9ration d\'expression sera n\\u00e9cessaire.\\"\\n\\n            Instructions :\\n            1. GARDE l\'ordre chronologique des segments\\n            2. FUSIONNE les segments en gardant leur sens original\\n            3. \\u00c9VITE les r\\u00e9p\\u00e9titions tout en conservant les informations importantes\\n            4. N\'AJOUTE aucune information qui n\'est pas dans les segments\\n            5. RETOURNE le texte consolid\\u00e9 en paragraphes si n\\u00e9cessaire\\n\\n            Format : Texte fluide en fran\\u00e7ais, respectant la chronologie des segments."}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 13:42:16,343 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:42:16,525 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:42:17,212 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:42:17,215 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=990 request_id=req_67424b165bd7098f06b08e36f54cd932 response_code=200
2025-06-20 13:42:17,217 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:17] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:42:17,903 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:42:17,905 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=682 request_id=req_744e3e103a9b420ad509e1bf73018e8d response_code=200
2025-06-20 13:42:17,906 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:17] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:42:18,047 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:18,048 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:42:18,050 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:42:18,059 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:42:18,142 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:18,143 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:42:19,266 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:42:19,268 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=607 request_id=req_4a4250ce3824922a3d039b291d37ad06 response_code=200
2025-06-20 13:42:19,678 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:42:19,681 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=644 request_id=req_dc240a1cc64ef1e1638e5676a8033d27 response_code=200
2025-06-20 13:42:19,793 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:42:19,795 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:19] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:42:21,913 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:42:21,915 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:42:24,003 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:42:24,005 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1623 request_id=req_98d19b3e522ef5ea3b0403c4a27e9f74 response_code=200
2025-06-20 13:42:24,110 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:42:24,113 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:42:24] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:43:11,145 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:11] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:43:11,334 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:11] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:43:11,353 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:11] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:43:11,865 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:11] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:43:20,057 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134320.wav, taille: 80339 bytes
2025-06-20 13:43:20,642 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134320.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:43:23,221 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:43:23,222 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646 \\u062c\\u064a\\u062a \\u0639\\u0646\\u062f \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u0627\\u0644\\u0641\\u0627\\u064a\\u062a\\u0647\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:43:23,233 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:43:23,255 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:43:23,836 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:43:23,839 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=293 request_id=req_deac6662a93263c9a252868940db39d7 response_code=200
2025-06-20 13:43:23,878 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:23] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:43:25,412 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134325.wav, taille: 80339 bytes
2025-06-20 13:43:26,268 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134325.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:43:29,821 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:43:29,822 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u062f\\u064a\\u0627\\u0644\\u064a \\u0627\\u0644\\u0642\\u0644\\u0639\\u0646\\u0642 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0645\\u0646\\u0641\\u0648\\u062e \\u0648\\u0641\\u064a \\u0627\\u0644\\u0642\\u064a\\u062d \\u0648\\u0627\\u0639\\"\\n            Transcription Fran\\u00e7aise: \\"WAT\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:43:29,827 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:43:29,844 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:43:30,063 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134330.wav, taille: 80339 bytes
2025-06-20 13:43:30,599 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134330.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:43:30,739 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:43:30,742 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=224 request_id=req_ed9255f505ef79e4b88c40ec7d534bd7 response_code=200
2025-06-20 13:43:30,816 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:30] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:43:33,966 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:43:33,967 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0646\\u0634\\u0648\\u0641 \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u0643 \\u0645\\u0646 \\u0647\\u0646\\u0627 \\u0627\\u0644\\u0633\\"\\n            Transcription Fran\\u00e7aise: \\"Google\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:43:33,969 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:43:33,975 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:43:34,887 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:43:34,890 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=355 request_id=req_35fb9270ebc19d2046ae0c0f6fdff1a8 response_code=200
2025-06-20 13:43:35,009 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:35] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:43:35,390 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134335.wav, taille: 80339 bytes
2025-06-20 13:43:35,921 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134335.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:43:40,063 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134340.wav, taille: 80339 bytes
2025-06-20 13:43:40,698 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134340.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:43:41,523 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:43:41,524 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u062a\\u062d\\u0633\\u0646\\u0627\\u062a \\u0645\\u0632\\u064a\\u0627\\u0646 \\u0645\\u0627 \\u062a\\u062d\\u0633\\u0646\\u0627\\u0634 \\u0627\\u064a \\u062e\\u0635\\u0646\\u0627 \\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"tunisienne\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:43:41,527 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:43:41,535 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:43:42,746 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:43:42,752 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=412 request_id=req_74cca62ddc16aa613b5f9361ce3bbd1d response_code=200
2025-06-20 13:43:42,809 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:42] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:43:43,468 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:43:43,470 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0648\\u0628\\u0631\\u0627\\u0633\\u064a\\u0648\\u0646 \\u0636\\u0631\\u0648\\u0631\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"op\\u00e9ration\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:43:43,484 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:43:43,493 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:43:44,084 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:43:44,087 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=209 request_id=req_a6a24917115ce7b2d94c0dfd9a9ae5e4 response_code=200
2025-06-20 13:43:44,165 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:44] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:43:45,374 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134345.wav, taille: 80339 bytes
2025-06-20 13:43:46,007 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134345.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:43:48,915 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:43:48,924 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:43:48,925 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:43:48,942 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:43:50,068 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134350.wav, taille: 80339 bytes
2025-06-20 13:43:50,666 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134350.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:43:50,922 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:43:50,943 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1261 request_id=req_3cb1c6f91f97343f0efcb5b7f6833918 response_code=200
2025-06-20 13:43:52,972 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:43:52,973 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:43:52,974 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:43:52,988 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:43:54,067 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:43:54,068 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:43:54,538 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:43:54,541 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=411 request_id=req_993b95a2ffc08be7a6846aac2826cb09 response_code=200
2025-06-20 13:43:55,355 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:43:55,359 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=984 request_id=req_8f3ce737de837b09400d539da64a3cfe response_code=200
2025-06-20 13:43:55,376 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134355.wav, taille: 80339 bytes
2025-06-20 13:43:55,483 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:43:55,490 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:55] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:43:55,992 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134355.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:43:57,108 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:43:57,110 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:43:57,893 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:43:57,901 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=511 request_id=req_3fa6de6785d7f1dfc6b7fa9f9f0a78b3 response_code=200
2025-06-20 13:43:58,016 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:43:58,019 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:58] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:43:58,652 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:43:58,653 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:43:58,654 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:43:58,657 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:43:59,881 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:59] "[36mGET / HTTP/1.1[0m" 304 -
2025-06-20 13:43:59,994 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:59] "[36mGET /assets/style.css HTTP/1.1[0m" 304 -
2025-06-20 13:43:59,998 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:43:59] "[36mGET /assets/script.js HTTP/1.1[0m" 304 -
2025-06-20 13:44:00,475 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:44:00,481 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=915 request_id=req_7f566db9700539edcf171df164e50a03 response_code=200
2025-06-20 13:44:00,542 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:00] "GET /api/debug/test-transcription HTTP/1.1" 200 -
2025-06-20 13:44:03,381 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:03,382 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:44:04,650 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:44:04,652 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1002 request_id=req_470e0b319cedf1d2c2fa41081f2ed724 response_code=200
2025-06-20 13:44:04,768 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:44:04,771 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:04] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:44:09,748 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134409.wav, taille: 80339 bytes
2025-06-20 13:44:10,300 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134409.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:44:13,542 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:44:13,544 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0633\\u0644\\u0627\\u0645 \\u0627\\u0646\\u0627 \\u0643\\u0646\\u062a \\u0643\\u0627\\u0646 \\u0634\\u0627\\u0641 \\u0645\\u0639\\u064a \\u0627\\u0644\\u0637\\u0628\\u064a\\u0628 \\u0627\\u0644\\u062d\\u0627\\u062f\\u062b \\u062f\\u064a\\u0627\\u0644\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"salam Anakin Cagnes-sur-Mer\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:44:13,554 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:13,557 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:14,597 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:44:14,605 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=231 request_id=req_ef20bb1b7ded9c72c8fc920036452f3d response_code=200
2025-06-20 13:44:14,689 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:14] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:44:15,100 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134415.wav, taille: 80339 bytes
2025-06-20 13:44:15,624 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134415.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:44:19,749 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134419.wav, taille: 80339 bytes
2025-06-20 13:44:20,324 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134419.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:44:22,406 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:22,407 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:44:22,408 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:22,419 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:25,050 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:44:25,132 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0627\\u0644\\u0633\\u064a\\u0645\\u0627\\u0646\\u0647 \\u064a\\u0634\\u0648\\u0641 \\u064a\\u0634\\u0648\\u0641 \\u0627\\u0630\\u0627 \\u062a\\u062d\\u0633\\u0646\\u062a \\u0627\\u0644\\u062d\\u0627\\u0644\\u0647 \\u062f\\u064a\\u0627\\u0644\\u064a \\u0645\\u0632\\u064a\\u0627\\u0646\\"\\n            Transcription Fran\\u00e7aise: \\"Maxime\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:44:25,291 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134425.wav, taille: 80339 bytes
2025-06-20 13:44:25,337 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:44:25,343 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:25,408 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1593 request_id=req_5ad6134134842d88173e4533c37bbb61 response_code=200
2025-06-20 13:44:25,415 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:25,963 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:25] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:44:26,373 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:44:26,376 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=289 request_id=req_61a21b98c6a772b2fa9f3fc043e6c2f6 response_code=200
2025-06-20 13:44:26,576 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:26] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:44:26,648 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134425.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:44:30,058 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134430.wav, taille: 80339 bytes
2025-06-20 13:44:30,583 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134430.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:44:30,795 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:44:30,797 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Tu es un expert en transcription m\\u00e9dicale marocaine.\\n            Fusionne ces deux transcriptions en une phrase coh\\u00e9rente en fran\\u00e7ais d\'une consultation m\\u00e9dicale :\\n\\n            Transcription Darija: \\"\\u0645\\u0627 \\u062a\\u062d\\u0633\\u0646\\u0627\\u062a \\u0648\\u0627\\u0634 \\u062e\\u0635\\u0646\\u0627 \\u0646\\u062f\\u064a\\u0631\\u0648\\u0627 \\u0627\\u0648\\u0628\\u064a\\u0631\\u0627\\u0633\\u064a\\u0648\\u0646 \\u0636\\u0631\\u0648\\u0631\\u064a\\"\\n            Transcription Fran\\u00e7aise: \\"op\\u00e9ration\\"\\n\\n            Instructions :\\n            - Compare les deux transcriptions et choisis la plus claire et coh\\u00e9rente\\n            - Si la transcription fran\\u00e7aise ne correspond pas au contexte de la darija, ignore-la\\n            - Formule une phrase simple et naturelle en fran\\u00e7ais en respectant le sens original\\n            - Ne pas ajouter de termes ou d\'interpr\\u00e9tations qui ne sont pas dans les transcriptions\\n            - Retourne une cha\\u00eene vide si aucune des transcriptions n\'est claire ou coh\\u00e9rente\\n\\n            Important : Utilise uniquement les mots et le sens pr\\u00e9sents dans les transcriptions, sans ajout."}], "temperature": 0.3, "max_tokens": 500}' message='Post details'
2025-06-20 13:44:30,803 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:30,811 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:31,573 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:44:31,580 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=362 request_id=req_b42c38891cf16f63ef700df1fd1daabf response_code=200
2025-06-20 13:44:31,612 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:31] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:44:33,130 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:33,133 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:44:33,134 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:33,140 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:34,448 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:44:34,451 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=478 request_id=req_58a420cad5023981a56245d90f5352d4 response_code=200
2025-06-20 13:44:35,060 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134435.wav, taille: 80339 bytes
2025-06-20 13:44:35,717 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134435.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:44:37,015 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:37,017 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:44:38,620 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:38,622 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:44:38,623 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:38,635 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:39,391 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:44:39,395 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=2173 request_id=req_727c67107b453046e0ee98e384add375 response_code=200
2025-06-20 13:44:39,503 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:44:39,506 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:39] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:44:40,042 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134440.wav, taille: 80339 bytes
2025-06-20 13:44:40,712 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:44:40,715 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=708 request_id=req_1e5f8b499d3fcd5ef7180ffc389811b4 response_code=200
2025-06-20 13:44:40,717 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134440.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:44:43,436 - app - INFO - Fichier sauvegardé: uploads\audio_20250620_134443.wav, taille: 54257 bytes
2025-06-20 13:44:43,899 - pydub.converter - DEBUG - subprocess.call(['ffmpeg', '-y', '-i', 'uploads\\audio_20250620_134443.wav', '-acodec', 'pcm_s32le', '-vn', '-f', 'wav', '-'])
2025-06-20 13:44:44,156 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:44,170 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:44:44,184 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:44,185 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:44:44,186 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:44,202 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:44,420 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:44] "OPTIONS /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:44:44,747 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-06-20 13:44:44,748 - openai - DEBUG - api_version=None data='{"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "\\n            Consolide ces segments de transcription en respectant leur ordre et leur sens original :\\n\\n            Segment 1: \\"J\'ai consult\\u00e9 un m\\u00e9decin pour mon accident.\\"\\nSegment 2: \\"Il est n\\u00e9cessaire de faire une op\\u00e9ration.\\"\\n\\n            Instructions :\\n            1. GARDE l\'ordre chronologique des segments\\n            2. FUSIONNE les segments en gardant leur sens original\\n            3. \\u00c9VITE les r\\u00e9p\\u00e9titions tout en conservant les informations importantes\\n            4. N\'AJOUTE aucune information qui n\'est pas dans les segments\\n            5. RETOURNE le texte consolid\\u00e9 en paragraphes si n\\u00e9cessaire\\n\\n            Format : Texte fluide en fran\\u00e7ais, respectant la chronologie des segments."}], "temperature": 0.3, "max_tokens": 2000}' message='Post details'
2025-06-20 13:44:44,751 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:44,755 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:45,723 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-06-20 13:44:45,735 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=300 request_id=req_2a7a7cbe32691376c38cbb1bd0e2a328 response_code=200
2025-06-20 13:44:45,738 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:45] "POST /api/transcription/consolidate HTTP/1.1" 200 -
2025-06-20 13:44:45,893 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:44:45,898 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=697 request_id=req_a5f555665b4a51c0b3ac00104d38fc4d response_code=200
2025-06-20 13:44:46,385 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 11
2025-06-20 13:44:46,388 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1255 request_id=req_040adf376800086d3574ad7a32206339 response_code=200
2025-06-20 13:44:46,507 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:44:46,510 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:46] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:44:46,958 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:46,966 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'ar'}" message='Post details'
2025-06-20 13:44:46,968 - urllib3.util.retry - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-06-20 13:44:46,974 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-06-20 13:44:48,165 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:48,167 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:44:49,021 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 43
2025-06-20 13:44:49,025 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=1040 request_id=req_5c148a8dbc022167eef67de923d7e7f8 response_code=200
2025-06-20 13:44:49,400 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:44:49,402 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=939 request_id=req_743ea7d67111a786a38f97315470ab38 response_code=200
2025-06-20 13:44:49,515 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:44:49,518 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:49] "POST /api/transcribe/process HTTP/1.1" 200 -
2025-06-20 13:44:51,248 - openai - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/audio/transcriptions
2025-06-20 13:44:51,254 - openai - DEBUG - api_version=None data="{'model': 'whisper-1', 'language': 'fr'}" message='Post details'
2025-06-20 13:44:52,115 - urllib3.connectionpool - DEBUG - https://api.openai.com:443 "POST /v1/audio/transcriptions HTTP/1.1" 200 None
2025-06-20 13:44:52,117 - openai - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/audio/transcriptions processing_ms=618 request_id=req_c6081b0590afaa185fe1baee385a2a7a response_code=200
2025-06-20 13:44:52,228 - app - DEBUG - Résultat transcription: {'darija': '', 'french': '', 'fused': ''}
2025-06-20 13:44:52,232 - werkzeug - INFO - 127.0.0.1 - - [20/Jun/2025 13:44:52] "POST /api/transcribe/process HTTP/1.1" 200 -
